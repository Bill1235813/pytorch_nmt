Such succession disputes become even more acute when there are multiple marriages and multiple sets of competing children.
Until the eruption of the current scandal, the youngest of Murdoch’s three children from his second marriage, James, was generally believed to stand the greatest chance of succeeding his father.
The complexities of modern marriage patterns make family life much more fraught, especially when phenomenal power and huge sums of money are involved.
All three of Murdoch’s marriages have produced children, though those from his current relationship are too young to be considered potential corporate successors.
In addition, succession planning can become complicated by the emergence of “substitute children” from the company’s management.
Rebekah Brooks, the editor of The News of the World at the beginning of the phone-hacking scandal, and subsequently the chief executive of News International, Murdoch’s British subsidiary, played precisely such a role.
The disintegration of the business empire is then accompanied and amplified by bitter disputes between the children and the substitute children.
Indeed, the crisis of the Murdoch family’s business empire is neither unique nor unprecedented.
In the first half of the 1990’s, many observers of the alleged Asian economic miracle emphasized trust and families’ capacity to cooperate with political authorities in order to realize long-term growth plans.
After the 1997-1998 Asia crisis, and as authoritarian regimes in South Korea and Indonesia disintegrated, these relationships were suddenly interpreted as corrupt, and the counter-view – that “crony capitalism” had become entrenched in these countries – soon prevailed.
The Arab Spring has been in large part a movement against corrupt family capitalism, embodied not only in ruling families like the Ben Alis, the Mubaraks, and the Assads, but also in the large family business empires that depended on and supported them.
As a result of globalization, large family firms could increase their size and their geographic range.
But globalization also increases the chances of backlashes that focus on the vulnerabilities, weaknesses, and mistakes of big family firms.
They are vulnerable to an Arab Spring (and a British summer) – and maybe to a US autumn that will focus not just on the Murdochs’ business, but also on its interplay with politics.
All Man’s Land
NEW DELHI – Ernest Hemingway’s collection of stories, Men without Women, examines tense gender relationships.
In a particularly poignant story, a young man convinces his partner to have an abortion, viewing their unborn child as a hindrance to the status quo.
Frustrated, the woman gives in.
That story, published more than 80 years ago, remains relevant today in India, where female fetuses face severe risks.
According to the 2011 census, the sex ratio of the country’s children has dipped from 927 females per 1000 males to 914, a 60-year low.
Ratios in the northern states are particularly alarming: only Himachal Pradesh now has a ratio of girls to boys above 900.
Despite being illegal, ultrasound sex-determination tests are being used across India to identify for abortion extraordinary numbers of healthy female fetuses.
But there are serious concerns about legal operations, too.
Genitoplasty – a sex-change operation on newborn girls – is a mushrooming, and deeply disturbing, business in India.
There’s only one word for it: gendercide.
Left unchecked, it will leave India’s next generation of men with a severe shortage of women.
Indian couples have a strong cultural preference, bordering on obsession, for sons over daughters – despite the strides in education and employment that women have made over the last few decades.
Education and wealth have nothing to do with it – in fact, some of the worst-affected areas are in India’s wealthiest cities.
However discomfiting a possibility, the real culprit might be Indian culture and tradition itself.
The expenses and pressure of the dowry system, and the fact that, in most joint families, only sons inherit property and wealth, contribute to this favoritism.
Perhaps just as important is that sons typically live with their parents even after they are married, and assume responsibility for parents in their old age.
Daughters, who live with their in-laws after they marry, are viewed as amanat – someone else’s property.
In short, sons represent income and daughters an expense.
In the old days, when families typically had 5-10 children, this didn’t matter so much.
The number of sons and daughters often evened out.
But, for today’s smaller families, whether the children are two boys or two girls influences everything from financial planning to preparations for old age.
Many have argued that Indian women should stand up to their families and refuse to abort their daughters.
But Indian women want male children just as much.
Unlike Hemingway’s character, they are often more than willing to abort a girl and try for a boy.
The novelist Salman Rushdie once put the question to supporters of abortion rights: “What should be done when a woman uses her power over her own body to discriminate against female fetuses?”
This raises other questions concerning the consequences of a large shortage of girls.
Will women be valued and treasured?
Or will the oversupply of men result in more bride trafficking, sexual violence, and female suicides?
Niall Ferguson, the British historian, cites scholars who attribute Japan’s imperial expansion after 1914 to a male youth bulge, and who link the rise of Islamist extremism to an Islamic youth bulge.
“Maybe the coming generation of Asian men without women will find harmless outlets for their inevitable frustrations, like team sports or video games.
But I doubt it,” he writes.
He warns us not to be surprised if, in the coming generation, “shrill nationalism is replaced by macho militarism or even imperialism.”
Unfortunately, there is no instant solution.
Saving our girls will require radically altering some of Indian society’s family arrangements, traditions, and attitudes.
And there is no easy way to accomplish this.
Legislation alone won’t help, for tradition is a law unto itself.
Hindu religious law, for example, allows a woman to claim an equal share in her parents’ wealth, but few exercise this right.
Culturally, she feels that she does not have an equal claim on her father’s property.
Nonetheless, India does need new laws – direct and enforceable – that clamp down on the cultural practices that underpin destructive traditions.
For example, India could enforce a ceiling on wedding expenditure – typically a father’s biggest expense associated with his daughter.
Constrained from spending on the wedding, he would compensate her differently – perhaps with a larger inheritance.
Gradually, this would become the norm, and tradition would adjust accordingly.
(Interestingly, the state of Kerala, whose people adhere to matrilineal inheritance, has among the most equal sex ratios and literacy rates in India.)
A more radical measure, which some have advocated, would be direction intervene, with the state providing benefits for families with more girls.
Perhaps the authorities could also penalize families with boys, at least temporarily.
India imagines herself as a woman – Bharat Mata, or Mother India.
The irony is that, unless far-reaching changes are made soon, Mother India could eventually be the only woman left in the country.
All Quiet on the Burundi Front?
Like its neighbors, Congo and Rwanda, Burundi is a war-torn land.
Its troubles have not riveted world attention in recent years, probably because Burundi's rebels failed to plumb the depths of savagery seen in Rwanda and Congo.
But, unlike its neighbors, this year can mark a turning point for Burundi.
Thanks to agreements between the rebels and the government that Nelson Mandela and South African Vice President Jacob Zuma helped broker, Burundi can now either turn decisively away from civil strife, or risk a return to the machete politics that have mauled Africa's Great Lakes region for a decade.
Since its independence from Belgium in 1962, Burundi has suffered five episodes of what amounts to the same civil war.
About 600,000 people have been killed and hundreds of thousands made into refugees.
Many portray this war as the result of hatred between the majority Hutu and the minority Tutsi.
But this does not explain why these groups supposedly hate each other so much.
Burundi's cultural and linguistic homogeneity, rare in Africa, belies the simplistic view that the Hutu and Tutsi fight because they are so different.
Indeed, most countries are far more heterogeneous than Burundi but have never fallen into ethnic war.
To understand the dynamics of conflict in Burundi, we need to examine three root causes.
The first such cause is the legacy of colonization.
In the 1920's and 1930's, the Belgian authorities enacted policies that defined the population along ethnic lines and favored the Tutsi in a deliberate - and successful - effort to divide society and fan resentment among Hutu leaders.
Second, the bloody 1959 revolution in Rwanda, a country mirroring Burundi's ethnic and social structure, induced Burundi's Tutsi to cling even more tightly to power.
At the same time, Burundi's Hutu saw Rwanda as a role model and believed their ethnic majority should guarantee them de facto control of the country.
Third, successive governments widened the ethnic divide through catastrophically predatory governance.
A tiny elite of Tutsi from the southern province of Bururi controlled all institutions, exploiting them to the fullest.
The army brutally suppressed any opposition to Bururi rule.
No surprise, then, that millions of Burundians felt alienated, and that many resorted to violence.
In October 1993, the killing by members of the army of Melchior Ndadaye, the first civilian, Hutu, non-Bururi, and democratically elected president provoked a bloody reaction by the Hutu.
Presidential assassinations do not necessarily lead to civil wars, but in Burundi, a large-scale massacre of Tutsi civilians by Hutu immediately followed the coup attempt.
Fearing retribution by the Tutsi-dominated army, large numbers of Hutu fled the country while armed rebels engaged the army.
For the first time, the army failed to crush the rebellion.
As a result, the Tutsi-dominated government entered into negotiations with Hutu leaders, which led to the signing of a political accord in August 2000.
But the accord had a major flaw: the absence of a cease-fire.
Violence only receded in 2003, when the main rebel group, the
These breakthroughs came about thanks to the dedicated mediation of Mandela and Zuma.
The presidents of Uganda and Tanzania, and the international community in general, also exerted leverage.
(Burundi is an aid-dependent country, so donors have considerable sway in influencing its rulers' behavior.)
The question now is whether each party will honor its commitments.
What guarantees exist that the rebel groups will fully demobilize?
Why should the rebels believe that the government will honor its commitments once they no longer represent a threat?
Neither party, it seems, can commit credibly to peace.
Burundi's donors need to join hands with African leaders to make certain that the agreements are implemented.
Everyone agrees that recent pledges of a $1 billion in aid are a sign that donors are ready to show Burundians that peace has a dividend.
But aid will help build peace only if it is carefully used.
It must be distributed to the needy rather than favoring the elite - a tendency established in the past.
Yet it would be dangerous to redress past imbalances solely at the expense of traditional beneficiaries, especially because they remain powerful enough to derail the peace process.
It is encouraging to note that Burundi's leaders have so far managed to integrate leaders from the opposition and rebel groups into the country's political and military institutions without dismissing incumbents.
The danger is that applying this approach rigorously will invariably result in a bloated civil service and army.
But while downsizing government may be fashionable in the West, now is not the time for slimming down Burundi's state sector.
For once, over employment is politically justified.
The international community must understand that the political benefits of not alienating the old elite while offering new opportunities to traditionally excluded groups outweigh the financial cost.
Burundi will need even deeper pockets from its donors to transform today's political overtures into sustainable peace.
All Stimulus Roads Lead to China
BEIJING – Now that the “green shoots” of recovery have withered, the debate over fiscal stimulus is back with a vengeance.
In the United States, those who argue for another stimulus package observe that it was always wishful thinking to believe that a $787 billion package could offset a $3 trillion fall in private spending.
But unemployment has risen even faster and further than expected.
Combine this with the continued fall in housing prices, and it is understandable that consumer spending remains depressed.
The banks, having been recapitalized only to the extent necessary to keep them afloat, still have weak balance sheets.
Their consequent reluctance to lend constrains investment.
Meanwhile, state governments, seeing revenues fall as a result of lower taxable incomes last year, are cutting back like mad.
If there was a case for additional stimulus back in February, that case is even stronger now.
But the case against additional stimulus is also strong.
The US federal deficit is an alarming 12% of GDP, and public debt as a share of national income is already projected to double, to 80% of GDP.
The idea that the US can grow out of its debt burden, as did Finland and Sweden following their financial crises in the 1990’s, seems unrealistic.
Given all this, more deficit spending will only stoke fears of higher future taxes and inflation.
It will encourage the reemergence of global imbalances.
And it will not reassure consumers or investors.
It is possible to argue the economics both ways, but the politics all point in one direction.
The US Congress lacks the stomach for another stimulus package.
It has already faced intense criticism for its failure to get the country’s fiscal house in order.
The slowness with which the first stimulus has been rolled out, and the fact that it will take even more time for its full effects to be felt, provides more fodder for the chattering classes.
Disappointment over the effects of the TARP has already destroyed popular – and Congressional – support for more public money to recapitalize the banks.
So, even those who find the economic logic of arguments for fiscal activism compelling must acknowledge that the politics are not supportive.
A second stimulus simply is not in the cards.
If there is going to be more aggregate demand, it can come from only one place.
That place is not Europe or Japan, where debts are even higher than in the US – and the demographic preconditions for servicing them less favorable.
Rather, it is emerging markets like China.
The problem is that China has already done a lot to stimulate domestic demand, both through government spending and by directing its banks to lend.
As a result, its stock market is frothy, and it is experiencing an alarming property boom.
Through May, property prices were up 18% year on year.
Understandably, Chinese officials worry about bubble trouble.
The obvious way to square this circle is to spend more on imports.
China can purchase more industrial machinery, transport equipment, and steelmaking material, which are among its leading imports from the US.
Directing spending toward imports of capital equipment would avoid overheating China’s own markets, boost the economy’s productive capacity (and thus its ability to grow in the future), and support demand for US, European, and Japanese products just when such support is needed most.
This strategy is not without risks.
Allowing the renminbi to appreciate as a way of encouraging imports may also discourage exports, the traditional motor of Chinese growth.
And lowering administrative barriers to imports might redirect more spending toward foreign goods than the authorities intend.
But these are risks worth taking if China is serious about assuming a global leadership role.
The question is what China will get in return.
And the answer brings us back, full circle, to where we started, namely to US fiscal policy.
China is worried that its more than $1 trillion investment in US Treasury securities will not hold its value.
It wants reassurance that the US will stand behind its debts.
It therefore wants to see a credible program for balancing the US budget once the recession ends.
And, tough talk notwithstanding, the Obama administration has yet to offer a credible roadmap for fiscal consolidation.
Doing so would reassure American taxpayers worried about current deficits.
Just as importantly, it would reassure Chinese policymakers.
We live in a multipolar world where neither the US nor China is large enough to exercise global economic leadership on its own.
For China, leadership means assuming additional risks.
But for this to be tolerable, the US needs to relieve China of existing risks.
Only by working together can the two countries lead the world economy out of its current doldrums.
All the Queen’s Children
NEW YORK – Does monarchy – constitutional monarchy, that is, not the despotic kind – have any redeeming features left?
The arguments against maintaining kings and queens are mostly quite rational.
It is unreasonable in this democratic age to pay special deference to people solely on the basis of their birth.
Are we really supposed to admire and love modern monarchies, such as the British House of Windsor, even more so today, just because some new princess has been plucked from the middle class?
Monarchy has an infantilizing effect.
Witness how otherwise sensible adults are reduced to nervously grinning sycophants when they are granted the privilege of touching an extended royal hand.
At great monarchical displays, such as the royal wedding in London, millions become enthralled by child-like dreams of a “fairy-tale” marriage.
The mystique of immense wealth, noble birth, and great exclusivity is further sustained by the global mass media that promote these rituals.
Now, one might argue that the dignified pomp of Queen Elizabeth II is preferable to the tawdry grandiosity of Silvio Berlusconi, Madonna, or Cristiano Ronaldo.
In fact, the British monarchy, especially, has been reinventing itself by adopting many of the most vulgar features of modern showbiz or sports celebrity.
And the worlds of royalty and popular fame often overlap.
For example, David Beckham and his ex-pop-star wife Victoria, live out their own dream of royalty, aping some of its gaudiest aspects.
They also happened to be among the favored guests at the latest royal wedding.
Similarly, while Britain has many outstanding musicians, the favorite of the royal court is Elton John.
Infantile or not, there is a common human craving for taking vicarious pleasure in the lives of kings, queens, and other shining stars.
To call these people’s ostentatious displays of extravagance wasteful is to miss the point: a world of glittering dreams that must remain entirely beyond our grasp is precisely what many people want to see.
But there is another, darker side to this craving, which is the wish to see idols dragged through the mud in vicious gossip magazines, divorce courts, and so on.
This is the vengeful side of our fawning, as though the humiliation of worshipping idols must be balanced by our delight in their downfall.
Indeed, to subject people who are born into royal families, or people who marry into them, to lives in a fishbowl, where they are on constant display, like actors and actresses in a continuous soap opera, where human relations are distorted and stunted by absurd rules of protocol, is a terrible form of cruelty.
The current Japanese empress and her daughter-in-law, both from non-aristocratic families, have had nervous breakdowns as a result.
Likewise, movie stars often fall victim to alcohol, drugs, and breakdowns, but at least they have chosen the lives they live.
Kings and queens, on the whole, have not.
Prince Charles might have been far happier as a gardener, but this was never an option.
One thing to be said for monarchs is that they provide people with a sense of continuity, which can be useful in times of crisis or radical change.
The King of Spain provided stability and continuity after the end of Franco’s dictatorship.
During World War II, European monarchs kept a sense of hope and unity alive among their subjects under Nazi occupation.
But there is something else, too.
Monarchies are often popular with minorities.
Jews were among the most loyal subjects of the Austro-Hungarian Emperor.
Franz Joseph I stood up for his Jewish subjects when they were threatened by German anti-Semites.
To him, Jews, Germans, Czechs, or Hungarians were all his subjects, wherever they lived, from the smallest Galician shtetl to the grand capitals of Budapest or Vienna.
This offered some protection to minorities at a time of rising ethnic nationalism.
In this sense, monarchy is a little like Islam, or the Catholic Church: all believers are supposed to be equal in the eyes of God, or the Pope, or the Emperor – hence the appeal to the poor and the marginalized.
This might explain some right-wing populists’ animus against monarchy.
The Dutch populist leader Geert Wilders, for example, has denounced Queen Beatrix on several occasions as a leftist, elitist, and multiculturalist.
Like the new wave of populists worldwide, Wilders promises to take his country back for his followers, to stop immigration (especially of Muslims), and to make the Netherlands Dutch again, whatever that means.
Beatrix, like Franz Joseph, refuses to make ethnic or religious distinctions between her subjects.
That is what she means when she preaches tolerance and mutual understanding.
To Wilders and his supporters, this is a sign of her molly-coddling of aliens, of appeasing Muslims.
To them, the queen seems almost anti-Dutch.
To be sure, like all European royal families, the origins of the Dutch royal family are decidedly mixed.
The emergence of kings and queens as specifically national figureheads is a relatively recent historical development.
Empires contained many nations, after all.
Queen Victoria, mostly of German blood, did not regard herself as a monarch of Britons alone, but of Indians, Malays, and many other peoples, too.
This aristocratic tradition of standing above the narrow strains of ethnic nationalism may be the best argument to hang on to royalty a little longer.
Now that many European nations have become increasingly mixed in terms of ethnicity and culture, the only way forward is to learn to live together.
If monarchs can teach their subjects to do so, then let us give at least one cheer for the remaining kings and queens.
Alpine Schadenfreude
Not surprisingly, the atmosphere at this year’s World Economic Forum was grim.
Those who think that globalization, technology, and the market economy will solve the world’s problems seemed subdued.
Most chastened of all were the bankers.
Against the backdrop of the sub-prime crisis, the disasters at many financial institutions, and the weakening of the stock market, these “masters of the universe” seemed less omniscient than they did a short while ago.
And it was not just the bankers who were in the Davos doghouse this year, but also their regulators – the central bankers.
Anyone who goes to international conferences is used to hearing Americans lecture everyone else about transparency.
There was still some of that at Davos.
I heard the usual suspects – including a former treasury secretary who had been particularly vociferous in such admonishments during the East Asia crisis – bang on about the need for transparency at sovereign wealth funds (though not at American or European hedge funds).
But this time, developing countries could not resist commenting on the hypocrisy of it all.  There was even a touch of schadenfreude in the air about the problems the United States is having right now – though it was moderated, of course, by worries about the downturn’s impact on their own economies.
Had America really told others to bring in American banks to teach them about how to run their business?
Had America really boasted about its superior risk management systems, going so far as to develop a new regulatory system (called Basle II)?
Basle II is dead – at least until memories of the current disaster fade.
Bankers – and the rating agencies – believed in financial alchemy.
They thought that financial innovations could somehow turn bad mortgages into good securities, meriting AAA ratings.
But one lesson of modern finance theory is that, in well functioning financial markets, repackaging risks should not make much difference.
If we know the price of cream and the price of skim milk, we can figure out the price of milk with 1% cream, 2% cream, or 4% cream.
There might be some money in repackaging, but not the billions that banks made by slicing and dicing sub-prime mortgages into packages whose value was much greater than their contents.
It seemed too good to be true – and it was.
Worse, banks failed to understand the first principle of risk management: diversification only works when risks are not correlated, and macro-shocks (such as those that affect housing prices or borrowers’ ability to repay) affect the probability of default for all mortgages.
I argued at Davos that central bankers also got it wrong by misjudging the threat of a downturn and failing to provide sufficient regulation.
They waited too long to take action.
Because it normally takes a year or more for the full effects of monetary policy to be felt, central banks need to act preemptively, not reactively.
Worse, the US Federal Reserve and its previous chairman, Alan Greenspan, may have helped create the problem, encouraging households to take on risky variable-rate mortgages by reassuring those who worried about a housing bubble that there was at most a little “froth” in the market.
Normally, a Davos audience would rally to the support of the central bankers.
This time, a vote at the end of the session supported my view by a margin of three to one.
Even the plea of one of central banker that “no one could have predicted the problems” moved few in the audience – perhaps because several people sitting there had, like me, explicitly warned about the impending problem in previous years.
The only thing we got wrong was how bad banks’ lending practices were, how non-transparent banks really were, and how inadequate their risk management systems were.
It was interesting to see the different cultural attitudes to the crisis on display.
In Japan, the CEO of a major bank would have apologized to his employees and his country, and would have refused his pension and bonus so that those who suffered as a result of corporate failures could share the money.
He would have resigned.
In America, the only questions are whether a board will force a CEO to leave and, if so, how big his severance package will be.
When I asked one CEO whether there was any discussion of returning their bonuses, the response was not just no, but an aggressive defense of the bonus system.
This is the third US crisis in the past 20 years, after the Savings &amp; Loan crisis of 1989 and the Enron/WorldCom crisis in 2002.
Deregulation has not worked.
Unfettered markets may produce big bonuses for CEO’s, but they do not lead, as if by an invisible hand, to societal well-being.
Until we achieve a better balance between markets and government, the world will continue to pay a high price.
Alternatives to Alternative Energy
VIRGINIA BEACH – The problem of long-term energy sources has been drifting towards crisis for decades.
Indeed, the catastrophes in Japan might finally achieve what decades of conflict in the Middle East have not: compel governments to invest in the research required to develop viable energy alternatives.
The immediate political response to the Japanese disaster will be to make small re-adjustments among known energy sources, including wind and solar.
But the current options that many governments wish to embrace will not do the job.
Production of the materials used to capture and store solar electricity, for example, can cause just as much environmental damage as conventional fuels, and existing wind and solar technology cannot easily meet the needs of large populations.
Of course, fossil fuels, mainly coal and natural gas, remain important, but their extraction and use is tied to groundwater pollution and carbon-dioxide emissions, especially in North America and China.
The tragedy in Japan reminds us that, though nuclear energy emits no CO2, it is toxic in other ways.
If there was ever a time for a massive investment in research into long-term energy sources, that time is now.
We need something on the scale of the Manhattan Project (which created the atomic bomb), or the Apollo Program (which put a man on the moon).
Both initiatives succeeded in a short period of time and at a relatively low price.
In current dollars, each cost about $200 billion – a mere fraction of what the United States has paid for the Iraq war, and less than the cost implied by the rise in oil prices over the past year.
Both the Apollo Program and the Manhattan Project had unique characteristics.
Each marshaled the sharpest minds from a range of countries to address one task.
Tolerance for failure was slim in both initiatives, so they tended to rely on the previous generation of scientific insight, because the resulting technology was more trustworthy.
Neither entailed a great scientific challenge, but rather a vast engineering problem.
Although invention was required, existing scientific methods were used.
Unfortunately, governments now focus only on one aspect of this investment format, in which technology that is almost ready is funded.
But this results in endless efforts to make non-ideal methods less troublesome.
We need a game changer, like the integrated circuit, radio, or electricity.
Such a paradigm shift requires an Apollo-scale investment, but in basic science.
There are several examples of the kind of phenomena that, with the benefit of new insight, could lead to unexpected energy sources.
Quite apart from daily sunlight, for instance, Earth is bombarded by all sorts of other radiation from outside our solar system.
Some of this we understand, but most of the material in the universe, and the forces associated with it, are not well explained.
There is most likely an exploitable galactic source of energy that is constant, unlimited, and in our sky right now.
Without basic research to help us understand these forces, their potential will elude us.
An even more mysterious effect occurs on Earth with living creatures.
According to general laws of physics, everything tends to disorder – a process known as entropy. Less well understood is why some agents do the opposite, tending toward order and structure.
Plants, for example, interact with their environment to produce locally ordered systems, resulting in the creation of wood (and other biomass).
When we burn wood, we reverse the process, unraveling that order and producing energy.
At this simple level, we understand how nature works.
But in more complex cases, in which living beings collaborate to build societies or create knowledge, our scientific models are inadequate.
This has prompted some scientists to begin investigating new models of energy from the perspective of “intelligence and information,” in which order is equivalent to information.
With such a fresh perspective on matter, new potentials could emerge.
For example, consider methane clathrate, an ice-like stone that in most cases is built in an ordered way by a complex collaboration of microbes.
Global deposits of methane clathrate contain more than twice the amount of energy of all known fossil fuels, and it can burn cleanly.
If not burned in a controlled way, the release of raw clathrates into the atmosphere would represent a global climate threat, and past massive releases have been catastrophic.
But a better understanding of biological “information flow” could help us use methane clathrate in ways that could actually counter global warming.
Solutions such as these are not explored, however, because they are not within obviously immediate reach, as the atomic bomb and the lunar landing were.
So, perhaps a radically new approach to research is also needed.
Given humanity’s common interest in new energy sources, it seems that the world’s brightest scientific minds should collaborate to identify them.
Such a project would flourish in a scientific establishment that is maturing, rather than frozen in its methods.
Whereas Japan, the US, and Europe are competent at research into what is almost known, the cutting-edge science is more likely to emerge in an economy hungry for resources and infrastructure, such as China.
Rather than a single laboratory, such a program could be a distributed virtual enterprise, taking advantage of the sort of innovative industrial collaboration in which China currently excels.
We need fundamental breakthroughs in alternative energy sources, and soon.
Getting them will probably require a large, collaborative effort focused on theoretical science. Changing our approach to research in this way might seem more difficult than using what we already have.
But, as with our natural resources, we are running out of options.
Alternatives to Austerity
NEW YORK – In the aftermath of the Great Recession, countries have been left with unprecedented peacetime deficits and increasing anxieties about their growing national debts.
In many countries, this is leading to a new round of austerity – policies that will almost surely lead to weaker national and global economies and a marked slowdown in the pace of recovery.
Those hoping for large deficit reductions will be sorely disappointed, as the economic slowdown will push down tax revenues and increase demands for unemployment insurance and other social benefits.
The attempt to restrain the growth of debt does serve to concentrate the mind – it forces countries to focus on priorities and assess values.
The United States is unlikely in the short term to embrace massive budget cuts, à la the United Kingdom.
But the long-term prognosis – made especially dire by health-care reform’s inability to make much of a dent in rising medical costs – is sufficiently bleak that there is increasing bipartisan momentum to do something.
President Barack Obama has appointed a bipartisan deficit-reduction commission, whose chairmen recently provided a glimpse of what their report might look like.
Technically, reducing a deficit is a straightforward matter: one must either cut expenditures or raise taxes.
It is already clear, however, that the deficit-reduction agenda, at least in the US, goes further: it is an attempt to weaken social protections, reduce the progressivity of the tax system, and shrink the role and size of government – all while leaving established interests, like the military-industrial complex, as little affected as possible.
In the US (and some other advanced industrial countries), any deficit-reduction agenda has to be set in the context of what happened over the last decade:
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a massive increase in defense expenditures, fueled by two fruitless wars, but going well beyond that;
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; growth in inequality, with the top 1% garnering more than 20% of the country’s income, accompanied by a weakening of the middle class – median US household income has fallen by more than 5% over the past decade, and was in decline even before the recession;
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; underinvestment in the public sector, including in infrastructure, evidenced so dramatically by the collapse of New Orleans’ levies; and
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; growth in corporate welfare, from bank bailouts to ethanol subsidies to a continuation of agricultural subsidies, even when those subsidies have been ruled illegal by the World Trade Organization.
As a result, it is relatively easy to formulate a deficit-reduction package that boosts efficiency, bolsters growth, and reduces inequality.
Five core ingredients are required.
First, spending on high-return public investments should be increased.
Even if this widens the deficit in the short run, it will reduce the national debt in the long run.
What business wouldn’t jump at investment opportunities yielding returns in excess of 10% if it could borrow capital – as the US government can – for less than 3% interest?
Second, military expenditures must be cut – not just funding for the fruitless wars, but also for the weapons that don’t work against enemies that don’t exist.
We’ve continued as if the Cold War never came to an end, spending as much on defense as the rest of the world combined.
Following this is the need to eliminate corporate welfare.
Even as America has stripped away its safety net for people, it has strengthened the safety net for firms, evidenced so clearly in the Great Recession with the bailouts of AIG, Goldman Sachs, and other banks.
Corporate welfare accounts for nearly one-half of total income in some parts of US agro-business, with billions of dollars in cotton subsidies, for example, going to a few rich farmers – while lowering prices and increasing poverty among competitors in the developing world.
An especially egregious form of corporate special treatment is that afforded to the drug companies.
Even though the government is the largest buyer of their products, it is not allowed to negotiate prices, thereby fueling an estimated increase in corporate revenues – and costs to the government – approaching $1 trillion dollars over a decade.
Another example is the smorgasbord of special benefits provided to the energy sector, especially oil and gas, thereby simultaneously robbing the treasury, distorting resource allocation, and destroying the environment.
Then there are the seemingly endless giveaways of national resources – from the free spectrum provided to broadcasters to the low royalties levied on mining companies to the subsidies to lumber companies.
Creating a fairer and more efficient tax system, by eliminating the special treatment of capital gains and dividends, is also needed.
Why should those who work for a living be subject to higher tax rates than those who reap their livelihood from speculation (often at the expense of others)?
Finally, with more than 20% of all income going to the top 1%, a slight increase, say 5%, in taxes actually paid would bring in&nbsp;more than $1 trillion over the course of a decade.
A deficit-reduction package crafted along these lines would more than meet even the most ardent deficit hawk’s demands.
It would increase efficiency, promote growth, improve the environment, and benefit workers and the middle class.
There’s only one problem: it wouldn’t benefit those at the top, or the corporate and other special interests that have come to dominate America’s policymaking.
Its compelling logic is precisely why there is little chance that such a reasonable proposal would ever be adopted.
Testing Times for Alzheimer’s
LONDON – Alzheimer’s disease is by far the most common cause of dementia and one of the world’s most feared disorders.
By 2050, there will be 135 million Alzheimer’s sufferers worldwide, a threefold increase from today, with three-quarters of cases occurring in low- and middle-income countries.
Predicting the onset of Alzheimer’s, let alone preventing or curing it, remains an immense challenge.
Alzheimer’s disease was identified more than a century ago from autopsy results that showed characteristic brain lesions called “amyloid plaques.”
The disease is more difficult to diagnose in the living.
Doctors rely on observation of memory loss and other thinking deficits (such as reasoning or language comprehension) – signs that plaques are already present in the brain.
But any cure&nbsp;would have to be administered before the plaques form, and years before symptoms of dementia appear.
Alzheimer’s might be more predictable if scientists had the time and resources to conduct far-reaching longitudinal studies over many years.
Such studies ideally would involve blood, imaging, memory, and medical tests, as well as detailed lifestyle questionnaires filled out by thousands of young and middle-aged people.
Study participants would be followed over decades to see who developed the disease, and which tests proved positive before Alzheimer’s was diagnosed.
In fact, two famous longitudinal studies – the Framingham Heart Study in Massachusetts and the Kungsholmen Project in Sweden – have led to important progress in predicting the disease. These studies found that short-term memory may be impaired for up to ten years before an Alzheimer’s diagnosis.
Major advances have since been made in brain imaging, biochemical analysis, and, perhaps most important, genetic testing.
Indeed, the risk of Alzheimer’s doubles if a parent or sibling has it, probably due in large part to the presence of the ApoE gene.
The risk triples for Europeans who inherit a particular type of ApoE, called ε4; inheriting two copies of ε4 increases the risk roughly tenfold.
But genetic testing alone is unlikely to be an accurate predictor, because around half of Alzheimer’s sufferers do not carry ε4, and probably half of those with ε4 do not develop the disease.
Moreover, though international studies of more than 70,000 people have found over 20 other genes linked to Alzheimer’s, their impact is minimal.
That said, a&nbsp;groundbreaking 2012 study&nbsp;published in the&nbsp;New England Journal of Medicine, analyzed a rare genetic mutation found in just 500 families around the world, which would lead to Alzheimer’s before the age of 50.
The study showed which tests were able to predict the outcome most accurately decades ahead of onset.
The research found that amyloid-beta – the substance that clumps together and forms amyloid plaques – becomes depleted in the cerebrospinal fluid around the brain as long as 25 years before the onset of dementia.
Fifteen years prior to onset, a positron emission tomography (PET) scan showed amyloid-beta being deposited in plaques in the brain itself.
And detailed short-term memory tests were abnormal ten years before onset, as suggested in the Framingham and Kungsholmen studies.
These tests are now becoming part of clinical practice, and are available commercially.
Memory and other cognitive tests can reveal whether one has minor problems with some aspects of thinking – a condition known as “mild cognitive impairment” that precedes Alzheimer’s disease.
The problem is that the tests must be administered by a trained neuropsychologist and take more than an hour to complete; moreover, many people with mild cognitive impairment do not progress to dementia.
Sampling cerebrospinal fluid via a lumbar puncture (or “spinal tap”) can predict which people with mild cognitive impairment will progress to dementia with over 80% accuracy, but this still means a misdiagnosis for one in five patients.
PET scans are slightly less accurate, while routine MRI brain scans can reveal with perhaps only 70% accuracy subtle abnormalities in people with mild cognitive impairment.
Scientists are therefore still searching for an accurate predictive test that is cheaper, quicker, and less invasive than PET scans or lumbar punctures.
This year, two small studies of blood tests seemed to predict Alzheimer’s 1-3 years before it occurred, but the tests are complicated and require the measurement of ten or more substances.
Whichever predictive methods doctors use over the next few years will probably enable them to inform those patients with mild cognitive impairment about their chances of developing Alzheimer’s in the short term.
The trickier question is whether we will be able to predict Alzheimer’s disease accurately in those with normal cognition and memory, or to predict it more than five years in advance.
Even if accurate early prediction of Alzheimer’s eventually is achieved, there are currently no drugs available to prevent or cure it before the amyloid plaques start destroying the mind.
That will be our next great challenge.
Ambivalent Arabia
A democratic tide seems to be sweeping across the Arab world.
Even the traditional Arab monarchies and Emirates are changing in its wake.
Kuwait now allows women to vote, Qatar has embraced an ambitious reform program, Bahrain has shown great tolerance of mass demonstrations, and the U.A.E. is allowing something like a free press.
But Saudi Arabia continues to be deeply wary of any sort of change, and thus remains a huge and seemingly immovable obstacle to region-wide reform.
Although the Saudi ruling family, the al-Saud, is under enormous pressure to follow the example of its neighbors, internal resistance to doing so remains very strong.
So the al-Saud have become Janus-faced: looking in one direction, the royal family encourages democratic reformers to speak out; looking in the opposite direction, it jails them when they do.
On May 15, in a closed trial without legal representation for the accused, three leading reformers – Ali Al Dumaini, a well-known journalist and poet, and university professors Abdullah Al Hamid and Matruk al Falih – were condemned and sentenced to prison terms ranging from six to nine years.
Their crime was to call for a constitutional monarchy.
The official verdict states that they threatened national unity, challenged those in authority, and incited public opinion against the state while using “foreign,” that is, Western, terminology.
Not long after the September 2001 terrorist attacks in the United States, these liberal reformers joined with 160 other professionals to write and sign a petition to Crown Prince Abdullah asking for reforms.
The petition called for the monarchy to work within constitutionally prescribed limits, and for an independent judiciary.
The reformers believe that such reforms are the only way for Saudi Arabia to survive the threat of violence, instability, and national fragmentation that is looming on its horizon.
Only a constitution, they argue, can restore much needed legitimacy to a political system that is widely perceived as deeply corrupt and inept.
Crown Prince Abdullah, Saudi Arabia’s de facto ruler in place of his incapacitated half-brother King Fahd, is keen to be seen as a champion of reform.
He received these proposals with a warm welcome in January 2003.
But his half-brother and more powerful rival, Prince Naif, the Minister of Interior, ordered the arrests, trial, and imprisonment of 13 reformers in March 2004.
Crown Prince Abdullah offered not a peep of opposition, leaving the reform agenda that he initiated in a political netherworld.
In order to maintain absolutist power and to minimize public anger, the Saudi princes, led by Prince Naif, asked the reformers to sign an agreement that they would never again ask for reform.
Prince Naif bans the very word “reform” from public discourse, because it suggests that there is something wrong with the system; his preferred term is “development.”
Of the thirteen reformers who were arrested, ten submitted to this demand, but the other three refused and have paid the price.
They remained in jail in Riyadh without legal representation until the final verdict.
Those who submitted had their passports withdrawn, lost their jobs, and were forbidden to speak to the press.
Under regional and international pressure, the Saudi ruling family has constructed a Potemkin village of reform while retaining absolute control over all political developments.
Earlier this year, they staged partial, and tightly regulated municipal elections, with no independent opinion permitted to influence when and how the ballots were held.
These entire female population was excluded, and only one-quarter of the male population was eligible to vote.
Inevitably, Wahhabi Islamists did best.
The al-Saud face two threats: one from violent Islamists, and the other from liberal reformers.
There is every indication that they fear the reformers far more.
Perhaps the princes believe that it is easier to kill “terrorist” criminals than to crush demands for social justice.
Indeed, killing violent Islamists and al-Qaeda affiliates is applauded by the international community, especially the United States, as success in the “war on terrorism.”
But as they hunt down and kill violent domestic extremists, they are quietly tightening the noose around all those who want moderate reform.
This repression of liberal reformers passes unnoticed in the wider world, with America’s silence particularly noticeable.
This silence is vital to the princes, for what the al-Saud care about most is US support.
As things stand in Saudi Arabia, the US administration has no credible ally for change outside of the existing regime.
So, unlike in Ukraine, Georgia, Kyrgizstan, and Lebanon, it does nothing to encourage popular opposition.
As long as the Saudi regime meets America’s oil needs and fights Islamist radicals, it will continue to receive US support and silence – and hence its tacit consent.
But turning a blind eye is shortsighted, for America and for the Saudis.
Those who make peaceful revolutions impossible make violent revolutions inevitable.
The liberal reformers who have been jailed could have paved the way for a peaceful transition to a reformed Saudi Arabia.
By jailing them, the regime has made it clear that violence is the only avenue open to those seeking change.
America and Europe Divided Over Saddam
Talk is growing of a change in US defense doctrine to allow for pre-emptive strikes on states that harbor weapons of mass destruction.
That talk is sending shudders across Europe, where many people connect it with America's oft-stated desire to remove Saddam Hussein from power in Iraq.
Ever since the Gulf war, Iraq has been a source of friction among the western permanent members of the UN Security Council.
By the end of 1999, divergence was complete: the United States and Britain were employing their air power to enforce the no-fly zones while France joined Russia and China in abstaining on resolution 1284.
As this UK-sponsored resolution was meant to bring the Iraq issue back to the Security Council after the withdrawal of the UN weapons inspectors and subsequent American air strikes of December 1998, hope for progress on Iraq within the Security Council was scant.
This rapidly changed after last September 11 th .
On May 14, 2002, the Security Council gave the tottering sanctions regime a new lease on life by unanimously adopting a simplified screening procedure.
Even Iraq showed signs of being prepared to consider a possible return of the UN weapons inspectors.
At first sight this seems to bode well for the transatlantic relationship.
In reality, the current relaxation is more likely a lull before the storm.
Most Europeans take it for granted that the US will attack Iraq, and that this act of unilateralism, coming in the wake of all the other irritants such as the ABM Treaty, the Kyoto Agreement, the steel tariffs and the International Criminal Court, will have a devastating effect on transatlantic relations.
Europe would be ill-advised to become mesmerized by this approaching disaster.
Everyone understands that the Iraqi government's improved attitude is caused by the Bush administration's sabre-rattling, but no one can tell whether this is a prelude to an inevitable war or a stratagem to make Iraq cooperate with UN weapons inspectors.
Obviously, the US cannot remove this uncertainty without robbing the sabre-rattling of its beneficial effect.
Given this ambiguity, there remains time for Europe to engage the US in a serious discussion of the options for dealing with Saddam.
The common aim should be to remove the threat posed by a dictator with so well-documented a predilection for weapons of mass destruction.
The options vary from resumed inspections to `regime change'.
There are arguments which make the choice far less clear-cut than it may seem.
Several of these are also being advanced within the Bush administration.
Europe can constructively participate in such discussion provided it first clears the way by:
1. ridding itself of its constant
2. showing some understanding for the view of some in the Bush administration that the US should not be bogged down by a continent that is soft, decadent and moralizing.
This is not a pleasant way of putting it, but many Americans remember how on two occasions in the former Yugoslavia - a pre-eminently European theatre - Europe was helpless until American warplanes showed up;
3. making clear that Europe and the US are
This debate about how to deal with Saddam might go as follows.
It is not difficult to overthrow Saddam, but it is impossible to predict who or what will take his place.
Iraq may even disintegrate, leaving us with a much stronger Iran, also a member of the
Moreover, Saddam may already possess a weapon of mass destruction but has been deterred from using it.
Once he is attacked by the US, he may use it against Israel, which will retaliate.
So it may well be wiser to induce Iraq to readmit the UN weapons inspectors and make sure they can do their job.
This will not entirely remove the Iraqi threat but will make it controllable.
Should this be the outcome, European governments would breathe a sigh of relief.
But the debate may also go the other way.
Saddam will cooperate with UN inspectors only as long as the American threat remains, and the US may conclude that it cannot afford that.
If President Bush then opts for regime change, Europe should not opt out.
This is easier said than done.
Many Europeans will argue that they cannot condone military action without a Security Council mandate.
But they already did, twice.
They condoned or even supported American air strikes against Baghdad in December 1998, and they supported or even participated in NATO's air strikes against the Federal Republic of Yugoslavia in March 1999.
True, some will say, but that was under the Clinton administration.
If Europe conveys the impression that its friendship with America depends on who wins the US presidential elections, it is likely to freeze the transatlantic relationship for years.
That hardly seems a rational policy for a continent in profound transition.
America and Global Public Goods
America is currently transfixed with the problem it has created for itself in Iraq, but the presidential candidates are also beginning to ask what principles should guide United States foreign policy after Iraq.
In my view, a focus on global public goods – things everyone can consume without diminishing their availability to others – could help America reconcile its preponderant power with others’ interests.
Of course, pure public goods are rare.
Most only partially approach the ideal case of clean air, where none can be excluded and all can benefit simultaneously.
Combating global climate change is probably the most dramatic current case.
If the largest beneficiary of a public good (like the US) does not take the lead in devoting disproportionate resources toward its provision, smaller beneficiaries are unlikely to be able to produce it because of the difficulties of organizing collective action when large numbers are involved.
While this responsibility often lets others become “free riders,” the alternative is no ride for anyone.
The US could gain doubly, both from the public goods themselves, and from the way they legitimize its preponderant power in the eyes of others.
America can learn from the lesson the nineteenth century, when Great Britain was a preponderant power and took the lead in maintaining the balance of power between Europe’s major states, promoting an open international economic system, and maintaining freedom of the seas.
These issues remain relevant today, and the establishment of rules that preserve access for all remains as much a public good now as it was then, even though some of the issues are more complex.
Maintaining regional balances of power and dampening local incentives to use force to change borders provides a public good for many (but not all) countries.
Similarly, maintaining open global markets is a necessary (though not sufficient) condition for alleviating poverty in poor countries even as it benefits the US.
Today, however, global public goods include new issues – not only climate change, but also preservation of endangered species, outer space, and the “virtual commons” of cyberspace.
A reasonable consensus in American public opinion supports ensuring both these and the “classic” global public goods, even if the US has failed to lead on some issues, notably global climate.
There are also three new dimensions of global public goods in today’s world.
First, the US should take the lead in helping to develop and maintain international laws and institutions to organize collective action to deal with not only trade and the environment, but also weapons proliferation, peacekeeping, human rights, and other concerns.
Others benefit from the order that such efforts provide, but so does the US.
Likewise, while unilateralists complain that the US is constrained by international regimes, so are others.
Second, the US should make international development a higher priority.
Much of the poor majority of the world is mired in a vicious circle of disease, poverty, and political instability.
Financial and scientific help from rich countries is important not only for humanitarian reasons, but also to prevent failed states from becoming sources of disorder for the rest of the world.
Here, too, America’s record is less than impressive.
Protectionist trade measures often hurt poor countries most, and foreign assistance is generally unpopular with the American public.
Development will take a long time, and the international community needs to explore better ways to make sure that help actually reaches the poor, but both prudence and a concern for soft power suggest that the US should take the lead.
Finally, as a preponderant power, the US can provide an important public good by acting as a mediator and convener.
By using its good offices to mediate conflicts in places like Northern Ireland, Morocco, and the Aegean Sea, the US has helped in shaping international order in ways that are beneficial to other nations.
The Middle East is the crucial current case.
It is sometimes tempting to let intractable conflicts fester, and there are some situations where other countries can play the mediator’s role more effectively.
Even when the US does not want to take the lead, it can share leadership with others, such as with Europe in the Balkans.
But often the US is the only country that can bring parties together.
When successful, such leadership increases American soft power while reducing sources of instability.
The US can also encourage other countries to share in production of such public goods.
Welcoming the rise of Chinese power in terms of that country’s becoming a “responsible stakeholder” is an invitation to begin such a dialogue.
Nevertheless, the US is likely to remain the world’s preponderant power even after it extricates itself from Iraq.
But it will have to learn to work with other countries to share leadership.
That will require combining the soft power of attraction with the hard power of military might to produce a “smart power” strategy for providing global public goods.
America at Stall Speed?
NEWPORT BEACH – Judging from the skittishness of both markets and “consensus expectations,” the United States’ economic prospects are confusing.
One day, the country is on the brink of a double-dip recession; the next, it is on the verge of a turbo-charged recovery, powered by resilient consumers and US multinationals starting to deploy, at long last, their massive cash reserves.
In the process, markets take investors on a wild rollercoaster ride, with the European crisis (riddled with even more confusion and volatility) serving to aggravate their queasiness.
This situation is both understandable and increasingly unsettling for America’s well-being and that of the global economy.
It reflects the impact of fundamental (and historic) economic and financial re-alignments, insufficient policy responses, and system-wide rigidities that frustrate structural change.
As a result, there are now legitimate questions about the underlying functioning of the US economy and, therefore, its evolution in the months and years ahead.
One way to understand current conditions – and what is needed to improve them – is to consider two events that recently attracted considerable worldwide attention: the launch of Boeing’s Dreamliner passenger jet and the tragic death of Apple’s Steve Jobs.
Let us start with some simple aeronautic dynamics, using an analogy that my PIMCO colleague, Bill Gross, came up with to describe the economic risks facing the American economy.
For the Dreamliner to take off, ascend, and maintain a steady altitude, it must do more than move forward.
It has to move forward fast enough to exceed critical physical thresholds, which are significantly higher than those for most of Boeing’s other (smaller) planes.
Failure would mean succumbing to a mid-air stall, with tepid forward motion giving way to a sudden loss of altitude.
Unless we are convinced of the Dreamliner’s ability to avoid stall speed, it makes no sense to talk about all the ways in which it will enhance the travel experience for millions of people around the world.
America’s economy today risks stall speed.
Specifically, the question is not whether it can grow, but whether it can grow fast enough to propel a large economy that, according to the US Federal Reserve, faces “balance-sheet deleveraging, credit constraints, and household and business uncertainty about the economic outlook.”
And, remember, it is just over a year since certain US officials were proclaiming the economy’s “summer of recovery” – a view underpinned by the erroneous belief that America was reaching “escape velocity.”
Stall speed is a terrifying risk for an economy like that of the US, which desperately needs to grow robustly.
Without rapid growth, there is no way to reverse persistently high and increasingly structural (and therefore protracted) unemployment; safely de-leverage over-indebted balance sheets; and prevent already-disturbing income and wealth inequalities from growing worse.
The private sector alone cannot and will not counter the risk of stall speed.
What is desperately needed is better policymaking.
Specifically, policymakers must be open and willing to understand the unusual challenges facing the US economy, react accordingly, and possess sufficiently potent policy instruments.
Unfortunately, this has been far from the case in America (and in Europe, where the situation is worse).
Moreover, US policymakers in the last few weeks have been more interested in pointing fingers at Europe and China than in recognizing and responding to the paradigm shifts that are at the root of the country’s economic problems and mounting social challenges.
This is where the insights of Steve Jobs, one of the world’s best innovators and entrepreneurs, come in.
Jobs did more than navigate paradigm shifts; he essentially created them.
He was a master at converting the complicated into the simple; and, rather than being paralyzed by complexity, he found new ways to deconstruct and overcome it.
Teamwork was an obligation, not a choice.
And he eschewed the search for the single “big bang” in favor of aiming for multiple breakthroughs.
Underlying it all was a willingness to evolve – a drive for perfection through experimentation.
Moreover, he excelled at selling to audiences worldwide both his vision and his strategy for realizing it.
So far, America’s economic policymakers have fallen short on all of these fronts.
Rather than committing to a comprehensive set of urgently-needed reinforcing measures, they seem obsessed with the futile search for the one “killer app” that will solve all of the country's economic problems.
No surprise that they have yet to find it.
Teamwork has repeatedly fallen hostage to turf wars and political bickering.
Little has been done to deconstruct structural complexity, let alone win sufficient public support for a medium-term vision, a credible implementation strategy, and a set of measures that is adequate to the task at hand.
The longer the policymaking impasse persists, the greater the stall-speed risk for an economy that already has an unemployment crisis, a large budget deficit, many underwater mortgages, and policy interest rates floored at zero.
This is an atmosphere in which unhealthy balance sheets come under even greater pressure, and healthy investors refuse to engage.
In the process, the risk of recession remains uncomfortably high, the unemployment crisis deepens, and inequities rise as already-stretched social safety nets prove even more porous.
America, China, and the Productivity Paradox
NEW HAVEN – In the late 1980s, there was intense debate about the so-called productivity paradox – when massive investments in information technology (IT) were not delivering measureable productivity improvements.
That paradox is now back, posing a problem for both the United States and China – one that may well come up in their annual Strategic and Economic Dialogue.
Back in 1987, Nobel laureate Robert Solow famously quipped, “You can see the computer age everywhere except in the productivity statistics.” The productivity paradox seemed to be resolved in the 1990s, when America experienced a spectacular productivity renaissance.
Average annual productivity growth in the country’s nonfarm business sector accelerated to 2.5% from 1991 to 2007, from the 1.5% trend in the preceding 15 years.
The benefits of the Internet Age had finally materialized.
Concern about the paradox all but vanished.
But the celebration appears to have been premature.
Despite another technological revolution, productivity growth is slumping again. And this time the downturn is global in scope, affecting the world’s two largest economies, the US and China, most of all.
Over the past five years, from 2010 to 2014, annual US productivity growth has fallen to an average of 0.9%.
It actually fell at a 2.6% annual rate in the two most recent quarters (in late 2014 and early 2015).
Barring a major data revision, America’s productivity renaissance seems to have run into serious trouble.
China is witnessing a similar pattern.
Although the government does not publish regular productivity statistics, there is no mistaking the problem: Overall urban employment growth has been steady, at around 13.2 million workers per year since 2013 – well in excess of the government’s targeted growth rate of ten million.
Moreover, hiring seems to be holding at that brisk pace in early 2015.
At the same time, output growth has slowed from the 10% trend of the 33 years ending in 2011 to around 7% today.
That downshift, in the face of sustained rapid job creation, implies an unmistakable deceleration of productivity.
Therein lies the latest paradox.
With revolutionary technologies now driving the creation of new markets (digital media and computerized wearables), services (energy management and DNA sequencing), products (smartphones and robotics), and technology companies (Alibaba and Apple), surely productivity growth must be surging.
As a modern-day Solow might say, the “Internet of Everything” is everywhere except in the productivity statistics.
But is there really a paradox?
Northwestern University’s Robert Gordon has argued that IT- and Internet-led innovations like automated high-speed data processing and e-commerce pale in comparison to the breakthroughs of the Industrial Revolution, including the steam engine, electricity, and indoor plumbing.
He maintains that, although these innovations led to dramatic transformations of the major advanced economies – such as higher female labor-force participation, increased transportation speed, urbanization, and normalized temperature control – these changes will be extremely hard to replicate.
Indeed, as taken with today’s revolutionary technologies as we are – I say this staring at my sleek new Apple Watch – I am sympathetic to Gordon’s argument.
If US productivity figures are to be taken at anything close to face value – a persistently sluggish trend interrupted by a 16-year spurt that now appears to have faded – it is possible that all America has accomplished are transitional efficiency improvements associated with the IT-enabled shift from one technology platform to another.
Optimists maintain that the official statistics fail to capture marked quality-of-life improvements, which may be true, especially in the light of promising advances in biotechnology and online education.
But this overlooks a much more important aspect of the productivity-measurement critique: the undercounting of work time associated with the widespread use of portable information appliances.
In the US, the Bureau of Labor Statistics estimates that the length of the average workweek has held steady at about 34 hours since the advent of the Internet two decades ago.
Yet nothing could be further from the truth: knowledge workers continually toil outside the traditional office, checking their email, updating spreadsheets, writing reports, and engaging in collective brainstorming.
Indeed, white-collar knowledge workers – that is, most workers in advanced economies – are now tethered to their workplaces essentially 24 hours a day, seven days a week, a reality that is not reflected in the official statistics.
Productivity growth is not about working longer; it is about generating more output per unit of labor input.
Any undercounting of output pales in comparison with the IT-assisted undercounting of working hours.
China’s productivity slowdown is probably more benign.
It is an outgrowth of the Chinese economy’s nascent structural transformation from capital-intensive manufacturing to labor-intensive services.
Indeed, it was only in 2013 that services supplanted manufacturing and construction as the economy’s largest sector.
Now the gap is widening, and that is likely to continue.
With Chinese services requiring about 30% more workers per unit of output than manufacturing and construction, combined, the economy’s structural rebalancing is now shifting growth to China’s lower-productivity services sector.
China has time before this becomes a problem.
As Gordon notes, there have been long-lasting productivity dividends associated with urbanization – a trend that could continue for at least another decade in China.
But there will come a time when this tailwind subsides and China begins to converge on the so-called frontier of the advanced economies.
At that point, China will face the same productivity challenges that confront America and others.
Chinese policymakers’ new focus on innovation-led growth seems to recognize this risk.
Without powerful innovations, sustaining productivity growth will be an uphill battle.
China’s recent shift to a slower-productivity trajectory is an early warning of what may well be one of its most daunting economic challenges.
There is no escaping the key role that productivity growth plays in any country’s economic performance.
Yet, for advanced economies, periods of sustained rapid productivity growth have been the exception, not the rule.
Recent signs of slowing productivity growth in both the US and China underscore this reality.
For a world flirting with secular stagnation, that is disturbing news, to say the least.
America Confronts Old and New Europe
US Secretary of Defense Donald Rumsfeld's petulant remark of last year about "old and new Europe" was right for the wrong reasons.
He meant it to refer to Europe's divisions, but in May, ten additional states joined the European Union.
The expanded Europe truly forms a new Europe.
Should America be nervous?
Fifty-four years after the announcement of the Schuman Plan that began to knit together the economies of France and Germany, the EU now has 25 countries and a population larger than that of the United States.
Eight of the new members are former Communist countries that were locked behind the Iron Curtain for nearly half a century.
Their attraction to the Union is a sign of the appeal - the "soft power" - of the idea of European unification.
Of course, this new Europe faces many problems.
The per capita income of the new countries is less than half of that of the fifteen members they are joining.
Concerns have been raised about the influx of cheap labor.
But average GDP growth rates in the new members are twice as high as in the original members, and this can provide a welcome stimulus to stagnant labor markets and sluggish economies.
Political arrangements are somewhat more problematic.
Negotiations are underway to revise a draft EU constitution.
Some Europeans worry that the constitution will enable courts to carry the integration process further and faster than public opinion in member states will tolerate.
Lack of grassroots support might lead to rejection of the constitution in countries like Britain, where referenda have been promised before the new arrangements come into force.
Across the Atlantic, most Americans (to the extent they pay attention) regard these changes with general approval.
But some express concern that the new Europe will be defined in opposition to the US.
Not only do the remarks of French leaders about recreating a multi-polar world arouse alarm, but recent public opinion polls show a decline in the popularity of the US among Europeans and a desire for more independent policies.
The Iraq War proved costly to American soft power, with the US losing about 30 percentage points of attractiveness on average in Europe, including in countries like Britain, Spain, and Italy, whose governments supported the war.
The recent photographs of detainees being abused and sexually degraded in Baghdad's Abu Ghraib prison added fuel to the fire.
Now some American neo-conservatives argue that the US should drop its longstanding support for European integration.
Such a policy change would be a serious mistake.
Not only would it add to anti-American attitudes and fail to accomplish its objectives, but it over-estimates the extent to which the new Europe is being formed in opposition to the US.
Whatever the rhetoric in France, for example, the policies and attitudes in countries such as Britain or Poland demonstrate that good trans-Atlantic relations can be maintained.
If anything, the risks of a US-Europe split will be reduced rather than increased by the EU's recent enlargement.
Moreover, there are several objective reasons why the current friction between Europe and the US is unlikely to lead to divorce.
For one thing, the divisive war in Iraq may turn out to be the last act of the twentieth century rather than a harbinger of the twenty-first.
American unilateralism is much less in evidence in the world's other hot spots, such as North Korea and Iran, both because of the costs of the war in Iraq and the realities of the situation in those other regions.
Moreover, while the common security threat from the Soviet Union has disappeared, both the US and Europe face a new common threat from radical
Europe and America also share a common structure of economic interests and values.
While trade produces frictions in democracies, it also enhances wealth.
If one looks at foreign direct investment, it is clear that the two sides of the Atlantic are closely integrated.
In terms of values, while some differences exist between Europe and America, at the fundamental level of democracy and human rights, no other two parts of the globe share more.
As the writer Robert Kagan concluded in the revision of his book in which he declared Europeans to be from Venus and Americans from Mars, it turns out that Americans seeking democratic legitimization of their policies and self-images cannot escape Europe.
In short, it is good for Americans - and for the world - that old and new Europe are becoming one.
We can all benefit from the soft power of an enlarged Europe.
America Embraces Trade Discrimination
NEW YORK – Economists generally agree on the advantages of openness in trade.
But the case for non-discrimination in trade is also a compelling one.
So good trade policy should push for multilateral trade liberalization such as at the Doha Round, rather than preferential trade agreements (PTAs) such as free-trade areas (FTAs), and also ensure that any retreat into protectionism does not degenerate into discriminatory trade practices.
The last G-20 meeting in Canada was a disappointment on the first front.
At the insistence of the United States, an earlier reference by the G-20 to a definite date for completing the Doha Round was dropped.
Instead, unwittingly rubbing salt into the wound, President Barack Obama announced his administration’s willingness to see the US-South Korea FTA through.
On the second front, there are distressing recent reports that the US Commerce Department is exploring ways to strengthen the bite of anti-dumping actions, which are now generally agreed to be a form of discriminatory protectionism aimed selectively at successful exporting nations and firms.
Equally distressing is Obama’s decision in August 13 to sign a bill, approved in a rare special session of the Senate, that raises visa fees on H1(b) and L-1 temporary work visas in order to pay for higher border-enforcement expenditures.
This proposal gained its legs from long-standing worries about the H1(b) and L-1 programs on the part of Republican Senator Chuck Grassley and Democratic Senator Richard Durbin, and had recently attracted the sponsorship of the influential Democratic Senator Charles Schumer of New York. Schumer had long agitated against “outsourcing” as inimical to American economic interests, even allying himself with the supply-side economist Paul Craig Roberts.
But he gained clout with the onset of the current crisis, and concern over intractable unemployment numbers is enabling politicians to justify all sorts of superficially attractive remedies.
Thus, it was asserted that a tax on foreign workers would reduce the numbers coming in and “taking jobs away” from American citizens.
Many supporters of the proposal claimed, incoherently, that it would simultaneously discourage foreign workers from entering the US and increase revenues.
Obama’s surrender exemplified the doctrine that one retreat often leads to another, with new lobbyists following in others’ footsteps.
Perhaps the chief mistake, as with recent “Buy American” provisions in US legislation, was to allow the Employ American Workers Act (EAWA) to be folded into the stimulus bill.
This makes it harder for companies to get governmental support to hire skilled immigrants with H1(b) visas: they must first show that they have not laid off or plan to lay off American workers in similar occupations.
Whatever the shortcomings of such measures in economic-policy terms, the visa-fee-enhancement provision is de facto discriminatory, and thus violates WTO rules against discrimination between domestic and foreign firms, or between foreign firms from different WTO countries.
While the visa-fee legislation is what lawyers call “facially” non-discriminatory, its design confers an advantage on US firms vis-à-vis foreign firms.
The fee applies to both foreign and US firms that employ at least 50 workers, of which 50% or more are H1(b) workers.
But US firms have additional access to foreign workers under the immigration laws.
India would be the chief loser relative to US firms, and, with several sizeable firms, such as Infosys and Wipro, adversely affected by the measure, it would also be the chief loser vis-à-vis smaller outsourcing firms from other countries.
The Indian government has lost no time in raising these objections – as well as the prospect of a formal WTO Dispute Settlement Mechanism complaint.
Such acts of discrimination in trade policies find succor in the media and in some of America’s prominent think tanks.
For example, in the wake of the vast misery brought by flooding to the people of Pakistan, the US and other governments have risen to the occasion with emergency aid.
But there have also been proposals to grant duty-free access to Pakistan’s exports.
But this would be discriminatory toward developing countries that do not have duty-free access, helping Pakistan at their expense.
Astonishingly, Nancy Birdsall of the Center for Global Development, who favors such discrimination, even wrote cynically and approvingly that such a policy “would have little impact on US textile producers.” Unfortunately, major US media, including The New York Times and The Wall Street Journal, have endorsed this deplorable assault on whatever non-discrimination remains in the world trading system.
Is it too unrealistic to hope that the Obama administration, which has so far been far too responsive to weak economics and strong politics, will stand up to these demands?
America Goes from Teacher to Student
Cambridge &#45;&#45; As the United States’ epic financial crisis continues to unfold, one can only wish that US policymakers were half as good at listening to advice from developing countries as they are at giving it.
Americans don’t seem to realize that their “sub-prime” mortgage meltdown has all too much in common with many previous post-1945 banking crises throughout the world.
The silver lining is that there are many highly distinguished current and former policymakers out there, particularly from emerging market countries, who have seen this movie before.
If US policymakers would only listen, they might get an idea or two about how to deal with financial crises from experts who have lived through them and come out safely on the other side.
Unfortunately, the parallel between today’s US crisis and previous financial crises is not mere hyperbole.
The qualitative parallels are obvious: banks using off-balance loans to finance highly risky ventures, exotic new financial instruments, and excessive exuberance over the promise of new markets.
But there are strong quantitative parallels as well.
Professor Carmen Reinhart of the University of Maryland and I systematically compared the run-up to the US sub-prime crisis with the run-up to the 19 worst financial crises in the industrialized world over the past 60 years. These include epic crises in the Scandinavian countries, Spain, and Japan, along with lesser events such as the US savings and loan crises of the 1980’s.
Across virtually all the major indicators – including equity and housing price runs-ups, trade balance deficits, surges in government and household indebtedness, and pre-crisis growth trajectories – red lights are blinking for the US.
Simply put, surging capital flows into the US artificially held down interest rates and inflated asset prices, leading to laxity in banking and regulatory standards and, ultimately, to a meltdown.
When Asia and Latin America had their financial meltdowns in the 1990’s and early 2000’s, they took advice not only from the IMF, but also from a number of small panels composed of eminent people representing diverse backgrounds and experiences.
The US should do the same.
The head of the IMF, Frenchman Dominique Strauss-Kahn, could easily select a superb panel from any range of former crisis countries, including Mexico, Brazil, Korea, Turkey, Japan, and Sweden, not to mention Argentina, Russia, Chile, and many others.
Admittedly, the IMF’s panel would have to look past America’s current hypocrisy.
The US Treasury strongly encouraged Asia to tighten fiscal policy during its 1990’s crisis.
But today the US Congress and President are tripping over themselves to adopt an ill-advised giant fiscal stimulus package, whose main effects will be to tie the hands of the next president in simplifying the US tax code and closing the budget deficit.
Americans firmly told Japan that the only way to clean up its economy was to purge insolvent banks and regenerate the financial system through Schumpeterian “creative destruction.”
Today, US authorities appear willing to contemplate any measure, no matter how inflationary, to insure that none of its major banks and investment houses fails.
For years, foreign governments complained about American hedge funds, arguing that their non-transparent behavior posed unacceptable risks to stability.
Now, many US politicians are complaining about the transparency of sovereign wealth funds (big government investors mainly from Asia and the Middle East), which are taking shares in trophy American assets such as Citibank and Merrill Lynch.
In fact, having countries like Russia and China more vested in the well-being of the US economy would not be a bad thing.
Yes, the IMF ought to develop a voluntary code of conduct for SWF’s, but it should not be used as a weapon to enforce financial protectionism.
For years, I, along with many others, have complained that emerging markets need greater representation in global financial governance.
Today, the issue goes far beyond symbolism.
The US economy is in trouble, and the problems it spins off are unlikely to stop at the US border.
Experts from emerging markets and elsewhere have much to say about dealing with financial crises.
America should start to listen before it is too late.
America Keeping Haiti Down
The IDB, the world's largest regional development bank, works in Latin America and the Caribbean purportedly to “contribute to the acceleration of economic and social development.”
Its actions in Haiti, however, have severely undermined those goals.

Roughly $54 million in IDB loans for water infrastructure in Haiti, home to literally the world’s worst water, offered a proven path to preventing deadly water-borne diseases. Designed to assist in fulfilling the right to water in the most impoverished nation in the Western Hemisphere, these loans and the lives they could have saved instead have become pawns in a deliberate political power play.
In 2001, US officials threatened to use their influence to stop previously approved IDB funding unless Haiti’s majority political party submitted to political demands to accept a particular apportionment of seats in a Haitian electoral oversight body.
Soon after, at the behest of the US, instead of disbursing the loans as planned, the IDB and its members took the unprecedented step of implicitly adding conditions to require political action by Haiti before the funds would be released.
These actions violated the IDB’s own charter, which strictly prohibits the Bank and its members from interfering in the internal political affairs of member states.
Internal emails reveal that a US legal counselor inside the IDB proposed to the US Treasury Department that, though the loans faced no legitimate technical obstacles, the US could effectively block them by “slowing” the process.
Indeed, by requesting further review of the loans, Haiti would have to make scheduled payments before the funds were even disbursed. “While this is not a ‘bullet-proof’ way to stop IDB disbursements,” the counsellor wrote, “it certainly will put a few more large rocks in the road.”
In 2001, then-US Ambassador to Haiti Dean Curran publicly and explicitly linked the withholding of IDB loans to the demand that Haiti’s political parties reach a compromise that America wanted.
These tactics worked.
Deprived of funds that had already been committed and expected, Haiti fell into arrears on money owed for loan repayment, triggering IDB policies that prevented the Bank from releasing loans.
In subsequent years, the US employed additional delaying tactics, working with the IDB to move the goal posts whenever Haiti appeared to be meeting their demands.
The results have been devastating.
The town of Port-de-Paix, slotted ten years ago by the IDB as the first project site due to its particularly deplorable water situation, has yet to see the implementation of any water projects.
A study conducted by Zanmi Lasante, Partners In Health, the Robert F. Kennedy Memorial Center for Human Rights, and New York University’s Center for Human Rights and Global Justice found no functioning public water sources in the city.
Researchers found three-quarters of water sources in the city contained high levels of coliform bacteria, a key indicator of contamination with fecal matter.
A frightening 15% of households reported symptoms likely related to typhoid.
If the US and other member states join the IDB and take on the responsibility to improve conditions in the Americas, they cannot then use their membership to undermine the basic rights of the people they claim to serve simply to advance their own political agenda.
The IDB and the US government must take responsibility for their actions and implement the necessary transparency mechanisms to ensure that such abuses do not recur.  Congressional inquiries and annual reviews of the Treasury Department by the Government Accountability Office could provide the oversight necessary to prevent future political misuse of the IDB and its funds.
The people of Haiti, as well as US taxpayers, deserve a system that makes public the status of IDB loans and projects in Haiti in order to ensure that the US and IDB member states uphold their commitments to development and human rights.
America’s Anti-Environmentalists
As an American, I am appalled, ashamed, and embarrassed by my country’s lack of leadership in dealing with global warming.
Scientific evidence on the risks mounts by the day, as most recently documented in England’s magisterial Stern Report .
Yet, despite the fact that the United States accounts for roughly 25% of all man-made global carbon emissions, Americans show little will or inclination to temper their manic consumption.
The first George W. Bush administration was probably right to refuse to sign the so-called “Kyoto Protocol,” albeit for the wrong reasons.
Among other problems, the Kyoto Protocol does not go far enough towards redistributing carbon emission rights towards developing countries.
But why can’t the US bring itself to raise taxes on gasoline and other sources of carbon emission like coal burning power plants?
It is not like the US government, running a huge deficit despite an economic boom, does not need the money.
Many people seem to think that the Bush administration is the problem.
Put a Texas oilman and his buddies in charge and what do you expect, conservation?
Unfortunately, that is a facile excuse.
American citizens’ resistance to moderating energy consumption for the sake of the global environment is much more deeply embedded.
Consider former US Vice President Al Gore, for example, whose documentary film on global warming, An Inconvenient Truth , is celebrated for its unflinching look at how fossil fuel consumption is leading mankind to the brink of catastrophe.
The evidence on global warming is considerably more muddled than Gore’s film suggests, but the basic problem is real.
Unfortunately, however, Gore was not successful in carrying the torch on global warming when he was a politician.
One cannot commend the 1990’s Clinton-Gore administration for taking any brave steps aimed at radically reducing carbon emissions.
Small wonder: the American public is fiercely resistant to anything that seriously forces them to compromise on their energy-burning, gas-guzzling lifestyle.
It is not just politicians who have failed to provide leadership here.
The venerable
The typical argument one hears is, “What about the poor guy with the gas-guzzling 1980 Chevy car, who has no other way to get to work?” It is a legitimate point, but if ocean levels start rising, as the
The change of position by the
Until Americans suck it up and start fixing global environmental problems that they, more than anyone, have caused, it will be difficult to get the wholehearted support of the rest of the world.
Developing countries ask why they should pay attention to global warming if rich countries are not prepared to curtail their own emissions sharply?
Why should poor countries worry about how deforestation contributes to global warming when rich countries remain so profligate?
The scientific evidence suggests that carbon emissions from anywhere in the world have about the same impact on global warming.
For this reason, a wide range of economists favor a uniform (“harmonized”) global tax that would tax carbon emissions equally everywhere in the world, and from whatever source – whether coal, oil, or gas, and whether consumers or businesses.
Such a tax is the most flexible and market-friendly approach, and would have the least impact on economic growth.
Instead, the complex system of quotas favored by the Europeans and embodied in the Kyoto Protocol is likely to lead to much larger inefficiencies and costs.
For this reason, England’s
America’s unwillingness to take the lead on environmental issues may some day be regarded as one of the country’s most profound political failures.
One hopes that it changes course soon, before we all are forced to wear swimsuits to work.
America’s Anti-Immigrant Road Rage
Because Latin American countries enjoy the billions of dollars that their countrymen in the United States send home, they should take note of how many of their benefactors are being treated by American officials.
Despite their numbers – the Urban Institute estimates that more than nine million undocumented immigrants live in the US, a number that exceeds the entire populations of countries like Costa Rica and Nicaragua – the undocumented worker has long been North America’s favorite punching bag.
Damned on Sunday, they are hired for work on Monday.
Attacks on immigrants went into high gear in February, when the US Congress passed a bill that will make it illegal for any state to issue driver’s licenses to undocumented workers.
No one in America is even writing about this or taking much notice because few care about those who are in the US illegally.
Undocumented workers pick America’s crops, clean Americans’ houses, and serve Americans their food, but their fate simply does not matter to many US citizens.
Most groups with nine million members who represent billions of dollars would be raising hell in Congress if they were targeted for ill treatment.
But the money undocumented workers earn goes abroad to build homes, start businesses, and take care of elderly parents throughout Latin America.
So the countries that benefit from this largesse have a responsibility to speak up for the constituents who help keep their economies afloat.
US Congresswoman Linda Sanchez says that if foreign presidents don’t speak up for their constituents in America, few others will.
If California is any indicator, a ban on driver’s licenses won’t be effective in keeping undocumented workers off the road.
It will merely make life riskier and more expensive for them, pushing them even further to the margins of society.
Gil Cedillo, a California state senator who has been trying to reverse earlier legislation that in 1994 made it illegal for undocumented workers in California to drive, wrote in a recent policy paper, “While the number of immigrant drivers may be minimally reduced, most simply drive without being trained, tested, licensed, and insured.”
Unlicensed drivers, he found, are nearly five times more likely to be in a fatal crash.
In addition to all the deaths, the net result of this, Cedillo found, was that unlicensed drivers cost Californians some $831 million a year in uninsured motorist coverage.
In some neighborhoods of Los Angeles where undocumented immigrants are concentrated, roughly 90% of drivers are uninsured.
Immigrants need to get to work and so they buy, sell, drive, and abandon cars in a parallel market.
When I talked to immigrants in Oakland, they called their license “tu licencia con dios,” or “your license with God.”
A benevolent God keeps the immigrant from being stopped by the police.
Undocumented workers thus enter the cycle of those who live and drive with nearly throwaway cars that cost between $200 and $700.
When it breaks down, the car of an unlicensed driver is towed to a lot, where it is rarely claimed.
It is then put up for auction and repurchased by agents who in turn sell it to another unlicensed immigrant.
The trick for an immigrant is to always buy cheap, because he never knows how long it will be before a car breaks down.
It is time for Latin America’s leaders to stand up for citizens who mean so much for their countries’ economies.
For example, fighting the Congress’s proposed nationwide ban on driver’s licenses for undocumented immigrants could be a high priority while negotiating new trade agreements with the US.
In any case, the time to act is now: once the ban is passed by Congress and signed by the president, it is unlikely to be lifted any time soon.
The California experience is a case in point.
Probably no other state governor has the political clout to win against the tide of activists who regard offering an undocumented immigrant a driver’s license as tantamount to offering them work, which they already have, and legitimacy, which they apparently don’t need to work.
While repealing one law to satisfy his voters – and get elected – Governor Arnold Schwarzenegger promised new legislation that would restore undocumented workers’ ability to obtain a driver’s license.
But the anti-immigrant vitriol of the 1990’s, which pushed California’s legislature to impose the ban, remains strong, and not even the immigrant Terminator can muster the courage to fight it.
Instead, Schwarzenegger, like other Americans, makes laws in the belief that nine million undocumented workers do not matter.
America’s Arab Comeback
AMMAN – Without much fanfare, the past few months have seen no anti-American demonstrations and no burning of American flags across the Arab world.
Arabs seem increasingly willing to accept – and even applaud – the Obama administration’s policy toward the region.
Of course, Arabs are still unhappy with the United States’ continued bias towards Israel.
Its inability to end the 44-year military occupation of Palestinian lands has not gone unnoticed.
But many Arabs nowadays prefer to give the US a break.
With the exception of the Obama administration’s lack of resolve in denouncing the treatment of protesters by the US-allied regimes in Bahrain and Yemen, America’s position on the Arab revolts has been welcomed.
Arabs, especially young Arabs, who comprise the majority of the region’s population, look up to America for its global power when it upholds democratic morals and values.
There is high respect for the concept of rule of, by, and for the people, as well as for the US Constitution’s guarantee of freedom of expression.
It is precisely the failure to apply these values in areas such as Palestine or Iraq that has made – and can still make – countless Arabs vehemently anti-American.
President Barack Obama’s election two years ago positively shocked Arabs and empowered Arab democrats, who saw it as proof of America’s true democratic nature.
Obama’s Cairo speech, delivered on one of his first foreign trips, promised a new US-Arab beginning, and certainly invigorated Arab democrats.
But the first test of Obama’s foreign leadership disappointed many Arabs.
A US veto of a Security Council resolution – supported by the Council’s 14 other members – to oppose Israeli settlements seemed to signal that Obama had crumbled under pressure from America’s pro-Israel lobby.
The US had not revised its policy, even with an African immigrant’s son living in the White House.
A more positive view of Obama emerged when the Arab revolts began in Tunisia and Egypt –countries with pro-US regimes.
While the US initially demonstrated prudence in word and deed, it quickly understood that the revolts truly reflected the will of the people and acted to align itself with the democratic cause.
The same people that Obama had called on in his Cairo speech to seek democracy had now formed the most important nonviolent movement the world had seen in decades.
Arab youth had finally moved, and Obama and his team made the right statements to encourage them, while also making it clear to the Egyptian and Tunisian regimes that they could no longer hide behind the claim that they were fighting America’s war in north Africa.
Pulling away from dictators without trying to take credit for or hijack the revolt was exactly what was required.
Arab youth had to fight and win democracy for themselves.
All that what was wanted from America, most of the young people thought, was withdrawal of its support for allies like Hosni Mubarak and other Arab dictators.
In Libya, however, the need was different.
The same energy on display in Cairo and Tunis was evident among Libyan youth, but this time, America was able to do little diplomatically because it had no relationship with Col. Muammar el-Qaddafi.
So, no surprise, the energy of Libyan youth ran head-on into Qaddafi’s inclination toward brutality and, more importantly, into his paid mercenaries.
America had a moral responsibility to protect the young people whom Obama had encouraged.
Another type of help was needed, but deciding what form it should take was complicated.
Arab countries, especially Egypt, had hundreds of thousands of their nationals working in Libya.
Their governments saw themselves as Qaddafi’s hostages.
But what the Arab countries couldn’t do with military support, they were able to do by providing political cover for the military intervention led by the US, Britain, and France.
The Gulf countries, which have no citizens working in Libya, were the first to denounce Qaddafi.
Then the Arab League met to follow the Gulf states’ lead.
With angry young Arabs from different countries demonstrating outside its Cairo offices and demanding support for their Libyan brethren, the Arab League took an uncharacteristic position: it agreed to denounce a fellow Arab leader.
Clearly, the Arab world was changing, and the US was suddenly no longer an enemy, but a friend.
After gaining Security Council support, the US, Europe, and some Arab countries began doing exactly what should be expected of the international community when a government is preparing to butcher its own citizens: prevent the slaughter.
Of course, America’s problems with Arabs and its challenges in the Middle East are far from over.
Obama must still fulfill his promises to celebrate with Palestinians their full membership of the UN this fall and to draw down its forces in Afghanistan.
But, for the moment, Arabs are not demonstrating against America.
Instead, with America’s help, they are enjoying the first blush of freedom.
A New Low for China Bashing
NEW HAVEN – As America’s election season nears its finish, the debate seems to have come unhinged.
Nowhere is that more evident than in the fixation on China – singled out by both President Barack Obama and his Republican challenger, Mitt Romney, as a major source of pressure bearing down on American workers and their families.
Get tough with China, both stressed in the presidential debates, and the pain will ease.
Nothing could be further from the truth.
Consider the following charges:
Currency manipulation. Since China reformed its exchange-rate regime in July 2005, the renminbi has risen 32% relative to the dollar and about 30% in inflation-adjusted terms against a broad basket of currencies.
These are hardly trivial amounts, and more renminbi appreciation can be expected in the years to come.
Unlike Japan, which was pressured by the West into a large yen revaluation in 1985 (the “Plaza Accord”), the Chinese have opted to move gradually and deliberately.
American officials call this “manipulation,” arguing that market forces would have resulted in a sharper renminbi appreciation than has occurred.
Fixated on stability – a concept alien to US politicians and policymakers – the Chinese prefer, instead, to play a more active role in managing the adjustment of their currency.
I call that prudence – perhaps even wisdom.
Two lost decades later, the guinea pig, Japan, might have a view on which approach works best.
Outsourcing and intellectual property. Notwithstanding some recent modest improvements in the US labor market, America’s job situation remains terrible.
Private-sector employment is still down 4.1 million from its January 2008 peak.
Yet there is not a shred of evidence to support bipartisan claims that this ongoing carnage is the result of outsourcing US manufacturing jobs to China.
While the manufacturing sector’s share of private employment fell from 11.9% in January 2008 to 10.7% in September 2012, this is only a small portion of the enormous secular decline since the early 1970’s, when manufacturing accounted for more than 30% of private-sector employment.
Weak demand – especially the post-crisis collapse in consumer spending growth – is a far more likely culprit than China in explaining the recent hiring shortfall.
China, for its part, has become a major workhorse of globalization – an assembly hub for inputs produced by multi-country supply chains and an offshore efficiency solution for hard-pressed Western multinational corporations.
About 50% of all exports leaving China have been processed previously by other economies, and close to 60% are shipped by Chinese subsidiaries of “foreign-invested enterprises.”
While these trends benefit Chinese workers, they also support America and other countries by holding down inflation and making it possible for their companies to cope with tough competitive pressures.
They allow beleaguered American families to stretch their paychecks (think Wal-Mart).
And they have not stopped innovative Western companies from putting their intellectual property and new technologies on the line in China in order to deliver spectacular new products to US customers (think Apple).
The trade deficit. Yes, the US runs a massive trade deficit with China – around $295 billion in 2011, or fully 40% of America’s total merchandise trade gap of $738 billion.
Republicans and Democrats alike argue that this is the crux of America’s jobs problem. After all, trade deficits mean job losses.
Because the biggest share of the US trade gap is with China, a country vilified as a currency-manipulating cheater, the bilateral trade deficit has become the lightening rod for China bashers.
It is what has driven Obama to go to the mat with China on recent disputes within the World Trade Organization and on restrictions on Chinese investment in Oregon wind farms, and what has led to saber-rattling by Romney on currency manipulation and trade sanctions.
But neither candidate acknowledges the much bigger elephant in the room.
In 2011, the US had trade deficits with 98 countries.
The other 97 deficits did not magically appear.
They are all part of an enormous multilateral trade deficit that stems from America’s unprecedented shortfall of saving – a depreciation-adjusted “net national saving rate” (combining businesses, households, and the government sector) that has been negative since 2008.
Lacking in savings and wanting to grow, the US runs massive current-account and multilateral trade deficits in order to import other countries’ surplus savings.
This goes to the heart of the folly of China bashing.
No leading country in world history has persistently maintained a negative saving rate.
Trade deficits – with China or any other country – are part of the price that America pays for its unbridled profligacy.
Unless and until the US faces up to its chronic aversion to saving – namely, by reducing massive federal budget deficits and encouraging the rebuilding of severely depleted household saving – multilateral trade deficits will persist.
Simple arithmetic and basic economics tell us that a multilateral problem cannot be addressed by a bilateral solution.
Politicians have a penchant for simple and powerful messages.
Yet those messages are often more spin than substance.
American families are hurting, and elected officials want to pin the blame on China, thereby deflecting attention from the difficult task of rebuilding saving, restoring competitiveness, and living within the country’s means.
Indeed, one could argue that it is the American public that is being manipulated by the erroneous charges leveled at China.
Fortunately, the campaign season is nearly over.
Left unanswered, however, is what comes next.
China bashers typically change their tune after a presidential election.
But there is nothing typical about the pressures that are likely to continue squeezing American families long after November 6.
Both Obama and Romney run the risk of painting themselves into a corner when it comes to China.
That could take all of us to the edge of a slippery slope.
America’s leaders need to come clean with the American people – before it is too late.
America’s Coming Social Democracy?
Almost all of the world’s developed countries consider themselves, and are, social democracies: mixed economies with very large governments performing a wide array of welfare and social insurance functions, and removing large chunks of wealth and commodity distribution from the market.
The United States is something different.
Or is it?
Whatever it has been in the past, the US in the future will have to choose whether, and how much, it will be a social democracy.
Once upon a time, according to mythology at least, America had little downward mobility.
On the contrary, before the Civil War you could start out splitting rails, light out for the Western Territory, make a success of yourself on the frontier, and wind up as President – if you were named Abraham Lincoln.
In the generation after World War II, you could secure a blue-collar unionized manufacturing job or climb to the top of a white collar bureaucracy that offered job security, relatively high salaries, and long, stable career ladders.
This was always half myth.
Setting out for the Western Territory was expensive. Covered wagons were not cheap.
Even in the first post-WWII generation, only a minority of Americans – a largely white, male minority – found well-paying stable jobs at large, unionized, capital-intensive manufacturing companies like GM, GE, or AT&T.
But if this story was half myth, it was also half true, particularly in the years after WWII.
Largely independent of education or family, those Americans who did value stability and security could grasp it in the form of jobs with “a future.”
Even for those not so lucky, economic risks were usually fairly low: the unemployment rate for married men during the 1960’s averaged 2.7%, and finding a new job was a relatively simple matter.
It was during this era – roughly from 1948 to 1973 – that sociologists found that a majority of Americans had come to define themselves not as working class, but as middle class.
The post-WWII period stands as a reference point in America’s collective memory, but it was in all likelihood an aberration.
In the early postwar decades, foreign competition exerted virtually no pressure on the economy, owing to the isolation of America’s continental market from the devastation of WWII.
At the same time, the war left enormous pent-up demand for the products of mass production: cars, washing machines, refrigerators, lawn mowers, television sets, and more.
Government policy back then began with a permanent military program of spending and R&D and continued through massive public works program and suburbanization, underpinned by the Federal Highway Program and subsidized home ownership loans from the Federal Housing Administration.
The regulatory institutions and behavioral norms that originated in the New Deal and developed during WWII came into full force: social security, a system of unionized labor relations, market regulation.
Favorable macroeconomic circumstances, the absence of foreign competition, a system of government support and regulation, and large-scale private provision of what in Europe would have been public social insurance all combined to give post-WWII America many of social democracy’s benefits without the costs. The economy did not stagger under the weight of ample benefits or high taxes.
Americans – at least white, male Americans – did not have to worry about tradeoffs between security and opportunity, because the US offered the advantages of both.
Corporate welfare capitalism substituted for what in Europe would have been government provided social democracy.
America was thus a special place. It had its cake and ate it, too: a combination of security with opportunity and entrepreneurship.
It seemed that this was the natural order of things.
Hence there was little pressure for government-sponsored social democracy: Why bother?
What would it add?
Now things are very different.
The typical American employer is no longer General Motors.
It is Wal-Mart.
Private businesses are providing their workers with less and less in the form of defined-benefit pensions, health insurance, and other forms of insurance against life’s economic risks.
Sharply rising income inequality has raised the stakes of the economic game.
A government that cannot balance its own finances cannot be relied on to provide macroeconomic stability.
Indeed, former Chairman of the US Federal Reserve Paul Volcker sees the US as so macroeconomically vulnerable as to be running a 75% chance of a full-fledged dollar crisis over the next several years.
The coming generation will be one of massive downward mobility for many Americans.
The political struggles that this generates will determine whether America will move more closely to the social democratic norm for developed countries, or find some way to accept and rationalize its existence as a country of high economic risk and deep divisions of income and wealth.
Syria and September 11
PARIS – By chance, it appears that the US Congress will decide on or around September 11 whether to endorse President Barack Obama’s proposal to respond militarily to the Syrian government’s use of poison gas against civilians.
The shadow of two previous events that took place on September 11 looms over the outcome – indeed, over the fact that the question is even being considered at all.
Long before September 11 became a day of infamy in the United States, it acquired similar significance in Chile, where 40 years ago, on September 11, 1973, the armed forces, led by General Augusto Pinochet, overthrew the country’s democratically elected government.
More than any other event of our era, that violent coup was responsible for launching both the contemporary global movement for human rights and the American movement to promote human rights internationally.
In part, this reflected the new regime’s cruelty.
More than three thousand people were murdered or “disappeared” during Pinochet’s rule, thousands more were tortured by his forces, and tens of thousands were forcibly exiled.
To an even greater extent, however, the motivation that spurred the human-rights movement was revulsion worldwide, including in the US, against American aid to Pinochet’s forces, a policy directed by President Richard Nixon and Secretary of State Henry Kissinger.
In the US, members of Congress turned the coup into a platform for efforts to promote human rights.
They condemned developments in Chile, held hearings about the importance of promoting human rights, and adopted legislation – over President Gerald Ford’s veto – requiring that human-rights standards guide US foreign policy.
A slightly revised version of that legislation remains in force.
Obama’s proclamation that the use of chemical weapons in Syria would cross a “red line” – and his implicit threat to use force if that line were crossed – reflects the commitment that the US has made during the past four decades to promote human rights worldwide.
The events of September 11, 2001, are also playing a crucial role in deciding the question of a punitive strike against Syrian President Bashar al-Assad’s regime.
One consequence of the terrorist attacks 12 years ago is that Americans and others in the West became aware that developments in the Middle East could affect their own safety and security.
Initially, the attacks unleashed a strong desire to retaliate, which later gave way to caution about intervention, owing to unforeseen consequences.
In Britain, continuing intense resentment over the deceptions that led to the country’s engagement in the Iraq war seems to be the main reason for Parliament’s refusal to back a strike against Syria.
Wariness of another Middle East war has also underpinned Obama’s unwillingness to go beyond a one-time punitive strike on Syria – with some in Congress opposed to even that.
Though Congress must guard against repeating its disastrous mistake in 2003, when it supported the war in Iraq, the commitment to promote human rights that the US made following September 11, 1973, seems a more appropriate standard for weighing Obama’s proposal for US military action in Syria. Maintaining the international prohibition on the use of chemical weapons is an urgent concern.
The Assad regime’s culpability for using these weapons is not in doubt.
If the US Congress deals with Obama’s proposal responsibly, and does not yield to those motivated by a partisan desire to embarrass him at every turn, it will enhance its own claim to recapture the constitutional power to authorize military conflict – a power that has been disregarded more often than not in the past half-century.
A critical part of its role must be to consider with care the limits that should be placed on a punitive strike.
The war in Iraq was misconceived from the start, because it was an attempt to avenge the September 11, 2001, terrorist attacks by invading and occupying a country that had no part in them.
Obama’s proposal to strike Syria, by contrast, is an attempt to enforce an important human-rights norm by directly punishing – through means that do not involve invasion and occupation – those who committed a gross violation.
It restores human rights to the central place in American foreign policy set forth after September 11, 1973.
America’s Constrained Choice
NEWPORT BEACH – The conventional wisdom about the November presidential election in the United States is only partly correct.
Yes, economic issues will play a large role in determining the outcome.
But the next step in the argument – that the winner of an increasingly ugly contest will have the luxury of pursuing significantly different policies from his opponent – is much more uncertain.
By the time the next presidential term starts in January 2013, and contrary to the current narratives advanced by the Obama and Romney campaigns, the incumbent will find himself with limited room for maneuver on economic policy.
Indeed, the potential differences for America are elsewhere, and have yet to be adequately understood by voters.
They center on the social policies that would accompany a broadly similar set of economic measures; and, here, the differences between the candidates are consequential.
Whoever wins will face an economy growing at a sluggish 2% or less next year, with a nagging risk of stalling completely.
Unemployment will still be far too high, and almost half of it will be hard-to-solve, long-term joblessness – and even more if we count (as we should) the millions of Americans who have dropped out of the labor force.
The financial side of the economy will also be a source of concern.
The fiscal deficit will continue to flirt with the 10%-of-GDP level, adding to worries about the country’s medium-term debt dynamics.
The banking sector will still be “de-risking,” limiting the flow of credit to small and medium-size companies and undermining hiring and investment in plant and equipment.
And the household sector will be only partly through its painful de-leveraging phase.
The policy front will be equally unsettling.
Having dithered and bickered for too long, the US Congress will find it increasingly difficult to postpone action on these challenges.
Meanwhile, the Federal Reserve’s unusual activism, including an ever-expanding list of experimental measures, will yield fewer benefits and entail growing costs and risks.
The US economy will also be operating in a more difficult global environment.
In the next few months, Europe’s debt crisis will most likely worsen.
With emerging economies (including China) slowing, and with meaningful multilateral policy coordination remaining inadequate, protectionist pressures will mount as major trading powers compete for a stagnant pie.
So, whether President Barack Obama or Mitt Romney prevails in November, the next president will be constrained by the twin need for urgent economic stabilization and longer-term reforms.
And, with headwinds from Europe and a synchronized global slowdown, the candidates will have no choice but to pursue, at least initially, similar economic policies to restore dynamic job creation and financial stability.
In striking the right balance between immediate economic stimulus and medium-term fiscal sustainability, the most urgent step will be to counter properly the looming fiscal cliff, as temporary tax cuts expire and deep, across-the-board spending reductions kick in automatically.
Failure to do so would significantly increase the risk of an outright American recession.
Serious medium-term budget reforms are needed to deal with the legacy of repeated congressional failures.
And, if provided with realistic numbers, the next president will soon recognize that the right mix of tax and spending reforms falls into a much narrower range than today’s competing political narratives suggest.
It is certainly not an either/or proposition.
Fiscal reforms work best in a dynamic economy.
To this end, Obama and Romney will need to lift the impediments to growth and job creation.
Here again – in areas like housing, the labor market, credit intermediation, and infrastructure – there is less room for maneuver than most politicians would like us to believe.
But this does not mean that there is no scope for differences.
There is, and they reflect the fact that general economic tendencies will be accompanied by multi-speed dynamics at many levels.
From persistent differences in unemployment rates depending on skills and education to record-high income and wealth inequalities, each economic decision will be accompanied by the need for social judgment – whether explicit or, more likely, implicit – regarding its distributional impact.
After an “age” of excessive leverage, debt creation, and credit entitlement that culminated in the 2008 global financial crisis, America still faces the tricky challenge of allocating cumulative losses that continuously inhibit investment, jobs, and competitiveness.
Until now, Congress’s excessive political polarization has translated into an approach that has pushed more of the burden of adjustment onto those who are less able to bear it.
In an ideal world, America’s next president would rapidly embark on a two-step approach to restoring job dynamism and financial soundness.
First, he would devise a comprehensive set of economic-policy initiatives that are both feasible and desirable – and, again, the scope for major differences here is limited.
Second, he would accompany this with an explicit set of social policies – and here the potential differences are profound – that addresses the need for equitable burden-sharing.
This is not really an election about such hotly-debated issues as outsourcing, tax increases versus entitlement reforms, government control of production versus unfettered private sector activity, or job creators versus free riders.
It is much more about the accompanying concepts of social fairness, entitlement, equality and, yes, standards of behavior for a rich and civilized society.
This is an election about social responsibility – a society’s obligation to support those who are struggling, through no fault of their own, to find jobs and make ends meet.
It is about protecting the most vulnerable segments of society, including by providing them access to proper health coverage.
It is about reforming an education system that fails America’s young people (and about providing appropriate retraining to those who need it).
Among the numerous issues of fairness and equality, it is about the rich giving back to a system that has brought them unimaginable wealth.
It is here where the differences between Obama and Romney are important.
The sooner the campaign debate pivots to this, the greater the probability that Americans will make a more informed choice and, thus, buy into the collective effort needed to escape national malaise.
America\u0027s Crisis Election
CAMBRIDGE – On November 4, Americans will elect their 44th president amidst the worst financial turmoil the country has known since the onset of the Great Depression in 1929.  Both candidates are United States senators with little experience as executives, so their ability to manage the crisis has become a central issue in the election.
At the beginning of the campaign, many observers predicted that Iraq would be the major issue in 2008.
Instead, it is the financial crisis.
In principle, this should help Barack Obama and the Democrats, because polls show them stronger on economic issues, whereas Republicans and John McCain do better on security issues.
After the Republican convention, polls showed McCain ahead in early September, but after the financial meltdown, Obama took the lead.
Although both men have warily embraced the $700 billion bailout of the financial sector, the contrasts between the two men are sharp.
Obama is not only the first African-American nominee of a major party, but also one of the youngest candidates ever.
McCain has experience as a naval aviator and more than two decades in the Senate.
If elected, he would be the oldest incoming president.
The two men differ in temperament as well as experience.
McCain is a man of strong traditional values who prides himself on his willingness to act quickly and decisively, which he sought to do during the negotiations on the bailout by suspending his campaign to return to Washington.
That effort appears to have backfired, because the Republicans that he leads initially balked at passing the legislation.
But McCain has shown himself to be resilient.
In 2007, many people wrote off his campaign, but he had the skills to resurrect it and capture the Republican nomination.
His choice of Alaska’s Governor Sarah Palin as his running mate shook up the presidential campaign.
Obama, while an inspirational orator, has shown a cool and calm demeanor in responding to both the financial crisis and the turbulence of political campaigning. When embarrassed by comments made by the pastor of his church, he delivered an exceptional speech about race in America.
If anything, some of Obama’s Democratic supporters wish he would show more emotion in responding to criticism.
One should be careful, however, about reading too much into national opinion polls measuring the candidates’ popular support.
American presidents are elected by an Electoral College in which each state votes in proportion to the number of members it has in Congress.
Since even the smallest states have two senators, this leads to overrepresentation of lightly populated Western states that tend to vote Republican.
In 2000, Al Gore won the popular vote, but George W. Bush prevailed in the electoral college.
Thus, the two candidates’ campaigns are focusing heavily on a dozen or so states in which voters are closely divided and could sway the electoral college outcome.
Each campaign is now desperately trying to gauge the impact of the financial crisis on these battleground states.
Not only does the Electoral College confuse predictions based on national opinion polls, but there is also the possibility of surprises which can lead to last-minute reversals.
A mistake in a presidential debate can turn the tide of public opinion overnight, as happened to President Gerald Ford in his debate with Jimmy Carter in 1976.
Conversely, Ronald Reagan’s performance in his debate with Carter in 1980 is often credited with his victory.
Another event that could turn the tables would be an “October surprise” associated with terrorism, which could switch the agenda from the financial crisis back to security, the Republicans’ stronger suit.
In 2004, shortly before the election, Osama bin Laden released a video tape that may have helped President Bush defeat Senator John Kerry.
From bin Laden’s point of view, Bush’s policies were more useful for his efforts to recruit supporters than Kerry’s might have been.
One would assume that Obama would prove even more unsettling to bin Laden.
A recent BBC poll of 22 countries found that if the world could vote, Obama would win in a landslide.
The pro-Obama margin varied from 82% in Kenya (where Obama’s father was born) to 9% in India.
But Americans do not like outside interference in their elections.
When Obama attracted a crowd of 200,000 to a speech in Berlin last summer, Republicans criticized him as an elitist who appeals to crowds overseas but not to blue-collar workers at home.
On the other hand, in a September poll that asked Americans to rate a series of foreign-policy goals for the next president, 83% ranked “improving America’s standing in the world” as most important.
And certainly the election of the first African-American as president would do wonders to restore the soft power that the Bush administration squandered over the past eight years.
Some people worry that Obama might be good for American soft power, but not for its hard power.
Machiavelli famously said that it is more important for a prince to be feared than to be loved.
Machiavelli may be correct, but we sometimes forget that the opposite of love is not fear, but hatred.
And Machiavelli made it clear that hatred is something a prince should carefully avoid.
When the exercise of hard power undercuts soft power, it makes leadership more difficult – as Bush found out after the invasion of Iraq.
Both McCain and Obama possess impressive hard-power political and organizational skills; otherwise, they would not be where they are today.
But when it comes to the soft power skills of emotional intelligence, vision, and communication, Obama outranks McCain.
Whether that will sway American voters wary of financial turmoil on November 4 remains to be seen.
America’s Crony Capitalism
Buenos Aires – For 20 years, Americans have denounced the “crony capitalism” of Third World countries, especially in Asia.
But, just as those regions have been improving their public and corporate governance – Hong Kong just witnessed a breakthrough court decision against a telecom tycoon who is the son of the province’s richest and most powerful man – crony capitalism is taking root in the United States, a country that the world long considered the gold standard of a level playing field in business.
The recently completed “stress tests” of US banks are but the latest indication that crony capitalists have now captured Washington, DC.
It is no surprise that stock markets liked the results of the stress tests that US Treasury Secretary Timothy Geithner administered to America’s big banks, for the general outcome had been leaked weeks before.
Indeed, most professional investors trashed the tests as dishonest even as their holdings benefited from a rising market.
Even The Wall Street Journal , usually financial markets’ loudest cheerleader, openly disparaged the tests’ integrity.
The government had allowed bankers to “negotiate” the results, like a student taking a final examination and then negotiating her grade.
The tests were supposed to reveal the true conditions of banks saddled with unaudited toxic assets in housing loans and financial derivatives.
The reasoning behind the tests seemed unimpeachable.
But was it?
As any seasoned banker knows, a well-managed bank should undertake internal “stress tests” regularly as a matter of good housekeeping.
The financial crisis should have mandated a running stress test to keep senior management up to date daily. Why, then, did the US need the government to conduct a financial exercise that bankers themselves could and should have done far better and faster?
The truth is that the tests were not designed to find answers.
Both Wall Street’s chieftains and the Obama administration already knew the truth.
They knew that if the true conditions at many big banks were publicly revealed, many would have been immediately declared bankrupt, necessitating government receivership to stop a tsunami of bank runs.
But the Obama administration did not want to be tagged as “socialist” for nationalizing banks, however temporarily, even though experts such as former US Federal Reserve Chairman Paul Volcker had recommended just that.
Moreover, nationalizing banks would have required dismissing Wall Street captains and their boards for grossly mismanaging their firms.
Wall Street’s titans, however, had convinced Obama and his team that their continued stewardship was essential to getting the world out of its crisis.
They successfully portrayed themselves as victims of a firestorm, rather than as accessories to arson.
Geithner and Larry Summers, Obama’s chief economic advisor, share Wall Street’s culture as protégés of Robert Rubin, the former treasury secretary who went on to serve as a director and senior counselor at Citigroup.
Neither man found it difficult to accept the bankers’ absurd logic.
The stress tests were meant to signal to the public that there was no immediate threat of bank failures.
This message, it was hoped, would stabilize the market so that prices for “toxic” assets could rise to a level at which bankers might feel comfortable selling them.
After all, senior bankers had been claiming that these assets were “mispriced,” and that pricing them at market levels would penalize the banks unnecessarily.
So far, Geithner seems to have succeeded in his “tests,” as the stock market has indeed more than stabilized, with prices of bank shares such as Citigroup and Bank of America quadrupling from their lows.
The feared implosion of Wall Street seems to have been avoided.
But no one ever seriously thought that the US would allow Citigroup and Bank of America, to name just two, to fail.
In fact, the stock market bottomed out last winter.
Markets had factored into share prices the belief that the US government would not allow any more banks to collapse.
What the world wanted was an accurate picture of what the banks were worth and “mark-to-market” valuations to guide investors as to how much new capital they needed.
The world also wanted to see the US retaking the high road in reinforcing business ethics and integrity – so lacking under the last administration.
As taxpayers had already put huge sums into rescuing failing banks, with the prospect of more to come, a transparent process to reveal how the money was being used was imperative.
Substantial public rescue funds have reportedly been siphoned off to foreign banks, Goldman Sachs, and staff bonuses for purposes unrelated to protecting public interests.
None of this was either revealed or debunked by Geithner’s tests.
Instead, public servants now appear to be in cahoots with Wall Street to engineer an artificial aura of profitability.
Moreover, the value of toxic assets remains as murky as ever.
Once sacrosanct accounting principles have been amended at Wall Street’s behest in order to allow banks to report essentially whatever they want.
And now negotiated stress test results have been released to “prove” that the banks are a lot healthier.
Calling this a Ponzi scheme might be too harsh.
But few financial professionals have been fooled.
Meanwhile, Wall Street chieftains and their boards of directors have nothing to fear from government.
On the contrary, they are now the government’s partners in a joint venture to manage this dishonest scheme.
Like swine flu, crony capitalism has migrated from corrupt Third World countries to America, once the citadel of sound public and private governance.
Is it any wonder that China is perceived as an increasingly credible model for much of the developing world, while the US is now viewed as a symbol of hypocrisy and double standards?
America’s Dangerous Debt Ceiling Debate
NEWPORT BEACH – It has been raised more than 70 times in the last 50 years, mostly without commotion.
It must be raised again this summer if the United States government is to continue paying its bills on time.
But now America’s debt ceiling has become the subject of intense political posturing and touch-and-go negotiations behind closed doors.
And, obviously, the outcome has implications that go well beyond the US.
As part of America’s system of checks and balances, Congress gets to do more than just approve the annual federal budget.
It also sets a limit on how much debt the US Treasury is allowed to issue.
Beyond this ceiling, the government can spend only from current revenues.
US Treasury Secretary Timothy Geithner recently informed members of Congress that the government will be in this situation on or around August 2.
Having already officially hit the ceiling, the Treasury is moving money around and tapping various pots of unused funds to pay its bills.
In a few weeks, this “flexibility” will be used up.
With the US government now borrowing around 40% of every dollar it spends, a truly binding debt ceiling would immediately force the government to reduce spending radically and in a disorderly fashion.
Politicians across the political spectrum know that such a situation would unsettle an already fragile US economy, severely weaken the dollar, and raise serious concerns about the country's ability to meet its debt-service obligations, including to the many foreign creditors that the US will need in the future.
Yet, in today’s polarized environment in Washington, Republicans and Democrats are unwilling to compromise – or at least to compromise “too early.”
By holding out, Republicans wish to force President Barack Obama’s administration into massive spending cuts.
Democrats respond that such a one-sided approach would be economically harmful and socially unjust.
In the meantime, both sides risk disrupting transfer payments (including to the elderly) and the provision of public services, as well as eroding further America’s global credit standing.
The overwhelming – and sensible – expectation is that the two parties will compromise and raise the debt ceiling before inflicting serious economic and financial dislocations.
The most recent precedent was the bipartisan agreement reached earlier this year on another fiscal issue that threatened to disrupt the normal functioning of government: the absence of a formally approved budget for this year.
A compromise would allow both parties to declare partial victory, for it would likely entail commitments to cut spending and some steps to make taxation more socially just.
But, like many last-minute agreements, it would have little durable impact.
In effect, the political system would again be kicking the can down the road, with real progress on necessary fiscal reforms expected only after the November 2012 presidential election.
Two scenarios for the timing of an interim compromise are possible, depending on whether it is a one- or two-step process.
Most observers expect a one-step process for bipartisan agreement before August 2.
But politicians may need two steps: an initial failure to agree, and then a quick deal in response to the resulting financial-market convulsions.
In the meantime, the Treasury would temporarily re-prioritize and slow outgoing payments.
This two-step process would be similar to what happened in 2008, when Congress was confronted with another cliffhanger: the Bush administration’s request for $700 billion to prevent a financial-market collapse and an economic depression.
Congress initially rejected the measure, but a dramatic 770-point drop in the stock market focused politicians’ minds, bringing them back to the table – and to agreement.
But the two-step scenario involves incremental risks to the US economy, and to its standing in the global system.
And the longer America’s politicians take to resolve the debt-ceiling issue, the greater the risk of an inadvertent accident.
This brings us to a third, and even more unsettling possibility: a longer and more protracted negotiation, resulting in greater disruptions to government entitlement payments, other contractual obligations, and public services.
Creditors would then ask many more questions before adding to their already-considerable holdings of US government debt, generating still more headwinds in a US economy that already faces an unemployment crisis and uneven growth.
The next few weeks will provide plenty of political drama.
The baseline expectation, albeit subject to risk, is that Democrats and Republicans will find a way to avoid disruptions that would damage the fragile US economy, but that the compromise will not meaningfully address the need for sensible medium-term fiscal reforms.
Such political paralysis on key economic issues is increasingly unsettling for the US private sector, and for other countries that rely on a strong US at the core of the global economy.
This helps to explain why so many companies continue to hoard cash, rather than investing domestically, and why a growing number of countries want to diversify gradually away from dependence on the dollar as the reserve currency and on US financial markets for intermediation of their hard-earned savings.
The world economy is hard-wired to the assumption of a strong America, and Americans benefit from this.
But the more their politicians argue over the debt ceiling, the greater the risk that the wiring will become irreparably frayed.
America’s Day of Reckoning
The pessimists who have long forecasted that America’s economy was in for trouble finally seem to be coming into their own.
Of course, there is no glee in seeing stock prices tumble as a result of soaring mortgage defaults.
But it was largely predictable, as are the likely consequences for both the millions of Americans who will be facing financial distress and the global economy.
The story goes back to the recession of 2001.
With the support of Federal Reserve Chairman Alan Greenspan, President George W. Bush pushed through a tax cut designed to benefit the richest Americans but not to lift the economy out of the recession that followed the collapse of the Internet bubble.
Given that mistake, the Fed had little choice if it was to fulfill its mandate to maintain growth and employment: it had to lower interest rates, which it did in an unprecedented way – all the way down to 1%.
It worked, but in a way fundamentally different from how monetary policy normally works.
Usually, low interest rates lead firms to borrow more to invest more, and greater indebtedness is matched by more productive assets.
But, given that overinvestment in the 1990’s was part of the problem underpinning the recession, lower interest rates did not stimulate much investment.
The economy grew, but mainly because American families were persuaded to take on more debt, refinancing their mortgages and spending some of the proceeds.
And, as long as housing prices rose as a result of lower interest rates, Americans could ignore their growing indebtedness.
In fact, even this did not stimulate the economy enough.
To get more people to borrow more money, credit standards were lowered, fueling growth in so-called “subprime” mortgages.
Moreover, new products were invented, which lowered upfront payments, making it easier for individuals to take bigger mortgages.
Some mortgages even had negative amortization: payments did not cover the interest due, so every month the debt grew more.
Fixed mortgages, with interest rates at 6%, were replaced with variable-rate mortgages, whose interest payments were tied to the lower short-term T-bill rates.
What were called “teaser rates” allowed even lower payments for the first few years: they were teasers, because they played off the fact that many borrowers were not financially sophisticated, and didn’t really understand what they were getting into.
And Alan Greenspan egged them to pile on the risk by encouraging these variable-rate mortgages.
On February 23, 2004, he pointed out that “many homeowners might have saved tens of thousands of dollars had they held adjustable-rate mortgages rather than fixed-rate mortgages during the past decade.”
But did Greenspan really expect interest rates to remain permanently at 1% – a negative real interest rate?
Did he not think about what would happen to poor Americans with variable-rate mortgages if interest rates rose, as they almost surely would?
Of course, Greenspan’s behavior meant that under his watch, the economy performed better than it otherwise would have.
But it was only a matter of time before that performance became unsustainable.
Fortunately, most Americans did not follow Greenspan’s advice to switch to variable-rate mortgages.
But even as short-term interest rates began to rise, the day of reckoning was postponed, as new borrowers could obtain fixed-rate mortgages at interest rates that were not increasing.
Remarkably, as short-term interest rates rose, medium- and long-term interest rates did not, something that was referred to as a “conundrum.”
One hypothesis is that foreign central banks that were accumulating trillions of dollars finally figured out that they were likely to be holding these reserves for years to come, and could afford to put at least some of the money into medium-term US treasury notes yielding (initially) far higher returns than T-bills.
The housing price bubble eventually broke, and, with prices declining, some have discovered that their mortgages are larger than the value of their house.
Others found that as interest rates rose, they simply could not make their payments.
Too many Americans built no cushion into their budgets, and mortgage companies, focusing on the fees generated by new mortgages, did not encourage them to do so.
Just as the collapse of the real estate bubble was predictable, so are its consequences: housing starts and sales of existing homes are down and housing inventories are up.
By some reckonings, more than two-thirds of the increase in output and employment over the past six years has been real estate-related, reflecting both new housing and households borrowing against their homes to support a consumption binge.
The housing bubble induced Americans to live beyond their means – net savings has been negative for the past couple of years.
With this engine of growth turned off, it is hard to see how the American economy will not suffer from a slowdown.
A return to fiscal sanity will be good in the long run, but it will reduce aggregate demand in the short run.
There is an old adage about how people’s mistakes continue to live long after they are gone.
That is certainly true of Greenspan.
In Bush’s case, we are beginning to bear the consequences even before he has departed.
America’s Deepening Moral Crisis
NEW YORK – America’s political and economic crisis is set to worsen following the upcoming November elections.
President Barack Obama will lose any hope for passing progressive legislation aimed at helping the poor or the environment.
Indeed, all major legislation and reforms are likely to be stalemated until 2013, following a new presidential election.
An already bad situation marked by deadlock and vitriol is likely to worsen, and the world should not expect much leadership from a bitterly divided United States.
Much of America is in a nasty mood, and the language of compassion has more or less been abandoned.
Both political parties serve their rich campaign contributors, while proclaiming that they defend the middle class.
Neither party even mentions the poor, who now officially make up 15% of the population but in fact are even more numerous, when we count all those households struggling with health care, housing, jobs, and other needs.
The Republican Party recently issued a “Pledge to America” to explain its beliefs and campaign promises.
The document is filled with nonsense, such as the fatuous claim that high taxes and over-regulation explain America’s high unemployment.
It is also filled with propaganda.
A quotation by President John F. Kennedy states that high tax rates can strangle the economy, but Kennedy’s was speaking a half-century ago, when the top marginal tax rates were twice what they are today.
Most of all, the Republican platform is devoid of compassion.
America today presents the paradox of a rich country falling apart because of the collapse of its core values.
American productivity is among the highest in the world.
Average national income per person is about $46,000 – enough not only to live on, but to prosper.
Yet the country is in the throes of an ugly moral crisis.
Income inequality is at historic highs, but the rich claim that they have no responsibility to the rest of society.
They refuse to come to the aid of the destitute, and defend tax cuts at every opportunity.
Almost everybody complains, almost everybody aggressively defends their own narrow and short-term interests, and almost everybody abandons any pretense of looking ahead or addressing the needs of others.
What passes for American political debate is a contest between the parties to give bigger promises to the middle class, mainly in the form of budget-busting tax cuts at a time when the fiscal deficit is already more than 10% of GDP.
Americans seem to believe that they have a natural right to government services without paying taxes.
In the American political lexicon, taxes are defined as a denial of liberty.
There was a time, not long ago, when Americans talked of ending poverty at home and abroad.
Lyndon Johnson’s War on Poverty in the mid-1960’s reflected an era of national optimism and the belief that society should make collective efforts to solve common problems, such as poverty, pollution, and health care.
America in the 1960’s enacted programs to rebuild poor communities, to fight air and water pollution, and to ensure health care for the elderly.
Then the deep divisions over Vietnam and civil rights, combined with a surge of consumerism and advertising, seemed to end an era of shared sacrifice for the common good.
For 40 years, compassion in politics receded.
Ronald Reagan gained popularity by cutting social benefits for the poor (claiming that the poor cheated to receive extra payments).
Bill Clinton continued those cuts in the 1990’s.
Today, no politician even dares to mention help for poor people.
The big campaign contributors to both parties pay to ensure that their vested interests dominate political debates.
That means that both parties increasingly defend the interests of the rich, though Republicans do so slightly more than Democrats.
Even a modest tax increase on the rich is unlikely to find support in American politics.
The result of all of this is likely to be a long-term decline of US power and prosperity, because Americans no longer invest collectively in their common future.
America will remain a rich society for a long time to come, but one that is increasingly divided and unstable.
Fear and propaganda may lead to more US-led international wars, as in the past decade.
And what is happening in America is likely to be repeated elsewhere.
America is vulnerable to social breakdown because it is a highly diverse society.
Racism and anti-immigrant sentiments are an important part of the attack on the poor, or at least the reason why so many are willing to heed the propaganda against helping the poor.
As other societies grapple with their own increasing diversity, they may follow the US into crisis.
Swedes recently gave enough votes to a right-wing, anti-immigrant party to give it representation in parliament, reflecting a growing backlash against the rising number of immigrants in Swedish society.
In France, Nicolas Sarkozy’s government has tried to regain popularity with the working class by deporting Roma migrants, a target of widespread hatred and ethnic attacks.
Both examples show that Europe, like the US, is vulnerable to the politics of division, as our societies become more ethnically diverse.
The lesson from America is that economic growth is no guarantee of wellbeing or political stability.
American society has become increasingly harsh, where the richest Americans buy their way to political power, and the poor are abandoned to their fate.
In their private lives, Americans have become addicted to consumerism, which drains their time, savings, attention, and inclination to engage in acts of collective compassion.
The world should beware.
Unless we break the ugly trends of big money in politics and rampant consumerism, we risk winning economic productivity at the price of our humanity.
America’s Economic Stalemate
CAMBRIDGE – The United States appears trapped in a dangerous economic stalemate.&#160; The refusal by both Republicans and Democrats to give ground on the budget is preventing the government from dealing with its massive fiscal deficit and rapidly rising national debt.
Indeed, the Congressional Budget Office projects that the national debt could increase to 82% of GDP over the next ten years – more than double the debt ratio as recently as 2008.
That forecast, moreover, is based on quite optimistic assumptions of strong economic growth and low interest rates.
With slower growth and more normal interest rates, the debt ratio could easily rise to more than 100% in 2021, and exceed 150% by 2030.
A major reason for the accelerating growth in government debt is America’s rapidly aging population and the resulting increase in the cost of the universal pension and health-care programs – Social Security and Medicare.
Most experts believe that limiting the rise in debt will require slowing the growth of these “entitlement” programs and increasing taxes as a share of GDP.
But President Barack Obama and the congressional Democrats oppose any reduction in future entitlement programs, while the Republican presidential candidates and their party’s congressional delegation oppose any increase in tax revenues.
The result is the current stalemate in reducing the fiscal deficit and reversing the growth of the national debt.
Republicans argue that the national debt’s growth should be limited only by cutting government spending.
Although some cuts in traditional outlays should be part of efforts to rein in spending, this approach should be supplemented by reducing “tax expenditures” – the special features of the tax code that subsidize health care, mortgage borrowing, local-government taxes, etc..
Limiting tax expenditures could reduce the annual deficit by as much as 2% of GDP, thereby reducing the debt-to-GDP ratio in 2021 by more than 25 percentage points.
Republicans generally reject this form of spending reduction, because it results in additional tax revenue.
While this method does indeed increase total revenue, the economic effect of limiting tax expenditures is the same as it is under any other method of cutting spending on those programs.
But the Republicans’ opposition to anything that raises revenue means that this key to breaking the budget stalemate won’t be implemented.
The budget cost of Social Security pensions could be gradually reduced by substituting annuities generated by investment-based personal retirement accounts for part of the current tax-financed benefits.
But even though such a reform could maintain income levels for retirees, Democrats oppose it, because it lowers traditional government benefits.
This reinforces the stalemate.
The two parties’ hardline stances anticipate the upcoming congressional and presidential elections in November 2012.
The Republicans, in effect, face the voters with a sign that says, “We won’t raise your taxes, but the Democrats will.” The Democrats’ sign, by contrast, says, “We won’t reduce your pension or health benefits, but the Republicans will.”
Neither side wants any ambiguity in their message before the election, thus ruling out the possibility of any immediate changes in tax expenditures or future Social Security pensions.
But, for the same reason, I am optimistic that the stalemate will end after the election.
At that point, both Republicans and Democrats will be able to accept reforms that they must reject now.
Another post-election route to deficit reduction would be to lower marginal tax rates and balance that revenue loss with cuts in tax expenditures.
Official analyses downplay the effect of lower marginal tax rates on taxable income, but experience shows that taxable income rises substantially as taxpayers respond to lower marginal rates by working more, taking more of their compensation in taxable cash than in fringe benefits, and reducing their tax-deductible consumption.
Reducing tax expenditures while lowering marginal tax rates can produce substantial revenue by increasing the level of taxable income.&#160;
The current economic stalemate is troubling, because financial markets could react adversely, and because delays in addressing the fiscal deficit means a higher national debt.
I may be too optimistic, but I think there is good reason to believe that the current budget stalemate reflects election posturing, and that the US political system will prove more effective at making progress on fiscal consolidation once the election is past.
America’s Election and the Global Economy
STANFORD – As America’s elections approach, with President Barack Obama slightly in front of his Republican challenger, former Massachusetts Governor Mitt Romney, pollsters still rate the races for control of the presidency and the United States Senate too close to call, with the House of Representatives likely to remain in Republican hands.
The differences between the candidates are considerable, and highly consequential for American economic policy and the global economy, although enactment of their programs will depend on the makeup of Congress.
The most important differences between the two candidates can be summarized as follows:
Spending.
Obama has dramatically increased spending.
He would likely continue many of his temporary programs (as Milton Friedman once observed, “There is nothing so permanent as a temporary government program.”); double down on having government pick winners and losers in green energy; expand spending on education and infrastructure; and substantially reduce defense expenditures.
Romney, by contrast, favors limiting overall federal spending, currently 24% of GDP, to 20%, and keeping defense at 4%.
He wants private markets, not government, to choose winning firms and technologies.
Democrats oppose most nondefense spending cuts, arguing that reductions would cause the economy to contract.
That case is strongest if the spending reductions are large and abrupt in a weak economy. If phased in over a multi-year period as the economy recovers, as Romney proposes, thrift would likely be expansionary.
For example, federal spending relative to GDP fell by five percentage points from the mid-1980’s to the late 1990’s in the US, and by an even larger margin in recent decades in Canada – that is, through periods of strong economic growth.
Taxes.
Obama would raise the top marginal tax rates on wages, capital gains, dividends, interest, and estates, especially on higher-income individuals and small businesses.
Yet he has never proposed comprehensive reform of either the personal or corporate income tax.
By contrast, Romney would reduce America’s corporate tax rate (the highest in the OECD) to 25% and tax American multinationals on a territorial, rather than a worldwide, basis in order to increase their tax competitiveness.
He would also lower personal tax rates by 20%, and make up lost revenue by limiting tax deductions and credits, particularly at the upper end, thereby raising about 18.5% of GDP, just above the historical average, at full employment.
Romney’s fiscal plan thus reduces deficits sufficiently to decrease the debt-to-GDP ratio.
He favors a balanced-budget amendment to the Constitution, and hopes to balance the budget over eight years.
Obama, by contrast, would run larger deficits – his spending increase is much larger than his tax increase – which imply large tax hikes in the future.
Moreover, he would run far larger debt ratios than Romney, because the main driver of the debt is entitlement spending.
Entitlements.
Obama has remained silent about reform of Medicare and Social Security, whose long-run deficits are several times the national debt.
Vice President Joe Biden has even said that “no changes” to Social Security are to be made.
Romney supports gradually increasing retirement ages, a premium-support model for Medicare, and shifting Medicaid (health insurance for the poor) to the states via block grants.
The Obama campaign is pummeling Romney on Medicare, and the Romney campaign is hammering Obama for his refusal to negotiate or even propose a solution.
The Obama policy would thus lead to ever-higher deficits and debt ratios well over 100% of GDP, a level that numerous studies imply would reduce US economic growth by one-third or more and might induce a sovereign-debt crisis.
Some observers suggest that Obama’s unspoken plan is ever-growing entitlements eventually paid for by a European-style value-added tax.
Trade.
Obama is the first US president in a long time who has not played a leading role on global trade liberalization.
The Doha Round of global trade talks remains stalled, and Obama delayed the three bilateral free-trade agreements that awaited approval when he came into office.
Romney is a proponent of free trade, but has said that he would be tougher on China’s trade practices and currency policies.
Regulation.
Obama wants to expand federal command-and-control regulation further (though the courts have stopped his extension of some regulatory powers).
Romney vows an economically balanced approach that would reform Obama’s major health-care, environmental, and financial-services regulations.
Appointments.
Every US president appoints thousands of officials, many with considerable power.
Romney has said that he would not reappoint Ben Bernanke as Fed Chairman (likely candidates: economists Glenn Hubbard, Greg Mankiw, John Taylor, and Martin Feldstein).
Other presidential appointees exert considerable influence on firms, industries, or the entire economy. For example, Obama’s appointees to the obscure National Labor Relations Board tried to prevent Boeing from expanding in South Carolina, despite the state’s anti-union “right to work” legislation.
These policies would affect US economic growth, the budget deficit, national saving, and hence global trade and capital flows.
With larger deficits under Obama than under Romney, America would need more capital from Europe, Latin America, and Asia, while higher taxes and debt would impede US growth and thus undermine these regions’ exports.
Obama would steer America in the direction of European social-welfare states; Romney’s agenda is designed to prevent that.
Whoever wins, a fiscal cliff looms at the end of 2012.
Previous legislation, if not reversed, will lead to large abrupt tax hikes and spending cuts, which the Congressional Budget Office forecasts would likely cause a recession in 2013.
While a post-election, lame-duck session of Congress will address the fiscal cliff, the deep differences between Republicans and Democrats on taxes and spending remain wide and difficult to bridge.
With uncertainty plaguing Europe’s finances and China slowing, the last thing the global economy needs is a stagnant or shrinking US economy.
But it will take strong leadership by the president-elect to avoid it.
America’s Employment and Growth Challenges
NEW YORK – For many, if not most, Americans, the crisis that befell them in 2008 – leading to slow growth, rising unemployment, and high anxiety among voters – appeared to spring from nowhere.
Certainly, the vast majority of economists, investment analysts, financial firms, and regulators failed to see the growing risk.
In fact, it had deep roots.
While the precise timing of any crisis is impossible to predict, ample signs of rising risk, distortions, structural problems, and imbalances could be seen by anyone who took the time to interpret a decade’s worth of mounting debt, low savings, surging asset prices, and excess consumption.
The United States was on an unsustainable growth path for at least a decade – probably longer – before the crisis.
Restoring balance and eliminating the distortions will require time, investment, and structural change, and should be the central focus of America’s economic policy.
The household sector is especially important.
If the main problem had been confined to excess leverage and risk-taking within the financial sector, the economic shock would have been large, but the recovery quicker.
It was the huge loss of households’ net worth that brought down the real economy (with an assist from the credit squeeze on smaller businesses).
Let’s be clear: elevated savings and reduced consumption relative to pre-crisis levels are likely to be permanent even after households reduce leverage and restore retirement savings – a process that in the US has removed roughly $1 trillion from the demand side of the economy.
To make up the difference, Americans need to compete effectively for a portion of global demand.
Does this mean that the US is headed for a “new normal,” rather than a reversion to pre-crisis conditions?
It does. Put bluntly, Americans were living beyond their means for too long.
With foreign borrowing financing a yawning trade deficit, the US economy as a whole spent more than it earned, which both caused and hid structural problems.
So the main post-crisis challenge is not to return to the old normal, which was not sustainable, nor is it to recover from a deep balance-sheet recession, but rather to make a structural transition from the old abnormal to a new normal that is sustainable.
This does not mean that recovery of households’ balance sheets can be ignored in the post-crisis period.
The US Federal Reserve has had to carry out a difficult balancing act: with no sign of inflation on the horizon – and at least some risk of deflation – it has maintained low interest rates even as credit conditions have eased. Contrary to most commentary, this is not a growth strategy, but rather an attempt to limit the considerable risk of another major downturn, induced by further balance-sheet damage in the housing sector.
True, low interest rates, together with a second round of quantitative easing, are causing considerable global distortions, as funds flow into fast-growing emerging markets, fueling inflationary pressure and asset bubbles.
But, given the US housing market’s fragility, raising interest rates could cause prices to plummet, sinking the economy again.  Despite their complaints, it is not clear that emerging economies would prefer another deep US downturn to the current flood of inbound capital that that they must manage.
As it is, deficient consumption and stubbornly high unemployment are likely to be with Americans for some time.
But this is not how the future was sold to the public, and, until recently, financial markets were acting as if recovery was at hand and would be relatively quick.
The proverbial dead-cat bounce – when freefall stops and inventories run out, causing output to pick up a bit – was misinterpreted as evidence of a V-shaped recovery: sharply down and sharply back up.
Despite the impression created, particularly in the US, by media commentary and political debate, fiscal stimulus clearly helped in the crisis, though its impact is diminishing rapidly.
Recent studies by the International Monetary Fund indicate that in most advanced countries, including the US, the growth in budget deficits was largely automatic, owing far more to declining tax revenues and rising expenditures on unemployment benefits than to stimulus spending.
The appropriate timing of fiscal retrenchment is, in fact, difficult to decide.
On one side is concern about another downturn and deflation.
On the other side is the risk of excessive debt, currency instability, and – where unemployment is structural – doubts about the benefits of additional stimulus.
Indeed, advanced countries, including the US, have dug themselves into a deep hole.
It is not yet a hole of the type one finds in Greece, where restoring fiscal balance and reviving economic growth are probably impossible without a restructuring of public debt. But climbing out will be difficult and painful.
At this stage, the best course would be to adopt a credible multi-year plan, based on reasonable but conservative growth assumptions, to reduce deficits to sustainable levels and limit the accumulation of public debt.
With a new, more hostile Congress, and with members of a new economic team coming on board, Obama’s challenge is to build a consensus around a medium- and long-term recovery strategy, with a focus on restoring growth and employment.
The limited fiscal resources that are available should be targeted on areas that affect competitiveness in the tradable sector.
That means forgoing some government services.
The truth is that all the net employment growth in the US economy over the last 20 years has been in the non-tradable sector, where Americans don’t have to compete.
Leading drivers of employment growth have been government, health care, and, until the crisis, construction.
While this is just one part of a much more complex story, it seems unlikely that these and other non-tradable sectors can sustain employment growth in the future.
With the tradable sector neutralized and the non-tradable sectors maxed out, the economy lacks sufficiently powerful growth engines.
That must be fixed, which requires that competitiveness become the central focus of longer-term US economic policy – the sooner, the better.
America’s Employment Dilemma
BERKELEY – There are always two paths to boost employment in the short term.
The first path is to boost demand for goods and services, and then sit back and watch employment rise as businesses hire people to make the goods and services to meet that demand.
The second path is not to worry about production of goods and services, but rather to try to boost employment directly through direct government hiring.
The first path is better: not only do you get more jobs, but you also get more useful stuff produced.
The problem is that it does not take effect very quickly.
It is subject to what Milton Friedman called “long and variable lags.”
Thus, policies aimed at boosting employment by the end of, say, this calendar year needed to be put in place about a year ago to have time to have reached their full effect.
Some countries – China, for example – did, indeed, implement such job-creation policies a year ago and are already seeing the benefits.
Others, like the United States, did not, and so unemployment remains at around 10%.
This is not to say that the Obama administration did not try to boost employment.
A year ago, it set five policy initiatives in motion:
• Additional deficit spending;
• Recapitalization of banks that appeared very vulnerable;
• Asset purchases by the US Treasury and other executive-branch entities to reduce the quantity of risky assets that the battered and risk-intolerant private sector was holding;
• Continued monetary easing via very low Federal Funds rates;
• Expansion of extraordinary policy interventions by the Federal Reserve.
The stress tests conducted by the US Treasury last year suggested that the banking sector had re-attained sufficient capital.
And the Fed has continued its low-interest monetary policy.
But the dysfunctional US Senate capped additional deficit spending at $600 billion over three years – only half of the $1.2 trillion that was the technocratic goal.
Moreover, the Fed became gun-shy and did not continue to increase its balance sheet beyond $2 trillion.
And large-scale market interventions funded and guided by the Treasury never came to pass on a sufficiently large scale to have any tangible effect on jobs.
In short, perhaps two and a half out of the Obama administration’s five policy initiatives came to fruition.
And, in the face of a recessionary crisis that turned out to be roughly twice as large as was forecast at the end of 2008, such limited action was not enough to keep the US unemployment rate below 10% – or even set it on a downward trajectory.
This brings us to the present moment, with US unemployment unacceptably high and refusing to fall.
As a result, there is now a very strong case to turn the focus of the US economy from measures aimed at increasing demand to measures aimed at boosting employment directly (without worrying much about whether these measures are efficient in the sense of substantially raising the quantity of goods and services produced).
In practice, that means that the government either hires people and puts them to work or induces businesses to hire more people.
We are talking about either direct government employment programs, or large tax credits for businesses that increase the number of workers they employ.
There is still time for a substantial shift in federal spending toward high-employment (but in all likelihood low-value) projects to reduce unemployment before the end of 2010 – if Congress acts quickly.
And there is still time for a substantial temporary and incremental new-hire tax credit aimed at getting businesses to boost employment before the end of 2010.
But will Congress act quickly?
Given the depth of political polarization in the US, and thus the need for 60 of 100 votes in the Senate to end a Republican filibuster, there is no sign of it being able to do so.
Such a plan can get off the ground only if 50 Democratic senators are willing to rely on the budget reconciliation process – used to combine the bills adopted by the House of Representatives and the Senate – and are willing to accelerate that process and complete it within a month.
Don’t hold your breath.
America’s Failed Militarized Foreign Policy
Many of today’s war zones – including Afghanistan, Ethiopia, Iran, Iraq, Pakistan, Somalia, and Sudan – share basic problems that lie at the root of their conflicts.
They are all poor, buffeted by natural disasters – especially floods, droughts, and earthquakes – and have rapidly growing populations that are pressing on the capacity of the land to feed them.
And the proportion of youth is very high, with a bulging population of young men of military age (15-24 years).
All of these problems can be solved only through long-term sustainable economic development.
Yet the United States persists in responding to symptoms rather than to underlying conditions by trying to address every conflict by military means.
It backs the Ethiopian army in Somalia.
It occupies Iraq and Afghanistan.
It threatens to bomb Iran.
It supports the military dictatorship in Pakistan.
None of these military actions addresses the problems that led to conflict in the first place.
On the contrary, American policies typically inflame the situation rather than solve it.
Time and again, this military approach comes back to haunt the US.
The US embraced the Shah of Iran by sending massive armaments, which fell into the hands of Iran’s Revolutionary Government after 1979.
The US then backed Saddam Hussein in his attack on Iran, until the US ended up attacking Saddam himself.
The US backed Osama bin Laden in Afghanistan against the Soviets, until the US ended up fighting bin Laden.
Since 2001 the US has supported Pervez Musharraf in Pakistan with more than $10 billion in aid, and now faces an unstable regime that just barely survives.
US foreign policy is so ineffective because it has been taken over by the military.
Even postwar reconstruction in Iraq under the US-led occupation was run by the Pentagon rather than by civilian agencies.
The US military budget dominates everything about foreign policy.
Adding up the budgets of the Pentagon, the Iraq and Afghanistan wars, the Department of Homeland Security, nuclear weapons programs, and the State Department’s military assistance operations, the US will spend around $800 billion this year on security, compared with less than $20 billion for economic development.
In a stunning article on aid to Pakistan during the Bush administration, Craig Cohen and Derek Chollet demonstrated the disastrous nature of this militarized approach – even before the tottering Musharraf regime’s latest crackdown.
They show that even though Pakistan faces huge problems of poverty, population, and environment, 75% of the $10 billion in US aid has gone to the Pakistani military, ostensibly to reimburse Pakistan for its contribution to the “war on terror,” and to help it buy F-16s and other weapons systems.
Another 16% went straight to the Pakistani budget, no questions asked.
That left less than 10% for development and humanitarian assistance.
Annual US aid for education in Pakistan has amounted to just $64 million, or $1.16 per school-aged child.
The authors note that “the strategic direction for Pakistan was set early by a narrow circle at the top of the Bush administration and has been largely focused on the war effort rather than on Pakistan’s internal situation.” They also emphasize that “US engagement with Pakistan is highly militarized and centralized, with very little reaching the vast majority of Pakistanis.”
They quote George Bush as saying, “When [Musharraf] looks me in the eye and says…there won’t be a Taliban and won’t be al-Qaeda, I believe him, you know?”
This militarized approach is leading the world into a downward spiral of violence and conflict.
Each new US weapons system “sold” or given to the region increases the chances of expanded war and further military coups, and to the chance that the arms will be turned on the US itself.
None of it helps to address the underlying problems of poverty, child mortality, water scarcity, and lack of livelihoods in places like Pakistan’s Northwest Frontier Province, Sudan’s Darfur region, or Somalia.
These places are bulging with people facing a tightening squeeze of insufficient rainfall and degraded pasturelands.
Naturally, many join radical causes.
The Bush administration fails to recognize these fundamental demographic and environmental challenges, that $800 billion of security spending won’t bring irrigation to Afghanistan, Pakistan, Sudan, and Somalia, and therefore won’t bring peace.
Instead of seeing real people in crisis, they see caricatures, a terrorist around every corner.
A more peaceful world will be possible only when Americans and others begin to see things through the eyes of their supposed enemies, and realize that today’s conflicts, having resulted from desperation and despair, can be solved through economic development rather than war.
We will have peace when we heed the words of President John F. Kennedy, who said, a few months before his death, “For, in the final analysis, our most basic common link is that we all inhabit this small planet.
We all breathe the same air.
We all cherish our children’s future. And we are all mortal.”
America’s Financial Leviathan
BERKELEY – In 1950, finance and insurance in the United States accounted for 2.8% of GDP, according to US Department of Commerce estimates.
By 1960, that share had grown to 3.8% of GDP, and reached 6% of GDP in 1990.
Today, it is 8.4% of GDP, and it is not shrinking.
The Wall Street Journal’s Justin Lahart reports that the 2010 share was higher than the previous peak share in 2006.
Lahart goes on to say that growth in the finance-and-insurance share of the economy has “not, by and large, been a bad thing....Deploying capital to the places where it can be best used helps the economy grow...”
But if the US were getting good value from the extra 5.6% of GDP that it is now spending on finance and insurance – the extra $750 billion diverted annually from paying people who make directly useful goods and provide directly useful services – it would be obvious in the statistics.
At a typical 5% annual real interest rate for risky cash flows, diverting that large a share of resources away from goods and services directly useful this year is a good bargain only if it boosts overall annual economic growth by 0.3% – or 6% per 25-year generation.
There have been many shocks to the US economy over the past couple of generations, and many factors have added to or subtracted from economic growth.
But it is not obvious that the US economy today would be 6% less productive if it had had the finance-insurance system of 1950 rather than the one that prevailed during the past 20 years.
There are five ways that an economy gains from a well-functioning finance-insurance system.
First, people are no longer as vulnerable to the effects of fires, floods, medical disasters, unemployment, business collapses, sectoral shifts, and so forth, because a well-working finance-insurance system diversifies and thus dissipates some risks, and deals with others by matching those who fear risk with those who can comfortably bear it.
While it might be true that America’s current finance-insurance system better distributes risk in some sense, it is hard to see how that could be the case, given the experience of investors in equities and housing over the past two decades.
Second, well-functioning financial systems match large, illiquid investment projects with the relatively small pools of money contributed by individual savers who value liquidity highly.
There has been one important innovation over the past two generations: businesses can now issue high-yield bonds.
But, given the costs of the bankruptcy process, it has never been clear why a business would rather issue high-yield bonds (besides gaming the tax system), or why investors would rather buy them than take an equity stake.
Third, improved opportunities to borrow allow one to spend more now, when one is poor, and save more later, when one is rich.
Households are certainly much more able to borrow, thanks to home-equity loans, credit-card balances, and payday loans.
But what are they really buying?
Many are not buying the ability to spend when they are poor and save when they are rich, but instead appear to be buying postponement of the “unpleasant financial retrenchment” talk with the other members of their household.
And that is not something you want to buy.
Fourth, we have seen major improvements in the ease of transactions.
But, while electronic transactions have made a great deal of financial life much easier, this should have been accompanied by a decrease, not an increase, in the finance share of GDP, just as automated switching in telecommunications led to a decrease in the number of telephone switchboard operators per phone call.
Indeed, the operations of those parts of the financial system most closely related to technological improvements have slimmed down markedly: consider what has happened to the checking operations of the regional Federal Reserve Banks.
Finally, better finance should mean better corporate governance.
Since shareholder democracy does not provide effective control over entrenched, runaway, self-indulgent management, finance has a potentially powerful role to play in ensuring that corporate managers work in the interest of shareholders.
And a substantial change has indeed occurred over the past two generations: CEOs focus much more attention than they used to on pleasing the stock market, and this is likely to be a good thing.
Overall, however, it remains disturbing that we do not see the obvious large benefits, at either the micro or macro level, in the US economy’s efficiency that would justify spending an extra 5.6% of GDP every year on finance and insurance.
Lahart cites the conclusion of New York University’s Thomas Philippon that today’s US financial sector is outsized by two percentage points of GDP.
And it is very possible that Philippon’s estimate of the size of the US financial sector’s hypertrophy is too small.
Why has the devotion of a great deal of skill and enterprise to finance and insurance sector not paid obvious economic dividends?
There are two sustainable ways to make money in finance: find people with risks that need to be carried and match them with people with unused risk-bearing capacity, or find people with such risks and match them with people who are clueless but who have money.
Are we sure that most of the growth in finance stems from a rising share of financial professionals who undertake the former rather than the latter?
America’s Fiscal Isolationism
DENVER – Patience might be a virtue, but not necessarily when it comes to American foreign policy.
Consider “the long war,” a bold concept embraced a few years ago to describe the continuing struggle against terrorism, the grudging progress that could realistically be achieved, and the enormous financial burden that it would impose for years to come.
It was also a realpolitik acknowledgement of the setbacks to be expected along the way (the “slog,” as then Defense Secretary Donald Rumsfeld put it).
Above all, the term was an effort to communicate to Americans, accustomed to waging war with speed and decisiveness (and insistent on it since Vietnam), the long-term sacrifice and commitment needed to win a war of survival.
Its proponents also understood that the war would not be limited to weapons, but would need to be a sustained effort, involving, as they put it, the “whole of government,” with civilian agencies marshaled behind military – or paramilitary – objectives.
Daunting as the effort would be, its advocates assumed a sustainable political consensus to support it.
After all, the United States had been attacked.
Today, that consensus is unraveling as America’s politicians wrestle with a federal budget that is itself turning into a long war – one with its own casualties.
The battle lines in this struggle suggest that there is little accord among political elites for any spending, let alone for a long war with far-flung commitments.
As a result, basic assumptions are being questioned at every turn.
Indeed, the current budget war seems to be reopening old divisions about America’s view of itself and the world.
The outcome is far from certain, but even isolationism, a perennial American malady, seems to be making a comeback.
Isolationism is a familiar refrain in US foreign policy among those elements of the right that consider the US too good for the world, as well as among those on the left who consider America a destructive global force.
But this time, as perhaps never before, a bipartisan isolationist impulse is being driven by the budget.
America’s fiscal crisis is profound, and it is not just about numbers.
As the emotions in Washington today suggest, the aversion to tax increases runs far deeper than concern about their effect on current economic performance and job growth.
In part, it represents a fundamental – some would say fundamentalist – view that taxes are to government what a bottle of whisky is to an alcoholic.
Government, as Ronald Reagan told us, is the problem, not the solution.
That message is bad news for American diplomacy.
The linkage between politicians’ unwillingness to fund domestic programs and the imperiled commitment to “the long war” might elude those in US foreign-policy circles, but it is not lost on the rest of the country.
Opinion surveys suggest that Americans want to maintain many of the “discretionary” domestic programs – schools, hospitals, transportation infrastructure, recreational parks, etc. – that are now on the chopping block in budget negotiations.
In places like rural El Paso County, on the eastern plains of Colorado, far from the federal budget debate’s epicenter, spending cuts are the order of the day.
School districts are increasing class sizes as they shed teachers, as well as deferring maintenance projects and curtailing the school-bus service.
These cuts are having a very real and immediate impact on El Paso County’s residents.
Can they, and other Americans who are losing vital services, really be expected to rise above it all and support funding to build new schools in Afghanistan?
Not only are America’s public schools starting to look second-rate, but so is its infrastructure, which had long been a source of national pride.
How many travelers nowadays can fail to note the difference between Asia’s new, efficient airports and the aging, clogged antiques in some major US cities?
The budget war is not producing any consensus on fixing America’s infrastructure, but it is beginning to produce a view that Afghanistan and Pakistan are far from being core US national interests.
Why, people ask, are schools and roads in Afghanistan and Iraq more important than those in Colorado or California? At one point in 2008, the US military picked up the cost of transporting a tiger for the Baghdad zoo.
When was the last time the US government did that for a US zoo (outside of Washington, of course)?
How this debate sorts itself out will have profound consequences for how America conducts itself in the world.
But it might also take a toll on how the world reacts to America’s fastest-growing export: unsolicited advice.
Countries take others’ advice for many reasons.
Sometimes they respect the adviser’s wisdom and insights (fairly rare in diplomacy).
Or they might fear the consequences of not taking the advice (an offer one cannot refuse, so to speak).
Or, as is true of many of America’s diplomatic transactions, accepting advice could open the way to a better relationship and to additional assistance.
In short, diplomacy – and US diplomacy, in particular – often involves money.
But what if there is no money to offer?
What if Americans, tired of the budget cuts in their neighborhoods, refuse to support funds even for “the long war”?
At that point, senior US officials might well arrive in a country, offer advice, and find that nobody is bothering to listen.
America’s Free-Trade Abdication
NEW YORK – The indifference and apathy that one finds in Washington from both the Congress and President Barack Obama on the Doha Round of world trade talks, and the alarm and concern expressed by statesmen elsewhere over the languishing negotiations, mark the end of the post-1945 era of American leadership on multilateral free trade.
Evidence of anxiety outside the US has been clear to everyone for almost a year.
German Chancellor Angela Merkel and British Prime Minister David Cameron were concerned enough to join with Turkey’s President Abdullah Gül and Indonesia’s President Susilo Bambang Yudhoyono in appointing Peter Sutherland and me as Co-Chairs of a High-Level Trade Experts Group in November 2010.
We held a prestigious Panel at Davos with these leaders in January 2011, where, on the occasion of our Interim Report, we gave full-throated support to concluding Doha.
But there was no response from the US government.
In September, former British Prime Minister Gordon Brown, former Spanish Prime Minister Felipe González, and former Mexican President Ernesto Zedillo reminded G-20 leaders that in November 2009, at their first meeting in London, they had expressed “a commitment to …conclude the Round in 2010.”
And, two weeks ago, the UN met again on the Millennium Development Goals (MDGs).
Goal 8 is about instruments such as trade and aid, and MDG 8A commits the UN member nations to “[d]evelop further an open, rule-based, predictable, non-discriminatory trading and financial system.”
But, while practically every country today has embraced preferential Free Trade Agreements, the recent leader in this proliferation is the US.
There, Congress and the president apparently have plenty of time to discuss bilateral FTAs with South Korea, Colombia, and Panama, as well as the regional Trans-Pacific Partnership (TPP), but none for negotiating the non-discriminatory Doha Round, which is languishing in its tenth year of talks.
Indeed, it is notable that, while Obama’s State of the Union address in January 2010 at least mentioned Doha, his address in January 2011 did not.
Obama confined himself to promoting the pending bilateral agreements with Colombia and other emerging-market countries.
Obama’s regrettable retreat from support for the Doha Round is the result of many factors and fallacies.
These were highlighted in an “Open Letter to Obama” that I organized and released, over the signatures of nearly 50 of today’s most influential trade experts worldwide, urging a presidential shift in policy towards Doha.
America’s president is captive to the country’s labor unions, who buy the false narrative that trade with poor countries is increasing the ranks of the poor in the US by driving down wages.
In fact, however, there is plenty of evidence for the rival narrative that rapid and deep labor-saving technological change is what is putting pressure on wages, and that imports of cheap labor-intensive goods that US workers consume are actually offsetting that distress.
Again, Washington lobbyists have bought into the absurd claim of trade experts such as Fred Bergsten that the gain from Doha, as it stands now, is a paltry $7 billion or so annually.
This ignores the far greater losses that a failed Doha Round would entail, for example, by undermining the World Trade Organization’s credibility as the principal guarantor of rules-based trade, and by leaving trade liberalization entirely to discriminatory liberalization under preferential bilateral agreements.
Again, someone needs to tell Obama that imports create jobs, too, and that his emphasis on promoting US exports alone is bad economics.
Most of all, Obama is badly served on trade by his senior colleagues.
Secretary of State Hillary Clinton, for example, was opposed to trade liberalization when she ran against Obama for president, and advocated a “pause” in free-trade negotiations.
She also misinterpreted the great economist Paul Samuelson as a protectionist, when he said nothing of the kind.
She has never recanted.
Likewise, now that Warren Buffett is considered to be Obama’s most trusted economic adviser, it is worth recalling that back in 2003 he produced the astonishing prescription that the best way to reduce the US trade deficit was to allow no more imports than it could finance from its export earnings.
An amused and alarmed Samuelson drew my attention to this nutty idea.
While Buffett’s prescription of higher taxes for America’s wealthy is entirely desirable, will Obama realize that a genius in one area may be a dunce in another?
What we need today is for the world’s leading statesmen to stop pussyfooting and to unite in nudging Obama towards a successful conclusion of the Doha Round.
That alone would provide the counterweight to the forces that pull him in the wrong direction.
It is still not too late.
America’s G-Zero Moment
NEW YORK – The 2008 financial crisis marked the end of the global order as we knew it.
In advance of the upcoming G-8 summit, it is impossible to overlook the fact that, for the first time in seven decades, the United States cannot drive the international agenda or provide global leadership on all of today’s most pressing problems.
Indeed, the US has trimmed its presence abroad by refusing to contribute to a eurozone bailout, intervene in Syria, or use force to contain Iran’s nuclear breakout (despite strong Israeli support).
President Barack Obama officially ended the war in Iraq, and is withdrawing US troops from Afghanistan at a pace constrained only by the need to save face.
America is handing off the leadership baton – even if no other country or group of countries is willing or able to grasp it.
In short, US foreign policy may be as active as ever, but it is downsizing and becoming more exacting about its priorities.
As a result, many global challenges – climate change, trade, resource scarcity, international security, cyber-warfare, and nuclear proliferation, to name a few – are bound to loom larger.
Welcome to the G-Zero world, a more turbulent, uncertain environment in which coordination on global policy issues falls by the wayside.
Paradoxically, this new environment, though daunting, is less troublesome for the US; in fact, it provides fresh opportunities for the US to capitalize on its unique position.
The G-Zero world is not all bad for the US – if it plays its cards right.
Many residual strengths take on greater importance in such a world, and America remains the world’s only true superpower and its largest economy – still more than twice the size of China’s.
Its defense expenditures represent nearly half the world total, and exceed those of the next 17 countries combined.
The dollar remains the world’s reserve currency, and investors’ scramble into US government debt at every peak in the crisis since 2008 has underscored America’s safe-haven status (even in crises that America caused).
Likewise, the US continues to lead in entrepreneurship, research and development, higher education, and technological innovation.
Moreover, it is now the world’s largest natural-gas producer and calorie exporter, which has reduced its vulnerability to price shocks or food shortages.
No country rivals America’s promotion of the rule of law, liberal democracy, transparency, and free enterprise.
While other countries certainly support these values, only the US has been willing, healthy, and big enough to ensure that they prevail.
So, as America curtails its global leadership, it will find itself in more demand.
Consider Asia, for example.&nbsp;As China’s economic importance and regional influence grows, its neighbors are seeking to deepen ties with the US.
Japan, Australia, Indonesia, and Taiwan have all recently closed trade and security-related deals with the US.
Even Burma has gotten on board, resuming diplomatic engagement with the US while trying to work its way out of China’s shadow.
In other words, in a G-Zero world, an increasingly aggressive global environment makes the US all the more appealing to countries seeking to hedge their bets.&nbsp;As a result, the US has an opportunity to act more precisely in its own interests.
Supplying less leadership allows the US to weigh opportunity costs before taking action, and to select the issues and circumstances that suit it the best.&nbsp;In this environment, military intervention in Libya does not necessitate the same in Syria.
The extent to which the US will capitalize on these opportunities remains to be seen.
In fact, America’s short-term advantages pose the biggest obstacle to its long-term outlook.
Call this the “safe-haven curse”:&nbsp;as long as the US remains the safest port in any storm, it faces no immediate pressure to address its weaknesses.
For example, for all of the hand-wringing about America’s national debt, investors will continue to loan the US money.
Over the long term, however, US policymakers must make steady progress in restoring confidence in the nation’s fiscal health by cutting politically sacred programs like social security, Medicare, and defense.
Officials will have to put aside short-term motives and party orthodoxy to bolster America’s aging infrastructure, reform its education and immigration systems, and pursue long-term fiscal consolidation.
America’s advantages in the G-Zero world afford it the chance to invest in the future.
But, by cushioning against sufficiently calamitous risks, the same advantages allow the US to procrastinate.
American politicians need to recognize the new G-Zero reality and rebuild America’s domestic sources of strength, even if only incrementally.&nbsp;If they do, the US will have the vigor and flexibility to shape the next world order.
America’s political system usually works well in crises.&nbsp;But, thanks to its residual advantages in a leaderless world, the US need not rely on a crisis to precipitate action.
It need only seize the G-Zero moment.
Obama’s Underachieving Foreign Policy
PARIS – To evaluate an American president’s foreign-policy performance after one term is challenging, given the complex diplomatic and strategic environment and significant domestic constraints that confront every US president.
Nevertheless, in advance of November’s presidential election, it is important to distinguish the forces that have shaped Barack Obama’s foreign policy, and to assess his handling of them.
Obama kept his promise to withdraw American forces from Iraq during his first term.
But the move proved to be a strategic defeat, given that it significantly diminished the United States’ political influence in Iraq.
Indeed, Prime Minister Nouri al-Maliki’s government is becoming increasingly allied with Iran.
Obama, who opposed the Iraq war, should not be blamed for current circumstances there.
But he was unable to improve the situation or help Iraq’s Shias and Sunnis reach a political compromise.
In contrast, Obama expanded the war in Afghanistan – which he considered to be a war of necessity – and put the Taliban on the defensive.
But the US will begin to withdraw troops after 2014, without having defined a political solution in line with its interests.
Meanwhile, America’s strategic partnership with Pakistan, where Obama won a significant symbolic victory by eliminating Osama bin Laden, is in tatters.
US-Pakistan relations have regressed to their level before September 11, 2001, with mutual distrust minimizing cooperation.
In fact, in all of the strategic challenges to US security that Obama inherited – Iran, North Korea, Iraq, Afghanistan, Pakistan, and the Israeli-Palestinian conflict – he has made virtually no significant political gains.
Notwithstanding Obama’s skillful response to the Arab Spring – the only strategic surprise that he has faced as president – his credibility in the Muslim world has steadily declined.
He has failed to deliver on the key promise of his Cairo speech in 2009: “to seek a new beginning between the United States and Muslims around the world.”
Moreover, Obama’s efforts to improve relations with Russia – embodied in the Strategic Arms Reduction Treaty (START) – did not lead to a genuine “reset” in bilateral ties, largely because an increasingly Soviet-style Russian leadership distrusts a US establishment that still regards Russia as a foe.
And the US-China relationship has deteriorated, with America seeking to manage China’s rise strategically – for example, through regional trade agreements and an enhanced military presence in Asia.
On multilateral issues, Obama’s performance is equally unimpressive.
After committing to a 17% reduction of greenhouse-gas emissions by 2020 – and despite his declaration that he would not tolerate inaction in this area – he simply stopped raising the issue after the Republicans’ sweeping victory in the November 2010 mid-term elections.
Likewise, domestic pressure has caused Obama to neglect trade issues.
The US is largely responsible for the failure of the Doha Round of global trade talks.
Obama’s one significant foreign-policy breakthrough has been to release the US from the grip of the “global war on terror.”
Jettisoning the Manichean rhetoric of that “war” allowed the US to regain the political legitimacy that former President George W. Bush had lost, without diminishing its strategic credibility.
After the Vietnam War, Jimmy Carter hoped to make a break with established US policy.
But his administration’s actions – including serious blunders in Iran and Afghanistan – made the US appear weak and indecisive.
While Obama’s policies have not weakened America’s international standing, they also have not led to achievements comparable to Richard Nixon’s rapprochement with China, largely owing to what might be described as the dogmatic pragmatism that underlies them – an emphasis on avoiding the worst, rather than on striving for the best.
Moreover, Obama has been confronted with significant constraints, including the global economic crisis, domestic political polarization, a hostile Congress, and the rise of emerging powers that need the US but are unwilling to accept its dominance.
As a result, he has failed to change strategic realities by, for example, reconciling America’s broader interests with those of Iran (a declared enemy), Pakistan (a “frenemy”), and Israel (a key ally).
To be sure, Obama faces a more complex diplomatic and strategic environment than Nixon faced in the 1970’s.
Unstable coalitions in Iran prevent any substantive negotiations between the two countries, while political fragmentation in Pakistan significantly hinders US policy there.
And the fragility of Israel’s ruling coalition, combined with strong congressional support for Prime Minister Binyamin Netanyahu, makes it difficult to influence the country’s policies, despite Israel’s significant impact on US strategy in the Arab world.
But Obama has also struggled to define the terms of a possible grand bargain.
Any agreement with Iran would require consent from Israel and the Gulf countries, which do not share the same objectives.
And the US cannot reach an accord with Pakistan without India’s consent, which America would be unable to force, especially given that it relies on India to counterbalance China’s growing clout in Asia.
With Israel, the terms are ostensibly simpler: in exchange for a stronger US security guarantee, Israel would accept the establishment of a Palestinian state based on the 1967 borders.
But Israel is also a crucial domestic political topic in the US; indeed, any distancing from Israel is unacceptable to most Americans.
While Obama’s first term could not be called a foreign-policy disappointment, his achievements – although not trivial – have been limited.
If he wins a second term, he is likely to find it increasingly difficult to win by playing not to lose.
America’s Groucho Marxists
LONDON – Groucho Marx has always been my favorite Marxist.
One of his jokes goes to the heart of the failure of the ideology – the dogmatic religion – inflicted on our poor world by his namesake, Karl.
“Who are you going to believe,” Groucho once asked, “me, or your own eyes?” For hundreds of millions of citizens in Communist-run countries in the twentieth century, the “me” in the question was a dictator or oligarchy ruling with totalitarian or authoritarian powers.
It didn’t matter what you could see with your own eyes.
You had to accept what you were told the world was like.
Reality was whatever the ruling party said it was.
The designated successor to Mao Zedong in China, Hua Guofeng, raised this attitude to an art form.
He was known as a “whateverist.” The Party and people should faithfully follow whatever Mao instructed them to do.
Groucho posed two insuperable problems for the “whateverists” of communism. First, your own eyes and your reason would surely tell you before long that the communist idyll – the withering away of the state and the triumph over need – would never come.
Communism, like the horizon, was always just beyond reach.
It would be interesting to know how many of those at Beijing’s Central Party School – the party’s main educational institute – believe that the Chinese state is about to wither away, or ever will.
The second application of Groucho’s question was that citizens of most Communist countries soon learned that the loss of freedom that they suffered was not compensated by greater prosperity or a higher quality of life.
The more that Russians, Poles, Czechs, and others saw of the life-style in the Western democracies, the more they questioned their own system.
In his magisterial book
So, in the political sphere, reason has trumped both faith in an unattainable goal and self-delusion about the consequences of its pursuit.
Authoritarian party-states, such as China and Vietnam, survive, but not through commitment to communism.
Their legitimacy depends on their ability to deliver economic growth through state-managed capitalism.
Democracies, of course, allow people to use their reason to make choices based on the evidence of their own eyes.
When you don’t like a government, you can turn the rascals out without overthrowing the whole system.
Change can be made in an evolutionary, rather than a revolutionary, way.
But no one should think that debate in democracies is always based on reason, or that democracy necessarily makes people more rational.
Sometimes reason does prevail.
This is what appeared to happen in the last Indian election, and the election in the United States of President Barack Obama was also plainly a supremely rational moment.
But reason does not seem to be getting much of a hearing during the current health-care debate in the US.
Outsiders, even admirers, have often wondered how the most globalized country in the world – a continent inhabited by people from every land – can be so irrationally insular on some issues.
We scratch our heads about America’s gun laws.
We were astonished during President George W. Bush’s first term at the administration’s hostility to science, reflected in its stance on climate change and Charles Darwin’s theory of evolution.
The opposition to health-care reform is a similar cause of bemusement.
We know that despite its great wealth – and its groundbreaking medical research – America’s health-care system is awful.
It is hugely expensive.
Its costs overwhelm workplace health-insurance schemes.
The poor go unprotected.
Too many of the sick are untreated.
Overall health statistics are worse than those in comparable countries.
Yet Obama’s attempts to reform health care have run into hysterical opposition.
His proposals would lead, it is said, to the state murdering the elderly.
They would introduce Soviet communism into the US – just like what apparently exists in Canada and Britain, with their state-sponsored health systems.
Communism in Toronto and London?
Or just better, cheaper, more reliable health care for all?
Reason seems to be having a hard time of it in the US just now.
Maybe it’s no coincidence that Groucho Marx was an American citizen.
But surely the way a society cares for its sick and needy and elderly is sufficiently important to deserve serious and thoughtful argument based on what we really can see with our own eyes rather than on uninformed partisan prejudice.
America’s Growth in the Decade Ahead
CAMBRIDGE – Although the strength of the US economy in 2010 remains uncertain, it is important to look ahead to its likely performance in the coming decade.
The rise of GDP over the next ten years will reflect the very positive effect of the eventual recovery from the current deep downturn, combined with a below-trend rise in the economy’s potential output at full employment.
When I add up all the key components, I conclude that the coming decade’s annual growth is likely to be about 1.9%, roughly the same as the average rate over the past ten years.
To understand why, let’s start with the cyclical recovery.
I’ll make the optimistic but plausible assumption that the economy will fully recover over the next decade, lowering the unemployment rate from the current 10% to about 5%.
That return to full employment will also reduce the number of people who, discouraged that no jobs exist for those with their skills, have stopped looking for work (and are therefore not counted as unemployed).
That cyclical recovery of employment will cause GDP to rise by about 13% over the next decade, or an average of 1.2% per year.
That represents a substantial turnaround from the past decade, when the unemployment rate rose from 4% to 10% and the labor-force participation rate fell from 67% to 65%, reducing GDP by about 1.6% per year.
The full rise in GDP will combine the 1.2%-per-year cyclical rebound with the increase in potential full-employment GDP.
The growth of potential GDP will reflect the structural rise of the labor force, the increase in the capital stock, and the improvement in multifactor productivity (i.e., the change in the output that results from improvements in technology rather than from increases in labor and capital.)
Although there are uncertainties about each of these components of growth, their performance in the coming years is unlikely to be as good as it was in recent decades.
Slower population growth and a demographically driven decline in the labor-force participation rate will reduce employment growth.
Indeed, the US Department of Labor recently predicted that the labor force will grow by only 8% between 2008 and 2018, down from 12% in the previous ten years.
That growth of the labor force will raise potential GDP by only about 0.5% per year.
Although the capital stock will benefit from a higher household saving rate, the increase will be offset by more government “dissaving” as budget deficits remain high.
A reluctance of foreign investors to keep accumulating dollar assets will cause a smaller capital inflow from the rest of the world.
Finally, the change in potential GDP will depend on what happens to the rate of change of multifactor productivity – that is, the change in output that results from changes in technology and production processes.
According to the OECD, US multifactor productivity rose at a relatively stable annual rate of about 0.75% from 1985 to 2000, and then jumped to 1.4% per year from 2001 through 2008.
There is no way to know whether the rate of growth of multifactor productivity will remain at its current level or will revert to the pre-2000 pace.
Assuming slower growth in the labor force than in the past decade, no rise in productivity due to capital accumulation, and a decline in multifactor productivity growth to its pre-2000 average implies that annual potential GDP growth will be only 1.4%.
Combining these conservative assumptions about potential GDP with the effect of the cyclical rebound – an estimated 1.2% annual rise in real GDP – would produce real GDP growth at an average annual rate of 2.6%, which would be significantly higher than the 1.9% rate in the decade ending in 2009.
But not all of the extra output produced over the next decade will remain in the US.
If the trade deficit is reduced by 3% of GDP between now and the end of the decade, the implied rise in exports and decline in imports would reduce output available for US consumption and investment by about 0.3% per year.
The effect of a decline in the dollar over the coming decade could be equally important.
If the real trade-weighted value of the dollar falls by 25% over the coming decade, and the full effect of that dollar decline is reflected in import prices, the increased cost of imports would reduce the growth of US real incomes by about 0.4% a year.
These two international effects would leave annual net growth of real goods and services available for US consumption and investment – both domestically produced and imported – at just 1.9%, implying no change compared to the past decade.
During those years, the rise in the volume of net imports just balanced the effect of the dollar’s fall on the total cost of imports.
As a result, the rise in the real value of goods and services available for US consumption and investment was the same as the rise of real GDP.
There are, of course, serious downside risks to this forecast, especially if the fiscal deficit remains high or adverse tax policies depress the rise in productivity.
The government should take the weak ten-year projection as a warning and a reason to devote policies to reducing fiscal deficits and strengthening incentives for growth.
America’s Houses of Cards
There are times when being proven right brings no pleasure.
For several years, I argued that America’s economy was being supported by a housing bubble that had replaced the stock market bubble of the 1990’s.
But no bubble can expand forever.
With middle-class incomes in the United States stagnating, Americans could not afford ever more expensive homes.
As one of my predecessors as Chairman of the US President’s Council of Economic Advisers famously put it, “that which is not sustainable will not be sustained.” Economists, as opposed to those who make their living gambling on stocks, make no claim to being able to predict when the day of reckoning will come, much less identifying the event that will bring down the house of cards.
But the patterns are systematic, with consequences that unfold gradually, and painfully, over time.
There is a macro-story and a micro-story here.
The macro-story is simple, but dramatic.
Some, observing the crash of the sub-prime mortgage market, say, “Don’t worry, it is only a problem in the real estate sector.” But this overlooks the key role that the housing sector has played in the US economy recently, with direct investment in real estate and money taken out of houses through refinancing mortgages accounting for two-thirds to three-quarters of growth over the last six years.
Booming home prices gave Americans the confidence, and the financial wherewithal, to spend more than their income.
America’s household savings rate was at levels not seen since the Great Depression, either negative or zero.
With higher interest rates depressing housing prices, the game is over.
As America moves to, say, a 4% savings rate (still small by normal standards), aggregate demand will weaken, and with it, the economy.
The micro-story is more dramatic.
Record-low interest rates in 2001, 2002 and 2003 did not lead Americans to invest more – there was already excess capacity.
Instead, easy money stimulated the economy by inducing households to refinance their mortgages, and to spend some of their capital.
It is one thing to borrow to make an investment, which strengthens balance sheets; it is another thing to borrow to finance a vacation or a consumption binge.
But this is what Alan Greenspan encouraged Americans to do.
When normal mortgages did not prime the pump enough, he encouraged them to take out variable-rate mortgages – at a time when interest rates had nowhere to go but up.
Predatory lenders went further, offering negative amortization loans, so the amount owed went up year after year.
Sometime in the future, payments would rise, but borrowers were told, again, not to worry: house prices would rise faster, making it easy to refinance with another negative amortization loan.
The only way (in this view) not to win was to sit on the sidelines.
All of this amounted to a human and economic disaster in the making.
Now reality has hit: newspapers report cases of borrowers whose mortgage payments exceed their entire income.
Globalization implies that America’s mortgage problem has worldwide repercussions.
The first run on a bank occurred against the British mortgage lender Northern Rock.
America managed to pass off bad mortgages worth hundreds of billions of dollars to investors (including banks) around the world.
They buried the bad mortgages in complicated instruments, buried them so deep that no one knew exactly how badly they were impaired, and no one could calculate how to re-price them quickly.
In the face of such uncertainty, markets froze.
Those in financial markets who believe in free markets have temporarily abandoned their faith.
For the greater good of all (of course, it is never for their own selfish interests), they argued a bailout was necessary.
While the US Treasury and the IMF warned East Asian countries facing financial crises ten years ago against the risks of bail-outs and told them not to raise their interest rates, the US ignored its own lectures about moral hazard effects, bought up billions in mortgages, and lowered interest rates.
But lower short-term interest rates have led to higher medium-term interest rates, which are more relevant for the mortgage market, perhaps because of increasing worries about inflationary pressures.
It may make sense for central banks (or Fannie Mae, America’s major government-sponsored mortgage company) to buy mortgage-backed securities in order to help provide market liquidity.
But those from whom they buy them should provide a guarantee, so the public does not have to pay the price for their bad investment decisions.
Equity owners in banks should not get a free ride.
Securitization, with all of its advantages in sharing risk, has three problems that were not adequately anticipated.
While it meant that American banks were not hit as hard as they would otherwise, America’s bad lending practices have had global effects.
Moreover, securitization contributed to bad lending: in the old days, banks that originated bad loans bore the consequences; in the new world of securitization, the originators could pass the loans onto others.
(As economists would say, problems of asymmetric information have increased.)
In the old days, when borrowers found it impossible to make their payments, mortgages would be restructured; foreclosures were bad for both the borrower and the lender.
Securitization made debt restructuring difficult, if not impossible.
It is the victims of predatory lenders who need government help.
With mortgages amounting to 95% or more of the value of the house, debt restructuring will not be easy.
What is required is to give individuals with excessive indebtedness an expedited way to a fresh start – for example, a special bankruptcy provision allowing them to recover, say, 75% of the equity they originally put into the house, with the lenders bearing the cost.
There are many lessons for America, and the rest of the world; but among them is the need for greater financial sector regulation, especially better protection against predatory lending, and more transparency.
America’s Interest-Rate Puzzle
A great puzzle in today’s world economy is the continued low level of long-term real interest rates in the United States.
Conventional macroeconomists like me look at America’s current-account deficit, now running at 7% of GDP, and know that such vast deficits are inevitably followed by large currency depreciations.
So we expect a substantial depreciation premium on US interest rates.
If the dollar falls 20% more against the euro sometime in the next ten years, US long-term interest rates should be two percentage points higher than euro rates.
If it falls 40% against the yen sometime in the next ten years, US long-term interest rates should be four percentage points higher than Japanese rates.
If it falls 60% against China’s currency, the yuan, sometime in the next ten years, US long-term interest rates should be six percentage points higher than Chinese rates.
But we are not seeing signs of anything like this.
The puzzle is not only that long-term rates are too low when viewed in the international context, but also that they are too low when viewed in America’s domestic context.
The Bush administration continues to have no plans to sew up the veins it has opened with its medieval economic policy, which holds that bleeding revenue from the government cures all economic problems.
This means that unless America’s domestic savings rate rises mightily – which it shows no signs of doing – and unless investment expenditure remains abnormally low for the rest of this decade, the supply of loanable funds to finance investment will soon be much less than demand when the current-account deficit narrows to sustainable levels.
But when supply is less than demand, prices rise sharply.
In this case, the price of loanable funds is the real interest rate.
An expectation that interest rates will be high sometime in the next decade should mean high interest rates on long-term bonds today.
Yet financial markets are not pricing dollar depreciation and a rise in long-term US interest rates accordingly.
When we macroeconomists talk to our friends on Wall Street, we find that they don’t view this as a puzzle at all.
On the contrary, they are puzzled about why we view the current low level of US long-term interest rates as worrisome.
From their perspective, today’s high demand for long-term dollar-denominated securities is easily explained: Asian central banks are buying in order to hold down their currencies, the US Treasury is borrowing short (and thus not issuing that many long-term securities), and US companies are not undertaking the kinds of investments that would lead them to issue many long-term bonds.
But for every market mispricing there is a profit opportunity: if long-term interest rates are, indeed, too low and long-term bond prices too high, investors will short long-term US bonds, park the money elsewhere, wait for bond prices to return to fundamentals, and then cover their short positions.
By doing so, they will push prices close to fundamentals today.
Wall Streeters, however, offer a counterargument: for any financial institution to, say, bet on the decline of the dollar against the yuan over the next five years in a serious, leveraged way is to put its survival at risk should the trades go wrong.
And trades do go wrong: remember the collapse of Long-Term Capital Management.
The existence of large financial-market actors that do not care about maximizing their profits magnifies the riskiness of the bets.
If, say, the Bank of China and the Federal Reserve decided to teach speculators a lesson by pushing the dollar’s value relative to the yuan up by 20% for a month, they could do so, bankrupting many financial institutions with short positions.
Similarly, any financial institution that bets on a sharp rise in long-term interest rates over the next five years in a serious, leveraged way also puts its survival at risk.
For where should they park their money?
Real estate rental yields and stock-market payouts are low, and real estate and stock prices may well fall as much as or more than bond prices if interest rates spike.
Only businesses that can borrow long-term now, lock in a low real interest rate, and invest in expanding their capacity can make the domestic bet that interest rates will rise.
But America’s businesses see enough risk in the future to be wary of getting stuck with unutilized capacity.
Economists believe that market forces drive prices to fundamentals.
But we are not careful enough to distinguish situations in which equilibrium-restoring forces are strong from those in which such forces are weak.
The dollar will fall and US long-term interest rates will rise, but only when traders on Wall Street and elsewhere decide that holding dollars and long-term US bonds is more risky in the short run.
When that happens, the long-run future will be now.
America’s Islamist Allies of Convenience
NEW DELHI – In just one decade, the United States has intervened militarily in three Muslim-majority countries and overthrown their governments.
Now the same coalition of American liberal interventionists and neoconservatives that promoted those wars is pushing for punitive airstrikes in Syria without reflecting on how US policy has ended up strengthening Islamists and fostering anti-Americanism.
Indeed, the last “humanitarian intervention” has clearly backfired, turning Libya into a breeding ground for transnational militants.
As the intense US debate about President Barack Obama’s proposed use of military force highlights, the attack-Syria push is not about upholding America’s national interest.
Rather, the desire to protect US “credibility” has become the last refuge of those seeking yet another war in the wider Middle East.
If “credibility” were purged from the debate and the focus placed squarely on advancing long-term US interests, it would become apparent that an attack on Syria might not yield even temporary geopolitical gains.
Beyond the short term, it would unleash major unintended consequences, potentially including an Iraq-style “soft” partition of Syria and the creation of a haven for extremists stretching across much of Islamist-controlled northern Syria and into the Sunni areas of Iraq.
Indeed, an attack would most likely increase America’s reliance on unsavory Islamist rulers in countries ranging from Saudi Arabia and Qatar to Turkey and the United Arab Emirates.
Some Arab monarchs have pledged to bankroll the US attack – an investment that they would easily recover, given that the war talk has already increased oil prices.
Al Qaeda-type groups already have gained ground in the Middle East and North Africa as an unintended byproduct of US policies, creating fertile conditions for stepped-up international terrorism in the coming years.
The US invasion and occupation of Iraq, for example, created a major opening for Al Qaeda, whose affiliates now represent the Sunni struggle against the Shia-dominated government.
Likewise, regime change in Libya aided the rise of Al Qaeda-linked militants, leading to the killing in Benghazi of the US ambassador.
A system based on sharia (Islamic law) has been imposed, human-rights abuses are legion, and cross-border movement of weapons and militants has undermined the security of Libya’s neighbors.
Meanwhile, America’s support for the regimes in Yemen and Saudi Arabia has contributed to the rise of Al Qaeda in the Arabian Peninsula.
In parts of southern Yemen, an Al Qaeda affiliate, Ansar al-Sharia, functions as a de facto government.
In Syria, where sizable chunks of territory are already under Islamist control and the pro-Al Qaeda Al Nusra Front overshadows the US-backed Free Syrian Army, the Obama administration is staring at the bitter harvest of its previous policy choices.
Airstrikes now would merely make matters worse by undercutting the FSA’s grassroots legitimacy and aiding Islamist forces.
Farther east, the US wants an “honorable” exit from Afghanistan – the longest war in its history – through a peace deal with the Taliban, its main battlefield opponent.
In seeking to co-opt the Taliban – an effort that has resulted in the Taliban establishing what amounts to a diplomatic mission in Doha, Qatar – the US is bestowing legitimacy on a thuggish militia that enforces medieval practices in the areas under its control.
America’s dalliances with Islamist-leaning political forces – and governments – have been guided by the notion that the cloak of Islam helps to protect the credibility of leaders who might otherwise be seen as foreign puppets.
That simply will not work, even in the short term.
On the contrary, until the Egyptian army removed him from the presidency, the Muslim Brotherhood’s Mohamed Morsi was coming to be seen by many as America’s man in Cairo.
In the long term, the US will gain nothing – and risk much – by continuing to back oil sheikhdoms that fund Muslim extremist groups and madrasas from the Philippines and India to South Africa and Venezuela.
By supporting Islamist rulers, the US is contributing to a trend evident from the Maghreb to the badlands of Afghanistan and Pakistan – Muslims killing Muslims.
American policy has also contributed to a growing conflict between Islamist and secular forces in Muslim countries.
This is best illustrated by Turkey, where Obama has ignored Prime Minister Recep Tayyip Erdoğan’s heavy-handed efforts to annul free speech and turn himself into a twenty-first-century Sultan.
There and elsewhere, the US, motivated by the larger geopolitical goal of containing Shia Iran and its regional allies, has embraced Sunni rulers steeped in religious and political bigotry, even though they pose a transnational threat to the values of freedom and secularism.
Moreover, the clash within Islam is likely to be destabilizing regionally and counterproductive to the interests of the free world.
Against this background, Obama should heed the doctrine proposed in 1991 by General Colin Powell.
The Powell doctrine stipulates that the US should use military force only when a vital national-security interest is at stake; the strategic objective is clear and attainable; the benefits are likely to outweigh the costs; adverse consequences can be limited; broad international and domestic support has been obtained; and a plausible exit strategy is in place.
Given the US record since the doctrine was formulated, another criterion should be added: the main beneficiaries of military intervention are not America’s mortal enemies.
Drone Wars
BRUSSELS – “Sometime they’ll give a war and nobody will come,” the American poet Carl Sandburg wrote hopefully in 1936.
His sentiment seems more apt than ever nowadays, but not because humanity has turned pacifistic.
Rather, wars are increasingly fought remotely, with drones – or unmanned aerial vehicles (UAVs) – doing the killing.
Under President Barack Obama, the number of drone strikes carried out by the United States has soared, with more than 300 UAV attacks reported in Pakistan alone.
In March 2011, the US Air Force for the first time trained more pilots for drones than for any other purpose.
This raises serious ethical questions.
With no military personnel risking their lives, UAVs make it easier to kill, and to justify war operations to the public at home.
Moreover, a human being’s reticence to kill is inversely related to the distance between attacker and target.
In the case of a pilot flying drones over Yemen by operating a joystick in Nevada, the threshold to pulling the trigger is dangerously low.
Killing is just a part of the job, to be followed by bowling, perhaps, or a quiet evening at home.
Meanwhile, the mere sound of drones terrorizes whole populations, indicating to enemies and civilians alike that they are being watched and might be attacked at any moment – which could well play into the hands of terrorist recruiters.
From a legal and human-rights point of view, the US drone program is even more alarming.
After all, countries such as Pakistan, Yemen, and Somalia do not belong to declared war zones.
Outside the context of war, in turn, state killings are legal only if they prove absolutely necessary to save lives.
They must be conducted either in self-defense after an attack, or in anticipatory self-defense against an immediate threat, when taking time to discuss non-lethal alternatives is not feasible.
More than a decade after September 11, America’s drone program does not fall into the first category of reactive self-defense.
Likewise, there is no evidence that any presumed terrorist who was killed outside of official war zones in the last few years represented a threat so immediate to US citizens’ lives that preventive and premeditated killing was the only option.
Unless US leaders prove otherwise in every case, American UAV attacks in countries like Pakistan or Yemen should be called what they are: extrajudicial killings.
US State Department legal adviser Harold Koh disagrees, arguing that America is involved in a worldwide “armed conflict with Al Qaeda, as well as the Taliban and associated forces.”
So, Koh claims, drone attacks are part of a global war, fought both in declared war zones and non-war countries; therefore, they are legal.
But, even under this adventurous assumption, human-rights issues arise.
The laws of war condone targeted killings only of “combatants” who “directly participate in hostilities.”
The killings must be proportionate, strategically necessary, and publicly justified.
Avoiding harm to civilians should be the top priority.
At the slightest sign of illegality, an investigation must be conducted, offenders prosecuted, and victims compensated.
The US drone program’s legal basis is entirely unclear, however.
Given that most information about UAV activity is classified, it is impossible to know whether all drone targets directly participated in hostilities.
And, while the Obama administration’s claim of zero or single-digit civilian fatalities may be true according to the official definition, it rests on the premise that any military-age male killed in a drone strike is a militant, unless intelligence posthumously proves otherwise.
A recent report by the law schools at Stanford University and New York University concludes that, in reality, civilian casualties in Pakistan may have accounted for up to 75% of all UAV victims between 2008 and 2011.
Others estimate a lower, but still alarming, rate of 30%.
The legal obligation of proportionality is clearly being violated.
Accountability is also being flouted.
Drone operations are carried out by the Central Intelligence Agency, an organization whose activities are shrouded in secrecy.
And, unlike military personnel, CIA agents enjoy extensive immunity, undermining international legal standards.
Without increased transparency, to declare America’s UAV campaign legal is impossible, both in the context of war and outside of armed conflict.
As long as the US keeps the rest of the world in the dark, illegal acts – including possible war crimes – may be committed with impunity.
Just as citizens worldwide are demanding increased economic and financial accountability, more pressure must be placed on the US to either prove that its drone activities are necessary and legal, or to stop them immediately.
Victims of UAV attacks, their families, and civil-society groups have begun to speak out against America’s questionable drone campaign, and to pursue legal action.
Others should feel encouraged to follow suit.
In the meantime, every drone strike will not only undermine human rights and international humanitarian law, but will also further widen a legal loophole that other governments and armed groups will not hesitate to exploit.
The US drone program does not make the world a safer place; it creates an environment in which unlawful killings can happen virtually anywhere, at any time, violating the fundamental human right not to be arbitrarily deprived of one’s life.
America’s Locust Years
BERKELEY – It is hard right now to write about American political economy.
Nobody knows whether the debt-ceiling tripwire will be evaded; if so, how; or what will happen if it is not.
If no deal to raise the debt ceiling is reached by August 3, interest rates on United States Treasury bonds could spike, or they could remain stable, as investors decide they have other problems to worry about.
Or the US Federal Reserve, the Peoples Bank of China (PBC), or both – or even some other body – could support the market.
Or interest rates could rise if people expect a much weaker global economy – and, in a weaker global economy with no inflation, investors should be holding more US Treasuries, not fewer.
Frankly, no one knows what legislative deal will be struck to raise the debt ceiling.
All we know as of this writing is that a deal would probably involve cuts in near-term spending, meaning weaker growth and higher unemployment over the next 18 months.
And we can assume that it would be repealed and replaced by something else come January 2013, either by a re-elected President Barack Obama, or by a new, Republican president.
So, rather than talking about the US debt ceiling, let us think instead about all of the things that the debt-ceiling impasse has prevented the US government from doing during the past six months – all of the useful policies that might have been debated and enacted, but were not.
The risks imposed by global warming, for example, have not gone away.
The sooner the world starts preparing to deal with those threats, the better.
Another six months should not be lost.
The employment-to-population ratio in the US remains flat – mired at the very low levels to which it fell during the recession.
With households desperately trying to rebuild their balance sheets, and with capital investment remarkably healthy, the only places to boost spending to restore capacity utilization and unemployment to normal levels are exports, government purchases, and construction investment.
But opportunities to pursue the necessary policies have not been grasped.
Here, too, another six months should not be lost.
Likewise, the US could have fulfilled its normal role as the conductor of the international economic orchestra.
It has not, even as the European Union continues to respond inadequately to its own slow-moving solvency crises.
The mandarins of northern Europe continue to measure out a drip-feed of support with coffee spoons.
Another six months have been lost.
America faces long-run and short-run problems: decaying infrastructure, weakening educational systems, and a dysfunctional health-care system that produces sub-standard outcomes at twice the cost of any other industrial country.
Solving any of these three problems would go a long way toward resolving the long-run financing imbalance between current tax rates and America’s long-run social-insurance promises that the debt-ceiling debate’s instigators supposedly want to address.
But the US government won’t address them.
Six months that could have been spent boosting the long-run growth potential of the American economy through infrastructure investment, educational reform, or an overhaul of health-care financing – greatly easing America's long-run deficit and debt dilemmas in the process – have been lost.
During the run-up to World War II, Winston Churchill, speaking in Parliament, lamented “the years that the locusts hath eaten” – the period during which preparatory action to face the great crisis of his day (the rise of Continental fascism) could have been taken, but was not.
Over the past century – with the notable exception of the Great Depression – the US political system has been remarkably good at foreseeing crises long before they have happened, and at least setting the foundation for dealing with them when they have occurred.
But so far in the third millennium, this skill – or simply run of luck – has deserted the US.
My view is that the problem would fix itself easily if only the Republican Party of Dwight D. Eisenhower could stage a comeback (though without Richard Nixon and Joseph McCarthy).
It is becoming increasingly clear, however, that the problem is one not only for the US, but for the rest of the world as well.
Since December 7, 1941, the world has in large part been able to rely on global governance by a somewhat-competent hyperpower.
That America may be gone for good.
If it is, the world needs to develop other institutions for global management – and quickly.
America’s Misplaced Deficit Complacency
CAMBRIDGE – The United States still faces a dangerous fiscal deficit, but one might not know it from the complacency that dominates budget discussions in Washington.
Regarded as an urgent problem until recently, the federal deficit is now being placed on the back burner of American politics.
The shift in thinking was triggered by the revised deficit forecasts recently published by the Congressional Budget Office, the independent technical agency responsible for advising Congress on budget issues.
According to the CBO’s report, the US fiscal deficit will decline from 7% of GDP in 2012 to 4% in 2013.
This reduction reflects the cuts in government spending on defense and non-defense programs mandated by the budget “sequester” that took effect in March, as well as the rise in revenue caused by higher rates for income and payroll taxes since the end of 2012.
More striking is the CBO’s projection that the deficit will continue to decline rapidly, reaching just 2.1% of GDP in 2015, before rising gradually to just 3.5% of GDP in 2023, the end of the CBO’s official forecast period.
That path of deficits implies that the government debt/GDP ratio will remain at about the current level of 75% for the next ten years.
Unfortunately, these headline-grabbing numbers are not likely to be borne out in reality; indeed, even the CBO does not believe that they represent what will occur.
Instead, these official forecasts represent a “baseline” scenario that the CBO is required to present.
The CBO’s “baseline budget” assumes that all of the deficit-reducing features in current law will remain unchanged.
These include, for example, an old legislative requirement that payments to physicians in the government’s Medicare program be reduced sharply in future years, a requirement that Congress has voted each year to “postpone.”
In order to provide better guidance, the CBO presents an “alternative fiscal scenario,” in which such very unlikely features are removed from the forecast.
The alternative forecast implies that the annual budget deficit at the end of ten years will be back up to 4.7% of GDP, with the debt/GDP ratio at 83% and rising.
And those estimates are based on the optimistic assumption that the economy will have returned gradually to full employment with low inflation and moderate interest rates.
Officials and others who favor stimulating growth through increased government spending ignore the CBO’s more realistic alternative scenario.
They buttress their argument that the deficit is not an immediate problem by pointing to very low interest rates on long-term government debt, with a 2% yield on the ten-year Treasury bond and a negative real interest rate on Treasury inflation-protected bonds (TIPS).
But such low rates do not reflect ordinary market sentiment; rather, they stem from the fact that the Federal Reserve is now buying more long-term securities than the government is issuing to finance the budget deficit.
Looking further ahead, the CBO warns that the combination of a rapidly aging population and the increase in medical costs will cause the deficit to rise rapidly, driven by the higher costs of pension and health-care benefits for middle-income retirees.
According to the CBO, without legislative changes, the fiscal deficit in 2037 will be 17% of GDP, while the national debt will increase to more than 195% of GDP.
A large and rising national debt is a serious danger to an economy’s health.
Higher debt-service costs require higher tax rates, which in turn weaken incentives and reduce economic growth.
By the end of the decade, the US will have to pay an amount equivalent to more than one-third of the revenue from personal-income taxes just to pay the interest on the national debt.
Foreign investors now hold more than half of that debt.
Paying interest to them requires sending more goods and services to the rest of the world than the US receives from the rest of the world.
That requires a weaker dollar to make US goods more attractive to foreign buyers and to make foreign goods more expensive to American consumers.
The weaker dollar reduces the US standard of living.
A large national debt also limits the government’s ability to respond to emergencies, including both military threats and economic downturns.
And it makes the US vulnerable to changes in financial-market sentiment, as the European experience has shown.
Reducing future deficits and reversing the rise in the national debt require raising tax revenue and slowing the growth of government pension and health-care programs.
Tax revenue can be raised without increasing marginal tax rates by limiting the tax subsidies that are built into the current tax code.
Those subsidies are a hidden form of government spending on everything from home mortgages and health insurance to the purchase of hybrid cars and residential solar panels.
Slowing the growth of the pension and health-care programs for middle-class retirees cannot be done abruptly.
It must begin by giving notice to those who are now a decade away from retirement – which is why it is important to launch such reforms now.
Unfortunately, the new complacency about future deficits makes it difficult, if not impossible, to enact the legislation needed to begin the process of trimming America’s long-term fiscal deficit.
It is important for policymakers and the public alike to understand the real fiscal outlook and the damage that high deficits will cause if prompt action is not taken.
Merely moving the problem to the back burner will not prevent it from boiling over.
Meeting America’s Growth Challenge
BERKELEY – The United States continues to recover from its deepest economic slump since the Great Depression, but the pace of recovery remains frustratingly slow.
There are several reasons to anticipate modest improvement in 2013, although, as usual, there are downside risks.
Prolonged recession or a financial crisis in Europe and slower growth in emerging markets are the main external sources of potential danger.
At home, political infighting underlies the two greatest risks: failure to reach a deal to raise the debt ceiling and an additional round of fiscal contraction that stymies economic growth.
Since 2010, tepid average annual GDP growth of 2.1% has meant weak job creation.
In both this recovery and the previous two, the rebound in employment growth has been weaker and later than the rebound in GDP growth.
But the loss of jobs in the most recent recession was more than twice as large as in previous recessions, so a slow recovery has meant a much higher unemployment rate for a much longer period.
Weak aggregate demand is the primary culprit for subdued GDP and employment growth.
The 2008 recession was triggered by a financial crisis that erupted after the collapse of a credit-fueled asset bubble decimated the housing market.
Private-sector demand contracts sharply and recovers only slowly after such crises.
The private-sector financial balance swung from a deficit of 3.7% of GDP in 2006, at the height of the boom, to a surplus of about 6.8% of GDP in 2010 and about 5% today.
This represents the sharpest contraction and weakest recovery in private-sector demand since the end of World War II.
Growth in two components of private demand, residential investment and consumption, which account for more than 75% of total spending in the US economy, has been especially slow.
Both sources of demand are likely to strengthen in 2013.
Residential investment is still at an historic low as a share of GDP as a result of overbuilding during the 2003-2008 housing boom and the tsunami of foreclosures that followed.
But the headwinds in the housing market are dissipating.
Home sales, prices, and construction all rose last year, while foreclosures declined.
Residential investment should be a source of output and job growth this year.
Large losses in household wealth, deleveraging from unsustainable debt, weak wage growth, and a decline in labor’s share of national income to a historic low have combined to constrain consumption growth.
Real median household income is still nearly 7% below its 2007 peak, real median household net worth dropped by 35% between 2005 and 2010 (and remains significantly below its pre-recession peak), and about 90% of the income gains during the recovery have gone to the top 1%.
To be sure, the balance-sheet headwinds holding back consumption have eased.
Households have slashed their debt – often through painful foreclosures and bankruptcies – and their debt relative to income has sunk to its 2005 level, significantly below its 2008 peak. &#160;Helped by low interest rates, debt service relative to household income has fallen back to levels not seen since the early 1980’s.
But consumption will be hit by the expiration of the payroll tax cut, which will reduce household income by about $125 billion this year.
Another factor holding back recovery has been weak growth in spending on goods and services by both state and local governments, and more recently by the federal government.
Indeed, since the recession’s onset, state and local governments have cut nearly 600,000 jobs and reduced spending for infrastructure projects by 20%.
The fiscal trends for 2013 are mixed, but negative overall.
While state and local government cutbacks in spending and employment are ending as the recovery boosts their tax revenues, the fiscal drag at the federal level is strengthening.
The American Taxpayer Relief Act – the tax deal reached in early January to avoid the “fiscal cliff” – shaves about $750 billion from the deficit over the next ten years and could take a percentage point off the 2013 growth rate.
In addition, although less widely appreciated, significant reductions in federal spending are already under way, with more likely to come.
Spending cuts and revenue increases that have been legislated since 2011 will reduce the projected deficit by $2.4 trillion over the next decade, with three-quarters coming from spending cuts, almost exclusively in non-defense discretionary programs.
Based on current economic assumptions, the US needs about $4 trillion in savings to stabilize the debt/GDP ratio over the next decade.
It is already three-fifths of the way there.
The so-called sequester (the across-the-board spending cuts scheduled to begin in March), would slash another $100 billion this year and $1.2 trillion over the next decade.
Although it could stabilize the debt/GDP ratio, the sequester would be a mistake: it fails to distinguish among spending priorities, would undermine essential programs, and would mean another significant dent in growth this year.
Moreover, despite the warnings of deficit alarmists, the US does not face an imminent debt crisis.
Currently, the federal debt held by the public is just over 70% of GDP, a level not seen since the early 1950’s.
However, government debt soars by an average of 86% after severe financial crises, so the increase in the federal debt by 70% between 2008 and 2012 is not surprising.
Nor is it alarming.
The US economy grew rapidly for several years after WWII with a higher debt/GDP ratio, and today’s ratio is lower than in all other major industrial countries (and roughly half that of Greece, analogies to which are absurd and misleading).
During the last two years, Washington has been obsessed with the need to cut the deficit and put the debt/GDP ratio on a “sustainable” path, even as global investors have flocked to US government debt, driving interest rates to historic lows.
The considerable progress that has been made on deficit reduction over the next ten years has been overlooked.
Also overlooked have been the immediate challenges of low growth, weak investment, and high unemployment.
It is time to refocus.
The US needs a plan for faster growth, not more deficit reduction.
Evsey Domar, a legendary growth economist (and one of my MIT professors) counseled that the problem of alleviating the debt burden is essentially a problem of achieving growth in national income.
We should heed his wisdom.
America’s New Progressive Era?
NEW YORK – In 1981, US President Ronald Reagan came to office famously declaring that, “Government is not the solution to our problem.
Government is the problem.”
Thirty-two years and four presidents later, Barack Obama’s recent inaugural address, with its ringing endorsement of a larger role for government in addressing America’s – and the world’s – most urgent challenges, looks like it may bring down the curtain on that era.
Reagan’s statement in 1981 was extraordinary.
It signaled that America’s new president was less interested in using government to solve society’s problems than he was in cutting taxes, mainly for the benefit of the wealthy.
More important, his presidency began a “revolution” from the political right – against the poor, the environment, and science and technology – that lasted for three decades, its tenets upheld, more or less, by all who followed him: George H. W. Bush, Bill Clinton, George W. Bush, and, in some respects, by Obama in his first term.
The “Reagan Revolution” had four main components: tax cuts for the rich; spending cuts on education, infrastructure, energy, climate change, and job training; massive growth in the defense budget; and economic deregulation, including privatization of core government functions, like operating military bases and prisons. Billed as a “free-market” revolution, because it promised to reduce the role of government, in practice it was the beginning of an assault on the middle class and the poor by wealthy special interests.
These special interests included Wall Street, Big Oil, the big health insurers, and arms manufacturers.

They demanded tax cuts, and got them; they demanded a rollback of environmental protection, and got it; they demanded, and received, the right to attack unions; and they demanded lucrative government contracts, even for paramilitary operations, and got those, too.
For more than three decades, no one really challenged the consequences of turning political power over to the highest bidders.
In the meantime, America went from being a middle-class society to one increasingly divided between rich and poor. CEOs who were once paid around 30 times what their average workers earned now make around 230 times that amount.
Once a world leader in the fight against environmental degradation, America was the last major economy to acknowledge the reality of climate change.
Financial deregulation enriched Wall Street, but ended up creating a global economic crisis through fraud, excessive risk-taking, incompetence, and insider dealing.
Maybe, just maybe, Obama’s recent address marks not only the end of this destructive agenda, but also the start of a new era.
Indeed, he devoted almost the entire speech to the positive role of government in providing education, fighting climate change, rebuilding infrastructure, taking care of the poor and disabled, and generally investing in the future.
It was the first inaugural address of its kind since Reagan turned America away from government in 1981.
If Obama’s speech turns out to mark the start of a new era of progressive politics in America, it would fit a pattern explored by one of America’s great historians, Arthur Schlesinger, Jr., who documented roughly 30-year intervals between periods of what he called “private interest” and “public purpose.”
In the late 1800’s, America had its Gilded Age, with the creation of large new industries by the era’s “robber barons” accompanied by massive inequality and corruption.
The subsequent Progressive Era was followed by a temporary return to plutocracy in the 1920’s.
Then came the Great Depression, Franklin Roosevelt’s New Deal, and another 30 years of progressive politics, from the 1930’s to the 1960’s.
The 1970’s were a transition period to the Age of Reagan – 30 years of conservative politics led by powerful corporate interests.
It is certainly time for a rebirth of public purpose and government leadership in the US to fight climate change, help the poor, promote sustainable technologies, and modernize America’s infrastructure. If America realizes these bold steps through purposeful public policies, as Obama outlined, the innovative science, new technology, and powerful demonstration effects that result will benefit countries around the world.
It is certainly too early to declare a new Progressive Era in America.
Vested interests remain powerful, certainly in Congress – and even within the White House.
These wealthy groups and individuals gave billions of dollars to the candidates in the recent election campaign, and they expect their contributions to yield benefits.
Moreover, 30 years of tax cutting has left the US government without the financial resources needed to carry out effective programs in key areas such as the transition to low-carbon energy.
Still, Obama has wisely thrown down the gauntlet, calling for a new era of government activism.
He is right to do so, because many of today’s crucial challenges – saving the planet from our own excesses; ensuring that technological advances benefit all members of society; and building the new infrastructure that we need nationally and globally for a sustainable future – demand collective solutions.
Implementation of public policy is just as important to good governance as the vision that underlies it.
So the next task is to design wise, innovative, and cost-effective programs to address these challenges.
Unfortunately, when it comes to bold and innovative programs to meet critical human needs, America is out of practice.
It is time to begin anew, and Obama’s full-throated defense of a progressive vision points the US in the right direction.
America’s New Trade Hypocrisy
As the current “development round” of trade talks moves into its final stages, it is becoming increasingly clear that the goal of promoting development will not be served, and that the multilateral trade system will be undermined.
Nowhere is this clearer than in a provision that is supposed to give the least developed countries almost duty-free access to developed countries’ markets.
A year ago, the leaders of the world’s richest countries committed themselves to alleviating the plight of the poorest.
At Doha in November 2001, they pledged to give something more valuable than money: the opportunity for poor countries to sell their goods and earn their way out of poverty.
With great fanfare, developed countries seemed for a while to be making good on their promise, as Europe extended the “Everything but Arms” initiative (EBA), under which it was unilaterally to open its markets to the poorest countries of the world.
The opening was less than it seemed.
The devil is in the details, as many less developed countries discovered that EBA’s complicated rules of origin, together with supply-side constraints, meant that there was little chance for poor countries to export their newly liberalized products.
But the coup de grace was delivered by the world’s richest country, the United States, which once again decided to demonstrate its hypocrisy.
The US ostensibly agreed to a 97% opening of its markets to the poorest countries.
The developing countries were disappointed with the results of Europe’s EBA initiative, and Europe has responded by committing itself to dealing with at least part of the problem that arises from the rules of origin tests.
America’s intention was, to the contrary, to seem to be opening up its markets, while doing nothing of the sort, for it appears to allow the US to select a different 3% for each country.
The result is what is mockingly coming to be called the EBP initiative: developing countries will be allowed freely to export everything but what they produce .
They can export jet engines, supercomputers, airplanes, computer chips of all kinds—just not textiles, agricultural products, or processed foods, the goods they can and do produce.
Consider Bangladesh. If we go by the most widely used six-digit tariff lines, Bangladesh exported 409 tariff lines to the US in 2004, from which it earned about $2.3 billion.
But its top 12 tariff lines – 3% of all tariff lines – accounted for 59.7% of the total value of its exports to the US.
This means that the US could erect barriers to almost three-fifths of Bangladeshi exports.
For Cambodia, the figure would be about 62%.
The situation is no better if the 3% rule applies to the tariff lines that the US imports from the rest of the world (rather than to the lines individual poor countries export to the US), for then the US can exclude roughly 300 tariff lines from duty-free and quota-free treatment.
For Bangladesh, this implies that 75% of the tariff lines, accounting for more than 90% of the value of its exports to the US, could be excluded from duty-free treatment.
Exclusion from duty-free treatment could reach 100% for Cambodia, which exported only 277 tariff lines to the US in 2004.
The official argument for the 3% exclusion is that it affects “sensitive products.”
In other words, while the US lectures developing countries on the need to face the pain of rapid adjustment to liberalization, it refuses to do the same.
(Indeed, it has already had more than 11 years to adjust to liberalization of textiles.)
But the real problem is far worse because the 3% exclusion raises the specter of an odious policy of divide and conquer, as developing countries are invited to vie with each other to make sure that America does not exclude
Indeed, there may be a further hidden agenda behind the 97% proposal.
At the World Trade Organization’s meeting Cancun in 2003, the developing countries stood together and blocked efforts to forge a trade agreement that was almost as unfair as the previous Uruguay round, under which the poorest countries actually became worse off.
It was imperative that such unity be destroyed.
America’s strategy of bilateral trade agreements was aimed at precisely that, but it enlisted only a few countries, representing a fraction of global trade.
The 97% formula holds open the possibility of extending that fragmentation
The US has already had some success in pitting the poor against each other.
Preferential access for African countries, under the African Growth and Opportunity Act (AGOA) and more recent initiatives, seems to be largely a matter of trade diversion – taking trade from some poor countries and giving it to others.
For example, Bangladesh’s share in US clothing markets declined from 4.6% in 2001 to 3.9% in 2004.
During the same period, AGOA countries’ market share in the US clothing sector increased from 1.6% to 2.6%, and it is likely to increase further when AGOA countries start to take full advantage of duty-free access.
AGOA had a sunset clause, but if the duty-free access becomes permanent for less developed countries in Africa – as stipulated in Hong Kong – then poor countries in Asia will continue to lose US market share.
The WTO is supposed to prevent these trade-diversionary agreements, but so far no case has been successfully brought.
Even if America succeeds in dividing the developing countries, however, it may inspire a degree of unity elsewhere.
Both those committed to trade liberalization within a multilateral system and those committed to helping developing countries will look at America’s new strategy with abhorrence.
America’s Opposing Futures
I recently learned something interesting: American international finance economists and American domestically oriented macroeconomists have very different – indeed, opposing – views of the likely consequences of America’s huge current-account deficit.
International finance economists see a financial crisis as likely, followed by a painful and perhaps prolonged recession in the United States.
Domestically oriented macroeconomists, by contrast, see a forthcoming fall in the value of the dollar not as a crisis, but as an opportunity to accelerate growth.
Domestically oriented macroeconomists look at the situation roughly like this: at some point in the future, foreign central banks will become less willing to continue buying massive amounts of dollar-denominated securities in order to prop up the greenback.
When they cease their large-scale dollar-purchase programs, the value of the dollar will fall – and it will fall hard.
But, according to this view, as the dollar’s value declines, US exports will become more attractive to foreigners and American employment will rise, with labor re-allocated to the newly-vibrant export sector.
It will be like what happened in Britain after it abandoned its exchange-rate peg and allowed the pound to depreciate relative to the Deutschmark , or what happened in the US in the late 1980’s, when the dollar depreciated against the pound, the Deutschmark , and – most importantly – the Japanese yen.
International finance economists see a far bleaker future.
They see the end of large-scale dollar-purchase programs by central banks leading not only to a decline in the dollar, but also to a spike in US long-term interest rates, which will curb consumption spending immediately and throttle investment spending after only a short lag.
To be sure, international finance economists also see US exports benefiting as the value of the dollar declines, but the lags in demand are such that the export boost will come a year or two after the decline in consumption and investment spending.
Eight to ten million people will have to shift employment from services and construction into exports and import-competing goods, implying that structural unemployment will rise.
Moreover, there may be a financial panic: large financial institutions with short-term liabilities and long-term assets will have a difficult time weathering a large rise in long-term dollar-denominated interest rates.
This mismatch can cause financial stress and bankruptcy just as easily as banks’ local-currency assets and dollar liabilities caused stress and bankruptcy in the Mexican and East Asian crises of the 1990’s and in the Argentinean crisis of this decade.
When international finance economists sketch this scenario, domestically oriented macroeconomists respond that it sounds like a case of incompetent monetary policy.
Why should the Federal Reserve allow long-term interest rates to spike just because other central banks have ceased their dollar-purchase programs?
Should not the Fed step in and replace them with its own purchases of long-term US Treasury bonds, thereby keeping long-term interest rates at a level conducive to full employment?
To this, international finance economists respond that the Fed does not have the power to do so.
When forced to choose between full employment and price stability, the international finance economists say that the Fed will choose price stability, because its institutional memory of the 1970’s, when inflation ran rampant, remains very strong.
Therefore, since a fall in the value of the dollar raises import prices, and thus functions as a negative shock to the supply side of the economy, the Fed will have to raise, not lower, interest rates, and sell, not buy, bonds.
Serious economists whom I respect enormously find themselves taking strong positions on opposite sides of this debate.
I’m not wise enough to say which side is right, but I certainly know which side I hope is wrong.
America’s Other 30%
NEW HAVEN – The American consumer is but a shadow of its former almighty self.
Personal consumption in the United States expanded at only a 1.5% annual rate in real (inflation-adjusted) terms in the second quarter of 2012 – and that was no aberration.
Unfortunately, it continues a pattern of weakness that has been evident since early 2008.
Over the last 18 quarters, annualized growth in real consumer demand has averaged a mere 0.7%, compared to a 3.6% growth trend in the decade before the crisis erupted.
Never before has the American consumer been this weak for this long.
The cause is no secret.
Consumers made huge bets on two bubbles – housing and credit.
Reckless monetary and regulatory policies turned the humble abode into an ATM, allowing families to extract dollars from bubbles and live beyond their means.
Both bubbles have long since burst, and US households are now dealing with post-bubble financial devastation – namely, underwater assets, record-high debt, and profound shortages of savings.
At the same time, sharply elevated unemployment and subpar income growth have combined to tighten the noose on over-extended consumers.
As a result, American households have hunkered down as never before.
Consumers are diverting what little income they earn away from spending toward paying down debt and rebuilding savings.
That is both logical and rational – and thus not something that the US Federal Reserve can offset with unconventional monetary easing.
American consumers’ unprecedented retrenchment has turned the US economy’s growth calculus inside out.
Consumption typically accounts for 70% of GDP (71% in the second quarter, to be precise).
But the 70% is barely growing, and is unlikely to expand strongly at any point in the foreseeable future.
That puts an enormous burden on the other 30% of the US economy to generate any sort of recovery.
In fact, the other 30% has not done a bad job, especially considering the severe headwinds coming from consumers’ 70%.
The 30% mainly consists of four components – capital spending by firms, net exports (exports less imports), residential construction, and government purchases.
(Technically, the pace of inventory investment should be included, but this is a cyclical buffer between production and sales rather than a source of final demand.)
Given the 0.7% trend in real consumption growth over the past four and a half years, the US economy’s anemic 2.2% annualized recovery in the aftermath of the Great Recession is almost miraculous.
Credit that mainly to the other 30%, especially to strong exports and a rebound in business capital spending.
By contrast, the government sector has been moving in the opposite direction, as state and local governments retrench and federal purchases top out after post-crisis deficit explosions.
The housing sector has started to recover over the past five quarters, but from such a severely depressed level that its growth has had little impact on the overall economy.
Given the strong likelihood that consumers will remain weak for years to come, America’s growth agenda needs to focus on getting more out of the other 30%.
Of the four growth components that fall into this category, two have the greatest potential to make a difference – capital spending and exports.
Prospects for these two sources of growth will not only influence the vigor, or lack thereof, of any recovery; they could well be decisive in bringing about an important shift in the US growth model.
The 70/30 split underscores the challenge: the US must face up to a fundamental rebalancing – weaning itself from excessive reliance on internal demand and drawing greater support from external demand.
Capital spending and exports, which together account for about 24% of GDP, hold the key to this shift.
At just over 10% of GDP, the share of capital spending is well below the peak of nearly 13% in 2000.
But capital spending must exceed that peak if US businesses are to be equipped with state-of-the-art capacity, technology, and private infrastructure that will enable them to recapture market share at home and abroad.
Only then could export growth, impressive since mid-2009, sustain further increases.
And only then could the US stem the rising tide of import penetration by foreign producers.
The other 30% is also emblematic of a deeper strategic issue that America faces – a profound competitive challenge.
A shift to external demand is not there for the asking. It must be earned by hard work, sheer determination, and a long overdue competitive revival.
On that front, too, America has been falling behind.
According to the World Economic Forum’s Global Competitiveness Index, the US slipped to fifth place in 2011-2012, from fourth place the previous year, continuing a general downward trend evident since 2005.
The erosion is traceable to several factors, including deficiencies in primary and secondary education as well as poor macroeconomic management.
But the US also has disturbingly low rankings in the quality of its infrastructure (#24), technology availability and absorption (#18), and the sophistication and breadth of its supply-chain production processes (#14).
Improvement on all counts is vital for America’s competitive revival.
But meeting the challenge will require vigorous growth from America’s other 30% – especially private capital spending.
With the American consumer likely to remain on ice, the same 30% must also continue to shoulder the burden of a sluggish economic recovery.
None of this can occur in a vacuum.
The investment required for competitive revival and sustained recovery cannot be funded without a long-overdue improvement in US saving.
In an era of outsize government deficits and subpar household saving, that may be America’s toughest challenge of all.
America\u0027s Other 87 Deficits
NEW HAVEN – The United States has a classic multilateral trade imbalance.
While it runs a large trade deficit with China, it also runs deficits with 87 other countries.
A multilateral deficit cannot be fixed by putting pressure on one of its bilateral components.
But try telling that to America’s growing chorus of China bashers.
America’s massive trade deficit is a direct consequence of an unprecedented shortfall of domestic saving.
The broadest and most meaningful measure of a country’s saving capacity is what economists call the “net national saving rate” – the combined saving of individuals, businesses, and the government.
It is measured in “net” terms to strip out the depreciation associated with aging or obsolescent capacity.
It provides a measure of the saving that is available to fund expansion of a country’s capital stock, and thus to sustain its economic growth.
In the US, there simply is no net saving any more.
Since the fourth quarter of 2008, America’s net national saving rate has been negative – in sharp contrast to the 6.4%-of-GDP averaged over the last three decades of the twentieth century.
Never before in modern history has the world’s leading economic power experienced a saving shortfall of such epic proportions.
Yet the US found a way to finesse this problem.
Exploiting what&#160;Valéry Giscard d’Estaing called the “exorbitant privilege” of the world’s reserve currency, the US borrowed surplus savings from abroad on very attractive terms, running massive balance-of-payments, or current-account, deficits to attract foreign capital.
The US current account, which was last in balance in 1991, hit a record deficit of $801 billion (6% of GDP) in 2006.
This gap has narrowed in the past couple of years, but much of the improvement probably reflects little more than the temporary impact of an unusually tough business cycle.
This is where America’s multilateral trade deficit enters the equation, for it has long accounted for the bulk of America’s balance-of-payments gap.
Since 2000, it has made up fully 96% of the cumulative current-account shortfall.
And that is what ultimately makes the China-centric blame game so absurd.
Without addressing the root of the problem – America’s chronic saving shortfall – it is ludicrous to believe that there can be a bilateral solution for a multilateral problem.
Yet that is exactly what US officials, together with many prominent economists, believe America needs.
Since the trade deficit is widely thought to put pressure on US jobs and real wages, the US-China trade imbalance has come under special scrutiny in these days of great angst.
Yes, China does account for the largest component of America’s multilateral trade deficit – making up 42% of the total trade gap in 2010.
Conscious outsourcing and supply-chain management decisions by US multinationals play an important role in exaggerating China’s share. But that does little to let China off the hook in the eyes of Washington.
Long-standing charges of currency manipulation provide the proverbial smoking gun that US politicians – of both parties –&#160;believe justifies the imposition of steep tariffs on China’s exports to the US (which totaled $365 billion in 2010).
That was precisely the argument behind the US Senate’s recent overwhelming approval of a “currency bill” that took dead aim on China.
While it may be convenient to hold others accountable for America’s problems, this is bad economics driving bad politics.
In an era of open-ended US government budget deficits and chronic shortfalls in personal saving, America is doomed to suffer subpar savings and massive multilateral trade deficits for as far as the eye can see.
In that vein, closing down trade with China, while failing to address the saving shortfall, is like putting pressure on one end of a water balloon.
The Chinese component of America’s multilateral trade deficit will simply migrate somewhere else – most likely to a higher-cost producer.
That would be the functional equivalent of a tax hike on beleaguered American families – hardly the solution that US politicians are promising.
This is not to ignore important US-China trade issues that need to be addressed.
Market access should be high on the agenda – especially for a sluggish US economy that needs new sources of growth, like exports.
With China now America’s third largest – and by far its most rapidly growing – export market, the US should push hard to expand business opportunities in China, especially as the Chinese economy tilts increasingly toward internal demand.
China should be viewed as an opportunity, not a threat.
At the same time, the US government should come clean with the American public about charges of Chinese currency manipulation and unfair trade practices.
The renminbi has, in fact, appreciated by 30% relative to the US dollar since mid-2005.
In broad multilateral terms – a far more meaningful gauge because it measures a currency’s value against a broad cross-section of a country’s trading partners – the “real effective” renminbi currently stands about 8% above its most recent 12-year average (1998-2010).
Yes, China continues to accumulate a vast fund of foreign-exchange reserves.
But this is as much the result of speculators’ “hot money” plays as it is a conscious and perfectly reasonable effort by Chinese policymakers to remain focused on financial stability and manage currency appreciation in a gradual, disciplined, and orderly fashion.
China-bashing in the US speaks to a corrosive shift in the American psyche.
It deflects attention away from those truly responsible for perpetuating the greatest saving shortfall in history.
Washington has been seduced by the political economy of false prosperity.
That seduction has encouraged America to squander its savings and live beyond its means for nearly two decades.
Now the game is up.
The ultimate test of any nation’s character is to look inside itself at moments of great challenge.
Swept up in the blame game, the US is doing the opposite.
And that could well be the greatest tragedy of all.
After all, America’s 88 deficits did not arise of thin air.
The American Consumer is Not Okay
NEW HAVEN – The spin-doctors are hard at work talking up America’s subpar economic recovery.
All eyes are on households.
Thanks to falling unemployment, rising home values, and record stock prices, an emerging consensus of forecasters, market participants, and policymakers has now concluded that the American consumer is finally back.
Don’t believe it.
First, consider the facts: Over the 21 quarters since the beginning of 2008, real (inflation-adjusted) personal consumption has risen at an average annual rate of just 0.9%.
That is by far the most protracted period of weakness in real US consumer demand since the end of World War II – and a massive slowdown from the pre-crisis pace of 3.6% annual real consumption growth from 1996 to 2007.
With household consumption accounting for about 70% of the US economy, that 2.7-percentage-point gap between pre-crisis and post-crisis trends has been enough to knock 1.9 percentage points off the post-crisis trend in real GDP growth. Look no further for the cause of unacceptably high US unemployment.
To appreciate fully the unique character of this consumer-demand shortfall, trends over the past 21 quarters need to be broken down into two distinct sub-periods.
First, there was a 2.2% annualized decline from the first quarter of 2008 through the second quarter of 2009.
This was crisis-driven carnage, highlighted by a 4.5% annualized collapse in the final two quarters of 2008.
Second, this six-quarter plunge was followed, from mid-2009 through early 2013, by 15 quarters of annualized consumption growth averaging just 2% – an upturn that pales in comparison with what would have been expected based on past consumer-spending cycles.
That key point appears all but lost on the consumer-recovery crowd.
In recent speeches and discussions with current and former central bankers, I have been criticized for focusing too much on the 0.9% trend of the past 21 quarters and paying too little attention to the 2% recovery phase of the post-crisis period.
At least it’s a recovery, they claim, and a sign of healing that can be attributed mainly to the heroic, unconventional efforts of the US Federal Reserve.
This brings us to the second part of the argument against optimism: analytics.
One of the first concepts to which an economics student is exposed in a basic macro course is “pent-up” consumer demand.
Discretionary consumption is typically deferred during recessions, especially for long-lasting durable goods such as motor vehicles, furniture, and appliances.
Once the recession ends and recovery begins, a “stock-adjustment” response takes hold, as households compensate for foregone replacement and update their aging durable goods.
Over most of the postwar period, this post-recession release of pent-up consumer demand has been a powerful source of support for economic recovery.
In the eight recoveries since the early 1950’s (excluding the brief pop following the credit-controls-induced slump in the 1980’s), the stock-adjustment response lifted real consumption growth by 6.1%, on average, for five quarters following business-cycle downturns; spurts of 7-8% growth were not uncommon for a quarter or two.
By contrast, the release of pent-up demand in the current cycle amounted to just 3% annualized growth in the five quarters from early 2010 to early 2011.
Moreover, the strongest quarterly gain was a 4.1% increase in the fourth quarter of 2010.
This is a stunning result.
The worst consumer recession in modern history, featuring a record collapse in durable-goods expenditures in 2008-2009, should have triggered an outsize surge of pent-up demand.
Yet it did anything but that.
Instead, the release of pent-up consumer demand was literally half that of previous business cycles.
The third point is more diagnostic: The shockingly anemic pattern of post-crisis US consumer demand has resulted from a deep Japan-like balance-sheet recession.
With the benefit of hindsight, we now know that the 12-year pre-crisis US consumer-spending binge was built on a precarious foundation of asset and credit bubbles. When those bubbles burst, consumers were left with a massive overhang of excess debt and subpar saving.
The post-bubble aversion to spending, and the related focus on balance-sheet repair, reflects what Nomura Research Institute economist Richard Koo has called a powerful “debt rejection” syndrome. While Koo applied this framework to Japanese firms in Japan’s first lost decade of the 1990’s, it rings true for America’s crisis-battered consumers, who are still struggling with the lingering pressures of excessive debt loads, underwater mortgages, and woefully inadequate personal saving.
Through its unconventional monetary easing, the Fed is attempting to create a shortcut around the imperative of household sector balance-sheet repair. This is where the wealth effects of now-rebounding housing prices and a surging stock market come into play.
But are these newfound wealth effects really all that they are made out to be?
Yes, the stock market is now at an all-time high – but only in current dollars.
In real terms, the S&amp;P 500 is still 20% below its January 2000 peak. Similarly, while the Case-Shiller index of US home prices is now up 10.2% over the year ending March 2013, it remains 28% below its 2006 peak.
Wealth creation matters, but not until it recoups the wealth destruction that preceded it.
Sadly, most American households are still far from recovery on the asset side of their balance sheets.
Moreover, though the US unemployment rate has fallen, this largely reflects an alarming decline in labor-force participation, with more than 6.5 million Americans since 2006 having given up looking for work.
At the same time, while consumer confidence is on the mend, it remains well below pre-crisis readings.
In short, the American consumer’s nightmare is far from over.
Spin and frothy markets aside, the healing has only just begun.
America’s Political Recession
BERKELEY – The odds are now about 36% that the United States will be in a recession next year.
The reason is entirely political: partisan polarization has reached levels never before seen, threatening to send the US economy tumbling over the “fiscal cliff” – the automatic tax increases and spending cuts that will take effect at the beginning of 2013 unless Democrats and Republicans agree otherwise.
More than a century ago, during the first Gilded Age, American politics was sharply polarized as well.
In 1896, future President Theodore Roosevelt was a Republican attack dog.
He denounced Democratic presidential candidate William Jennings Bryan as a mere puppet of the sinister governor of Illinois, John Peter Altgeld.
Bryan, Roosevelt said, “would be as clay in the hands of the potter under the astute control of the ambitious and unscrupulous Illinois communist.”
The “free coinage of silver” would be “but a step towards the general socialism which is the fundamental doctrine of his political belief.”
He and Altgeld “seek to overturn the...essential policies which have controlled the government since its foundation.”
Such language is as extreme as any we hear today – and from a man who was shortly to become Vice President (and later President, following the assassination of William McKinley).
We have heard Texas Governor Rick Perry call obliquely for the lynching of his fellow Republican, Federal Reserve Chairman Ben Bernanke, should he come to the Lone Star State.
And we have seen Kansas Secretary of State Kris Kobach explore the possibility of removing President Barack Obama from the ballot in Kansas, because, Kobach suggested, Obama is “not a natural-born citizen.”
But neither Perry nor Kobach is likely ever to be a US president, whereas Theodore Roosevelt was more than a partisan.
He was happy to make deals with Democrats – to put himself at the head not just of the Republican Party but of the bipartisan Progressive coalition, trying either to yoke the two forces together or to tack back and forth between them to achieve legislative and policy goals.
Obama broadly follows Ronald Reagan’s (second-term) security policy, George H.W. Bush’s spending policy, Bill Clinton’s tax policy, the bipartisan Squam Lake Group’s financial-regulatory policy, Perry’s immigration policy, John McCain’s climate-change policy, and Mitt Romney’s health-care policy (at least when Romney was governor of Massachusetts).
And yet he has gotten next to no Republicans to support their own policies.
Indeed, like Clinton before him, Obama has been unable to get Republican senators like Susan Collins to vote for her own campaign-finance policies, McCain to vote for his own climate-change policy, and – most laughably – Romney to support his own health-care plan.
Likewise, he has been unable to get Republican Vice-Presidential candidate Paul Ryan to endorse his own Medicare cost-control proposals.
There are obvious reasons for this.
A large chunk of the Republican base, including many of the party’s largest donors, believes that any Democratic president is an illegitimate enemy of America, so that whatever such an incumbent proposes must be wrong and thus should be thwarted.
And the Republican cadres believe this of Obama even more than they believed it of Clinton.
This view clearly influences Republican office-holders, who fear the partisan beast that mans their campaigns’ phone banks and holds the purse strings.
Moreover, ever since Clinton’s election in 1992, those at the head of the Republican Party have believed that creating gridlock whenever a Democrat is in the White House, and thus demonstrating the government’s incapacity to act, is their best path to electoral success.
That was the Republicans’ calculation in 2011-2012.
And November’s election did not change the balance of power anywhere in the American government: Obama remains President, the Republicans remain in control of the House of Representatives, and the Democrats control the Senate.
Now, it is possible that Republican legislators may rebel against their leaders, arguing that they ran for office to govern, not to paralyze the government in the hope that doing so will give the party power to reign as it wishes after the next election.
It is possible that Republican leaders like Representatives John Boehner and Eric Cantor and Senator Mitch McConnell will conclude that their policy of obstruction has been a failure.
They might note that, although the economy remains deeply troubled and depressed in the aftermath of a financial crisis for which they set the stage, Obama’s policies have been by far the most successful of those in any major advanced country, and conclude that he has been a relatively good president, and one worth supporting.
But don’t count on it.
Right now, every senior politician in America is telling their favorites in the press that they are confident that compromise on the “fiscal cliff” will be reached before the end of December.
But they are telling their favorites this because they think that pessimism now will lead to their being blamed for gridlock later.
It seems to me that the odds are around 60% that real negotiation will not begin until tax rates go up on January 1.
And it seems to me that, if gridlock continues into 2013, the odds are 60% that it will tip the US back into recession.
Let us hope that it will be short and shallow.
Bye-Bye, Middle East?
PARIS – For some time now, a certain strategic vision has been gaining traction: the United States is becoming energy-independent, paving the way for its political retreat from the Middle East and justifying its strategic “pivot” toward Asia.
This view seems intuitively correct, but is it?
Energy-hungry America has long depended on the global market to meet domestic demand.
In 2005, the US imported 60% of the energy that it consumed.
Since then, however, the share of imports has decreased, and it should continue to do so.
The US is expected to become energy self-sufficient in 2020, and to become an oil exporter by 2030.
This scenario would grant the US three enormous advantages.
It would enhance US economic competitiveness, especially relative to Europe, given the lower costs involved in the extraction of shale gas.
It would also reduce America’s exposure to growing unrest in the Arab world.
Finally, it would increase the relative vulnerability of America’s main strategic rival, China, which is becoming increasingly dependent on Middle East energy supplies.
These facts obviously need to be taken seriously, but their implications for US foreign policy in the Middle East should not be too hastily drawn.
Above all, though energy dependence is a key element of US policy in the region, it is far from being the only factor.
Israel’s security and the desire to contain Iran are equally important.
Moreover, the Middle East’s role in the global geopolitics of energy will grow in the coming decades, making it difficult to see how a superpower like the US could simply walk away from the region.
Within the next 15 years, OPEC countries will account for 50% of global oil production, compared to only 42% today.
Furthermore, the country on which this increase will most likely hinge is Iraq.
Could the US ignore a country that in roughly ten years will become the world’s second-largest oil exporter, generating more than $200 billion annually in revenue, while increasingly being dominated by an authoritarian Shia regime that is close to Iran?
Would it withdraw in the face of the consequent strategic threat to its three allies – Saudi Arabia, Turkey, and Israel – in the region?
Such a possibility seems even more far-fetched as long as the Iranian nuclear crisis remains unresolved and the Syrian crisis continues to widen the region’s Shia-Sunni divide (reflected in increased tension between Turkey and Iran).
Even as US President Barack Obama was visiting Asia in November – a trip meant to underscore America’s “pivot” – he was forced to devote considerable time and attention to mediating a cease-fire between Israel and Hamas in Gaza.
Indeed, if oil were truly America’s only or paramount interest in the Middle East, its special relationship with Israel would be mystifying, given the harm that it implies for US interests among Arab oil exporters.
Even when its energy dependence on the Middle East was at its peak, the US rarely altered its policy of support for Israel.
It is also important to bear in mind that in 1973, the US suffered less from the OPEC oil embargo than Europe did, even though America, which had resupplied Israel in its war with Egypt and Syria in October of that year, was the primary target.
In the end, America’s position in the region strengthened after Egypt became a US ally and made peace with Israel.
China’s growing interest in the Middle East also decreases the likelihood of an American withdrawal.
The US will remain concerned about ensuring the security of energy supplies for its Asian allies, which, like China, are increasingly dependent on the region’s oil exporters.
Nevertheless, while an American withdrawal from the Middle East seems highly unlikely, US exposure to the region will indeed decline; as that happens, America’s role there will probably become more subdued – and perhaps more cynical.
Its involvement in the Israeli-Palestinian conflict will likely be limited to maintaining the status quo rather than seeking a comprehensive settlement.
This stance – suggested by America’s opposition to granting Palestine observer-state status at the United Nations – would amount to an admission by the US that it has given up on the creation of two states in the Middle East.
That would certainly satisfy Israeli Prime Minister Binyamin Netanyahu and the Palestinian fringe seeking to weaken the Palestinian Authority.
But it would fully vindicate those who believe that Obama is more a man of good will than a visionary.
America’s Perpetual Christmas
Has the United States transcended the laws of economics?
As the New Year begins, the US continues to race ahead of its rich-country counterparts.
The gargantuan US trade deficit?
No problem.
In 2005, it widened further, and the dollar only strengthened.
Low investment and a deteriorating primary education system?
Not to worry.
The super-flexible US economy keeps managing to produce more with less.
Nor are there any signs of America’s economic hegemony starting to fold under the weight of maintaining its unilateral military dominance.
Instead of feeling the pinch of wartime privations, like in any ordinary country, American consumers are binging as if it were Christmas all year round.
There are those who truly believe in the idea that America is exceptional. Those true believers argue that America’s consumers can long pursue their spendthrift ways because their country’s economy is better than everyone else’s.
The US labor market is more flexible than Europe’s, enabling it to react more nimbly to the ever shifting sands of globalization. And, unlike most countries, especially in Latin America and Asia, the US system ruthlessly prunes weak corporate leadership.
Moreover, the true believers cite America’s better-funded and hyper-competitive university system, which sucks in a disproportionate share of the world’s top students and researchers.
Many ultimately choose to immigrate to America permanently, and it is relatively easy for them to do so, thanks to a society that still welcomes outsiders with open arms (even if things have become more difficult since 2001).
On top of all this, the US military, rather than being a burden, feeds the country’s technological superiority by subsidizing basic research.
By contrast, skeptics hold that the US economy already contains the seeds of its own socio-economic decline.
They point to worsening income inequality, as images beamed worldwide from post-hurricane New Orleans illustrated all too clearly.
Poor children do not have reasonable access to health care. Nor are the non-poor faring particularly well, as wage growth has remained virtually flat for a very long time, even as corporate profits are booming.
Indeed, this disconnect may explain why polls do not give President Bush the credit for economic management that his strong record would seem to merit.
Nor does it help Americans’ mood that they spend far more of their lives working than do citizens in Europe or, these days, even Japan.
All of these factors place deep stresses on the social fabric which, so the skeptics argue, will ultimately play out in the political arena.
Interestingly, both sides cite America’s gaping trade deficit – believe it or not, the US is soaking up two-thirds of global excess saving – to support their arguments.
The true believers view the deficits as evidence that the world recognizes how special the US is and wants to buy in.
Skeptics see an empire living on borrowed money and borrowed time.
So which is it?
In my view, those who think that America is about to collapse are likely to be disappointed.
Nevertheless, I suspect that the age of American exceptionalism is near an end, and soon per capita income in Europe and Japan will approach that of the US, rather than falling farther behind.
Though the next few years are likely to underscore some of the weaknesses that the skeptics highlight, the end will come mainly because other countries will find creative ways to mimic the most effective US institutions, albeit within their own legal, political, and social frameworks.
We would do well to recall how, at the beginning of the 1990’s, book after book was still being written urging US and European corporations to imitate Japan or face certain doom.
The last 15 years have of course revealed deep flaws in Japan’s financial system.
But another major factor contributing to Japan’s decline was that firms elsewhere began adopting Japanese methods, such as just-in-time supply chains.
Surely, imitation will someday impinge on superior US growth performance as well.
Perhaps the biggest weakness in the true believers’ argument is the trade deficit.
For the moment, America’s ability to borrow vast sums at low interest rates acts like a huge dose of steroids on the economy.
It artificially props up consumption growth and allows the government to defer hard choices between taxes and military expenditures.
At some point, the party is going to end.
The unwinding of the US economy might even begin in 2006, particularly if Japan continues to grow out of its doldrums, the US housing market softens dramatically, and Europe’s economic recovery accelerates.
Individually, these are each highly plausible scenarios, and collectively they would hit the US trade deficit like a perfect storm.
Perhaps the end will come in a different way, but it is difficult to imagine the age of US exceptionalism lasting indefinitely.
Can the end come abruptly in 2006?
This is not the most likely scenario, but it is not unthinkable.
America’s Strategy Vacuum
NEW HAVEN – Apparently, policymakers at the Federal Reserve are having second thoughts about the wisdom of open-ended quantitative easing (QE).
They should.
Not only has this untested policy experiment failed to deliver an acceptable economic recovery; it has also heightened the risk of another crisis.

The minutes of the January 29-30 meeting of the Fed’s Federal Open Market Committee (FOMC) speak to a simmering discontent: “[M]any participants…expressed some concerns about potential costs and risks arising from further asset purchases.” The concerns range from worries about the destabilizing ramifications of an exit strategy from QE to apprehension about capital losses on the Fed’s rapidly ballooning portfolio of securities (currently $3 trillion, and on its way to $4 trillion by the end of this year).
As serious as these concerns may be, they overlook what could well be the greatest flaw in the Fed’s unprecedented gambit: an emphasis on short-term tactics over longer-term strategy.
Blindsided by the crisis of 2007-2008, the Fed has compounded its original misdiagnosis of the problem by repeatedly doubling down on tactical responses, with two rounds of QE preceding the current, open-ended iteration.
The FOMC, drawing a false sense of comfort from the success of QE1 – a massive liquidity injection in the depths of a horrific crisis – mistakenly came to believe that it had found the right template for subsequent policy actions.
That approach might have worked had the US economy been afflicted by a cyclical disease – a temporary shortfall of aggregate demand.
In that case, countercyclical policies – both fiscal and monetary – could eventually be expected to plug the demand hole and get the economy going again, just as Keynesians argue.
But the US is not suffering from a temporary, cyclical malady. It is afflicted by a very different disease: a protracted balance-sheet recession that continues to hobble American households, whose consumption accounts for roughly 70% of GDP.
Two bubbles – property and credit – against which American families borrowed freely, have long since burst. But the aftershocks linger: Household-debt loads were still at 113% of disposable personal income in 2012 (versus 75% in the final three decades of the twentieth century), and the personal-saving rate averaged just 3.9% last year (compared to 7.9% from 1970 to 1999).
Understandably fixated on balance-sheet repair, US consumers have not taken the bait from their monetary and fiscal authorities.
Instead, they have cut back on spending.
Gains in inflation-adjusted personal-consumption expenditure have averaged a mere 0.8% over the past five years – the most severe and protracted slowdown in consumer demand growth in the post-World War II era.
The brute force of massive monetary and fiscal stimulus rings hollow as a cyclical remedy to this problem.
Another approach is needed.
The focus, instead, should be on accelerating the process of balance-sheet repair, while at the same time returning monetary and fiscal policy levers to more normal settings.
Forgiveness of “underwater” mortgages (where the outstanding loan exceeds the home’s current market value), as well as reducing the foreclosure overhang of some 1.5 million homes, must be part of that solution.
How else can the crisis-battered housing market finally clear for the remainder of US homeowners?
The same can be said for enhanced saving incentives, which would contribute to longer-term financial security for American households, most of which suffered massive wealth losses in the Great Recession.
Expanded individual retirement accounts and 401K pension schemes, special incentives for low-income households (most of which have no retirement plans), and an end to the financial repression that the Fed’s zero-interest-rate policy imposes on savers must also be part of the solution.
Yes, these are controversial policies.
Debt forgiveness raises thorny ethical concerns about condoning reckless and irresponsible behavior.
But converting underwater “non-recourse” mortgage loans, where only the house is at risk, into so-called “recourse liabilities,” for which nonpayment would have consequences for all of a borrower’s assets, could address this concern, while simultaneously tempering America’s culture of leverage with a much greater sense of responsibility.
Timing is also an issue, especially with respect to saving incentives.
To avoid the shortfall in aggregate demand that might arise from an abrupt surge in saving, these measures should be phased in over a period of 3-5 years.
The main benefit of these proposals is that they are more strategic than tactical – better aligned with the balance-sheet problems that are actually afflicting the economy.
As the quintessential laissez-faire system, the US has outsourced strategy to the invisible hand of the market for far too long.
That has left the government locked into a reactive and often misguided approach to unexpected problems.
Thus, the Fed is focused on cleaning up after a crisis rather than on how to avoid another one.
The same is true of US fiscal policy, with an event-driven debate that now has ever-shorter time horizons: the fiscal cliff on January 1, sequestration of expenditures on March 1, expiration of the continuing budget resolution on March 27, and the new May 18 debt-ceiling limit.
A compliant bond market, which may well be the next bubble, is mistakenly viewed as the ultimate validation of this myopic approach.
The dangers of America’s strategy vacuum and the related penchant for short-termism have been mounting for some time.
Harvard Business School professor Michael Porter famously raised this concern in a 1996 article in the Harvard Business Review.
His focus was on corporate decision-making and misaligned incentives leading to a worrisome dichotomy between the short-term tactics of “operational effectiveness” (cost cutting, outsourcing, and reengineering) and the long-term visionary bets that frame successful strategies.
While Porter’s critique was directed at business managers, it bears critically on the current US policy debate.
A successful long-term strategy cannot be seen as a succession of short-term fixes.
The internal debate in the FOMC represents a healthy and long-overdue recognition that the central bank may be digging itself into an ever-deeper hole by committing to misguided policies aimed at the wrong problem.
A comparable debate is raging over fiscal policy.
Can America finally face up to the perils of its strategy vacuum?
America’s Political Class Struggle
NEW YORK – America is on a collision course with itself.
This month’s deal between President Barack Obama and the Republicans in Congress to extend the tax cuts initiated a decade ago by President George W. Bush is being hailed as the start of a new bipartisan consensus.
I believe, instead, that it is a false truce in what will become a pitched battle for the soul of American politics.
As in many countries, conflicts over public morality and national strategy come down to questions of money.
In the United States, this is truer than ever.
The US is running an annual budget deficit of around $1 trillion, which may widen further as a result of the new tax agreement.
This level of annual borrowing is far too high for comfort.
It must be cut, but how?
The problem is America’s corrupted politics and loss of civic morality. One political party, the Republicans, stands for little except tax cuts, which they place above any other goal.
The Democrats have a bit wider set of interests, including support for health care, education, training, and infrastructure.
But, like the Republicans, the Democrats, too, are keen to shower tax cuts on their major campaign contributors, predominantly rich Americans.
The result is a dangerous paradox.
The US budget deficit is enormous and unsustainable.
The poor are squeezed by cuts in social programs and a weak job market.
One in eight Americans depends on Food Stamps to eat.
Yet, despite these circumstances, one political party wants to gut tax revenues altogether, and the other is easily dragged along, against its better instincts, out of concern for keeping its rich contributors happy.
This tax-cutting frenzy comes, incredibly, after three decades of elite fiscal rule in the US that has favored the rich and powerful.
Since Ronald Reagan became President in 1981, America’s budget system has been geared to supporting the accumulation of vast wealth at the top of the income distribution.
Amazingly, the richest 1% of American households now has a higher net worth than the bottom 90%.
The annual income of the richest 12,000 households is greater than that of the poorest 24 million households.
The Republican Party’s real game is to try to lock that income and wealth advantage into place.
They fear, rightly, that sooner or later everyone else will begin demanding that the budget deficit be closed in part by raising taxes on the rich.
After all, the rich are living better than ever, while the rest of American society is suffering.
It makes sense to tax them more.
The Republicans are out to prevent that by any means.
This month, they succeeded, at least for now.
But they want to follow up their tactical victory – which postpones the restoration of pre-Bush tax rates for a couple of years – with a longer-term victory next spring.
Their leaders in Congress are already declaring that they will slash public spending in order to begin reducing the deficit.
Ironically, there is one area in which large budget cuts are certainly warranted: the military.
But that is the one item most Republicans won’t touch.
They want to slash the budget not by ending the useless war in Afghanistan, and by eliminating unnecessary weapons systems, but by cutting education, health, and other benefits for the poor and working class.
In the end, I don’t think they will succeed.
For the moment, most Americans seem to be going along with Republican arguments that it is better to close the budget deficit through spending cuts rather than tax increases.
Yet when the actual budget proposals are made, there will be a growing backlash.
With their backs against the wall, I predict, poor and working-class Americans will begin to agitate for social justice.
This may take time.
The level of political corruption in America is staggering.
Everything now is about money to run electoral campaigns, which have become incredibly expensive.
The mid-term elections cost an estimated $4.5 billion, with most of the contributions coming from big corporations and rich contributors.
These powerful forces, many of which operate anonymously under US law, are working relentlessly to defend those at the top of the income distribution.
But make no mistake: both parties are implicated.
There is already talk that Obama will raise $1 billion or more for his re-election campaign.
That sum will not come from the poor.
The problem for the rich is that, other than military spending, there is no place to cut the budget other than in areas of core support for the poor and working class.
Is America really going to cut health benefits and retirement income?  Will it really balance the budget by slashing education spending at a time when US students already are being out-performed by their Asian counterparts?
Will America really let its public infrastructure continue to deteriorate?
The rich will try to push such an agenda, but ultimately they will fail.
Obama swept to power on the promise of change.
So far there has been none.
His administration is filled with Wall Street bankers.
His top officials leave to join the banks, as his budget director Peter Orszag recently did.
He is always ready to serve the interests of the rich and powerful, with no line in the sand, no limit to “compromise.”
If this continues, a third party will emerge, committed to cleaning up American politics and restoring a measure of decency and fairness.
This, too, will take time.
The political system is deeply skewed against challenges to the two incumbent parties.
Yet the time for change will come.
The Republicans believe that they have the upper hand and can pervert the system further in favor of the rich.
I believe that they will be proved wrong.
America\u0027s Problems Run Deeper than Wall Street
CAMBRIDGE – With less than two months remaining before America’s presidential election, much attention is focused on the state of the American economy and the challenges that it will present to the next president.
We are in the midst of a financial crisis caused by the serious mispricing of all kinds of risks and by the collapse of the housing bubble that developed in the first half of this decade.
What started as a problem with sub-prime mortgages has now spread to houses more generally, as well as to other asset classes.
The housing problem is contributing to the financial crisis, which in turn is reducing the supply of credit needed to sustain economic activity.
Indeed, the financial crisis has worsened in recent weeks, reflected in the US Federal Reserve’s takeover of quasi-government mortgage lenders Fannie Mae and Freddie Mac – which may cost American taxpayers hundreds of billions of dollars – as well as the bankruptcy of Lehman Brothers and the sale of Merrill Lynch.
Ultimately, these financial failures reflect the downward spiral of house prices and the increasing number of homes with negative equity, i.e., with substantial mortgage debt in excess of market values.
Negative equity is significant because mortgages in the United States are generally “no recourse” loans.
If a homeowner defaults, creditors can take the house, but they cannot take other property or income to make up any unpaid balance.
Even in those states where mortgages are not “no recourse” loans, creditors generally do not pursue the assets or income of individuals who default.
We cannot be sure about how much further house prices will fall.
Experts say another 15% decline is required just to return to the pre-bubble price path.
But there is nothing to stop the decline from continuing once it reaches that point.
The growing gap between mortgage debts and house prices will continue to increase the rate of defaults.
Many homeowners who can afford to make their mortgage payments will choose to default, move to rental housing, and wait to purchase until house prices have declined further.
As homeowners with large negative equity default, the foreclosed homes contribute to the excess supply that drives prices down further.
And the lower prices lead to more negative equity and therefore to more defaults and foreclosures.
It is not clear what will stop this self-reinforcing process.
Declining house prices are key to the financial crisis and the outlook for the economy, because mortgage-backed securities, and the derivatives based on them, are the primary assets that are weakening financial institutions.
Until house prices stabilize, these securities cannot be valued with any confidence.
And that means that the financial institutions that own them cannot have confidence in the liquidity or solvency of potential counterparties – or even in the value of their own capital.
Without this confidence, credit will not flow and economic activity will be constrained.
Moreover, because financial institutions’ assets were bought mainly with borrowed money, the shortage of credit is exacerbated by their need to deleverage.
Since raising capital is difficult and costly, they deleverage by lending less.
But the macroeconomic weakness in the US now goes beyond the decreased supply of credit.  Falling house prices reduce household wealth and therefore consumer spending.
Falling employment lowers wage and salary incomes.
The higher prices of food and energy depress real incomes further.
And declining economic activity in the rest of the world is lowering demand for US exports.
The US Federal Reserve has, in my judgment, responded appropriately by reducing the federal funds interest rate sharply and creating a variety of new credit facilities.
The low interest rate helped by making the dollar more competitive, but otherwise monetary policy appears to have lost traction because of the condition of the housing sector and the dysfunctional state of the credit markets.
The US Congress and the Bush administration enacted a $100 billion tax rebate in an attempt to stimulate consumer spending.
Those of us who supported this policy generally knew that history and economic theory implied that such one-time fiscal transfers have little effect, but we thought that this time might be different.
Our support was, in the words of Samuel Johnson, a triumph of hope over experience.
In the end, our hopes were frustrated.
The official national income accounting data for the second quarter are now available, and they show that the rebates did very little to stimulate spending.
More than 80% of the rebate dollars were saved or used to pay down debt.
Very little was added to current spending.
So that is where the US is now: in the middle of a financial crisis, with the economy sliding into recession, monetary policy already at maximum easing, and fiscal transfers impotent.
That is an unenviable situation, to say the least, for any incoming president.
Obama’s Burmese Gamble
ARLINGTON – The rapprochement between the United States and Myanmar (Burma) has proceeded at a blistering pace.
A year ago, the two countries did not even have ambassadors in each other’s capitals.
In May, President Thein Sein became the first leader from Myanmar to visit the White House in nearly a half-century.
But has Barack Obama’s administration been too quick to embrace what was, until recently, one of the world’s most repressive regimes?
Or, on the contrary, is decisive US support essential to Myanmar’s fledgling reform process?
Until the recent opening, Myanmar, which gained independence in 1948, had been ruled by a secretive military junta since 1962.
As recently as 2010, the regime held elections so blatantly rigged that the main opposition party refused to participate.
But in 2011, shortly before assuming the presidency, Sein, a general who served as Prime Minister under the junta, began to take steps that impressed even the most skeptical observers.
Unlike the token gestures of reform offered by previous rulers, Sein’s actions appeared substantive and meaningful.
One important change was the release of hundreds of political prisoners, including the regime’s most prominent opponent, Aung San Suu Kyi, who had been under house arrest for nearly 15 years.
Moreover, Sein initiated a dialogue with Suu Kyi, a Nobel Peace Prize winner and the leader of the National League for Democracy (NLD), about a transition to civilian rule.
The subsequent elections bolstered hope for Myanmar’s democratic future.
In 1990, when the NLD won 81% of the seats in Parliament, the junta promptly voided the results and arrested Suu Kyi.
In 2012, the NLD won 43 of the 44 seats that it contested, and the military accepted Suu Kyi as the reform movement’s legitimate leader.
Furthermore, Sein has reached out to the Karen, Kachin, and other ethnic minorities – groups whose members have suffered decades of official persecution and mistreatment.
And efforts to open Myanmar’s economy to international trade have transformed the country’s commercial capital, Yangon (Rangoon), with businesspeople now arriving on direct flights from at least a half-dozen foreign capitals and once-empty streets now congested with imported cars.
But, in some areas, reform has been painfully slow.
In fact, when it comes to human rights and minority protections, Myanmar may even be regressing.
The liberalization process has exposed the country’s long-standing religious divisions, leading to a wave of sectarian violence aimed primarily at the minority Muslim community.
From coastal Rakhine to inland towns like Meiktila and Tatkon, Buddhist monks have incited violence against Muslims (and sometimes vice versa), with local officials often tacitly permitting religious bloodletting.
At his meeting with Sein in Washington, DC, Obama condemned the violence against Myanmar’s Muslims, which has displaced many of them.
On the same day, the US State Department released its annual report on religious freedom, in which Myanmar was included among the world’s eight worst offenders.
This has not always been the case.
Although Myanmar is an overwhelmingly Buddhist country, dozens of religious and ethnic communities have long lived there side by side.
In the heart of Yangon, the golden dome of the Sule Pagoda stands just across the street from the minarets of the Bengali Mosque.
In order to achieve the peace and stability needed to consolidate Myanmar’s democratic transition, both Sein and Suu Kyi should do more to establish themselves as representatives of all of Myanmar’s citizens.
Muslims need to be assured of their personal security and guaranteed full civil rights.
The Obama administration has staked significant political capital on the wager that Myanmar’s promise may finally bear fruit.
And, indeed, the rate of change in Myanmar over the last two years has been nothing short of remarkable.
But, as Sein acknowledged at the White House, Myanmar’s government “has been encountering obstacles and challenges along [its] democratization process.” How it copes with these problems – and those that have yet to arise – will determine whether America has given its blessing prematurely.
America’s Reactionary Feminists
NEW YORK – It is obvious that the left and the media establishment in the United States cannot fully understand the popular appeal of the two Republican tigresses in the news – first Sarah Palin, and now, as she consolidates her status as a Republican presidential front-runner, Michele Bachmann.
What do they have that other candidates don’t –&#160;and that so many Americans seem to want?
Both Bachmann and Palin are regularly derided in the mainstream press.
In Palin’s case, the dominant perception is that she is an intellectual lightweight: a clip of her unable to mention a single newspaper or news magazine that she reads regularly got millions of hits on YouTube during the last presidential election.
Bachmann, on the other hand,&#160;is portrayed as being slightly unhinged.
Indeed, I can attest from personal experience that to debate her is to encounter someone who is absolutely certain of facts that must exist somewhere in a parallel universe.
But it would be a mistake simply to dismiss their appeal with no effort to comprehend its source.
This is especially true of Bachmann.
Palin has not managed to secure the support and mentorship of the Republican Party establishment, and will continue to showcase her odd appeal as a media personality.
But Bachman, weirdly, might become President of the United States.
The nature of their attraction has to do with two strains in American thought to which the US left and media establishment are truly blind.
One is the American tradition of populist demagoguery – a tradition that, in the twentieth century, included the racist Father Charles Coughlin in the 1930’s, the anti-Communist witch-hunter Joe McCarthy in the 1950’s, and the radical Malcolm X in the 1960’s.
Populist leaders inspire passionate devotion, usually in people who feel (and often are) economically, politically, and culturally marginalized.
These populist movements’ energy can be directed for good or ill, but demagogues in America embrace similar tactics to fuel their rise to visibility and power.
They use emotive rhetoric.
They often invent shadowy networks of “elite” forces ranged against the ordinary, decent American.
They create an “us versus them” scenario.
And they ask their listeners to believe that they alone will restore American dignity and articulate the wishes of the unheard.
Palin and Bachmann speak this highly personal or emotional language, which even the most rock-ribbed male Republican finds difficult to emulate.
In the last three decades, America’s male-dominated politics has become increasingly wonky, abstract, and professionalized.
This is bad for demagoguery, but it does not inhibit the tigresses on the right, who did not come up through the “old boy’s club.”
As a result, Palin is free to talk about “death panels” – a wholly invented threat of President Barack Obama’s health-care reform – and Bachmann can summon the spirit of McCarthy to raise the equally bizarre specter of socialism’s tentacles infiltrating the highest levels of government.
Both can issue homespun appeals as “hockey moms” or “soccer moms” – precisely the type of emotionalism that more cut-and-dried professional male politicians, even (or especially) at the top of the party, cannot manage to deliver.
The second reason that Bachmann and Palin appeal to so many Americans – and this should not be underestimated, either – has to do with a serious historical misreading of feminism.
Because feminism in the 1960’s and 1970’s was articulated via the institutions of the left – in Britain, it was often allied with the labor movement, and in America, it was reborn in conjunction with the emergence of the New Left – there is an assumption that feminism itself must be leftist.
In fact, feminism is philosophically as much in harmony with conservative, and especially libertarian, values – and in some ways even more so.
The core of feminism is individual choice and freedom, and it is these strains that are being sounded now more by the Tea Party movement than by the left.
But, apart from these sound bites, there is a powerful constituency of right-wing women in Britain and Western Europe, as well as in America, who do not see their values reflected in collectivist social-policy prescriptions or gender quotas.
They prefer what they see as the rugged individualism of free-market forces, a level capitalist playing field, and a weak state that does not impinge on their personal choices.
Many of these women are socially conservative, strongly supportive of the armed forces, and religious – and yet they crave equality as strongly as any leftist vegetarian in Birkenstocks.
It is blindness to this perfectly legitimate approach to feminism that keeps tripping up commentators who wish to dismiss women like Margaret Thatcher, or Muslim women, or now right-wing US women leaders, as somehow not being the “real thing.”
But these women are real feminists – even if they do not share policy preferences with the already recognized “sisterhood,” and even if they themselves would reject the feminist label.
In the case of Palin – and especially that of Bachmann – we ignore the wide appeal of right-wing feminism at our peril.
America\u0027s Retreat from Asia
The United States' planned withdrawal of troops from Asia, which President George W. Bush announced on August 16, need not harm peace and stability in the region and particularly in Korea.
But a key condition for a smooth redeployment of US troops is close consultations by America with its allies, something it has not done well up to now.
South Korea and Japan need to have their views taken into serious account if this now inevitable withdrawal is to succeed.
By contrast, unilaterally announcing the withdrawal - and then unilaterally implementing it - may harm the very purpose that the remaining US troops in Asia are intended to serve: assuring deterrence, stability, and nonproliferation in Korea and Asia.
The withdrawal plan is causing countless worries.
In Japan, there are concerns that it will make the country America's frontline command post in Asia, possibly beyond the scope of its bilateral security treaty with the US.
One result is that China feels nervous about the implications of any expansion of the American-Japanese military partnership.
But the impact of America's planned troop withdrawals is felt most keenly in South Korea.
In June, the Bush administration revealed its plan to withdraw some 12,500 of the 37,000 US soldiers stationed in South Korea by the end of 2005.
These include 3,600 troops from the 2nd Brigade of the 2nd Infantry Division, who are already earmarked for redeployment in Iraq.
The US Defense Department justifies this change as part of the so-called "Global Posture Review" that it has been carrying out to provide more flexibility and mobility in deploying troops to more urgently needed places around the world.
But the unilateral nature of the announcement, and the abrupt timing of the plan, has incited alarm in South Korea, and perhaps in Japan, that withdrawal could pose serious risks to the vital role that US forces have performed in deterring another war in Korea.
South Koreans genuinely fear that the plan may weaken deterrence by sending North Korea - which is demanding a US military withdrawal while refusing to abandon its nuclear weapons ambitions - the message that intransigence pays.
Indeed, it should not be forgotten that North Korea maintains an army of 1.1 million troops.
Moreover, the manner in which the Bush administration unveiled its withdrawal plan has weakened the credibility of the US-Korean alliance.
America's unilateral announcement has fuelled rumors to the effect that withdrawal must have something to do with the rising tide of anti-Americanism in South Korea, and especially with the country's reluctance and delay in dispatching an additional 3,600 of its own soldiers to Iraq.
The Bush administration tries to rebut these charges by saying that the plan will not weaken the deterrence capabilities of American forces, for America's far more powerful air and naval presence in the area will be maintained. Moreover, the US plans to strengthen South Korea's own forces by supplying some $11 billion worth of high-technology equipment over the next five years.
Militarily, this argument does make sense.
Politically and psychologically, however, the method, let alone the timing and implementation of the withdrawals, raises many questions about the ongoing viability of the US-Korean security alliance, for the alliance now seems adrift, without a common purpose and with little direction from either side.
Yet the Bush administration insists: "The US views South Korea as a strong and steadfast ally.
We are committed to South Korea's security and to our alliance and partnership with Seoul."
If Washington is serious about these words, it should transform this commitment into a long-term and comprehensive alliance that can survive the current estrangement - and continue even after Korean unification - by making a joint declaration with South Korea's government at the highest level.
In order to allay misgivings and restore trust in the alliance, it is necessary for the US and South Korea to reaffirm their common interests and values in pursuing deterrence, nonproliferation, stability, and democracy on the Korean peninsula and across Asia.
Once they resolve to continue their alliance with these purposes in mind, it should be possible for responsible officials to work out guiding principles for concrete security cooperation.
Specific negotiations on withdrawing American troops from Korea or on redeploying them from the DMZ to south of Seoul must be carried out according to these principles.
In so doing, America must treat South Korea as a full partner with its own voice in making decisions that affect its security interests.
As an American ally for 51 years, and as East Asia's third-largest economy, South Korea is entitled to be fully consulted on such decisions.
Despite anti-American sentiments among some South Koreans, a majority of the country's people wants American forces to remain as a stabilizing force.
Securing a peaceful and nuclear-free Korean peninsula, a place where the interests of China, Japan, Russia, and America directly intersect, is one of the most important security goals anywhere on the planet.
For this reason, America and South Korea must restore a strategic vision for the future.
America’s Saving Rate and the Dollar’s Future
CAMBRIDGE – The saving rate of American households has risen sharply since the beginning of the year, reaching 6.9% of after-tax personal income in May, the highest rate since 1992.
In today’s economy, that is equivalent to annual savings of $750 billion.
While a 6.9% saving rate is not high in comparison to that of many other countries, it is a dramatic shift from the household-saving rate of less than 1% that the United States experienced in 2005, 2006, and 2007.
Before it began rising last year, the US household saving rate had been declining for more than 20 years in response to the increasing level of household wealth.
The rising stock market and the higher value of homes induced individuals to consume more of their incomes and to save less.
As a result, most working individuals reduced the amount that they saved for their retirement, and retirees were able to increase their spending.
The net saving rate fell to near zero.
The sharp drop in household wealth over the past two years, however, put an end to that.
Dramatically lower share prices and a 35% fall in home prices reduced household wealth by $14 trillion, a loss equal to 140% of annual disposable income.
Individuals now have to save more to prepare for retirement, and retirees have less wealth to spend.
Looking ahead, the saving rate may rise even further, and will, in any case, remain high for many years.
The increase in the household saving rate reduces America’s need for foreign funds to finance its business investment and residential construction.
Taken by itself, today’s $750 billion annual rate of household saving could replace that amount in capital inflows from the rest of the world.
Since the peak annual rate of capital inflow was $803 billion (in 2006), the increased household saving has the potential to eliminate almost all of America’s dependence on foreign capital.
The annual capital inflow is equal each year to the US current-account deficit – the sum of the trade deficit plus the net interest and dividends that America’s government and businesses owe to the rest of the world.
The fall in the capital inflow would therefore bring with it a fall in the trade deficit.
Since reducing the trade deficit requires increasing exports and shrinking imports, the international value of the dollar must decline to make US products more attractive to foreign buyers and US goods and services more attractive to American consumers.
Without a fall in the dollar and the resulting rise in net exports, a higher saving rate and reduced consumer spending could push the US economy into a deep recession.
By contrast, the lower dollar makes reduced consumption consistent with full employment by shifting consumer spending from imports to domestic goods and services, and by supplementing this rise in domestic demand with increased exports.
But this direct link between higher household saving and a lower dollar will only be forged if higher household saving is not outweighed by a rise in government dis-saving, i.e., by a larger government deficit.
A large fiscal deficit increases the need for foreign funds to avoid crowding out private investment.
Put differently, the value of the dollar reflects total national saving, not just savings in the household sector.
Unfortunately, the US fiscal deficit is projected to remain high for many years.
The Congressional Budget Office projects that the US government’s budget deficit will average 5.2% of GDP over the next decade, and be 5.5% of GDP a decade from now.
If that high level of government borrowing occurs, it will absorb all of the available household savings even at the current elevated level.
That would mean that the US would continue to need substantial inflows of foreign capital to fund business investment and housing construction.
So the dollar would have to stay at its current level to continue to create the large trade deficit and resulting capital inflow.
It is, of course, possible – I would say likely – that China and other foreign lenders will not be willing to continue to provide the current volume of lending to the US.
Their reduced demand for dollars will cause the dollar to decline and the trade deficit to shrink.  That reduced trade deficit and the resulting decline in capital inflows will lead to higher real interest rates in the US.
The higher interest rate will reduce the level of business investment and residential construction until they can be financed with the smaller volume of national saving plus the reduced capital inflows.
Although the higher level of household saving will limit the rise in US interest rates, it will not change the fact that the combination of large future fiscal deficits and foreign lenders’ reduced willingness to buy US securities will lead to both a lower dollar and higher US interest rates.
America’s Saving Surprise
CAMBRIDGE – The household saving rate in the United States has tripled in the past three years.
Why?
And what does it mean for the US economy and the rest of the world?
The rapid rise in saving has reduced consumer spending, slowing the pace of GDP growth in 2009 and in early 2010.
If the saving rate continues to rise rapidly, it could push America’s fragile economy into another downturn.
That would mean lower imports, creating a potential problem for countries that depend for their employment on exporting to the US.
Higher household saving depresses consumption because it is the difference between households’ after-tax income and what they spend.
The saving may be deposited in bank accounts or used to buy mutual funds or corporate stock.
Saving may also take the form of individual contributions to retirement accounts or employer contributions to corporate saving plans.
Paying down debt on credit cards or mortgages also counts as saving – but increases in the value of existing assets like stocks or real estate do not, even though they increase the value of household wealth.
In any year, some households are savers and others, especially retirees, are dissavers that use past saving to finance current consumption.
The nation’s net household saving rate is the difference between the saving of the savers and the dissaving of the dissavers.
The recent rise in the US household saving rate reversed a long-term decline that began 25 years ago.
Before that, between 1960 and 1985, American households saved an average of 9% of their after-tax incomes.
The saving rate in each of those 25 years was between 7% and 11%.
But, after 1985, a variety of changes caused saving to decline until it reached less than 2% in 2007.
One reason was that rising stock markets and higher house prices made individuals wealthier, reducing their need to save for retirement and allowing retirees to dissave more.
The general shift from defined-benefit pension plans to defined-contribution plans meant that employees felt the effect of rising share prices directly in their own personal accounts.
Moreover, the increased availability of credit cards gave Americans a greater ability to dissave, buying goods and services now and paying for them later.
Mortgages became more widely available.
Rising house prices also allowed homeowners to refinance their mortgages, obtaining additional cash to spend on other things.
Credit lines secured by home equity provided another new way to finance spending.
All of this changed abruptly when the American economy fell into a deep recession at the end of 2007.
The stock market dropped sharply.
Home prices fell 40%, completely wiping out the equity of one-third of all homeowners with mortgages.
Household wealth is now $10 trillion dollars less than it was before the recession began.
That fall in wealth means that households must save more to prepare for retirement, and that retirees are not able to dissave as much as they did before.
Banks and credit-card companies have become much more cautious about extending credit.
And, with unemployment stubbornly high, many households are saving in order to have additional cash if they should lose their job or be put on shorter hours.
There is no way to predict what the saving rate will do next.
Households’ need to rebuild wealth, and the lack of access to credit, implies that the saving rate could continue to rise from the 6.4% recorded in June (the most recent month for which data are available) to the 9% rate that America averaged in the decades before 1985.
If that were to happen quickly, total spending could decline, pushing the economy into a double-dip recession.
But if households instead become optimistic about the pace of recovery, they might choose to cut back on their saving in order to maintain consumption, despite weak earnings.
Only time will tell.
Household saving is only one part of net national saving.
Since after-tax personal income accounts for about 75% of GDP, a household saving rate of 6% translates into just 4.5% of GDP.
Corporate retained earnings have averaged about 3% of GDP after allowing for depreciation of existing plant and equipment.
The combination of household and corporate saving brings total private saving to 7.5% of GDP.
Unfortunately, government borrowing to finance its deficit over the rest of this decade is projected to absorb about 5% of GDP.
That would leave a net national saving rate of just 2.5% of GDP.
Such a low national saving rate would not be sufficient to finance the level of new investment in plant, equipment, and housing that the country needs.
So, despite the rise in the household saving rate, unless federal government policies change to shrink America’s future budget deficits, the US will continue to be dependent on capital inflows from the rest of the world.
If that happens, global imbalances will continue to add risk to the global economy.
America\u0027s Schizophrenic Economy
The news about America's economy that dribbled out over the first half of March painted - once again - a picture that only a schizophrenic could create.
Real investment (investment adjusted for the declining prices of high-tech and information-related capital goods) continued to roar ahead.
Production and sales were consistent with the consensus forecast of real GDP growth at an annual rate of 4% or more.
Yet, despite all this, employment remained stagnant: net job creation in the United States continues to stall.
This does not mean that employment in America cannot grow.
Roughly 300,000 more Americans are employed in education and health care than a year ago - an annual rate of employment growth of 1.7%.
A quarter of a million more Americans are employed in business and professional services than a year ago - a 1.6% annual rate of employment growth.
The logic of stagnant employment is not that adding jobs to the American economy is impossible, but that demand growth is insufficient to create more jobs than are lost.
This is easy to demonstrate.
Total nominal spending in America grows at 5.5% per year.
Inflation is 1.5% per year. And overall productivity growth is 3.5% per year.
So the equation is simple: 5.5%-1.5%-3.5% = 0.5%.
That 0.5% is all that is left for job growth, because that's all the job growth required to meet demand given the remarkably strong rate of growth of productivity.
Where America's productivity growth is coming from is clear.
A relatively small part of it is coming from simple speed-up: in an economy where the amount of time it takes for the unemployed to find new jobs is close to a post-WWII record high, demands for speeding-up the pace of work will be met with a "Yes, boss!" rather than a "Take this job and shove it!"
A bigger part of this increased productivity comes from the extraordinary technological revolutions in computers and communications that have led to dramatic increases in the usefulness - and decreases in the cost - of high-tech capital.
The boost to wealth provided by the "new economy" is exceeding even its most avid boosters' wildest dreams.
What is unexpected is that the new wealth is flowing not to the shareholders of dot-com companies, but to purchasers and users of high-tech capital and the consumers they serve.
But why does this seem so surprising?
At the end of the nineteenth century the huge amount of investment and technological progress in America's railroads appeared to benefit everyone but the stockholders and bondholders of railroad companies, as bust followed boom and ramming worthless securities down the throats of investors became Wall Street's favorite sport.
Yet another part of US productivity growth due to the fact that high-tech capital gives America's firms enormous incentives to make massive but hard to see - and even harder to measure - investments in organization and business processes that are complementary to computerization and networking.
For the US to have a rate of productivity growth of 3.5% per annum rather than the pre-1995 rate of 1.2% is amazing.
That means an annual increment to world income of $250 billion from this source alone.
That's the equivalent of adding productive power equal to a quarter of the economy of India - and adding it every year.
This persistent acceleration in American productivity growth has, however, created a massive political problem for President George W. Bush.
Demand growth at a pace that in any previous decade would have been seen as highly satisfactory is suddenly desperately insufficient, and Bush is being blamed (with some justice) for the slack labor market that has resulted.
But for everyone except Bush - and those left unemployed by the lag in demand - it is an extraordinary opportunity.
The remarkable boosts to productivity that have been within America's grasp will ultimately lead to accelerating growth of real profits and real wages, if only US policy makers resist the temptation to pursue politically expedient, but economically damaging, measures to "protect" output and employment.
As the world's leading-edge economy, America faces the hardest work in ensuring growth, for it must create - not only copy and adapt - new technologies, better forms of capital, and more productive business organizations.
If America can grow as fast as it is now, that is very good news for other, less-developed economies, especially since one powerful effect of ongoing technological revolutions in computers and communications is to make it much easier to participate in the global division of labor now centered in the US.
So the schizophrenic American economy is a sign that the world is entering an economic era of truly wonderful things - if only we properly, and patiently, grasp them.
America’s Scorched Earth Management
Signs of the American economy’s perilous condition are everywhere – from yawning fiscal and current-account deficits to plummeting home prices and a feeble dollar.
But something that shows up in none of the economic indicators may be driving many of them: the deterioration of American management, which is undermining not only many of America’s great enterprises, but also its legendary spirit of enterprise.
Paradoxically, one indicator that has been improving steadily in the US – productivity – may be the clearest sign of the problem.
When it comes to productivity, managers either invest in employee training, more efficient manufacturing processes, and the like, or they take steps that appear to boost productivity in the short run but that erode it in the long run.
Productivity is a measure of output per hour worked.
So a company that fires all its workers and then ships from stock can look very productive – until it runs outs of stock.
Of course, no company can do that, but many US companies have been shedding workers and middle managers in great numbers – the figures for January 2008 were up 19% from a year earlier.
Meanwhile, those employees left behind must work that much harder, often without increased compensation.
Workers’ wages, adjusted for inflation, fell in 2007, continuing a trend throughout this decade.
That, too, is “productive” – until these overworked people quit or burn out.
A sustainable company is not a collection of “human resources.”
It is a community of human beings.
Its strength resides in its people, its culture, and the goodwill it has built up among its customers and suppliers.
So, as workers and middle managers have been departing these companies, they have taken with them not only much critical information, but often also the hearts and souls of their enterprises, with profound effects on American competitiveness.
Consider high technology, where America is supposed to excel.
According to a November 2006 report by The Task Force on the Future of American Innovation, made up of prominent universities, think tanks, industry trade associations, and corporations, the high-tech trade deficit widened in 2005, for the third consecutive year. This is not clothing or cars, but America’s largest, and most renowned, export sector.
This deficit reflects an underlying research deficit.
Of the 25 companies granted the most US patents in 2006, only eight were American; 12 were Japanese.
Perhaps this helps to explain why, in a survey of more than 60,000 people in 29 countries conducted in 2007 by the New York-based Reputation Institute to rank the “world’s most respected companies,” the first US company on the list appeared in 15th place; the second was in 25th place.
No one can determine how much of America’s productivity gains in recent years have resulted from squeezing human capital, because such things are not measured.
But there has clearly been a great deal of reliance on this strategy, with companies shedding employees not only because they must, but often because they have not met Wall Street analysts’ financial expectations.
Managers’ increased focus on maximizing shareholder value won many adherents when the idea was introduced in the 1980’s: the impersonal discipline of financial markets would force companies to become more productive and innovative.
And, in fact, much of the US productivity increase in the 1980’s and 1990’s can likely be attributed to large-scale investment in information and communications technology.
But, as the marginal productivity gains from such investment began to fall, senior managers’ survival and compensation continued to be tied to stock-market performance.
As a result, many simply learned to manage their companies’ short-term share price at the expense of attention to their products and customers.
Moreover, because maximizing shareholder value is a poor incentive for workers and middle managers, companies’ boards have increasingly centralized power around chief executives, thereby encouraging a “heroic” form of leadership that is detached from the rest of the enterprise. Indeed, in many cases, the CEO – frequently a Wall Street-endorsed “superstar” parachuted in to “shake things up” – now

This shift to “heroic” leadership can be seen in ballooning CEO compensation.
According to a January 2008 report by the Hay Group, the CEO’s of the 50 largest US companies are now paid almost three times what their European counterparts receive ­– which is many hundreds of times more than their own workers.
Until recently, the US asset-price bubble ­– first in the stock market, then in real estate – masked the underlying depreciation of American enterprises.
But the bubble itself resulted from the same management pathologies as those afflicting the real economy.
After all, managing for the short run encouraged mortgage lenders to offer artificially low “teaser” interest rates to lure potential homeowners.
And then those who bought these mortgages never bothered to investigate their underlying value – a spectacular abdication of managerial responsibility.
Now that the bubble has burst, America’s current economic downturn is likely to be far worse than previous ones, because US enterprises will have to be rebuilt, slowly and carefully.
The dramatic weakening of the US dollar may help America to narrow its massive trade deficit, but we should not expect any sustained improvement without drastic changes in American management.
Fortunately, it may be possible to minimize the fallout for the rest of the world.
While American economists, politicians, and business leaders have for years sought to sell their model of management abroad, many companies elsewhere have not been buying it.
As a result, other key economies remain healthier than America’s.
Make no mistake: this problem was made in America, and that is where it will have to be solved.
America\u0027s Second Gilded Age
The richest Congressional district in the US is the so-called "silk-stocking" district of New York City's Upper East Side, with a per-capita income of $41,151 per year.
The poorest Congressional district is a largely Hispanic-immigrant district in Los Angeles, with a per-capita income of $6,997 a year.
In 1973 the poorest fifth of America's families had incomes that averaged $13,240 a year (in today's dollars); in 2000 the average incomes of the poorest fifth were the same: $13,320.
By contrast, the richest 5% of America's families in 1973 had an average income of $149,150, and in 2000 the richest 5% had an average income of $254,840.
The increase in inequality was large enough to give a 2/3 income boost to the well-off over a time when incomes in the middle grew by only 10% and incomes at the bottom not at all.
To outsiders, the most peculiar thing about America's rising inequality is that so few Americans object.
Surely a society with a skewed income distribution is worse off than one in which incomes are more equal.
An extra $10,000 a year does little to raise the well-being of a multi-millionaire, while a deficiency of $10,000 a year makes a huge impact on how a middle-class family lives.
If you follow Nobel Prize-winner James Buchanan's utilitarian principle that you should evaluate a society's social welfare by imagining that you have an equal chance of being poor and rich, it is easy to judge that the more equal society has a better set of social and economic arrangements.
From there it is easy to make the leap to the position that - so long as redistributive taxes don't slow economic growth - when inequality rises, it is the government's duty to tax the rich and transfer money to the poor to offset the rise.
Yet there are no calls in mainstream politics to sharply increase the progressiveness of the income tax.
Indeed, even at the left end of mainstream discourse, the boldest call is for the well-off merely to contribute their "fair share" to paying for the costs of government.
One candidate for the Senate in the recent US elections, Erskine Bowles of North Carolina (a former chief of staff to President Clinton) was judged bold and foolhardy not for proposing redistributive tax increases, but simply for placing a higher priority on the federal government paying for prescription medicines than on a further cut in the highest marginal tax rate.
What happened?
Bowles lost.
Virtually no mainstream American politician seems opposed to eliminating the estate tax - a policy move that will further concentrate wealth for no countervailing supply-side gain.
As Clinton's Assistant to the President for Economic Policy Gene Sperling once wrote, staff aides who tell Congressmen that estate tax repeal "...costing tens of billions of dollars... will benefit only a few thousand families" are answered "maybe so, but I think I met every one of them at my last fundraiser."
It's not the case that the striking increase in income inequality was necessary to deliver rapid economic growth.
Most of the increase took place, after all, between 1973 and 1995 - a period during which American economic growth was slower than in any other period since the Great Depression.
It's not the case that income gains in the middle have been large enough to make mainstream voters feel generous about what is happening among their merchant princes: save for the past half-decade, income gains away from the top have been so meager that it's hard to argue that people are living much better than their parents did.
So why don't Americans feel more alarm at their country's rising income inequality?
Part of the reason that they don't is that most Americans do not recognize what is going on.
One poll found that 19% of Americans think their incomes put them in the top 1% of income distribution - and that 20% more hope to reach the top 1% someday.
Deep in the core of American ideology and culture is a constellation of beliefs and attitudes: belief that the future will be brighter than the present; that what you accomplish you make with your own hands; that individuals should rely on themselves, not the state; that people can cross oceans and mountains to make for themselves a better life; and that those who succeed do so not through luck and corruption but through preparation and industry.
These are not beliefs conducive to social democracy.
For two generations starting in 1933 America did look a lot like a west European-style social democracy.
The shock of the Great Depression and the response of Roosevelt's New Deal probably accounts for the shockingly "un-American" attitude toward redistribution of that era.
But somebody ten years old when Franklin Roosevelt was elected is now eighty.
Memories of the Great Depression are dying out.
So what now seems likely is that the older and more enduring - call it the Gilded Age - pattern of American ideology, culture, and political economy is reasserting itself.
Inequality, it seems, is as American as apple pie.
America’s Self-Defeating Hegemony
When I wrote about the “end of history” almost twenty years ago, one thing that I did not anticipate was the degree to which American behavior and misjudgments would make anti-Americanism one of the chief fault-lines of global politics.
And yet, particularly since the terrorist attacks of September 11, 2001, that is precisely what has happened, owing to four key mistakes made by the Bush administration.
First, the doctrine of “preemption,” which was devised in response to the 2001 attacks, was inappropriately broadened to include Iraq and other so-called “rogue states” that threatened to develop weapons of mass destruction.
To be sure, preemption is fully justified vis-à-vis stateless terrorists wielding such weapons.
But it cannot be the core of a general non-proliferation policy, whereby the United States intervenes militarily everywhere to prevent the development of nuclear weapons.
The cost of executing such a policy simply would be too high (several hundred billion dollars and tens of thousands of casualties in Iraq and still counting).
This is why the Bush administration has shied away from military confrontations with North Korea and Iran, despite its veneration of Israel’s air strike on Iraq’s Osirak reactor in 1981, which set back Saddam Hussein’s nuclear program by several years.
After all, the very success of that attack meant that such limited intervention could never be repeated, because would-be proliferators learned to bury, hide, or duplicate their nascent weapons programs.
The second important miscalculation concerned the likely global reaction to America’s exercise of its hegemonic power.
Many people within the Bush administration believed that even without approval by the UN Security Council or NATO, American power would be legitimized by its successful use.
This had been the pattern for many US initiatives during the Cold War, and in the Balkans during the 1990’s; back then, it was known as “leadership” rather than “unilateralism.”
But, by the time of the Iraq war, conditions had changed: the US had grown so powerful relative to the rest of the world that the lack of reciprocity became an intense source of irritation even to America’s closest allies.
The structural anti-Americanism arising from the global distribution of power was evident well before the Iraq war, in the opposition to American-led globalization during the Clinton years.
But it was exacerbated by the Bush administration’s “in-your-face” disregard for a variety of international institutions as soon it came into office – a pattern that continued through the onset of the Iraq war.
America’s third mistake was to overestimate how effective conventional military power would be in dealing with the weak states and networked transnational organizations that characterize international politics, at least in the broader Middle East.
It is worth pondering why a country with more military power than any other in human history, and that spends as much on its military as virtually the rest of the world combined, cannot bring security to a small country of 24 million people after more than three years of occupation.
At least part of the problem is that it is dealing with complex social forces that are not organized into centralized hierarchies that can enforce rules, and thus be deterred, coerced, or otherwise manipulated through conventional power.
Israel made a similar mistake in thinking that it could use its enormous margin of conventional military power to destroy Hezbollah in last summer’s Lebanon War.
Both Israel and the US are nostalgic for a twentieth-century world of nation-states, which is understandable, since that is the world to which the kind of conventional power they possess is best suited.
But nostalgia has led both states to misinterpret the challenges they now face, whether by linking al-Qaeda to Saddam Hussein’s Iraq, or Hezbollah to Iran and Syria.
This linkage does exist in the case of Hezbollah, but the networked actors have their own social roots and are not simply pawns used by regional powers.
This is why the exercise of conventional power has become frustrating.
Finally, the Bush administration’s use of power has lacked not only a compelling strategy or doctrine, but also simple competence.
In Iraq alone, the administration misestimated the threat of WMD, failed to plan adequately for the occupation, and then proved unable to adjust quickly when things went wrong.
To this day, it has dropped the ball on very straightforward operational issues in Iraq, such as funding democracy promotion efforts.
Incompetence in implementation has strategic consequences.
Many of the voices that called for, and then bungled, military intervention in Iraq are now calling for war with Iran.
Why should the rest of the world think that conflict with a larger and more resolute enemy would be handled any more capably?
But the fundamental problem remains the lopsided distribution of power in the international system.
Any country in the same position as the US, even a democracy, would be tempted to exercise its hegemonic power with less and less restraint.
America’s founding fathers were motivated by a similar belief that unchecked power, even when democratically legitimated, could be dangerous, which is why they created a constitutional system of internally separated powers to limit the executive.
Such a system does not exist on a global scale today, which may explain how America got into such trouble.
A smoother international distribution of power, even in a global system that is less than fully democratic, would pose fewer temptations to abandon the prudent exercise of power.
America’s Self-Inflicted Decline
MELBOURNE – If the broad post-World War II prosperity that has endured for six decades comes to an end, both the United States and Europe will be responsible.
With rare exceptions, politics has become a discredited profession throughout the West.
Tomorrow is always treated as more important than next week, and next week prevails over next year, with no one seeking to secure the long-term future.
Now the West is paying the price.
President Barack Obama’s instincts may be an exception here, but he is fighting powerful hidebound forces in the United States, as well as a demagogic populism, in the form of the Tea Party, that is far worse – and that might defeat him in 2012, seriously damaging America in the process.
America’s friends around the world watched with dismay the recent brawl in over raising the federal government’s debt ceiling, and the US Congress’s inability to come to anything like a balanced and forward-looking compromise.
On the contrary, the outcome represents a significant victory for the Tea Party’s minions, whose purpose seems to be to reduce government obligations and expenditures to a bare minimum (some object even to having a central bank), and to maintain President George W. Bush’s outrageous tax breaks for the wealthy.
America’s current fiscal problems are rooted in a long period of unfunded spending.
Bush’s wars in Afghanistan and Iraq, and the manner in which he conducted the “global war on terror” made matters much worse, contributing to a totally unsustainable situation.
Indeed, Obama inherited an almost impossible legacy.
In the weeks since the debt ceiling agreement, it has become increasingly clear that good government might be impossible in the US.
The coming months of campaigning for the US presidency will be spent in petty brawling over what should be cut.
The example of recent weeks gives us no cause for optimism that US legislators will rise above partisan politics and ask themselves what is best for America.
In these circumstances, it is not surprising that financial markets have returned to extreme volatility.
The expenditure cuts mandated by the outcome of the debt-ceiling debate will reduce economic activity, thereby undermining growth and making debt reduction even more difficult.
Providing further fiscal stimulus to boost economic growth would carry its own risks, owing to the debt ceiling and another, more ominous factor: America is already overly indebted, and there are signs that major holders of US government securities are finally tired of being repaid in depreciated currency.
Most importantly, China’s call for the introduction of a new reserve currency stems from its frustration with the failure of major governments – whether in the US or Europe – to govern their economic affairs with realism and good sense.
China recognizes that America is in great difficulty (indeed, it recognizes this more clearly than the US itself), and that, given the poisonous political atmosphere prevailing in Washington, there will be no easy return to good government, economic stability, and strong growth.
America’s leadership in world affairs began to weaken with the unilateralism of Bush, and today’s economic problems are reinforcing this tendency.
To reverse America’s decline, Obama needs bipartisan support for his (quite mainstream) policies, but so far the US Congress has shown no stomach for a principled approach to its legislative duties.
If Germany’s half-hearted efforts to stabilize Europe somehow turn out to be successful, America’s position will be further eroded, and central banks around the world will begin to regard the euro once again as a reliable alternative to the dollar as a reserve currency.
The alternative, as China has suggested, would be to develop a new reserve currency.
These realities represent a power shift of a kind that we have not experienced in our lifetimes.
China’s economic power over the US is now substantial, and will limit not only America’s influence in the financial markets, but also its capacity to use military power.
If this forces America back towards what the international-relations scholar Joseph Nye calls “soft power and multilateral diplomacy,” it may well be a good thing.
But such approaches are anathema to the US Republican Party, and to its Tea Party faction in particular, and they might unnerve the many Asians who are nervous at China’s growing military might.
The counter-argument – that any sell-off or failure by China to continue to buy US government securities would hurt China as much as America – is not valid.
As each year passes, China’s markets expand worldwide, and its domestic market comes to represent a greater percentage of its own GDP.
As a result, China will not need a strong dollar in the long term.
Americans need to get their economic house in order before China loses its incentive to support the dollar.
On several occasions in the post-WWII period, the US has learned with great pain that there are limits to the effective use of military power.
American objectives could not be achieved in Vietnam.
The outcome in Iraq will not be determined until the last American troops have been withdrawn.
In Afghanistan, where withdrawal dates have already been set, it is difficult to believe that a cohesive unified state can be established.
As the efficacy of military power is reduced, so the importance of economic power grows.
Recognition of these central realities – and bipartisanship in addressing them – is critical for America’s future, and that of the West.
America’s Sleeping Watch Dog
I want to deviate from my usual economic theme this month and focus instead on the system by which the press – mostly the American press – covers government nowadays.
But perhaps this is not too great a deviation, for the behavior of the press affects not only politics, but economics as well.
Consider an editorial written in March by the Washington Post’s editorial director, Fred Hiatt, in which he makes a very small and limited apology for the newspaper’s coverage and evaluation of the Bush administration.
According to Hiatt, “We raised such issues” as whether the Bush administration had properly thought its proposed adventure in Iraq through, “but with insufficient force.” In other words, Hiatt finds fault with himself and his organization for saying the right thing, but not loudly enough.
Next, consider a comment by the former editor of the New York Times, Max Frankel, about how the Washington ecology of media leaks is healthy, because “most reporters do not just lazily regurgitate...leaks.” Instead, “they use them as wedges to pry out other secrets” and so oversee the government.
The system may be “sloppy and breed confusion,” but “tolerating abusive leaks by government [that misinform] is the price that society has to pay for the benefit of receiving essential leaks about government.”
So, where Hiatt sees a press corps that was a little too cowardly about overseeing the Bush administration, Frankel sees a press corps where a sloppy and confusing process is nevertheless doing a reasonable job.
I see a very different picture.
It was the summer of 2000 when I began asking Republicans I know – generally people who might be natural candidates for various sub-cabinet policy positions in a Republican administration – how worried they were that the Republican presidential candidate, George W. Bush, was clearly not up to the job.
They were not worried, they told me, that Bush was inadequately briefed and strangely incurious for a man who sought the most powerful office in the world.
One of President Clinton’s problems, they said, was that the ceremonial portions of the job bored him – and thus he got himself into big trouble.
Look at how Bush had operated as president of the Texas Rangers baseball club, they said.
Bush let the managers manage the team and the financial guys run the business.
He spent his time making sure the political coalition to support the Texas Rangers in the style to which it wanted to be accustomed remained stable.
Bush knows his strengths and weaknesses, they told me.
He will focus on being America’s Queen Elizabeth II, and will let people like Colin Powell and Paul O’Neill be America’s Tony Blair and Gordon Brown.
By the summer of 2001, it had become clear that something had gone very wrong.
By that point, Bush had rejected O’Neill’s and Christine Todd Whitman’s advice on environmental policy, just as he had rejected Alan Greenspan’s and O’Neill’s advice on fiscal policy, Powell’s and Condoleezza Rice’s advice on the importance of pushing forward on negotiations between Israel and Palestine, and – as we learned later – George Tenet’s and Richard Clarke’s advice about the importance of counterterrorism.
A strange picture of Bush emerged from conversations with sub-cabinet administration appointees, their friends, and their friends of friends.
He was not just under-briefed, but also lazy: he insisted on remaining under-briefed.
He was not just incurious, but also arrogant: he insisted on making uninformed decisions, and hence made decisions that were essentially random.
And he was stubborn: once he had made a decision – even, or rather especially, if it was glaringly wrong and stupid – he would never revisit it.
So, by the summer of 2001, a pattern was set that would lead British observer Daniel Davies to ask if there was a Bush administration policy on anything of even moderate importance that had not been completely bollixed up.
But if you relied on either the Washington Post or the New York Times, you would have had a very hard time seeing it.
Today, it is an accepted fact that the kindest thing you can say about the Bush administration is that it is completely incompetent, which is the line now taken by hard-line Bush supporters like the National Review and the commentator Robert Novak.
Why didn’t the American press corps cover the Bush administration properly for its first five years?
I really do not know.
I do know that the world cannot afford to rely again on America’s press for its information: fool me once, shame on you; fool me twice, shame on me.
So I appeal to all of you working for newspapers, radio, and television stations outside the United States: it is to you that we – including those of us in America – must look to discover what our own government is doing.
America’s Sputnik Moment in Beijing
NEW YORK – August 8, 2008, may someday be remembered as the first day of the post-American era.
Or it could be remembered as another “Sputnik moment,” when, as with the Soviet foray into outer space in 1957, the American people realized that the country had lost its footing and decided it was time for the United States to get its act together.
There was no mistaking the power and symbolism of the opening ceremonies for the Beijing Olympic Games on August 8.
That multimedia spectacular did far more than trace China’s 5,000-year history; it was a statement that China is a major civilization that demands and deserves its rightful place in the global hierarchy.
There was also no mistaking the symbolism of seeing President Bush, waving cheerfully from his spot in the bleachers while Chinese President Hu Jintao sat behind what looked more like a throne.
It is hard to imagine that China’s government, which obsesses over every minute issue of diplomatic protocol, had not orchestrated this stark image of America’s decline relative to the country to which it owes $1.4 trillion.
It would be hard to imagine Franklin Roosevelt or Ronald Reagan accepting a similar relative position.
At the very same time that Bush was waving from the stands, Russia was invading Georgia, America’s closest partner in the Caucasus.
Russia’s message to other West-leaning countries in the former Soviet world was clear: America cannot protect you.
Frighteningly, the Russians were likely correct.
While the Iraq quagmire has made it difficult for America to project force around the world, America’s growing debt, conflicts with friends and enemies alike, absence of any perceivable strategy for changing times, and its political system’s seeming inability to take action to address these challenges have combined to turn America into a struggling giant.
Today, from Iran to Darfur to Zimbabwe to Georgia, the world is witnessing the effects of a budding post-American world, and the picture does not look pretty.
As much as we all value the rise of new powers like China and India, it remains to be seen whether these countries will become as benevolent a power as America, however flawed, has been over the past half-century.
Neo-colonialism is returning to Africa, the global project of human rights is in retreat, and the world trade system is becoming far less open.
Brutal dictators go unpunished because their interests are protected by large powers with stakes in their natural resources.
Reversing this trend is not only in America’s interest, but also in the world’s interest.
To do so, Americans must identify and address the great challenges the United States faces, starting from the ground up.
Fixing America’s campaign finance structure, which leads to massive misallocations of government funds, resuscitating America’s wildly uneven and often moribund education system, building an immigration system that actively recruits the most talented people from around the world via a fast track to US citizenship, and developing a national energy policy that moves the US far more quickly toward energy independence would all be important steps in this direction.
Working to rebuild the traditional bipartisan foreign-policy consensus would also make the US a far more predictable partner to friends and allies around the world.
And America must be a respectful partner in order to encourage rising powers like India and China to play more constructive roles in international affairs.
The world is not ready for the post-American era, and countries like China and India must play a far greater role in strengthening the existing institutions of world peace and, where appropriate, building new ones that can promote a positive agenda of security, dignity, rights, and prosperity across the globe.
The world community is not there yet, and until it is, the world needs a new kind of American leader – a leader able to inspire Americans to fix their problems at home and work with partners across the globe in promoting a common agenda as bold and progressive as the order built from the ashes of World War II 60 years ago.
The Beijing Olympics could be remembered as a new “Sputnik moment” for the US, inspiring the country to meaningfully face the music of a changing world.
But America can make it so only by recognizing the great challenges it faces and taking bold steps towards addressing them, at home and with allies abroad.
America’s Perilous Pivot
MADRID – The Pacific or the Middle East?
For the United States, that is now the primary strategic question.
The violence in Gaza, coming as President Barack Obama was meeting Asia’s leaders in Phnom Penh, perfectly encapsulates America’s dilemma.
Instead of being able to focus on US foreign policy’s “pivot” to Asia, Obama was forced to spend many hours in conversation with the leaders of Egypt and Israel, and to dispatch Secretary of State Hillary Clinton from Asia, in order to facilitate a cease-fire in Gaza.
Of the two geopolitical focal points demanding America’s attention, one represents the future and the other the past.
Whereas Asia played an important role in a US presidential election campaign that was marked by often-heated references to China’s rise, the Middle East has kept the US bogged down for decades.
In addition to the eternal Israel-Palestine conflict, Iraq’s instability, the Arab Spring, Syria’s civil war, and the ongoing nuclear standoff with Iran all demand America’s attention.
If the Iran crisis were to boil over, the pivot to Asia would no longer be America’s main foreign-policy priority.
But if the dispute with Iran is resolved diplomatically, the Middle East might, perhaps, be relegated to a position of lesser importance, as Obama clearly desires.
The question, therefore, is whether the US will find itself drawn into another war in a region on which it depends less and less for energy.
Indeed, the revolution in non-conventional hydrocarbons, particularly shale gas and oil, which the International Energy Agency recently predicted would make the US the world’s largest oil producer by 2020, and the top energy producer overall by 2030, will have enormous global repercussions.
For the US, energy self-sufficiency is the perfect excuse for a phased withdrawal from the Middle East; freed from energy dependency, America should be able to concentrate on the Pacific.
Although maintaining stable global energy prices and its alliance with Israel means that the US cannot cut itself off completely from the Middle East’s troubles, the shift in focus to Asia began early in Obama’s first administration, with Clinton announcing America’s strategic reorientation even before US troops began withdrawing from Iraq.
Following his re-election, Obama’s first foreign visit was to Myanmar, Thailand, and Cambodia – a choice that cannot have pleased China, as all three are ASEAN members, while Myanmar was, until it began its democratic transition, a close Chinese ally.
Asia is, of course, experiencing rapid economic growth, but managing the region’s strong nationalist tensions calls for the creation of regional security structures, together with closer economic integration.
Complicating matters even more is what US scholar Kenneth Lieberthal and Wang Jisi, the dean of international studies at Peking University, called in a recent paper for the Brookings Institution “strategic distrust.”
Cultivating strategic trust between the twenty-first century’s leading powers will be fundamental to the international system’s harmonious functioning.
But how can this be achieved?
As China will be importing three-quarters of its oil from the Middle East by 2020, one step forward would be China’s cooperation in finding solutions to the region’s problems.
After the January 2013 Israeli elections, Iran will again move to the top of Obama’s foreign-policy agenda.
Military intervention in Iran – which itself will be holding a presidential election in June – would incite not only regional, but global, instability.
The Arab world, Russia, and China would be forced to take sides, straining global relations between the different poles of power and raising tensions in the Pacific.
So China has a large strategic interest in working with the US to avoid a showdown.
Beyond Iran, the volatile situation throughout the Middle East urgently demands solutions.
The latest eruption of violent conflict between Hamas and Israel underscores the importance of reviving the peace process.
Syria’s civil war, in which a growing number of regional players have become involved, is beginning to look increasingly like a trial run for all-out war between Sunni Muslims (Saudi Arabia and the other Gulf States, Turkey, and Egypt) and Shia Muslims (Iran and Hezbollah) for regional dominance.
Iran’s leaders appear to believe that the US, having incurred extremely high economic and human costs from more than a decade of war, would rather avoid another military intervention.
US public opinion seems to confirm this.
A recent survey by the Chicago Council on Global Affairs indicated that 67% of Americans believe that the Iraq war was not worthwhile.
Moreover, 69% do not believe that the US is safer from terrorism since the war in Afghanistan, and 71% say that the experience in Iraq shows that the US should take greater care in how it uses force.
But, if Americans seem unlikely to be willing to invest billions of dollars in another dead-end foreign adventure, Iran’s leaders, for their part, are increasingly hemmed in by international sanctions, which are beginning to wreak havoc on the country’s economy.
Both sides may believe that their best option – at least for now – is to negotiate.
Peaceful resolution of the Iranian question would help the US to complete its shift toward Asia.
China may not wish for that outcome, but its own vital interest in the security of Middle East energy supplies should compel it to cooperate.
After all, another Middle East conflict would poison and distort relations in the region for decades, which would be the worst of all possible consequences – for the US and China alike.
America’s Suicidal Statecraft
Since its victory in the Cold War, America’s global hegemony has rested on three pillars: economic power, military might, and a vast capacity to export its popular culture.
The recent emergence of additional powers – the European Union, China, India, and a Russia driven to recover its lost status – has eroded America’s capacity to shape events unilaterally.
Even so, America remains by far the world’s most powerful country; its decline has more to do with its incompetent use of power than with the emergence of competitors.
It is American leaders’ “suicidal statecraft,” to use Arnold Toynbee’s pithy phrase for what he considered the ultimate cause of imperial collapse, that is to blame for America’s plight.
Consider the Middle East.
Nothing reveals the decline of the United States in the region better than the contrast between America’s sober use of power in the first Gulf War in 1991 and the hubris and deceit of today’s Iraq war.
In 1991, America forged the most formidable international coalition since World War II, and led it in a fully legitimate war aimed at restoring regional balance after Saddam Hussein’s invasion of Kuwait.
In 2003, America went to war without its trans-Atlantic allies after manipulating false assertions.
In doing so, the US embarked on a preposterous grand strategy that aimed no less at simultaneously dismantling Iraq’s tyrannical regime, restructuring the entire Middle East, destroying al-Qaeda, and helping democracy to take root throughout the Arab world.
The result has been utter failure: military defeat and a severe degradation of America’s moral standing.
Rather than undermining radical Islam, the US has legitimized it, in Iraq and beyond.
Indeed, what will now shape the future of the region is not democracy, but the violent divide between Shiites and Sunnis that the Iraq war precipitated.
It is this Muslim civil war that is allowing al-Qaeda to gain a larger pool of recruits.
With Iraq probably becoming the first Arab country to be ruled by Shiites, and hence integrated into an expanding Shiite Iranian empire, America’s Sunni allies in the region now view the US as unreliable.
Indeed, the US is seen as practically complicit in inciting a monumental reversal of Islam’s fortunes, the Shia revival.
Nor is the gospel of democracy especially dear to America’s Arab allies, for the call to democratize has only emboldened the Islamists to challenge the incumbent elites for power.
Admittedly, violent Islamic fundamentalism has deeper roots in the fading promise of Arab nationalism.
But America’s misbegotten democratic message has ended up alienating both its conservative regional allies, as it gave a new lease on life to political Islam, which can use the ballot box as a route to power, and the Islamists, whose electoral gains are then rejected by the US.
America’s biggest strategic blunder in the Middle East arguably concerns the emergence of Iranian power.
By destroying Iraq as a counterbalancing regional force, the US dealt a major blow to its traditional Gulf allies, for whom Iraq served as a barrier against Iran’s ambitions.
America offered Iran on a silver platter strategic assets that Khomeini’s revolution failed to acquire either in eight years of war against Saddam or in its abortive attempts to export the Islamic revolution throughout the region.
Likewise, Iran’s nuclear program gained momentum thanks to its sense of impunity following the colossal failure in Iraq of America’s concept of “preventive war.”
The calamitous US military experience in Iraq has left it strategically diminished.
Iraq has now become God’s playground, and America can hope to achieve a modicum of stability there only with the help of other regional powers.
Nevertheless, the US will remain the most influential external actor in the Middle East, for its failure is one of leadership, not of actual power.
Humbled by military defeat, America can recover its regional relevance only by avoiding the sin of hubris, and learning to lead without attempting to dominate.
This requires engaging revolutionary forces like Iran and Syria; respecting, rather than ostracizing, those Islamist movements that have opted out from jihadism in favor of political participation; and leading an international alliance for an Arab-Israeli peace based on the Arab League initiative.
Indeed, the paradox of America’s pernicious policies in Iraq is that they have created favorable conditions for an Arab-Israeli peace, as the emergence of Iran and the threat of a fundamentalist tsunami have focused Arab minds on the urgency of a settlement with Israel.
The Palestinian issue is not the source of all the Middle East’s ills, but its resolution would dramatically improve America’s standing among Arabs.
More importantly, it would deny Iran the ability to link popular Islamic and Arab causes with its own hegemonic ambitions.
America’s Threat to Trans-Pacific Trade
MUMBAI – As if undermining the World Trade Organization’s Doha Round of global free-trade talks was not bad enough (the last ministerial meeting in Geneva produced barely a squeak), the United States has compounded its folly by actively promoting the Trans-Pacific Partnership (TPP).
President Barack Obama announced this with nine Asian countries during his recent trip to the region.
The TPP is being sold in the US to a compliant media and unsuspecting public as evidence of American leadership on trade.
But the opposite is true, and it is important that those who care about the global trading system know what is happening.
One hopes that this knowledge will trigger what I call the “Dracula effect”: expose that which would prefer to remain hidden to sunlight and it will shrivel up and die.
The TPP is a testament to the ability of US industrial lobbies, Congress, and presidents to obfuscate public policy.
It is widely understood today that free-trade agreements (FTAs), whether bilateral or plurilateral (among more than two countries but fewer than all) are built on discrimination.
That is why economists typically call them preferential-trade agreements (PTAs).
And that is why the US government’s public-relations machine calls what is in fact a discriminatory plurilateral FTA, a “partnership” invoking a false aura of cooperation and cosmopolitanism.
Countries are, in principle, free to join the TPP.
Japan and Canada have said they plan to do so.
But a closer look reveals that China is not a part of this agenda.
The TPP is also a political response to China's new aggressiveness, built therefore in a spirit of confrontation and containment, not of cooperation.
The US has been establishing a template for its PTAs that includes several items unrelated to trade.
So it is no surprise that the TPP template includes numerous agendas unrelated to trade, such as labor standards and restraints on the use of capital-account controls, many of which preclude China’s accession.
From the outset, the TPP’s supposed openness has been wholly misleading.
Towards this end, the TPP was negotiated with the weaker countries like Vietnam, Singapore, and New Zealand, which were easily bamboozled into accepting such conditions.
Only then were bigger countries like Japan offered membership on a “take it or leave it” basis.
The PR machine then went into overdrive by calling the inclusion of these extraneous conditions as making the TPP a “high-quality” trade agreement for the twenty-first century, when in fact it was a rip-off by several domestic lobbies.
American regionalism closer to home shows the US now trying to promote the Free Trade Agreement of the Americas (FTAA).
But its preferred template was to expand the North America Free Trade Agreement (Canada, Mexico, and the US) to the Andean countries and include huge doses of non-trade-related issues, which they swallowed.
This was not acceptable to Brazil, the leading force behind the FTAA, which focuses exclusively on trade issues.
Brazil’s former President Luiz Lula Inácio da Silva, one of the world’s great trade-union leaders, rejected the inclusion of labor standards in trade treaties and institutions.
The result of US efforts in South America, therefore, has been to fragment the region into two blocs, and the same is likely to happen in Asia.
Ever since the US realized that it had chosen the wrong region to be regional with, it has been trying to win a seat at the Asian table.
The US finally got it with the TPP, simply because China had become aggressive in asserting its territorial claims in the South China Sea, the South China Sea, and vis-à-vis India and Japan.
Many Asian countries joined the TPP to “keep the US in the region” in the face of Chinese heavy-handedness.
They embraced the US in the same way that East Europeans rushed to join NATO and the European Union in the face of the threat, real or imagined, posed by post-Soviet Russia.
America’s design for Asian trade is inspired by the goal of containing China, and the TPP template effectively excludes it, owing to the non-trade-related conditions imposed by US lobbies.
The only way that a Chinese merger with the TPP could gain credibility would be to make all non-trade-related provisions optional.
Of course, the US lobbies would have none of it.
America’s Three Deficits
BERKELEY – This year began with a series of reports providing tantalizing evidence that economic recovery in the United States is strengthening.
The pace of job creation has increased, indicators for manufacturing and services have improved, and consumption spending has been stronger than anticipated.
But it is too early to celebrate.
Output growth in the US remains anemic, and the economy continues to face three significant deficits: a jobs deficit, an investment deficit, and a long-run fiscal deficit, none of which is likely to be addressed in an election year.
Although output is now higher than it was in the fourth quarter of 2007, it remains far below what could be produced if labor and capacity were fully utilized.
That gap – between actual and potential output – is estimated at more than 7% of GDP (more than $1 trillion).
The output gap reflects a deficit of more than 12 million jobs – the number of jobs needed to return to the economy’s peak 2007 employment level and absorb the 125,000 people who enter the labor force each month.
Even if the economy grows at 2.5% in 2012, as most forecasts anticipate, the jobs deficit will remain – and will not be closed until 2024.
America’s jobs deficit is primarily the result of inadequate aggregate demand.
Consumption, which accounts for about 70% of total spending, is constrained by high unemployment, weak wage gains, and a steep decline in home values and consumer wealth.
The uptick in consumption in the last months of 2011 was financed by a decline in the household saving rate and a large increase in consumer credit.
Neither of these trends is healthy or sustainable.
With an unemployment rate of 8.5%, a labor-force participation rate of only 64%, and stagnant real wages, labor income has fallen to an historic low of 44% of national income.
And labor income is the most important component of household earnings, the major driver of consumption spending.
Even before the Great Recession, American workers and households were in trouble.
The rate of job growth between 2000 and 2007 slowed to only half its level in the three preceding decades.
Productivity growth was strong, but far outpaced wage growth, and workers’ real hourly compensation declined, on average, even for those with a university education.
Indeed, the 2002-2007 period was the only recovery on record during which the median family’s real income declined.
Moreover, job opportunities continued to polarize, with employment growing in high-wage professional, technical, and managerial occupations, as well as in low-wage food-service, personal-care, and protective-service occupations.
By contrast, employment in middle-skill, white-collar, and blue-collar occupations fell, particularly in manufacturing.
Hard-pressed American households slashed their savings rates, borrowed against their home equity, and increased their debt to maintain consumption, contributing to the housing and credit bubbles that burst in 2008, requiring painful deleveraging ever since.
Three forces have driven the US labor market’s adverse structural changes:
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Skill-biased technological change, which has automated routine work while boosting demand for highly educated workers with at least a college degree.
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Global competition and the integration of labor markets through trade and outsourcing, which have eliminated jobs and depressed wages.
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; America’s declining competitiveness as an attractive place to locate production and employment.
Technological change and globalization have created similar labor-market challenges in other developed countries.
But US policy choices are responsible for the erosion of America’s competitiveness.
In particular, the US is underinvesting in three major areas that help countries to create and retain high-wage jobs: skills and training, infrastructure, and research and development.
Spending in these areas accounts for less than 10% of US government spending, and this share has been declining over time.
The federal government can currently borrow at record-low interest rates, and there are many projects in education, infrastructure, and research that would earn a higher return, create jobs now, and bolster US competitiveness in attracting high-wage jobs.
President Barack Obama has offered numerous proposals to invest in the foundations of national competitiveness, but Congressional Republicans have rebuffed them, claiming that the US faces an impending fiscal crisis.
In fact, the federal deficit as a share of GDP will shrink significantly over the next several years, even without further deficit-reduction measures, before rising to unsustainable levels by 2030.
The US does indeed face a long-run fiscal deficit, largely the result of rising health-care costs and an aging population.
But the current fiscal deficit mainly reflects weak tax revenues, owing to slow growth and high unemployment, and temporary stimulus measures that are fading away at a time when aggregate demand remains weak and additional fiscal stimulus is warranted.
At the very least, to keep the economy on course for 2.5% growth this year, the payroll tax cut and unemployment benefits proposed by Obama should be extended through the end of the year.
These measures would provide insurance to the fragile recovery and add nothing to the long-run fiscal gap.
So, how should the US economy’s jobs deficit, investment deficit, and long-run fiscal deficit be addressed?
Policymakers should pair fiscal measures to ameliorate the jobs and investment deficits now with a multi-year plan to reduce the long-run fiscal deficit gradually.
This long-run plan should increase spending on education, infrastructure, and research, while curbing future growth in health-care spending through the cost-containment mechanisms contained in Obama’s health-reform legislation.
Approving a long-run deficit-reduction plan now but deferring its starting date until the economy is near full employment would prevent premature fiscal contraction from tipping the economy back into recession.
Indeed, enactment of such a package could bolster output and employment growth by easing investor concerns about future deficits and strengthening consumer and business confidence.
Painful choices about how to close the long-run fiscal gap should be decided now and implemented promptly once the economy has recovered.
But, for the next few years, the priorities of fiscal policy should be jobs, investment, and growth.
America’s Ungovernable Budget
NEW YORK – The heart of any government is found in its budget.
Politicians can make endless promises, but if the budget doesn’t add up, politics is little more than mere words.
The United States is now caught in such a bind.
In his recent State of the Union address, President Barack Obama painted a convincing picture of modern, twenty-first-century government.
His Republican Party opponents complained that Obama’s proposals would bust the budget.
But the truth is that both parties are hiding from the reality: without more taxes, a modern, competitive US economy is not possible.
Obama rightly emphasized that competitiveness in the world today depends on an educated workforce and modern infrastructure.
That is true for any country, but it is especially relevant for rich countries. The US and Europe are in direct competition with Brazil, China, India, and other emerging economies, where wage levels are sometimes one-quarter those in high-income countries (if not even lower).
America and Europe will keep their high living standards only by basing their competitiveness on advanced skills, cutting-edge technologies, and modern infrastructure.
That is why Obama called for an increase in US public investment in three areas: education, science and technology, and infrastructure (including broadband Internet, fast rail, and clean energy).
He spelled out a vision of future growth in which public and private investment would be complementary, mutually supportive pillars.
Obama emphasized these themes for good reason.
Unemployment in the US now stands at nearly 10% of the labor force, in part because more new jobs are being created in the emerging economies, and many of the jobs now being created in the US pay less than in the past, owing to greater global competition.
Unless the US steps up its investment in education, science, technology, and infrastructure, these adverse trends will continue.
But Obama’s message lost touch with reality when he turned his attention to the budget deficit.
Acknowledging that recent fiscal policies had put the US on an unsustainable trajectory of rising public debt, Obama said that moving towards budget balance was now essential for fiscal stability.
So he called for a five-year freeze on what the US government calls “discretionary” civilian spending.
The problem is that more than half of such spending is on education, science and technology, and infrastructure – the areas that Obama had just argued should be strengthened.
After telling Americans how important government investment is for modern growth, he promised to freeze that spending for the next five years!
Politicians often change their message from one speech to the next, but rarely contradict it so glaringly in the same speech.
That contradiction highlights the sad and self-defeating nature of US budget policies over the past 25 years, and most likely in the years to come.
On the one hand, the US government must invest more to promote economic competitiveness.
On the other hand, US taxes are chronically too low to support the level of government investment that is needed.
America’s fiscal reality was made painfully clear two days after Obama’s speech, in a new study from the Congressional Budget Office, which revealed that the budget deficit this year will reach nearly $1.5 trillion – a sum almost unimaginable even for an economy the size of the US.
At nearly 10% of GDP, the deficit is resulting in a mountain of debt that threatens America’s future.
The CBO study also made clear that December’s tax-cut agreement between Obama and the Republican opposition willfully and deliberately increased the budget deficit sharply.
Various tax cuts initiated by George W. Bush were set to expire at the end of 2010.
Obama and the Republicans agreed to continue those tax cuts for at least two years (they will now probably continue beyond that), thereby lowering tax revenue by $350 billion this year and again in 2012.
Tax cuts for the richest Americans were part of the package.
The truth of US politics today is simple.
The key policy for the leaders of both political parties is tax cuts, especially for the rich.
Both political parties, and the White House, would rather cut taxes than spend more on education, science and technology, and infrastructure.
And the explanation is straightforward: the richest households fund political campaigns.
Both parties therefore cater to their wishes.
As a result, America’s total tax revenues as a share of national income are among the lowest of all high-income countries, roughly 30%, compared to around 40% in Europe.  But 30% of GDP is not enough to cover the needs of health, education, science and technology, social security, infrastructure, and other vital government responsibilities.
One budget area can and should be cut: military spending.
But even if America’s wildly excessive military budget is cut sharply (and politicians in both parties are resisting that), there will still be a need for new taxes.
The economic and social consequences of a generation of tax cutting are clear.
America is losing its international competitiveness, neglecting its poor – one in five American children is trapped in poverty – and leaving a mountain of debt to its young.
For all of the Obama administration’s lofty rhetoric, his fiscal-policy proposals make no serious attempt to address these problems.
To do so would require calling for higher taxes, and that – as George H. W. Bush learned in 1992 – is no way to get re-elected.
America’s Unhinged “Pivot”
NEW DELHI – President Barack Obama’s first foreign trip since winning a second term highlights Asia’s new centrality to America’s economy and security.
But Obama’s Asian tour also underscores the main question about American policy in the region: Will the United States’ “pivot” to Asia acquire concrete strategic content, or will it remain largely a rhetorical repackaging of old policies?
The United States, quick to capitalize on regional concerns triggered by China’s increasingly muscular self-assertion, has strengthened its military ties with its existing Asian allies and forged security relationships with new friends.
But the heady glow of America’s return to center stage in Asia has obscured key challenges in remaining the region’s principal security anchor in the face of China’s strategic ambitions.
One challenge is the need to arrest the erosion of America’s relative power, which in turn requires comprehensive domestic renewal, including fiscal consolidation.
But the need for spending cuts also raises the prospect that the US might be unable to finance a military shift toward the Asia-Pacific region – or, worse, that it will be forced to retrench there.
The US under Obama has increasingly ceded ground to China, a trend that admittedly began when the Bush administration became preoccupied with the wars in Afghanistan and Iraq.
This has spurred doubts about America’s ability to provide strategic heft to its “pivot” by sustaining a higher level of commitment in the Asia-Pacific region, where it already maintains 320,000 troops.
The proposed deployment of an additional 2,500 Marines in Australia is largely symbolic.
In fact, after raising Asians’ expectations of a more robust US response to China’s growing assertiveness, the Obama administration has started to tamp down the military aspects of its “pivot,” emphasizing instead greater US economic engagement.
That change has come as a relief to those in the region who fear being forced to choose between the US and China.
But, for the countries bearing the brunt of China’s recalcitrant approach to territorial and maritime disputes, this emphasis raises new doubts about America’s commitment.
In fact, the economic reorientation of the US “pivot” corrects a policy that had overemphasized the military component and put the US on a path toward conflict with China.
It was Secretary of State Hillary Clinton who signaled a more hawkish US stance on China with her tough talk at the 2010 Association of Southeast Asian Nations (ASEAN) Regional Forum in Hanoi; now she is moderating that position by promoting trade and investment during her visits to Asian countries.
Obama, too, is highlighting the economic aspects of the US “pivot,” portraying his Asia tour as an effort to generate more domestic manufacturing jobs through higher exports to “the most rapidly growing and dynamic region in the world.”
Even his historic visit to Myanmar – the first ever by a US president – is as much about trade as it is about weaning a strategically located, resource-rich country from Chinese influence.
The refocus on trade and economic issues has also prompted Washington to promote the Trans-Pacific Partnership, which aims to create a new Asia-Pacific free-trade group that excludes China.
Moreover, the US is emphasizing the importance of the East Asia Summit and ASEAN, whose summit overlaps with the EAS meeting in Phnom Penh that Obama will be attending.
The US course correction is being dictated by another consideration as well: America has nothing to gain from taking sides in China’s disputes with its neighbors – unless, of course, US interests are directly at stake, as in the South China Sea, where Chinese maritime claims threaten freedom of navigation in some of the world’s most heavily trafficked shipping lanes.
Concern for its own national interest explains why America has charted a course of tacit neutrality regarding the revival of Sino-Indian territorial disputes, including China’s sudden resurrection of a claim to the large Himalayan Indian state of Arunachal Pradesh.
Similarly, the US has urged both China and Japan to resolve peacefully their dispute over the Japanese-controlled Senkaku Islands.
America’s main goal is to prevent the standoff from escalating to the point that it would be forced – against its own interests –&#160;to take Japan’s side.
When US Defense Secretary Leon Panetta met Chinese leader Xi Jinping in China in September, he got “an earful” that the US should stay out of the Sino-Japanese dispute.
Indeed, amid the orchestrated anti-Japanese protests in China in September, Panetta – instead of advising China to rein in the often-violent demonstrations –&#160;publicly reiterated America’s neutrality in the struggle over control of the islands.
The correction in US policy actually extends even to terminology.
American diplomats have now abandoned the term “pivot” altogether, owing to its military connotation, in favor of “rebalancing.”
Whatever one calls it, the new policy approach is all about China, with America bolstering alliances and friendships with countries around China’s periphery, including India, Japan, the Philippines, Vietnam, Indonesia, and South Korea.
Yet the Obama administration continues to deny that China is at the center of its strategy.
In fact, it is reluctant to say or do anything publicly that might raise China’s hackles.
The Asia-Pacific region will loom larger in Obama’s second-term agenda, especially as the ongoing US troop withdrawal ends the Afghanistan war by 2014.
But Obama will have to define a clearer US policy, addressing China’s rapid rise under an authoritarian regime that aggressively pursues border claims and whips up nationalism at home.
The US and the rest of Asia must not merely adjust to China; they must seek to shape a China that plays by the rules.
America’s War-Torn Economy
NEW YORK – Some say there are two issues in the coming American elections: the Iraq war and the economy.
On days when the war seems to be going better than expected, and the economy worse, the economy eclipses the war; but neither is faring well.
In some sense, there is only one issue, and that is the war, which has exacerbated America’s economic problems.
And when the world’s largest economy is sick – and it is now very sick – the entire world suffers.
It used to be thought that wars were good for the economy.
After all, World War II is widely thought to have helped lift the global economy out of the Great Depression.
But, at least since Keynes, we know how to stimulate the economy more effectively, and in ways that increase long-term productivity and enhance living standards.
This war, in particular, has not been good for the economy, for three reasons.
First, it has contributed to rising oil prices.
When the United States went to war, oil cost less than $25 a barrel, and futures markets expected it to remain there for a decade. Futures traders knew about the growth of China and other emerging markets; but they expected supply – mainly from low-cost Middle East providers – to increase in tandem with demand.
The war changed that equation.
Higher oil prices mean that Americans (and Europeans and Japanese) are paying hundreds of millions of dollars to Middle East oil dictators and oil exporters elsewhere in the world rather than spending it at home.
Moreover, money spent on the Iraq war does not stimulate the economy today as much as money spent at home on roads, hospitals, or schools, and it doesn’t contribute as much to long-term growth.
Economists talk about “bang for the buck” – how much economic stimulus is provided by each dollar of spending.
It’s hard to imagine less bang than from bucks spent on a Nepalese contractor working in Iraq.
With so many dollars going abroad, the American economy should have been in a much weaker shape than it appeared.
But, much as the Bush administration tried to hide the true costs of the war by incomplete and misleading accounting, the economy’s flaws were covered up by a flood of liquidity from the Federal Reserve and by lax financial regulation.
So much money was pumped into the economy and so lax were regulators that one leading American bank advertised its loans with the slogan “qualified at birth” – a clear indication that there were, in effect, no credit standards.
In a sense, the strategy worked: a housing bubble fed a consumption boom, as savings rates plummeted to zero.  The economic weaknesses were simply being postponed to some future date; the Bush administration hoped that the day of reckoning would come after November 2008.  Instead, things began to unravel in August 2007.


Now it has responded, with a stimulus package that is too little, too late, and badly designed.
To see the inadequacy of that package, compare it with the more than $1.5 trillion that was borrowed in home equity loans in recent years, most of it spent on consumption.
That game – based on a belief in ever-spiraling home prices – is over.
With home prices falling (and set to continue to fall), and with banks uncertain of their financial position, lenders will not lend and households will not borrow.
So, while the additional liquidity injected into the financial system by the Fed may have prevented a meltdown, it won’t stimulate much consumption or investment.
Instead, much of it will find its way abroad.
China, for example, is worried that the Fed’s stimulus will increase its domestic inflation.
There is a third reason that this war is economically bad for America.
Not only has America already spent a great deal on this war – $12 billion a month, and counting – but much of the bill remains to be paid, such as compensation and health care for the 40% of veterans who are returning with disabilities, many of which are very serious.
Moreover, this war has been funded differently from any other war in America’s history –perhaps in any country’s recent history.
Normally, countries ask for shared sacrifice, as they ask their young men and women to risk their lives.
Taxes are raised.
There is a discussion of how much of the burden to pass on to future generations.  In this war, there was no such discussion.
When America went to war, there was a deficit.
Yet remarkably, Bush asked for, and got, a reckless tax cut for the rich.
That means that every dollar of war spending has in effect been borrowed.
For the first time since the Revolutionary War, two centuries ago, America has had to turn to foreigners for financing, because US households have been saving nothing .
The numbers are hard to believe.
The national debt has increased by 50% in eight years, with almost $1 trillion of this increase due to the war – an amount likely to more than double within ten years.
Who would have believed that one administration could do so much damage so quickly?
America, and the world, will be paying to repair it for decades to come.
Obama’s Year of Iran
PRINCETON – As US President Barack Obama begins his second term, he will have to devote much of his attention to figuring out how to get America’s domestic finances in order.
But foreign-policy issues loom large as well, and, notwithstanding the ongoing conflict in Syria and the possible spread of war across Africa’s Sahel region, the consensus in Washington is that 2013 will be the “year of decision” on Iran.
Obama began his first administration with an offer to engage with the Islamic Republic; as he memorably put it in his first inaugural address in 2009, “We will extend a hand if you are willing to unclench your fist.”
He repeated that commitment, although much more obliquely, in his second inaugural address: “We will show the courage to try and resolve our differences with other nations peacefully – not because we are naive about the dangers we face, but because engagement can more durably lift suspicion and fear.”
As the American scholar and activist Hussein Ibish recently argued, Obama has appointed a cabinet designed to give him maximum room to negotiate a deal with Iran.
In particular, naming military veterans as Secretary of State and Secretary of Defense will provide him with valuable domestic political cover for an agreement that would inevitably require lifting sanctions on Iran and almost certainly recognizing its right to enrich uranium at a low level of concentration.
That should signal to Iran’s rulers not only that the US is serious about a deal, but also that whatever the US offers is likely to be the best deal that they can get.
The Obama administration has assembled an extraordinary coalition of countries to impose economic sanctions that are having a demonstrable effect on the price and availability of goods in Iran and on the ability of even powerful institutions, such as the Revolutionary Guard, to do business.
But coalitions do not hold together forever, and the pain of sanctions often cuts both ways, affecting buyers as well as sellers.
Countries like South Korea and Japan, for example, have curtailed their imports of Iranian oil only reluctantly; countries like China and Russia rarely play straight on sanctions in the first place.
Moreover, Obama can threaten that “all options are on the table” only so many times without losing credibility with the Iranians and other countries in the Middle East.
As Brookings Institution foreign-policy expert Suzanne Maloney points out, countries in the region and beyond are already dismayed at the lack of US leadership concerning Syria.
If the US gives negotiations one more serious try (a credible offer and a genuine willingness to engage), gets rebuffed, and then does nothing, it will effectively declare itself a paper tiger.
At that point, the sanctions coalition will most likely disintegrate amid a much broader loss of confidence in US leadership.
The US has thus painted itself into a corner.
Former US National Security Adviser Zbigniew Brzezinski recently argued strongly against military action, proposing, instead, a strategy that would continue sanctions and extend deterrence.
Like US policy toward the Soviet bloc during the Cold War, “An Iranian military threat aimed at Israel or any other US friend in the Middle East would be treated as if directed at the United States itself and would precipitate a commensurate US response.”
I can certainly see the wisdom in Brzezinski’s approach.
But Obama has marched the US and its allies too far down the current path.
Moreover, and crucially, Brzezinski forgets that Obama’s determination to stop Iran from acquiring a nuclear weapon does not stem only from his concern for Israel’s security or the stability of the wider Middle East.
Obama has repeatedly committed himself to the goal of turning the world in the direction of “global zero” – a world without nuclear weapons.
He believes (as do former Secretaries of State Henry Kissinger and George Shultz, former Secretary of Defense William Perry, and former Senator Sam Nunn) that unless the world finds a way to live without nuclear weapons, we will find ourselves in an international system in which 30-50 states possess them, raising the danger of accidental or deliberate launch to an unacceptably high level.
Convincing great powers to eliminate their nuclear arsenals might seem as politically fanciful as pushing gun-control legislation through the US Congress, but on that issue, too, Obama has made clear that he is willing to try.
However logical or attractive a containment policy might be, and however disastrous the consequences of bombing are likely to be, Obama’s commitment to realizing global denuclearization as part of his legacy implies that he will not allow another country to acquire a nuclear weapon on his watch, as his predecessors allowed India, Israel, North Korea, and Pakistan to do.
Thus, the stakes for both the US and Iran are very high.
Other countries would do well not to underestimate Obama’s resolve; governments that have relations with Iran should emphasize that the time to make a deal is now.
And countries like Turkey and Brazil (and perhaps India and Egypt) could play a useful role by devising face-saving ways for the Iranians to meet the international community’s demands, together with longer-term alternatives for fuel enrichment that would be consistent with reducing the global nuclear threat.
America’s allies, in turn, must be prepared to close ranks with it on both the outlines of a deal and the willingness to strike militarily.
The art of statecraft is not to choose between war and diplomacy as if they were mutually exclusive alternatives, but to understand how they fit together.
In the case of Syria, the West has repeatedly called for diplomacy while ruling out any military action, with predictably bad results.
The US will not make that mistake with Iran.
America Shoots Itself
One of the casualties of the war against terrorism--or, rather, of the way the United States is conducting the war--is the US influence in promoting human rights worldwide.
For the international human rights movement, this is a severe setback.
For more than a quarter of a century, ever since advancing human rights internationally became an explicit and avowed goal of US foreign policy under President Jimmy Carter, American influence played a leading role in mitigating abuses.
The consequences were most profound in what were the countries of the Soviet empire, but they extended to other regions as well.
Even where the US supported regimes that committed grave violations of rights--or served as an apologist for them because other national interests took precedence--it was often possible for the human rights movement to embarrass Washington by making it the surrogate villain for its clients' abuses.
In the 1980's, this approach focused attention on abuses in conflict-ridden Central America and in Saddam Hussein's Iraq, which the Reagan Administration favored in its struggle with America's enemy, Ayatollah Khomeini's Iran.
It thus sometimes achieved indirectly what could not be done directly: the leveraging of American influence to promote human rights.
But America's capacity to promote human rights in other countries has never been weaker than now.
One reason is the tremendous increase in anti-Americanism since the terrorist attacks of September 11, 2001.
This is largely due to a widespread perception of American arrogance.
Despite (or because of) its insistence that all who are not with America are against it, the Bush administration alienated many who previously counted themselves either as friends of the US or did not take sides.
At the same time, rising anti-Americanism preceded the US response to the terrorist attacks.
The Bush team was outspoken in its hostility to a range of international agreements, from the Kyoto Treaty to reduce global warming to the establishment of the International Criminal Court.
Whatever goodwill towards the US prevailed after September 11 was quickly squandered.
The Bush administration proclaimed a national security policy that insists that America provides the only sustainable model for national success, and asserted its right to engage in unilateral, preemptive military strikes.
It treated the UN Security Council with disdain in its rush to war in Iraq, invoking justifications that have not stood up to scrutiny.
Since then, it has continued to insist that its arguments for invading Iraq are beyond criticism, while making a mess of the postwar administration by refusing to share authority.
The other major reason that America is losing its effectiveness as a promoter of human rights is a widespread perception of hypocrisy.
Even before the terrorist attacks on New York and Washington, America's image as a rights proponent had been tarnished, particularly in Europe, by its continued practice of capital punishment and, to a lesser degree, by its high incarceration rate--approximately seven times the average in the European Union's fifteen member countries.
Since September 2001, the cause for concern has grown dramatically.
Much international attention has focused on the USA Patriot Act's sanctioning of grave violations of civil liberties, and on the subsequent treatment of thousands of immigrants--particularly south Asian Muslims--who have faced secret detention and deportation.
Above all, the rest of the world has looked on with alarm as the US holds more than 600 men at Guantanamo Bay in Cuba without access to family or counsel, and without prospect of an impartial hearing or trial.
In some instances, reports of rights violations in the US are exaggerated.
But this is an inevitable consequence of the Bush administration's own haughty manner, with leading spokespersons, such as Attorney General John Ashcroft, proclaiming their own righteousness in leading the effort to abrogate rights.
Ashcroft is much less known internationally than Secretary of Defense Donald Rumsfeld, but he is an even match in arousing dislike for the US among those who do know him.
Unfortunately, there is no ready substitute for the US as a force for advancing human rights internationally.
The UN has been useful as a forum for adopting standards, but its machinery for seeking compliance with those standards is weak and has been badly compromised over the years by its failure to address grotesque abuses.
The choice of Libya to chair the UN Human Rights Commission adds insult to injury.
Some European governments have evolved strong human rights polices but, for a variety of reasons, they have been unable, individually or collectively, to exert the influence of the US.
Fortunately, while this is likely to remain true for the foreseeable future, the international human rights movement is not completely without resources.
Its own prestige is high: groups such as Amnesty International and Human Rights Watch are respected voices, to whom many governments feel obliged to pay attention.
There is also the promise of new institutions.
In cases of extreme rights abuses, the chance that an international criminal tribunal will ultimately sit in judgment of those principally responsible is growing, thereby becoming a deterrent to would-be tyrants elsewhere.
America should take note.
America Should Not Lower the Nuclear Threshold
President Bush has pushed stopping the spread of nuclear weapons to the top of the international agenda.
Ironic, then, that America's nuclear weapons development program may promote the very proliferation it seeks to prevent, as US Senator Dianne Feinstein explains.
With the world's focus on the debate over Iraq, the war on terror, and the Bush administration's doctrine of unilateral preemption, the American government's new emphasis on the utility of nuclear weapons has not received the attention it deserves.
This is unfortunate, as this exploration of new uses for nuclear weapons represents a revolutionary shift in US national security policy.
Today, the world faces unprecedented challenges at the nexus of terror and weapons of mass destruction.
With both North Korea and Iran openly pursuing nuclear ambitions and a potential nuclear arms race in South Asia, it is critical that America provide leadership, in both word and in deed, to reduce the risks and the role of nuclear weapons throughout the world.
Instead, the Bush administration seems intent on doing just the opposite.
Many of the actions of the American administration, and much of the US government's rhetoric, may actually be increasing the threat from nuclear weapons rather than making the world safer.
The Bush administration's January 2002 Nuclear Posture Review signaled a major change in US nuclear policy by advancing a new triad that integrates nuclear weapons with conventional strike options and blurring the line between the use of conventional and nuclear weapons.
It also specified scenarios in which the US might use nuclear weapons first, even against non-nuclear states, and called for a new generation of US nuclear warheads, including low yield or so-called "mini-nukes."
The US has never had a no-first-strike policy, but it has likewise never had a policy such as that embodied in the Nuclear Policy Review.
Today, under the terms of the ideas set out in that review, the US contemplates the first use of nuclear weapons, and seeks to integrate tactical battlefield nuclear weapons alongside conventional munitions.
Despite efforts to downplay the significance of the Nuclear Posture Review since its publication, it remains, in my view, extremely provocative and dangerous.
Earlier this year, at a hearing of the US Senate's Committee on Energy and Natural Resources, I asked Energy Secretary Spencer Abraham, whose Department oversees America's research and development of nuclear weapons, whether the Bush administration wanted to develop new low-yield nuclear weapons.
Secretary Abraham said it did not; that his department was only studying adaptations of existing weapons.
Yet, there should be no doubt that the Bush administration is beginning the research and development of new nuclear weapons.
Just this year, a 10-year-old ban on the research and development of nuclear weapons below five kilotons--the bomb at Hiroshima was 15 kilotons--was eliminated.
Pushed by the Bush administration, Congress authorized $21 million for the study and development of new nuclear weapons, including a 100-kiloton bunker buster, as well as tactical battlefield nuclear weapons.
Moreover, the time to test readiness of the Nevada test site has been moved up from three years to two years, and funding has been provided to produce additional fissile material for new nuclear weapons.
I argued and voted against these new nuclear initiatives in the US Senate earlier this year.
Clearly, the nuclear door is being reopened.
For, by taking the steps called for in the Nuclear Posture Review--specifically, developing "new capabilities...to defeat emerging threats," including "extensive research and timely fielding of
This approach is not in America's national interest, nor is it consistent with American traditions and values.
A first-use of nuclear weapons by the US should be unthinkable, and responding to a non-nuclear attack with nuclear weapons violates a central tenet of just war and US military tradition.
Indeed, nuclear options should not be considered as an extension of conventional options.
Why?
Because this inevitably lowers the threshold for use.
So, if the US develops nuclear weapons that blur the distinction between conventional and nuclear forces, the message this sends to the rest of the world must be considered.
I believe it is critical that the US set a very high international standard for nuclear restraint.
If America does not, it may very likely encourage others to develop their own standards and their own nuclear arsenals.
That seems to be happening.
Both India and Pakistan are nuclear powers, and the history of bloody warfare between them presents a major and ongoing security threat to South Asia.
If either country adhered to the thinking embodied in the Bush administration's new nuclear policy, there would be little reason for each not to seek to integrate nuclear weapons even more deeply into their own contingency plans--and possibly use them.
At a time when the US brands as "evil" certain countries based, in part, on their pursuit of nuclear arms and weapons of mass destruction, it must be especially careful in how it considers its own options and contingencies regarding nuclear weapons.
If the US is not careful, our own new nuclear posture could provoke the very nuclear-proliferation activities we are seeking to prevent.
America the Hypocritical
In commemorating the 230th anniversary of America’s independence last July, President George W. Bush noted that the patriots of the Revolutionary War believed that all men are created equal, and with inalienable rights.
Because of these ideals, he proclaimed, the United States “remains a beacon of hope for all who dream of liberty and a shining example to the world of what a free people can achieve.”
But, at the same time, his administration was holding approximately 400 prisoners at the US Naval Base at Guantánamo Bay in Cuba.
Some of them have now been there for more than five years.
None of them has ever been put on trial.
Last month, a highly reputable source confirmed that the Guantánamo prisoners are suffering from more than indefinite detention.
The US Federal Bureau of Investigation released documents showing that an FBI agent witnessed “on several occasions” detainees who were “chained hand and foot in [a] fetal position to [the] floor,” without a chair, or food or water.
In these conditions, “most urinated or defecated on [them]selves.”
They were left there for 18 or 24 hours, or more.
On one of these occasions, the agent reported, “the air conditioning was turned up so low that the barefooted detainee was shaking with cold.”
On another occasion the room was unventilated, the temperature over 100 degrees Fahrenheit, and the detainee was almost unconscious on the floor with a pile of hair next to him – “he had apparently been pulling it out throughout the night.”
Another FBI agent was laughingly told by a civilian contractor, “[Y]ou have to see this.”
He was then taken to an interrogation room where he saw a longhaired man with a full beard who was gagged with duct tape that “covered much of his head.”
When the agent asked how the tape would be removed, he was not given any answer.
Other FBI agents reported seeing prisoners left in shackles for 12 hours or more, again in cold conditions, being subjected to strobe lights and loud rap music for many hours, or being forced to wrap themselves in an Israeli flag.
The FBI report noted these incidents with the comment: “doesn’t seem excessive given Department of Defense policy.”
Several of the detainees told the FBI agents that they had no connection with terrorism and had no idea why they had been abducted and taken to Guantánamo.
Many prisoners were not captured fighting in Afghanistan.
Some were picked up in Bosnia, Indonesia, Thailand, Mauritania, and Pakistan.
The Bush administration says that the detainees are “enemy combatants” in the global war against terror – a war that is being waged around the world, and that could last for decades.
The commander of the Guantánamo task force, Rear Admiral Harry B. Harris, Jr., recently defended harsh treatment of his prisoners, claiming, “They’re all terrorists; they’re all enemy combatants.”
But the CIA has made mistakes before.
For example, Murat Kurnaz, a German-born Turkish man, was held in Guantánamo for four years before being released last August.
The case of Khaled el-Masri, a German citizen of Lebanese descent, appears to be another of these errors.
Seized by the CIA in Macedonia, he was taken to Afghanistan and interrogated for five months before being released without charge.
A German court has now issued arrest warrants for those involved in his abduction.
If there are any human rights at all, the right not to be locked up indefinitely without trial is surely one of them.
The US Constitution’s Bill of Rights puts considerable emphasis on that right, specifying in the Sixth Amendment that in all criminal prosecutions, “the accused shall enjoy the right to a speedy and public trial, by an impartial jury” and “to be informed of the nature and cause of the accusation; to be confronted with the witnesses against him.”
None of the Guantánamo inmates has been granted these rights.
So it has never been proved, by the standards laid down in the US Constitution that any of them really are terrorists.
But the Sixth Amendment does not apply to the Guantánamo prisoners, because they are not US citizens and are in a facility that, technically, is not part of US territory, although it is under the full control of the US government.
Whatever US courts say about it, abducting people all over the world, locking them up for years without establishing that they are guilty of anything, and subjecting them to harsh and abusive treatment is a flagrant violation of international law.
By any standard of justice, it is also just plain wrong.
Tom Paine, the great American revolutionary and author of
America the Pariah
America Wakes Up to Climate Change
After years of debate in the United States, and opposition to action by the Bush administration, America is finally waking up to the reality of global climate change.
Leadership is still not coming from the president, but the private sector has begun to act.
Leaders of major US companies have decided that global man-made climate change is real, must be controlled, and that business must play a constructive part in the process.
Thus, even as the Bush administration and some scientific contrarians pretend that there is no problem, US corporate leaders are seeking practical solutions.
The basic situation has been clear for years.
Global use of fossil fuels is contributing to a sharp rise in atmospheric carbon dioxide, which is causing the Earth to warm.
Rainfall patterns are changing.
Deserts and dry regions are becoming drier.
Extreme weather events such as hurricanes and typhoons are likely to increase.
Flooding in Europe is likely to intensify, a process that may already have begun.
Sea levels are rising, and could climb sharply if global warming leads to a destabilization of the Greenland and Antarctic ice sheets.
In short, the scientific evidence is strong and growing that the planet is at grave risk, with many ill effects already being felt and more to come.
The proper responses are also increasingly understood.
We must move to a sustainable energy system, one that does not mean a huge increase of carbon in the atmosphere.
This will require a shift to renewable energy sources such as solar power, and perhaps nuclear power, as well as new technologies to capture carbon dioxide at power plants and then to dispose of the carbon dioxide in safe underground deposits.
Society will have to pay a price for these investments in new energy technologies, but the benefits will be vastly greater than the price.
The US is the world’s major emitter of carbon dioxide from energy use, but it has done the least among all major economies to confront the global challenge.
The Bush administration claims that more research is needed before any action is taken.
Yet real action in the US is starting, thanks to leadership in other parts of the world, and thanks to the enlightened understanding of some major American businesses.
First, the rest of the world ratified the Kyoto Protocol to control emissions of carbon dioxide.
At the beginning of this year, Europe introduced a new Greenhouse Gas Emissions Trading Scheme that uses market-based incentives to control carbon emissions.
American companies operating in Europe are part of that system for their European-based emissions, so that US companies are being pulled into climate control even if their own government avoids the issue.
Second, major US investors, such as pension fund managers, are realizing that US companies that fail to control their emissions may be vulnerable to financial losses in the future.
They know that, sooner or later, the US will have to join the rest of the world in controlling climate change.
At that point, power companies that use antiquated technologies that emit massive amounts of greenhouse gases may face serious financial losses.
So investors are telling companies to report their carbon emissions today in order to assess future liabilities.
Similarly, many company bosses know that pretending that climate problems do not exist is bad for shareholders, because reality will one day strike.
They know that investing today in clean technologies can give them a long-term competitive advantage.
As a result, many companies are taking steps now to limit their emissions to avoid future financial liabilities and a lack of investor confidence.
The most dramatic breakthrough of this kind occurred when General Electric, one of the world’s most important, innovative, and respected companies, announced that it was going “green” with a major new corporate focus on environmentally sound technologies and a commitment to limit its own greenhouse gas emissions.
With GE’s leadership, which it termed “ecomagination” (combining ecology with imagination), many US businesses are sure to follow.
It is too early to count on success in engaging the US on climate change.
The Bush administration continues to delay and to avoid sound science.
Yet it is reasonably clear that a tipping point has been reached.
Reality is catching up with the US, as it already has elsewhere in the world.
As US citizens and businesses continue to suffer the results of climate change – heat waves, droughts, hurricanes, and floods – more and more Americans, including an increasing number of business leaders, will press America’s political leaders for real action.
The solutions will not be easy, and the effort must last over many decades in all parts of the world.
But the effort needs to start now.
As with Europe’s new carbon trading, all producers and consumers around the globe will need to face market incentives to adopt technologies and consumption patterns that slow (and eventually stop) the increase of greenhouse gases in the atmosphere.
We will all need to pay a “market price” when we contribute to global climate change, so that we give true economic incentives to sustainable energy systems and new public investments – for example, mass transit – that reduce greenhouse gas emissions and thereby head off future climatic disasters.
Alliances for Peace
WASHINGTON, DC – I grew up in the shadow of World War II, and at the dawn of the Cold War.
My father’s work as a Foreign Service officer gave me an opportunity to see history up close in a searing way: I will never forget walking the beaches of Normandy with him and seeing the burned hulks of Higgins’ boats still on those shores, just a few years after so many young men went to their graves so the world could be free.
Likewise, I will never forget the eerie feeling of riding my bike through the Brandenburg Gate from West Berlin into the East, and seeing the contrast between people who were free and those who were trapped behind the Iron Curtain.
What strikes me now, all these years later, is that a generation of leaders won not only a war, but also the peace.
They did it together.
The United States and our partners worked to create alliances that brought prosperity and stability to Western Europe, Japan, and South Korea.
Old enemies became new allies, and together pioneered a new global economic system that made the world more prosperous.
And even as the Cold War raged, leaders found ways to cooperate on arms control and prevent a nuclear Armageddon.
In short, by building effective and indispensable international institutions and strategic partnerships, we did not just avoid another catastrophic world war; we ultimately ended the Cold War and lifted global living standards for hundreds of millions of people.
That is the remarkable story of the twentieth century.
The question now is what story will emerge from the twenty-first century.
Today, the world order faces new challenges.
Russian aggression is rattling allies.
Extremists who hijack religion threaten governments and people everywhere.
Technology is accelerating a shift in the balance of power between governments and governed that offers both opportunities for democratic accountability and obstacles to inclusive politics.
We have gone from a world where power resided in hierarchies to one where it inhabits networks.
Statecraft has yet to adapt.
The international institutions and partnerships that emerged in the postwar years demand both maintenance and modernization.
In the face of all of this turbulence, some suggest that America should turn inward.
That is nothing new.
Some argued the same after WWII.
They argued it again 25 years ago, after the fall of the Berlin Wall.
They were wrong then – and they are wrong now.
The need for leadership has never been greater, and the US has never been more engaged with the world.
Our role in Afghanistan’s first-ever peaceful, democratic transition reminds us all that, having invested so much blood and treasure in helping to give Afghans a chance to succeed in battle, the world has just as much responsibility to help its leaders succeed in governance.
We know that the destruction of 100% of Syria’s declared chemical weapons would not have happened without direct, hands-on diplomacy and perseverance, just as Syria’s immoral and horrifying civil war will not end without an equal commitment.
So, too, in Asia, where President Barack Obama and Chinese President Xi Jinping just announced ambitious commitments to tackle climate change, we are reminded of what countries can accomplish together with real leadership – and of how much additional leadership is required to conclude a successful climate agreement in Paris next year.
The world has changed, and we are changing with it.
Lines on the map no longer contain the gravest threats, and the players are no longer divided neatly into two camps.
In the twenty-first century, next door is everywhere.
That is why the world needs coalition diplomacy.
No country can defeat terrorism on its own.
No country can solve the existential threat of climate change alone.
No country can eradicate extreme poverty, combat potential pandemics, or improve nuclear security by itself.
None of us can live safer, richer lives by turning our back to the world.
We must build on our history of working with allies by forming new coalitions – with governments, with civil society, and, yes, with everyday people.
A good example is the international effort to confront the Islamic State’s malign brutality in Iraq and Syria.
Political, humanitarian, and intelligence tools from more than 60 countries are being used to support unified military action.
Success depends not on what one or even a handful of countries can do alone, but on what all of us are able to achieve by moving forward together against this common threat.
On an equally important front, the US is working with the United Nations to galvanize a global response to the danger posed by the Ebola virus.
I have personally talked with more than 50 foreign leaders, and we all agree that only by coordinating our actions can we stop the devastation in West Africa and halt Ebola’s spread.
We are making progress on both issues, but much work remains.
Bringing together countries with competing interests and varying resources is hard work.
It demands intense diplomatic engagement and calls upon relationships that have been built and maintained over decades, as well as alliances with new partners.
But by overcoming differences and coordinating efforts to defeat the Islamic State and conquer Ebola, we are reinforcing support for a world order grounded in collective solutions to common problems.
Cooperation is equally vital in reinforcing the bedrock economic principles on which America and other countries built their postwar prosperity.
Frustration cannot grow faster than opportunity in any country.
For example, the negotiations on the Trans-Pacific Partnership (TPP) reflect President Obama’s determination to strike an accord with countries that represent one-third of global trade and 40% of global GDP.
The benefits – for both the US and our partners – are enormous.
Estimates are that the TPP could provide $77 billion a year in real income and support 650,000 new jobs in the US alone. The Transatlantic Trade and Investment Partnership being negotiated with the European Union offers another major step toward increasing trade.
Whether for mutual security or shared prosperity, genuine partnerships are not built overnight.
Patient diplomacy and a collective will are needed to advance common goals.
America’s objectives remain the same as they have been for decades – peace, prosperity, and stability for the US and for our partners around the world.
Inequality and the American Child
NEW YORK – Children, it has long been recognized, are a special group.
They do not choose their parents, let alone the broader conditions into which they are born.
They do not have the same abilities as adults to protect or care for themselves.
That is why the League of Nations approved the Geneva Declaration on the Rights of the Child in 1924, and why the international community adopted the Convention on the Rights of the Child in 1989.
Sadly, the United States is not living up to its obligations.
In fact, it has not even ratified the Convention on the Rights of the Child.
The US, with its cherished image as a land of opportunity, should be an inspiring example of just and enlightened treatment of children.
Instead, it is a beacon of failure – one that contributes to global sluggishness on children’s rights in the international arena.
Though an average American childhood may not be the worst in the world, the disparity between the country’s wealth and the condition of its children is unparalleled.
About 14.5% of the American population as a whole is poor, but 19.9% of children – some 15 million individuals – live in poverty.
Among developed countries, only Romania has a higher rate of child poverty.
The US rate is two-thirds higher than that in the United Kingdom, and up to four times the rate in the Nordic countries.
For some groups, the situation is much worse: more than 38% of black children, and 30% of Hispanic children, are poor.
None of this is because Americans do not care about their children.
It is because America has embraced a policy agenda in recent decades that has caused its economy to become wildly unequal, leaving the most vulnerable segments of society further and further behind.
The growing concentration of wealth – and a significant reduction in taxes on it – has meant less money to spend on investments for the public good, like education and the protection of children.
As a result, America’s children have become worse off.
Their fate is a painful example of how inequality not only undermines economic growth and stability – as economists and organizations like the International Monetary Fund are finally acknowledging – but also violates our most cherished notions of what a fair society should look like.
Income inequality is correlated with inequalities in health, access to education, and exposure to environmental hazards, all of which burden children more than other segments of the population.
Indeed, nearly one in five poor American children are diagnosed with asthma, a rate 60% higher than non-poor children.
Learning disabilities occur almost twice as frequently among children in households earning less than $35,000 a year than they do in households earning more than $100,000.
And some in the US Congress want to cut food stamps – on which some 23 million American households depend, threatening the poorest children with hunger.
These inequalities in outcomes are closely tied to inequalities in opportunities.
Inevitably, in countries where children have inadequate nutrition, insufficient access to health care and education, and higher exposure to environmental hazards, the children of the poor will have far different life prospects from those of the rich.
And, partly because an American child’s lifetime prospects are more dependent on his or her parents’ income and education than in other advanced countries, the US now has the least equality of opportunity of any advanced country.
At America’s most elite universities, for example, only around 9% of students come from the bottom half of the population, while 74% come from the top quarter.
Most societies recognize a moral obligation to help ensure that young people can live up to their potential.
Some countries even impose a constitutional mandate for equality of educational opportunities.
But in America, more is spent on the education of rich students than on the education of the poor.
As a result, the US is wasting some of its most valuable assets, with some young people – bereft of skills – turning to dysfunctional activities.
American states like California spend about as much on prisons as on higher education – and sometimes more.
Without compensatory measures – including pre-school education, ideally beginning at a very young age – unequal opportunities translate into unequal lifelong outcomes by the time children reach the age of five.
That should be a spur to policy action.
Indeed, while inequality’s harmful effects are wide-reaching, and impose huge costs on our economies and societies, they are largely avoidable.
The extremes of inequality observed in some countries are not the inexorable result of economic forces and laws.
The right policies – stronger social safety nets, progressive taxation, and better regulation (especially of the financial sector), to name a few – can reverse these devastating trends.
To generate the political will that such reforms require, we must confront policymakers’ inertia and inaction with the grim facts of inequality and its devastating effects on our children.
We can reduce childhood deprivation and increase equality of opportunity, thereby laying the groundwork for a more just and prosperous future – one that reflects our own avowed values.
So why don’t we?
Of the harm that inequality inflicts on our economies, politics, and societies, the damage done to children demands special concern.
Whatever responsibility poor adults may bear for their lot in life – they may not have worked hard enough, saved enough, or made good decisions – children’s circumstances are thrust upon them without any sort of choice.
Children, perhaps more than anyone, need the protection that rights afford – and the US should be providing the world with a shining example of what that means.
American Conservatism’s Crisis of Ideas
BERKELEY – On the back left corner of my desk right now are three recent books: Arthur Brooks’ The Battle, Charles Murray’s Coming Apart, and Nicholas Eberstadt’s A Nation of Takers.
Together, they constitute an important intellectual movement, which also happens to be a large part of the reason that American conservatism today has little that is constructive to say about managing the economy – and little purchase on the center of the American electorate.
But let’s back up historically, to the founding of what we might call modern conservatism in early nineteenth-century Britain and France.
There were some – Frédéric Bastiat and Jean-Baptiste Say come to mind – who believed that government should put the unemployed to work building infrastructure when markets or production were temporarily disrupted.
But they were balanced by those like Nassau Senior, who spoke out against even famine relief: Although a million people would die in the Irish Potato Famine, “that would scarcely be enough.”
The main thrust of early conservatism was root-and-branch opposition to every form of social insurance: make the poor richer, and they would become more fertile.
As a result, farm sizes would drop (as land was divided among ever more children), labor productivity would fall, and the poor would become even poorer.
Social insurance was not just pointless; it was counterproductive.
The proper economic policy was to teach people to venerate the throne (so that they would respect property), the paternal hearth (so that they would not marry imprudently young), and the religious altar (so that they would fear pre-marital sex).
Then, perhaps, with women chaste for half or more of their childbearing years, the surplus population would diminish and conditions for the poor would be as good as they could be.
Fast-forward 150 years to post-World War II America, and to the original Chicago School critique of the New Deal version of social insurance – that it created “notches” that perverted economic incentives.
The government, Milton Friedman and others argued, told the poor: make more money and we will take away your free housing, food stamps, and income support.
People are rational, Friedman said, so they will not work for long if they get nothing or next to nothing for it.
The big difference between the Malthusian conservative critics of social insurance in the early nineteenth century and the Chicago critics of the 1970’s is that the Chicago critics had a point: Providing public support to the “worthy” poor, and then removing it when they began to stand on their own feet, poisoned incentives and was unlikely to lead to good outcomes.
And so, from 1970 to 2000, a broad coalition of conservatives (who wanted to see the government stop encouraging immorality), centrists (who wanted government money spent effectively), and leftists (who wanted poverty alleviated) removed the “notches” from the social-insurance system.
Presidents Jimmy Carter, Ronald Reagan, George H. W. Bush, Bill Clinton, and even George W. Bush and their supporters created the current system, in which tax rates and eligibility thresholds are not punitive disincentives to enterprise.
So what is the problem that America’s new generation of conservative critics of social insurance sees?
It is not that raising poor people’s standard of living above bare subsistence produces Malthusian catastrophe, or that taxes and withdrawal of welfare benefits make people work, at the margin, for nothing.
For Eberstadt, the problem is that dependence on government is emasculating, and that too many people are dependent on government.
For Brooks, it is that knowing that public programs make one’s life easier causes one to vote for non-Republican candidates.
For Murray, it is that social insurance means that behaving badly does not lead to catastrophe – and we need bad behavior to lead to catastrophe in order to keep people from behaving badly.
The crucial point is that America’s conservative elites believe Brooks, Eberstadt, and Murray.
To this day, Mitt Romney is convinced that he lost the presidency in 2012 because Barack Obama unfairly gave Latino-Americans subsidized health insurance; gave women free reproductive health coverage (excluding abortion); and gave other groups similar “gifts.”
He could “never convince them that they should take personal responsibility and care for their lives.”
In fact, it would be a tough sell for any candidate to convince Americans who receive government benefits that they are dependent rather than empowered; that it is bad for people to vote for politicians who make their lives better; and that good public policy seeks to create human catastrophe rather than to avert it.
The problem for American conservatives is not their choice of candidates or the tone of their rhetoric.
It is that their ideas are not politically sustainable.
American Crony Capitalists Go to War
When financial crisis hit Asia in 1997, America's leaders charged Asian governments with practicing crony capitalism.
In retrospect, the charge seems like rank hypocrisy.
America has shown itself to be second to none in practicing cronyism, first with its rotten corporate scandals of recent years, and now in Iraq.
Asian capitalists may have stolen some borrowed loot, but at least they didn't mix finance with war.
Whatever other goals lay behind the Iraq war, the Bush Administration seems keen to line the pockets of its cronies and to capture increased control over Middle East oil and pipeline routes.
Only a few pesky obstacles--the UN, and the Iraqi people--stand in their way.
The Iraq war was ostensibly launched because of Saddam's weapons of mass destruction, yet each passing day suggests that the threat was exaggerated.
Another goal also loomed large: control over 11% (or more) of the world's oil reserves and, in the longer term, control over pipeline routes between the Mediterranean, the Caspian Sea, and the Indian Ocean.
The failure to locate Saddam's WMD's is putting America's grab for Iraqi oil into sharp focus.
The Cheney-Rumsfeld team is so arrogant that it acts as if it can flaunt the takeover of Middle East oil while brushing aside questions.
In Afghanistan last year, the US installed Hamid Karzai, a former consultant for oil giant Unocal, as interim leader.
It also appointed Kalmay Khalilzad, another former Unocal consultant --indeed, Karzai's boss--as special US envoy.
Khalilzad and Karzai spent considerable efforts in the late 1990s to get an American-built pipeline to carry gas from Turkeminstan through Afghanistan to Pakistan and the Indian Ocean.
Even before the bombs stopped falling on Baghdad, Khalilzad's writ as Special Envoy was extended to Iraq.
Among his likely jobs in Iraq will be to secure a pipeline carrying Iraqi oil from Mosul, Iraq to Haifa, Israel via Syria.
To stop Syria from objecting, the US is now threatening it as well.
Khalilzad will have plenty of support in the Bush Administration, which is heavily loaded with oil industry executives.
National Security Advisor Condeleeza Rice was a Director of Chevron-Texaco before coming to the National Security Council.
She even had an oil tanker named after her.
Commerce Secretary Don Evans is also an oil-company CEO.
Vice President Richard Cheney was in effect lead conductor of the group when he served as Chairman of Halliburton, the world's largest oil services company.
Halliburton is now at the front of the line for Iraqi reconstruction projects, for which contracts are being handed out without any transparent and competitive process whatsoever.
But what is happening here is more than "guilt by association" with the oil industry.
The Bush Administration is flouting every rule to give its cronies the inside track.
Before joining the Pentagon, Donald Rumsfeld was a key player as well.
A longstanding sidekick of Cheney, Rumsfeld traveled to Baghdad in 1983 and 1984 at the behest of former Bechtel Corporation President George Shultz, then passing a bit of non-corporate time as US Secretary of State.
Rumsfeld's hidden mission was to win Saddam's support of a Bechtel-built oil pipeline to run from Iraq via Jordan to the Gulf of Aqaba.
This is the same Bechtel which built Saddam's "dual use" chemical industry; now it has been awarded a non-competitive $600 million mega-contract to rebuild Iraqi infrastructure.
American newspapers now report that former Shell Oil CEO Philip Carroll will be appointed as the US czar of Iraqi oil.
Carroll's most recent job was as Chief Executive of Fluor, the giant construction conglomerate, another company that, together with Bechtel and Halliburton, is in line for the big bucks that will soon be paid (using Iraq's oil earnings) for US-led reconstruction.
The United Kingdom can't match the US in cronyism, but Britain's support for America in the war also has a commercial logic.
While Saddam gave oil contracts to French, Russian, and Chinese oil firms, UK firms such as BP were frozen out.
UK firms are no doubt counting on returning to Iraq on America's coattails.
Only a few hurdles remain before the US can consummate its crony takeover of Iraq's oil.
America will soon try to appoint an Iraqi regime that will aim to cancel many of Saddam's oil contracts with France, Russia, and China, in order to make room for US and UK firms.
But this will be harder to accomplish than simply sending in the US army.
The US can not legally market Iraqi oil, much less invest in new fields, until the old UN sanctions against Iraq are lifted.
But the rest of the world believes that lifting the sanctions is tantamount to handing Iraq's oil future over to the US and UK occupying forces and their corporate cronies.
More telling, and significant in the long term, is the remarkable anti-US and anti-UK sentiment now sweeping Iraq.
Rather than being welcomed as liberators, the US and UK are seen as new colonial occupiers, and the Iraqis are mobilizing to push the occupiers out.
The US may have done something few could have expected: united the Shi'ites and the Sunnis in a common cause.
Democracy may come to Iraq, and the will of the people will be to stop the plunder of their country's natural resources by US crony capitalists.
The Indispensable American Partner
MADRID – The United States is gearing up for that most intoxicating (and exhausting) of political events: an open-seat race for the presidency.
With US President Barack Obama's eight years in office coming to an end, and Vice President Joe Biden unlikely to run, the race will be without an incumbent.
As a result, the election could be less a referendum on the last eight years than a contest of ideas, with foreign policy emerging as a key topic.
The potential candidates have already sought to stake out their positions on key foreign-policy issues, with early Republican frontrunner Jeb Bush, for example, delivering a speech devoted entirely to the topic.
As for the Democrats, former Secretary of State Hillary Clinton's likely nomination (despite recent revelations that she used her personal email account to conduct government business) reinforces foreign policy's centrality to the election.
Recognizing this trend, the World Economic Forum Global Agenda Council has brought together a group of experts and practitioners to help infuse substance into the foreign-policy discussions leading up to the US election, including by preparing a public discussion paper.
From my perspective as the group's only European member, the overarching message should be that the US must conceive of itself not as “the indispensable power," as it now does, but as “the indispensable partner."
This is not merely a matter of semantics; such a change will require the US to re-conceive its role in the world.
But the payoff, for both the US and the liberal world order that it created, would be substantial.
The key to success will be America's ability to retain the best – and abandon the worst – of that most American of notions: exceptionalism.
The sense in the US that the country is unique, with a special mission to promote prosperity, security, and freedom worldwide, has long shaped American foreign policy.
The idea extends as far back as 1630, when John Winthrop, the Massachusetts Bay Colony's first governor, declared that his community must act as a “city upon a hill," setting an example for the world.
In doing so, he planted the seed of the values-based approach that was adopted by the US as it spearheaded the development of the rules and structures that order today's world.
Those rules and structures have delivered unprecedented economic growth, benefiting all (though the US has reaped the greatest rewards).
But, ironically, the notion of American exceptionalism often has led the US to undermine the international system that it nurtured.
Indeed, US history reveals a persistent isolationist streak, in which the “city upon a hill" is not a beacon, but a fortress.
At times, including over the last six years, the belief that the US is better off going it alone has led to withdrawal from the world.
This tendency was not a serious issue before World War II (though the people of Abyssinia and Manchuria may beg to differ).
But today, US withdrawal from the international system that it built has serious ramifications – namely, the kind of chaos and lawlessness exemplified by Russia's invasion of Ukraine.
Yet isolationism is not America's most destructive impulse.
Worse is its “exemptionalism": its penchant for opting out of the rules that it promotes – and often actively enforces – elsewhere.
The lengthy – and growing – list of major international conventions left unratified by the US includes the Rome Statute of the International Criminal Court, the Convention on the Elimination of All Forms of Discrimination Against Women, the Mine Ban Convention, the Convention on the Rights of the Child, and the Convention on the Rights of Persons with Disabilities.
Beyond the resentment that such an attitude engenders, American exemptionalism directly undermines multilateral institutions' capacity to address challenges that the US is unwilling or unable to resolve on its own.
How can the US expect China to follow rules on maritime delimitation in the East and South China Seas when it refuses to ratify the United Nations Convention on the Law of the Sea?
US President Barack Obama's administration has tried to create the illusion of a change of course in this regard, pushing “soft" deals that allow the US to participate without submitting to binding rules.
Such was the case with the much-lauded “handshake agreement" between Obama and Chinese President Xi Jinping on carbon-dioxide emissions in November.
But, though such arrangements make for great headlines, they do not provide the stability and predictability necessary for long-term success.
For that, hard rules and strong institutions are essential.
If the US is to serve as the world's “indispensable partner," it must recommit to the rules-based order that has served it – and the world – so well for the last seven decades.
It should begin by strengthening the flagging institutions that have served as the backbone of the liberal international order.
Specifically, the US should finally approve the International Monetary Fund reform package that was agreed in 2010; promote real progress at the Non-Proliferation Treaty Review Conference in May; and ensure that this December's UN Framework Convention on Climate Change Conference in Paris yields formal commitments.
Indispensable partnership is about helping countries help themselves.
It requires vision, commitment, and, most important, leadership.
A frank discussion about America's foreign policy could prove vital to ensuring that this “city upon a hill" remains a beacon of hope – and a catalyst of progress.
American Foreign Policy after Iraq
What comes after Iraq?
If President George W. Bush’s current troop “surge” fails to produce an outcome that can be called “victory,” what lessons will the United States draw for its future foreign policy?
Will it turn inward, as it did after its defeat in Vietnam three decades ago?
Will it turn from promoting democracy to a narrow realist view of its interests?
Even while discussion in Washington is fixated on Iraq, a number of thoughtful foreign observers are asking these longer-term questions.
Analysts and pundits have often been mistaken about America’s position in the world.
For example, two decades ago, the conventional wisdom was that the US was in decline.
A decade later, with the Cold War’s end, the new conventional wisdom was that the world was a unipolar American hegemony.
Some neo-conservative pundits drew the conclusion that the US was so powerful that it could decide what it thought was right, and others would have to follow.
Charles Krauthammer celebrated this view as “the new unilateralism,” and it heavily influenced the Bush administration even before the attacks on September 11, 2001.
But the new unilateralism was based on a profound misunderstanding of the nature of power in world politics.
Power is the ability to get the outcomes one wants.
Whether the possession of resources will produce such outcomes depends upon the context.
For example, a large, modern tank army is a powerful resource if a war is fought in a desert, but not if it is fought in a swamp – as America discovered in Vietnam.
In the past, it was assumed that military power dominated most issues, but in today’s world, the contexts of power differ greatly.
I have likened the distribution of power in politics today as analogous to a three-dimensional chess game.
On the top board – military relations among states – the world is, indeed, unipolar, and likely to remain that way for decades.
But on the middle board of economic relations, the world is already multipolar, and the US cannot obtain the outcomes it wants without the cooperation of Europe, Japan, China, and others.
And, on the bottom board of transnational issues outside the control of governments – including everything from climate change to pandemics to transnational terrorism – power is chaotically distributed, and it makes no sense at all to claim American hegemony.
Yet it is on this bottom board that we find most of the greatest challenges we face today.
The only way to grapple with these problems is through cooperation with others, and that requires the “soft” power of attraction as well as the hard power of coercion.
There is no simple military solution that will produce the outcomes we want.
The new unilateralists who dominated Bush’s first administration made the mistake of thinking that the unipolar distribution of power in the military context was sufficient to guide foreign policy.
They were like a young boy with a hammer who thinks that every problem resembles a nail.
The danger of their approach is now obvious.
Whoever plays a three-dimensional game by focusing on only one board is bound to lose in the long run.
Fortunately, the pendulum has begun to swing back toward cooperation.
In Bush’s second term, some of the most extreme unilateralists have departed from the government, and the president has approached difficult problems like North Korea or Iran with a more multilateral approach than during his first term.
Likewise, for all the complaints about the United Nations, the US and others turned to UN peacekeepers to sort out the mess after the Lebanon War last summer.
The Iraq War, in particular, increased public awareness of the mistakes in Bush’s first term, but other issues are changing as well.
Americans now view cooperative action on global climate change more favorably.
Similarly, the threat of pandemics means that Americans may come to recognize the importance of a stronger World Health Organization, just as the problem of nuclear proliferation is increasing awareness of the importance of the International Atomic Energy Agency.
The nature of these problems means that the US does not have the luxury of turning inward no matter what the outcome in Iraq.
These are not problems you can leave overseas.
They follow you home.
It also is unlikely that American foreign policy will return to a narrow realism and drop all emphasis on democracy and human rights.
While the Iraq War discredited the idea of coercive democratization, both Republicans and Democrats have a strong strand of idealism in their foreign policy orientations.
The problem for whoever is elected president in 2008 will be to find appropriate realistic means to advance democratic values and adjust official rhetoric accordingly.
When rhetoric greatly outstrips reality, others view it as hypocrisy.
Americans will need to find ways to assert their narrative of democracy, freedom, and rights in a manner that respects diversity and the views of others.
What Iraq has taught is the importance of developing civil society and the rule of law before trying to hold broad-based elections.
Democracy is more than voting, for it requires large investments in education, institutions, and promotion of non-governmental organizations.
It must be rooted in the indigenous society and bear its characteristics, not be imposed from abroad.
It is highly unlikely that the US will react after Iraq as it did after Vietnam.
The paradox of American power is that the world’s only military superpower cannot protect its citizens by acting alone.
America’s Global Balancing Act
With Russia’s invasion of Ukraine and annexation of Crimea, the disintegration of Iraq’s and Syria’s borders, and increasing Chinese assertiveness in the South and East China Seas, the post-Cold War era appears to have ended in 2014.
Is that true?
The post-Cold War era was not really an “era,” but rather a gradual transition from a bilateral Cold War to a more complex international order that still involves, in the final analysis, two world powers.
In brief, the decisive axis of the new order increasingly involves the United States and the People’s Republic of China.
The Sino-American competition involves two significant realities that distinguish it from the Cold War: neither party is excessively ideological in its orientation; and both parties recognize that they really need mutual accommodation.
America’s supposed “pivot to Asia” took a back seat in 2014 to the crises in Ukraine and the Middle East.
To what extent has uncertainty about the US commitment in Asia stoked tension between China and America’s Asian allies?
I disagree with the premises of the question.
I do think America has made it quite clear that it is in the interest both of America and China to avoid situations in which they will be pushed toward a collision.
The recent indications of some initial dialogue between China and India, and between China and Japan, suggest that China also realizes that escalating old grievances is not in its interest.
The more serious problem with the “pivot to Asia” was its actual wording, which implied a military posture designed to “contain” or “isolate” China.
The Chinese have come to realize more clearly that we were not deliberately attempting to isolate them, but that we had a stake in the avoidance of collisions in the Far East that could produce a wider spillover.
Xi Jinping has used his war on corruption to concentrate more power in his hands than any Chinese leader since Deng Xiaoping, 30 years ago.
How do you see Xi’s presidency evolving?
Power in China is somewhat informally defined, and its limits are set more by political realities than by constitutional arrangements.
That makes it difficult to say whether Xi’s power is greater than any Chinese leader’s since Deng.
He certainly has an authoritative personality and without doubt is more active on the international scene than some of his predecessors.
He has also been very decisive in attacking the growing corruption that has become a major source of internal malaise, reaching even the highest levels of government.
In that respect, it may be argued that his power is more wide-ranging than that of his predecessors, but in fairness it must also be noted that the patterns of corruption that his predecessors faced were not as acute and widespread as they have become in recent years.
At the same time, the increasing emphasis in party journals on the proposition that China’s armed forces must be viewed as servants of the Communist Party, and not simply of the nation, seems to suggest concern that the military may be developing its own view of Chinese domestic affairs, in addition to proclaiming with increasing assertiveness its responsibility for national security.
The Party elite, quite understandably, does not find this reassuring.
Can Russian President Vladimir Putin’s regime withstand a prolonged period of low energy prices and Western sanctions?
What risks do you see emerging should Russia’s economy continue to decline, with Putin increasingly unable to reward his political base?
There is, of course, a danger that at some point Putin may choose to lash out and create a truly massive international crisis, and perhaps precipitate some new form of direct East-West warfare.
But to say that, one must also assume that to some extent he himself is unbalanced and has shifted from a kind of guerilla warfare against the West, always with some possibility of retreat, to all-out combat.
The outcome of that would be inherently unpredictable, but probably in any case very destructive for Russian wellbeing.
If Russia’s economy continues to decline, and if the West succeeds in deterring Putin from further use of force, it is still conceivable that some acceptable resolution (a form of which I recommended publicly by talking about the Finland model) may be contrived.
But that depends in turn on the West’s firmness in supporting Ukraine’s efforts to stabilize itself.
Following the withdrawal of US troops from Afghanistan and Iraq, much of the world now perceives the US as being in a period of “retreat,” similar to the post-Vietnam War era.
Is the US embracing a form of neo-isolationism?
Or will America’s apparent inward turn be as brief as it was following Vietnam?
I do not believe that the US is in a “period of retreat.”
The fact of the matter is that the redistribution of global power has produced a situation in which the US is no longer the sole hegemon.
The US has to acknowledge the fact that the world is now much more complex.
The spread of conflict throughout the Middle East is currently precipitated more by the rise of religious sectarianism than by American interventionism.
In these volatile circumstances, greater attention must be given to the national interests of countries such as Turkey, Iran, Saudi Arabia, Egypt, and Israel.
By the same token, the interests of any one of them must not be allowed to become the total interest of the US.
What may surprise the world most in 2015?
Perhaps the gradual reappearance in Russia of a more politically assertive liberal middle class.
That middle class was beginning to play a more significant role in shaping domestic and international Russian policy under Dmitri Medvedev.
With Putin’s return to power and his recent adventurism, it has been pushed aside by deliberately awakened and intensely stimulated national chauvinism.
Waving a chauvinist banner, however, may not be the best solution for dealing with international problems, especially if the West is intelligent and united.
The Russian middle class, quite naturally, wishes to live in a society like that of Western Europe.
A Russia that gradually begins to gravitate toward the West will also be a Russia that ceases to disrupt the international system.
America’s Enemy Within
NEW YORK – Barring any unexpected new revelations, there is not much to be learned from the Tsarnaev brothers, better known as “the Boston bombers.”
We can dig into their family histories in strife-torn Dagestan, or examine, once again, the lethal appeal of Islamist radicalism.
But I doubt that this would be enlightening.
The elder brother, Tamerlan, who died in a gun battle with the police, appears to fit perfectly the profile of what the German writer Hans Magnus Enzensberger calls “the radical loser.”
And his younger brother, Dzhokhar, recovering from gunshot wounds in a Boston hospital while waiting to be put on trial for his life, seems to have been a pathetic follower who acted less out of deep conviction than out of fraternal love.
The radical loser is the kind of young man who feels victimized by an unfeeling, uncaring world.
That sour sense of rejection, felt by many confused youths, turns for some into a fierce desire for vengeance.
Like Samson in the temple of Gaza, he wishes to destroy himself in a public act of violence, taking as many people as possible with him.
Anything can trigger this final act: a lover’s rejection, a job application denied.
In the case of Tamerlan, a talented boxer, he was denied the chance to become a champion because he was not yet a United States citizen.
Radical Islamism offered him a ready-made cause to die for.
More interesting, and in a way far more disturbing, has been the reaction in the US to the Boston bombings, which killed three people and injured 264.
Even after Tamerlan had died, and Dzhokhar, already wounded, was the only known fugitive, the Boston authorities decided to close down the entire city.
Public transport was halted, trains to and from the city were stopped, shops and business closed, and citizens were told to stay home.
Until the surviving bomber was found, Boston was reduced to a ghost town.
If two troubled young men with homemade bombs cobbled together from fertilizer and pressure cookers can have this effect on a major American city, one can imagine how tempting their example must now be to other radical losers, not to mention radical groups.
It shows how vulnerable a modern city can be when its leaders lose their nerve.
The authorities’ overblown reaction – and that of much of the press – was all the odder for having occurred just as the US Senate was voting down a bill that would have made it harder for known killers and mentally disturbed people to buy guns, or for private individuals to acquire weapons normally used only in warfare.
It seems as though Americans can tolerate a society in which schoolchildren and other innocents are regularly murdered by deranged men with weapons bought on the open market, but erupt in collective hysteria when the killings are committed by people labeled as “terrorists.”
This may reflect what people are accustomed to.
The Spanish had grown so inured to acts of violence from Basque separatists that the murder of 191 people in Madrid by Islamist extremists in 2004 was met with remarkable sang-froid.
When 52 people were killed in a suicide bombing on the London Underground the following year, the British, too, reacted with relative calm, having lived through years of Irish terrorist violence in the 1970’s.
Like the Spanish, they were used to it.
Americans, despite the attacks of September 11, 2001, are not.
Worse than that, a number of Republican senators, including such luminaries as John McCain, called for stripping Dzhokhar Tsarnaev, who is a US citizen, of his legal rights and placing him before a military tribunal as an “enemy combatant,” as though the 19-year-old college student were a soldier in a war against America.
Exaggerated fear of outside enemies has always been part of the American political landscape.
The “nation of immigrants” was traditionally regarded as a refuge from danger.
The evil outside world should not be able to touch the Land of the Free.
When it does – Pearl Harbor, September 2001 – all hell breaks loose.
Another factor may be the need for a common enemy in a country whose citizens come from so many different cultures and traditions.
Besieged by Communists or Islamists, people feel a sense of belonging.
Defense of the nation against dangerous outsiders – and their domestic agents, whether real or imagined – provides a powerful bond.
Such bonds can be useful, even necessary, in times of war.
But the politics of fear poses a danger to the US itself.
The aim of political terrorist groups, such as Al Qaeda, is to provoke retaliation and maximize publicity for their cause.
As common criminals, such groups’ members would not achieve this goal.
But by claiming to be soldiers at war with the world’s biggest military power, they gain sympathy, as well as recruits, among the radical losers and the disaffected.
Former President George W. Bush once explained terrorism as the expression of hatred for American freedom.
But when terrorism results in torture of prisoners, ever more police surveillance, and official threats to US citizens’ legal rights – or, for that matter, when a crime committed by two young immigrants causes an entire city to be shut down – Americans’ government is harming their freedom more than any terrorist could ever hope to do.
American Funk
NEW YORK – The eccentric Bengali intellectual Nirad C. Chaudhuri once explained the end of the British Raj in India as a case of “funk,” or loss of nerve.
The British had stopped believing in their own empire.
They simply lost the will, in Rudyard Kipling’s famous words, to fight “the savage wars of peace.”
In fact, Kipling’s poem, “The White Man’s Burden,” which exhorted the white race to spread its values to the “new-caught sullen peoples, half devil and half child,” was not about the British Empire at all, but about the United States.
Subtitled “The United States and the Philippine Islands,” it was published in 1899, just as the US was waging a “savage war of peace” of its own.
Chaudhuri had a point.
It is difficult to sustain an empire without the will to use force when necessary.
Much political rhetoric, and a spate of new books, would have us believe that the US is now in a dangerous state of funk.
For example, Republican presidential candidate Mitt Romney likes to castigate President Barack Obama for “apologizing for America’s international power,” for daring to suggest that the US is not “the greatest country on earth,” and for being “pessimistic.”
By contrast, Romney promises to “restore” America’s greatness and international power, which he proposes to do by boosting American military force.
Romney’s Kipling is the neo-conservative intellectual Robert Kagan, whose new book, The World America Made, argues against “the myth of American decline.” Yes, he admits, China is growing in strength, but US dominance is still overwhelming; American military might can still “make right” against any challenger.
The only real danger to US power is “declinism”: the loss of self-belief, the temptation to “escape from the moral and material burdens that have weighed on [Americans] since World War II.” In a word, funk.
Like Chaudhuri, Kagan is an engaging writer.
His arguments sound reasonable.
And his assessment of US firepower is no doubt correct.
True, he has little time for domestic problems like antiquated infrastructure, failing public schools, an appalling health care system, and grotesque disparities in income and wealth.
But he is surely right to observe that no other power is threatening to usurp America’s role as the world’s military policeman.
Less certain, however, is the premise that the world order would collapse without “American leadership.”
France’s King Louis XV allegedly declared on his deathbed: “Après moi, le déluge” (After me, the flood).
This is the conceit of all great powers.
Even as the British were dismantling their empire after World War II, the French and Dutch still believed that parting with their Asian possessions would result in chaos.
And it is still common to hear autocratic leaders who inherited parts of the Western empires claim that democracy is all well and good, but the people are not yet ready for it.
Those who monopolize power cannot imagine a world released from their grip as anything but a catastrophe.
In Europe after World War II, Pax Americana, guaranteed by US military power, was designed “to keep the Russians out and Germany down.”
In Asia, it was meant to contain communism, while allowing allies, from Japan to Indonesia, to build up economic strength.
Spreading democracy was not the main concern; stopping communism – in Asia, Europe, Africa, the Middle East, and the Americas – was.
In this respect, it succeeded, though at great human cost.
But, now that the specter of global communist domination has joined other fears – real and imagined – in the dustbin of history, it is surely time for countries to start handling their own affairs.
Japan, in alliance with other Asian democracies, should be able to counterbalance China’s growing power.
Similarly, Europeans are rich enough to manage their own security.
But neither Japan nor the European Union seems ready to pull its own weight, owing in part to decades of dependency on US security.
As long as Uncle Sam continues to police the world, his children won’t grow up.
In any case, as we have seen in Iraq and Afghanistan, “savage wars of peace” are not always the most effective way to conduct foreign policy.
Old-fashioned military dominance is no longer adequate to promote American interests.
The Chinese are steadily gaining influence in Africa, not with bombers, but with money.
Meanwhile, propping up secular dictators in the Middle East with US arms has helped to create Islamist extremism, which cannot be defeated by simplysending more drones.
The notion promoted by Romney and his boosters that only US military power can preserve world order is deeply reactionary.
It is a form of Cold War nostalgia – a dream of returning to a time when much of the globe was recovering from a ruinous world war and living in fear of communism.
Obama’s recognition of America’s limitations is not a sign of cowardly pessimism, but of realistic wisdom.
His relative discretion in the Middle East has allowed people there to act for themselves.
We do not yet know what the outcome there will be, but “the greatest country on earth” cannot impose a solution.
Nor should it.
American Gulag
Recently, the United States achieved the dubious honor of boasting the largest prison and jail population on earth.
It reached this zenith by surpassing cash-strapped Russia - long its only rival as a mass imprisonment society - after Russia released thousands of inmates so as to save money.
A few years earlier, as America rushed to lock up ever more of its population for ever-pettier offenses, the absolute size of its incarcerated population surpassed that of China - despite China's population being more than four times that of America.
According to research conducted by the British Home Office, America now incarcerates over one fifth of the world's total prisoners.
There is something bitterly ironic in this. For America really is a land of liberty, a place where lives, often scarred by injustice elsewhere, can be remade.
How tragic, therefore, that over the past twenty years, the country's political leaders have so often decided to deal with many of the most noxious side-effects of poverty - from chronic drug use and the establishment of street drug markets, to hustling, to gang membership and the spraying of graffiti on public buildings - through a vast over-reliance on incarceration.
How doubly tragic that this has occurred in tandem with a political assault on the Great Society anti-poverty programs put in place during the 1960s; that the investments in infrastructure, public education, public healthcare and job training which might curtail crime more effectively are, instead, being replaced by massive public expenditures on building new prisons to incarcerate hundreds of thousands of low-level offenders.
With such vicious cycles of crime, punishment and dis-investment in poor communities it is no surprise that the prison population has expanded to such an extent.
The numbers buttressing this sprawling prison system are extraordinary.
Approximately two million Americans are now serving either prison or jail time, over one million of them for non-violent offenses (a preponderance of these either for drug use or low-level drug sales).
Per hundred thousand residents, the US has an incarceration rate over five times that of England, six times that of Canada, and seven times that of Germany.
Somewhere in the region of 10% of African American men in their twenties live behind bars.
In some states, where a single felony conviction is enough to bar the offender from ever being able to vote again, over one quarter of African American males are disenfranchised.
High levels of disenfranchisement in Florida likely played a critical role in the much-disputed electoral victory of President Bush.
Since 1980, a virtual ``prison industrial complex'' has arisen, with phenomenal rates of new-prison construction abetted by lucrative construction and prison-guard union lobbies.
Several states, including California, now spend more on prisons than they do on higher education.
Despite dramatically falling crime rates over the last ten years (which most criminologists attribute more to demography - there have simply been fewer young men of late - than incarceration), prison populations have continued to soar.
Much of that increase has more to do with public perceptions about supposed crime waves and ham-handed public and political responses to occasional headline-capturing murders, than any actual underlying crime rate.
As the actual number of truly heinous crimes has in fact fallen, increasingly it is small-time hoodlums, drug users, and mentally ill people who have been drawing long spells behind bars.
America today has five times as many prisoners as it did in 1980.
One of the most dismaying developments is the spread of so-called ``three-strikes-and-you're out'' laws.
California's version, passed by citizen referendum in 1993 and ratcheted into place by state legislators in 1994, provides for the life imprisonment of any criminal with two previous serious convictions who is found guilty of any third felony.
By the end of last year there were about 7,000 people serving life sentences in California under this law.
Many thousands of them are serving life for small-time ``Third Strikes'': minor drug crimes, car theft, petty fraud, burglary, and drunk driving (even graffiti spraying, to the tune of $400 damage, which has now been reclassified as a felony).
One such man is fifty-eight year old heroin addict Billy Ochoa, who is serving a staggering 326 years in a supermax (super maximum security) prison for $2,100 of welfare fraud.
Because he had been convicted of several burglaries over the previous decades, when Ochoa was caught making fraudulent applications for food stamps and emergency housing vouchers in Los Angeles, he was tried under the Three Strikes law and given sentences on thirteen separate counts to be served in one of the toughest, most secure prisons in America.
Ochoa's sentence, apart from its extravagant cruelty, may ultimately cost taxpayers as much as a million dollars.
In many high security American prisons, inmates are routinely kept in virtual isolation, fed in their cells, allowed out for only half an hour of exercise a day, sometimes denied a TV, a radio, or even decorations for their concrete walls - conditions which have been documented to drive many of them into states of serious psychosis.
How can things have come to this America?
Now is the time - with the world watching America fight to defend its values - for the worst excesses of its criminal justice system to be addressed.
It is a tragedy that a great democracy should have so ugly and vast a prison system corroding both its reputation and its polity.
American Hegemony or American Primacy?
CAMBRIDGE – No country in modern history has possessed as much global military power as the United States.
Yet some analysts now argue that the US is following in the footsteps of the United Kingdom, the last global hegemon to decline.
This historical analogy, though increasingly popular, is misleading.
Britain was never as dominant as the US is today.
To be sure, it maintained a navy equal in size to the next two fleets combined, and its empire, on which the sun never set, ruled over a quarter of humankind.
But there were major differences in the relative power resources of imperial Britain and contemporary America.
By the outbreak of World War I, Britain ranked only fourth among the great powers in terms of military personnel, fourth in terms of GDP, and third in military spending.
The British Empire was ruled in large part through reliance on local troops.
Of the 8.6 million British forces in WWI, nearly a third came from the overseas empire.
That made it increasingly difficult for the government in London to declare war on behalf of the empire when nationalist sentiments began to intensify.
By World War II, protecting the empire had become more of a burden than an asset.
The fact that the UK was situated so close to powers like Germany and Russia made matters even more challenging.
For all the loose talk of an “American empire,” the fact is that the US does not have colonies that it must administer, and thus has more freedom to maneuver than the UK did.
And, surrounded by unthreatening countries and two oceans, it finds it far easier to protect itself.
That brings us to another problem with the global hegemon analogy: the confusion over what “hegemony” actually means.
Some observers conflate the concept with imperialism; but the US is clear evidence that a hegemon does not have to have a formal empire.
Others define hegemony as the ability to set the rules of the international system; but precisely how much influence over this process a hegemon must have, relative to other powers, remains unclear.
Still others consider hegemony to be synonymous with control of the most power resources.
But, by this definition, nineteenth-century Britain – which at the height of its power in 1870 ranked third (behind the US and Russia) in GDP and third (behind Russia and France) in military expenditures – could not be considered hegemonic, despite its naval dominance.
Similarly, those who speak of American hegemony after 1945 fail to note that the Soviet Union balanced US military power for more than four decades.
Though the US had disproportionate economic clout, its room for political and military maneuver was constrained by Soviet power.
Some analysts describe the post-1945 period as a US-led hierarchical order with liberal characteristics, in which the US provided public goods while operating within a loose system of multilateral rules and institutions that gave weaker states a say.
They point out that it may be rational for many countries to preserve this institutional framework, even if American power resources decline.
In this sense, the US-led international order could outlive America’s primacy in power resources, though many others argue that the emergence of new powers portends this order’s demise.
But, when it comes to the era of supposed US hegemony, there has always been a lot of fiction mixed in with the facts.
It was less a global order than a group of like-minded countries, largely in the Americas and Western Europe, which comprised less than half of the world.
And its effects on non-members – including significant powers like China, India, Indonesia, and the Soviet bloc – were not always benign.
Given this, the US position in the world could more accurately be called a “half-hegemony.”
Of course, America did maintain economic dominance after 1945: the devastation of WWII in so many countries meant that the US produced nearly half of global GDP.
That position lasted until 1970, when the US share of global GDP fell to its pre-war level of one-quarter.
But, from a political or military standpoint, the world was bipolar, with the Soviet Union balancing America’s power.
Indeed, during this period, the US often could not defend its interests: the Soviet Union acquired nuclear weapons; communist takeovers occurred in China, Cuba, and half of Vietnam; the Korean War ended in a stalemate; and revolts in Hungary and Czechoslovakia were repressed.
Against this background, “primacy” seems like a more accurate description of a country’s disproportionate (and measurable) share of all three kinds of power resources: military, economic, and soft.
The question now is whether the era of US primacy is coming to an end.
Given the unpredictability of global developments, it is, of course, impossible to answer this question definitively.
The rise of transnational forces and non-state actors, not to mention emerging powers like China, suggests that there are big changes on the horizon.
But there is still reason to believe that, at least in the first half of this century, the US will retain its primacy in power resources and continue to play the central role in the global balance of power.
In short, while the era of US primacy is not over, it is set to change in important ways.
Whether or not these changes will bolster global security and prosperity remains to be seen.
Renewing American Leadership
MADRID – December always provides an opportunity to pause and reflect on what was and what will be.
This year, one of the conclusions that such reflection yields is that the United States remains firmly at the center of the liberal world order.
Another is that the US needs to do more to lead in the way that its international standing demands.
Doubts about America’s continued global leadership have been proliferating for years.
But, though the much-discussed multi-polar world order may well be in the cards, the reality is that, for now, efforts to address global challenges – from climate change to conflict in the Middle East – demand US engagement.
Unfortunately, the narrative of American decline has gained so much traction in recent years that even US officials seem to have started to believe it, pursuing weak and piecemeal policies (or, in some cases, doing nothing at all).
President Barack Obama’s restrained foreign-policy approach appears to be fueling, not reducing, global instability.
The reasons for this lack of strong action are disputed.
Some blame Obama’s own fears about repeating his predecessors’ mistakes; others blame a hostile Congress for tying his hands.
In fact, both factors may be at work.
It may well be true that Obama would rather exercise caution – even when bold action is called for – than act impulsively and potentially cause more damage.
But the negative impact of an obstructionist, highly partisan US Congress should not be underestimated.
For example, by blocking reforms to International Monetary Fund governance that were agreed in 2010, Congress has damaged, perhaps irreparably, the legitimacy and relevance of the Bretton Woods institutions.
Likewise, by refusing to ratify the United Nations Convention on the Law of the Sea, the US Congress has undermined America’s credibility as it attempts to reaffirm international law in the South China Sea, where China is acting with increasing audacity.
And, by opposing the inclusion of legally binding climate commitments, it weakened the global climate agreement that was reached this month in Paris, leaving compliance and implementation uncertain.
Stalemate has become the name of the game in US politics in recent years.
That is why next year’s presidential election is so crucial.
It offers an opportunity for a fresh start, a new approach that produces the type of policy actions that the world needs.
The key is engagement – among branches of the US government, between the US government and the public, and between the US and the rest of the world.
For starters, to avoid the kind of obstructionism that prevailed in the last eight years, the next president must engage Congress directly and actively.
And, in fact, two of the Obama administration’s recent wins – the passage of so-called trade promotion authority (fast-track negotiating authority to conclude the Trans-Pacific Partnership) and the reauthorization of the small but vital Export-Import Bank – were the result of dedicated outreach, education, and, yes, cajoling of lawmakers.
The Iran nuclear agreement, one of Obama’s hallmark achievements, involved similar efforts to engage Congress, from protracted trips to Capitol Hill by Obama administration officials to a creative approach that allowed legislators to display their displeasure for the deal, without blocking its progress.
Even in America’s highly divisive political atmosphere, it seems, where there is a will, there is a way.
America’s next president must also improve engagement with citizens, whose widespread disaffection constrains – or allows – US leaders to pursue a weak foreign policy.
Like many Europeans today, most Americans do not seem to understand – or care to understand – that the crumbling of the liberal world order would have dire consequences for all of them.
It was not always this way.
Immediately after World War II, the memory of war, together with the enduring threat posed by the Soviet Union, made plain the importance of building and maintaining a liberal world order.
Today, though the need for such an order is just as great, the argument is not nearly as comprehensible or emotionally powerful.
Discussion of rules and institutions comes across as bloodless.
It is up to political leaders – and especially the president – to figure out how to make a compelling case about what is at stake.
Only this approach can secure the mandate from the public that the next US president will need to engage effectively with other world leaders.
And make no mistake: Such engagement is indispensable.
While the US must play an integral role in addressing global challenges, from ending the Syrian civil war to following through on the promises of the Paris climate agreement, it cannot do it alone.
Real progress will demand real cooperation.
In the second half of the twentieth century, the US showed that committed leadership could help to ensure widespread stability and prosperity.
In the twenty-first century, it has showed how devastating a lack of such leadership can be.
Finger pointing will not fix anything.
Only by pursuing genuine, deep, and sustained engagement, both at home and abroad, can the next administration ensure that the coming years will be better than the last.
American Pie in the Sky
NEW YORK – While the risk of a disorderly crisis in the eurozone is well recognized, a more sanguine view of the United States has prevailed.
For the last three years, the consensus has been that the US economy was on the verge of a robust and self-sustaining recovery that would restore above-potential growth.
That turned out to be wrong, as a painful process of balance-sheet deleveraging – reflecting excessive private-sector debt, and then its carryover to the public sector – implies that the recovery will remain, at best, below-trend for many years to come.
Even this year, the consensus got it wrong, expecting a recovery to above-trend &nbsp;annual GDP growth – faster than 3%.
But the first-half growth rate looks set to come in closer to 1.5% at best, even below 2011’s dismal 1.7%.
And now, after getting the first half of 2012 wrong, many are repeating the fairy tale that a combination of lower oil prices, rising auto sales, recovering house prices, and a resurgence of US manufacturing will boost growth in the second half of the year and fuel above-potential growth by 2013.
The reality is the opposite: for several reasons, growth will slow further in the second half of 2012 and be even lower in 2013 – close to stall speed.
First, growth in the second quarter has decelerated from a mediocre 1.8% in January-March, as job creation – averaging 70,000 a month – fell sharply.
Second, expectations of the “fiscal cliff” – automatic tax increases and spending cuts set for the end of this year – will keep spending and growth lower through the second half of 2012.
So will uncertainty about who will be President in 2013; about tax rates and spending levels; about the threat of another government shutdown over the debt ceiling; and about the risk of another sovereign rating downgrade should political gridlock continue to block a plan for medium-term fiscal consolidation.
In such conditions, most firms and consumers will be cautious about spending – an option value of waiting – thus further weakening the economy.
Third, the fiscal cliff would amount to a 4.5%-of-GDP drag on growth in 2013 if all tax cuts and transfer payments were allowed to expire and draconian spending cuts were triggered.
Of course, the drag will be much smaller, as tax increases and spending cuts will be much milder.
But, even if the fiscal cliff turns out to be a mild growth bump – a mere 0.5% of GDP – and annual growth at the end of the year is just 1.5%, as seems likely, the fiscal drag will suffice to slow the economy to stall speed: a growth rate of barely 1%.
Fourth, private consumption growth in the last few quarters does not reflect growth in real wages (which are actually falling).
Rather, growth in disposable income (and thus in consumption) has been sustained since last year by another $1.4 trillion in tax cuts and extended transfer payments, implying another $1.4 trillion of public debt.
Unlike the eurozone and the United Kingdom, where a double-dip recession is already under way, owing to front-loaded fiscal austerity, the US has prevented some household deleveraging through even more public-sector releveraging –&nbsp;that is, by stealing some growth from the future.
In 2013, as transfer payments are phased out, however gradually, and as some tax cuts are allowed to expire, disposable income growth and consumption growth will slow.
The US will then face not only the direct effects of a fiscal drag, but also its indirect effect on private spending.
Fifth, four external forces will further impede US growth: a worsening eurozone crisis; an increasingly hard landing for China; a generalized slowdown of emerging-market economies, owing to cyclical factors (weak advanced-country growth) and structural causes (a state-capitalist model that reduces potential growth); and the risk of higher oil prices in 2013 as negotiations and sanctions fail to convince Iran to abandon its nuclear program.
Policy responses will have very limited effect in stemming the US economy’s deceleration toward stall speed: even with only a mild fiscal drag on growth, the US dollar is likely to strengthen as the eurozone crisis weakens the euro and as global risk aversion returns.
The US Federal Reserve will carry out more quantitative easing this year, but it will be ineffective: long-term interest rates are already very low, and lowering them further would not boost spending.
Indeed, the credit channel is frozen and velocity has collapsed, with banks hoarding increases in base money in the form of excess reserves.
Moreover, the dollar is unlikely to weaken as other countries also carry out quantitative easing.
Similarly, the gravity of weaker growth will most likely overcome the levitational effect on equity prices from more quantitative easing, particularly given that equity valuations today are not as depressed as they were in 2009 or 2010.
Indeed, growth in earnings and profits is now running out of steam, as the effect of weak demand on top-line revenues takes a toll on bottom-line margins and profitability.
A significant equity-price correction could, in fact, be the force that in 2013 tips the US economy into outright contraction.
And if the US (still the world’s largest economy) starts to sneeze again, the rest of the world – its immunity already weakened by Europe’s malaise and emerging countries’ slowdown – will catch pneumonia.
American Power after Bin Laden
OXFORD – When one state is preponderant in power resources, observers often refer to the situation as hegemonic.
Today, many pundits argue that other countries’ rising power and the loss of American influence in a revolutionary Middle East point to the decline of “American hegemony.”
But the term is confusing.
For one thing, possession of power resources does not always imply that one can get the outcomes one prefers.
Even the recent death of Osama bin Laden at the hands of United States special forces does not indicate anything about American power one way or the other.
To see why, consider the situation after World War II.
The US accounted for more than one-third of global product and had an overwhelming preponderance in nuclear weapons.
Many considered it a global hegemon.
Nonetheless, the US was unable to prevent the “loss” of China, “roll back” communism in Eastern Europe, prevent stalemate in the Korean War, defeat Vietnam’s National Liberation Front, or dislodge the Castro regime in Cuba.
Even in the era of alleged American hegemony, studies show that only one-fifth of America’s efforts to compel change in other countries through military threats were successful, while economic sanctions worked in only half of all cases.
Yet many believe that America’s current preponderance in power resources is hegemonic, and that it will decline, like that of Britain before it.
Some Americans react emotionally to that prospect, though it would be ahistorical to believe that the US will have a preponderant share of power resources forever.
But the term “decline” conflates two different dimensions of power: absolute decline, in the sense of decay or loss of ability to use one’s resources effectively, and relative decline, in which the other states’ power resources become greater or are used more effectively.
For example, in the seventeenth century, the Netherlands flourished domestically but declined in relative power as other states grew in strength.
Conversely, the Western Roman Empire did not succumb to another state, but instead to internal decay and swarms of barbarians.
Rome was an agrarian society with low economic productivity and a high level of internecine strife.
While the US has problems, it hardly fits the description of absolute decline in ancient Rome, and the analogy to British decline, however popular, is similarly misleading.
Britain had an empire on which the sun never set, ruled more than a quarter of humankind, and enjoyed naval supremacy.
But there are major differences in the relative power resources of imperial Britain and contemporary America.
By World War I, Britain ranked only fourth among the great powers in terms of military personnel, fourth in GDP, and third in military spending.
The costs of defense averaged 2.5-3.4% of GDP, and the empire was ruled in large part with local troops.
In 1914, Britain’s net export of capital gave it an important financial kitty to draw upon (though some historians consider that it would have been better to have invested the money in domestic industry).
Of the 8.6 million British forces in WWI, nearly one-third were provided by the overseas empire.
With the rise of nationalism, however, it became increasingly difficult for London to declare war on behalf of the empire, the defense of which became a heavier burden.
By contrast, America has had a continental-scale economy immune from nationalist disintegration since 1865.
For all the loose talk of American empire, the US is less tethered and has more degrees of freedom than Britain ever had.
Indeed, America’s geopolitical position differs profoundly from that of imperial Britain: while Britain faced rising neighbors in Germany and Russia, America benefits from two oceans and weaker neighbors.
Despite these differences, Americans are prone to cycles of belief in decline.
The Founding Fathers worried about comparisons to the decline of the Roman republic.
Moreover, cultural pessimism is very American, extending back to the country’s Puritan roots.
As Charles Dickens observed a century and a half ago, “if its individual citizens, to a man, are to be believed, [America] always is depressed, and always is stagnated, and always is in an alarming crisis, and never was otherwise.”
More recently, polls showed widespread belief in decline after the Soviet Union launched Sputnik in 1957, then again during the Nixon-era economic shocks in the 1970’s, and after Ronald Reagan’s budget deficits in the 1980’s.
At the end of that decade, American’s believed the country was in decline; yet, within a decade, they believed that the US was the sole superpower.
Now many have gone back to believing in decline.
Cycles of declinism tell us more about American psychology than about underlying shifts in power resources.
Some observers, such as the Harvard historian Niall Ferguson, believe that “debating the stages of decline may be a waste of time – it is a precipitous and unexpected fall that should most concern policy makers and citizens.”
Ferguson believes that a doubling of public debt in the coming decade cannot erode US strength on its own, but that it could weaken a long-assumed faith in America’s ability to weather any crisis.
Ferguson is correct that the US will have to come to terms with its budget deficit to maintain international confidence, but, as I show in my book The Future of Power, doing so is within the range of possible outcomes.
America enjoyed a budget surplus only a decade ago, before George W. Bush’s tax cuts, two wars, and recession created fiscal instability.
The US economy is still ranked near the top in competitiveness by the World Economic Forum, and the political system, in its own messy way, has slowly begun to wrestle with the necessary changes.
Some believe a political compromise between Republicans and Democrats can be reached before the 2012 election; others suggest an agreement is more likely after the election.
Either way, fuzzy statements about hegemonic decline would again prove misleading.
American Power and the 2004 Campaign
America's presidential election campaign is heating up, and with it the debate about American power.
A year ago, after the blitz victory in the four-week Iraq War, many people thought the issue was settled.
But the subsequent difficulties in Iraq - and in America's foreign relations more generally - have placed that topic at the heart of the election campaign.
It is hard to recall, but a little over a decade ago, conventional wisdom - both inside and outside the US - held that America was in decline.
In 1992, the winner of the New Hampshire primary election argued that "the Cold War is over - and Japan won."
When I published Bound to Lead in 1990, I predicted the continuing rise of American power.
But today I regard it as equally important to challenge the new conventional wisdom that America is invincible, and that the "new unilateralism" should guide US foreign policy.
After the collapse of the Soviet Union, some analysts described the resulting world as unipolar and saw few constraints on American power.
This is misleading.
Power in a global information age is distributed among countries in a pattern that resembles a complex three-dimensional chess game.
On the top chessboard, military power is largely unipolar.
The US is the only country with large state of the art air, naval, and ground forces capable of global deployment - thus, the quick victory in Iraq last year.
But on the middle chessboard, economic power is multi-polar, with the US, Europe, Japan, and China representing two-thirds of world production.
On this economic board, other countries often balance American power.
The bottom chessboard is the realm of transnational relations that cross borders beyond government control.
At the benign end of the spectrum, this realm includes actors as diverse as bankers electronically transferring huge sums; at the other end are terrorists transferring weapons or hackers disrupting Internet operations.
On this bottom board, power is widely dispersed, and it makes no sense to speak of unipolarity, multipolarity, or hegemony.
Those who recommend a unilateral American foreign policy based on such traditional descriptions of American power are relying on a woefully inadequate analysis.
Many of the real challenges to American power are coming not on the upper military board, on which the unilateralists concentrate, but on the lower transnational board.
Ironically, the temptation to go it alone may ultimately weaken the US in this domain.
Why is this true?
Today's information revolution and the type of globalization that accompanies it are transforming and shrinking the world.
At the beginning of the 21st century, these two forces increased American power, particularly the ability to influence others through attractive, or what I call "soft" power.
But with time, technological gains will spread to other countries and peoples, diminishing America's relative pre-eminence.
For example, today America's 5% of the global population represents more than half of all Internet users.
But in a decade or two, Chinese may become the language of the largest number of Internet users.
It will not dethrone English as a lingua franca, but at some point, the Asian market will loom larger than the American market.
Even more important, the information revolution is creating virtual communities and networks that cut across national borders, and transnational corporations and non-governmental actors - terrorists included - will play larger roles.
Many organizations will have soft power of their own as they attract citizens into coalitions that cut across national boundaries.
The terrorist attacks on New York, Washington, and now Madrid are terrible symptoms of the deep changes already occurring.
Technology has been diffusing power away from governments, and empowering individuals and groups to play roles in world politics - including wreaking massive destruction - that were once reserved to governments.
Privatization has been the leitmotif in economic policy in recent years, but in politics the privatization of war is terrorism.
Moreover, as globalization shrinks distance, events in faraway places - like Afghanistan - have a greater impact on everyone's lives.
The world has moved from the Cold War to the Global Information Age, but the dominant foreign policy paradigms have not kept pace.
Today's growing global networks of interdependence are putting new items on national and international agendas; Americans simply cannot solve many of these by themselves.
International financial stability is vital to prosperity, but the US needs the cooperation of others to ensure it.
In a world where borders are becoming more porous than ever to everything from drugs to infectious diseases to terrorism, Americans will be forced to work with other countries beyond their borders.
Because of its leading edge in the information revolution, and its vast investment in traditional power resources, the US will remain the world's single most powerful country well into this new century.
While potential coalitions to check American power may be created, it is unlikely that they will become firm alliances unless the US handles its hard coercive power in an overbearing unilateral manner that undermines its "soft" or attractive power.
American Retreats
Los Angeles – As Barack Obama’s incoming administration debates the pace and consequences of withdrawal from Iraq, it would do well to examine the strategic impact of other American exits in the final decades of the twentieth century.
Although American commitments to Lebanon, Somalia, Vietnam, and Cambodia differed mightily, history reveals that despite immediate costs to America’s reputation, disengagement ultimately redounded to America’s advantage.
In all of these cases, regional stability of sorts emerged after an American military withdrawal, albeit at the cost of a significant loss of life.
America’s former adversaries either became preoccupied with consolidating or sharing power, suffered domestic defeat, or confronted neighboring states.
Ultimately, America’s vital interests prevailed.
The evidence today suggests that this pattern can be repeated when the United States departs Mesopotamia and leaves Iraqis to define their own fate.
Of the four withdrawals, arguably the 1982-1984 American intervention in Lebanon marks the closest parallel to Iraq today.
A country torn by sectarian violence beginning in 1975, Lebanon pitted an even more complex array of contestants against each other than Iraq does today.
Into this fray stepped the US and its Western allies.
Their objective was to create a military buffer between the PLO and Israeli forces that were then fighting in Beirut in order to promote the departure of both.
The massacres in Palestinian refugee camps prompted a new commitment to “restore a strong and central government” to Lebanon, to quote President Ronald Reagan.
But the result of intervention was that US forces became just one more target, culminating in the 1983 bombing of a US Marine barracks that killed 241 American soldiers.
A similar suicide bombing two days later claimed the lives of 58 French soldiers.
In February 1984, facing a quagmire, Reagan acceded to Vice President George H.W. Bush’s recommendation to get out of Lebanon.
But the withdrawal of Western forces did not stop the fighting.
The civil war continued for another six years, followed by a bumpy political aftermath: Syrian intervention and expulsion (two decades later), as the Lebanese defined their own fate with the US exercising only background influence.
In 1992, the sirens of Somalia’s political collapse lured the US into another civil war to save a country from itself.
The US humanitarian mission to that benighted country sought to salvage a failed United Nations enterprise to secure and feed Somalia’s ravaged population.
The US committed 28,000 troops, which for a time imposed a modicum of security.
But ill-equipped and poorly led UN replacement forces for the American presence put the remaining US troops in the bull’s eye as they attempted to bring to justice the Somali warlord responsible for the death of Pakistani peacekeepers.
The ensuing bloodbath of US soldiers generated images that the American public could not stomach, prompting the exit of American and then UN forces.
As unrest mounted with these military retreats, offshore US forces monitored and intercepted jihadists who sought to enter Somalia, while Kenya and Ethiopia blocked the unrest from metastasizing across the region.
In 2006, the capture of Somalia’s capital, Mogadishu, by the Islamic Courts raised the specter of a jihadist state.
But Somalia soon demonstrated that quagmires can be a two-way street.
Following Ethiopia’s intervention, the Islamists found themselves out of power.
Today, Somalia remains a dysfunctional state, as rival clans, jihadists, and an interim government with Ethiopian support compete for power.
The US, now out of the quagmire, exercises limited influence from afar.
While Lebanon and Somalia remain damaged and failed states, respectively, regional and domestic factors have cauterized the consequences of America’s retreat from Vietnam and Southeast Asia.
The result is the stable region that the world sees today.
But the US saw things very differently in the 1960’s, when the ghosts of Munich hovered over Vietnam’s jungles.
As President George W. Bush argued about the war in Iraq, US President Lyndon Johnson predicted that defeat in Vietnam “would be renewed in one country and then another.”
What Johnson failed to foresee were the domestic and regional constraints that would prevent the dominos from falling in the way he predicted.
Although the US bombed northeastern Cambodia intensely throughout the Vietnam War years, it had no stomach for a ground commitment there.
Still within congressional restraints, the Nixon administration attempted to bolster Cambodia’s military government.
But, despite modest material support, the US could not sustain a government that could not sustain itself.
Rather than the dominos falling following America’s retreat from Saigon in 1975, a Vietnam-Cambodian War ensued.
This in turn stimulated China’s unsuccessful intervention in North Vietnam.
The withdrawal by all of these invading armies to the recognized international boundaries demonstrated that nationalist forces were dominant in the region, not communist solidarity.
None of these American exits was without consequence.
But, while the US suffered costs to its reputation around the world, the supposed advantages from this for America’s opponents proved illusory.
America’s departure from Mesopotamia will likewise put the burden of problem solving onto Iraqis and other regional players, leaving the US offshore to assist when and where it deems appropriate.
History suggests that, in fits and starts, Iraq, like Vietnam and Lebanon, will find itself able to sort out its own affairs.
A Wiser America
NEW YORK – When America absorbed the bombings at the Boston Marathon, what was striking was what did not happen.
Twelve years after the attacks of September 11, 2001, the country was saddened, but it was also better informed.
There was little of the rampant jingoism, get-them-at-all-costs bloodlust, constant speechifying, and flag-waving that followed the 2001 attacks.
Perhaps most remarkable was the absence of reflexive Islamophobia and of the willingness to fight any war – even the wrong war in the wrong country for the wrong reasons – against the supposedly culpable “other.”
Instead, this time, Americans’ sadness was mingled with cynicism and suspicion.
The country is warier of being manipulated.
While Americans certainly mourn the dead and support the city of Boston, there has been a kind of penetration into the national consciousness that, after the 2001 attacks, America’s leaders used the bogeyman of terrorism to encroach on individual rights, fund almost every conceivable domestic-security boondoggle, and advance the self-interested agendas of the defense and surveillance industries.
Even conservative, Fox News-watching Americans have become aware, in a way that was not the case in the aftermath of the 2001 attacks, that America has created its own “blowback.”
The spin that worked so well back then – that the attacks occurred because “they hate our freedoms” – does not ring true anymore.
Americans know that a million refugees have fled Iraq; the Oscar-nominated documentary Five Broken Cameras and other media have shown how the United States contributes to the brutalization of Palestinians – a major driver of “jihad,” or what the US State Department calls “extremism”; US soldiers have repeatedly been implicated in war crimes; and Jeremy Scahill’s book Dirty Wars, which details targeted assassinations by the US around the world, has hit bookstores.
In short, while no one condones violence against innocents like that suffered by the victims at the Boston Marathon, Americans are far more aware than they were 12 years ago of their own slaughter of innocents around the world.
Their self-image is no longer that of the “good guys,” against whom an act of violence is mad and inexplicable.
Americans also are more aware of how such attacks are used to justify abuses of their own rights.
Immediately, the bombings began to be cited by some leaders as a call to limit constitutional rights.
Republican Senators John McCain and Lindsey Graham have called for the surviving suspect, Dzokhar Tsarnaev, to be labeled an “enemy combatant” and shipped to Guantánamo Bay – an idea that many Americans find chilling.
Other responses appall many in the US as well.
The fact that Tsarnaev, despite his many requests, was not initially informed of his right to remain silent and be represented by an attorney – normally a required part of any US arrest – caused considerable anxiety.
The panicky public response that permitted the establishment of GITMO is no more.
Americans recognize that a violation of anyone’s rights threatens the rights of all.
Notable, too, are the conspiracy theories this time around.
Most Americans probably do not actually believe that the bombing was a “false flag” event, perpetrated by others than the Tsarnaev brothers; rather, the conspiracy theories seem to show how jaded Americans have become about their government’s approach to “terror.”
After all, US leaders lied about so much in the aftermath of the 2001 attacks.
They lied about Saddam Hussein’s weapons of mass destruction; lied about why Iraq had to be attacked, and then about the course of the war there; and the head of the federal Environmental Protection Agency at the time, Christie Whitman, even lied about the air quality in lower Manhattan after the attack, leading thousands of New York City children to suffer from severe respiratory problems.
Of course, reliance on fear and misdirection may still be part of official strategy.
With Dzokhar Tsarnaev in custody and his brother dead, the next round of stories reported on alleged “sleeper cells” and planned attacks that had been thwarted by America’s security services.
The Boston Globe, for example, ran an article about the man – identified only by his first name, Danny – whom the brothers carjacked three days after the attack.
Danny claimed that the only word of the brothers’ conversation that he understood was “Manhattan,” and that the terrorists had asked him if his car could leave the state – say, to get to New York.
The Globe’s one-source report proved nothing – and was unverifiable by other reporters or citizens – but it suggested much, leading to a spate of equally unverifiable reports that New York had been targeted.
Other recent “terror”-related reporting has been as flimsy.
In Charles Savage’s recent account of the Guantánamo “uprising,” The New York Times credulously reproduced the “arsenal” that GITMO officials showed reporters in a video still.
The “weapons” were allegedly made from mop handles and nail files – objects that, as I know from having reported from Guantánamo, are literally impossible for any detainee to obtain.
The prisoners are housed far from anything like mops or other cleaning articles; they are given no chores to perform; and they receive no mail.
In swallowing the official account without skepticism – Savage did not ask where any of these items may have come from – The New York Times has apparently learned nothing from its badly flawed reporting on Saddam’s supposed WMD.
Fortunately, most Americans have learned from the past, and this was reflected in the public response this time around – sadness, yes, but also some wisdom.
Perhaps Americans have moved closer to understanding that they can and must fight terrorism in a civilized way, as free and thoughtful people.
Amnesty for Saddam?
Senior US officials, including Secretary of Defense Donald Rumsfeld, have recently suggested that Saddam Hussein and his top henchmen might be given an amnesty for their past crimes in exchange for leaving Iraq and averting war.
Is such an amnesty a good idea?
How should it be judged by those attempting to end the practice of exempting from punishment government officials guilty of monstrous crimes?
These are weighty questions.
In trying to answer them, two considerations seem fundamental.
First, one should consider the severity of the crimes committed by those who would escape punishment.
Second, we should consider how much death and suffering would be avoided by letting such a ruler and his henchmen go free.
A third factor that should also be taken into account is what damage would be done to the emerging international legal system for ending the impunity long enjoyed by state officials who use their power to commit atrocities.
As for the severity of Saddam Hussein's criminal behavior, there is probably no official now in power anywhere in the world with as much blood on his hands.
An incomplete list of his crimes includes:
using chemical weapons against Iranian troops during the eight-year Iran-Iraq war that he started in 1980;
murdering about 5,000 residents of the predominantly Kurdish town of Halabja in March 1988 through the use of chemical weapons, after using these weapons in previous months against Kurdish villages in the vicinity;
murdering about 100,000 Kurds during the "Anfal" campaign between February and September 1988, mainly by transporting the victims to a desert area where they were forced into trenches, machine-gunned, and then covered with sand by bulldozers;

destroying the ancient civilization of the Marsh Arabs in southeastern Iraq, followed by the forced resettlement and murder of the region's former residents;
his actions in Kuwait when Iraq invaded in 1990, including the disappearance--still unresolved--of hundreds of Kuwaiti citizens;
savage reprisals against the Shiites in southern Iraq in the aftermath of the 1991 Gulf War;
and persecution of any and all Iraqis suspected of dissent or disloyalty.
Each of these constitutes a war crime, a crime against humanity and, in the case of the Anfal campaign and its mass slaughter, and perhaps also in the case of the Marsh Arabs, the gravest crime of all, genocide.
Although we cannot know how many lives would be lost and how much misery would be inflicted in an invasion of Iraq to oust Saddam's regime, the cost would unquestionably be great.
No matter how compelling the case for punishing Saddam Hussein and such partners in crime as Ali Hassan al-Majid ("Ali Chemical" to the Kurds), Saddam's cousin and the principal organizer of the Anfal campaign, it is equaled by our duty to try to minimize harm to the living.
The apparent conflict between doing justice and preserving peace may be resolved through international law.
As matters currently stand, there is no mechanism for bringing Saddam Hussein to trial.
The International Criminal Court, which is now taking shape in The Hague with the selection of its first justices, does not have retroactive jurisdiction.
It cannot consider crimes committed prior to July 1, 2002.


So Saddam could be tried only before a new
If Saddam were granted sanctuary in a country such as Belarus or Libya, he would probably remain safe from prosecution, but only as long as he never leaves.
For example, Uganda's Idi Amin and Ethiopia's Haile Mariam Mengistu--deposed tyrants who rival Saddam in the scale of their criminality--have taken care not to stray from their shelters in Saudi Arabia and Zimbabwe, respectively.
If Saddam is ready to abdicate to preserve his life, he should get that much security, no more.
Without amnesty from a body such as the UN Security Council, the theoretical possibility that he could be prosecuted would be preserved.
He could not move freely.
His crimes would neither be forgiven nor forgotten.
Amnesty for Saddam Hussein is simply intolerable.
But condemning thousands to death in order to be able to punish him is intolerable as well.
Let him go where we can't get at him, but with no guarantee of impunity if his actions or fate bring him to a place where justice can be done.
An Accidental Cure for Iraq
Doctors use the word “crisis” to describe the point at which a patient either starts to recover or dies.
President George W. Bush’s Iraqi patient now seems to have reached that point.
Most commentators appear to think that Bush’s latest prescription – a surge of 20,000 additional troops to suppress the militias in Baghdad – will, at best, merely postpone the inevitable death of his dream of a democratic Iraq.
Yet as “Battle of Baghdad” begins, factors beyond Bush’s control and not of his making (at least not intentionally) may just save Iraq from its doom.
One key factor is that, for the first time since the United States and Britain invaded Iraq, Arab Sunni leaders are backing a US military plan for that country.
These Sunni leaders live in abject fear of the geopolitical earthquake that any disintegration of political authority in Baghdad would bring, believing that all-out civil war would invariably follow – a war that would not respect international borders.
Of course, America has been encouraging Sunni leaders in this belief.
Secretary of State Condoleezza Rice’s recent tour of Middle East capitals helped spread the word to Egypt, Jordan, Saudi Arabia, and the Gulf states that any US failure and sudden withdrawal would be certain to destabilize them.
Given the fragile grip that these leaders have over their societies, America’s warnings have been taken to heart.
But the truly curious factor that might bring success to Bush is that those who have opposed or resented America’s presence in Iraq, such as the Iranian-backed Shi’a parties now also appear to want Bush’s new strategy to succeed.
They are for it because they believe it will defang Moqtada al-Sadr, the rogue Shi’a cleric whose power has mushroomed over the past three years – to the point that he now dominates much of Baghdad and holds the allegiance of countless angry young Shi’a men.
Of course, attacking Moqtada al-Sadr’s Mahdi Army in the name of fighting militia death squads has the potential to draw American military forces into a level of urban warfare unseen since the Falluja assaults of 2004 and 2005.
Al-Sadr is seen as the protector of the Shi’a of Iraq and has are an estimated 60,000 fighters in his militia.
But he is deeply mistrusted by other Shi’a leaders, who fear that they may one day have to take him on by themselves.
Better to let the Americans do it, though of course these Shi’a leaders prefer a slow strangulation of al-Sadr to a direct and bloody assault.
But make no mistake: how al-Sadr is handled is the big test of Bush’s new strategy.
Should the US choose to face al-Sadr and his forces head on, they risk alienating Iraq’s largest sectarian community, the Shi’a, adding fuel to the anti-occupation resistance and thus probably dooming Bush to failure.
Iran and Syria, which have played a spoiler role in Iraq up to now, may also now be anxious to find a way to pull the country back from the brink.
Bush still refuses to talk to either of them, and has lately been having US troops arrest Iranian agents in Iraq.
Yet Iran may already see itself as victorious, with the current Iraqi government friendlier than any the Iranians have ever known.
So maintaining that government in office has now become a strategic priority for Iran, particularly as it is now clear that any US hopes of using Iraq as a permanent military base are dead.
The “surge” also opens, perhaps for the first time, a serious possibility of pouring water on the insurgent fires in Anbar province, the heartland of the Sunni insurgency.
The US has achieved relative successes in the province through alliances with Sunni tribes.
The hope is that such realistic and pragmatic accommodations will be extended to Iraqis who are fighting under the banner of a nationalist and anti-occupation agenda.
So some of the stars have come into alignment for Bush.
But to keep them there in the long term, the Iraqi government will need to amend the constitution in a way that appeases the Sunni community.
Reassuring Iraq’s Sunnis that they have a place in the new Iraq will also reassure neighboring Sunni governments, which have mostly turned a blind eye to the support for the insurgency that has come from their lands.
Of course, should the US see failure ahead, it could seek to broaden the war beyond Iraq’s borders by attacking Iran, a policy reminiscent of “Operation Sideshow,” when US failure in Vietnam in the late 1960’s enticed President Nixon into attacking Cambodia and Laos.
But Iran has resources that Cambodia and Laos could never muster; indeed, its ability to retaliate could set the entire region ablaze.
Whereas America’s war in Indochina was a tragic mistake, the cost of a wider war precipitated by the crisis in Iraq would be incomparably greater – for both the patient and the doctor.
An Age of Diminished Expectations?
CAMBRIDGE – As the United States and European economies continue to struggle, there is rising concern that they face a Japanese-style “lost decade.”
Unfortunately, far too much discussion has centered on what governments can do to stimulate demand through budget deficits and monetary policy.
These are key issues in the short term, but, as every economist knows, long-run economic growth is determined mainly by improving productivity.
There is no doubt that Japan’s massive 1992 financial crisis was a hammer blow, from which it has yet to recover, and the parallels with the US and Europe today are worrisome.
Both seem set for a long period of slow credit growth, owing both to necessary stricter financial regulation and to the fact that their economies remain significantly over-leveraged.
There are no simple shortcuts in the healing process.
Yet, in assessing the Japanese experience and its relevance today, it is important to recognize that Japan’s fall to earth was due not only to its financial crisis.
Japan also suffered a number of severe productivity shocks, which had much to do with its longer-term problems.
Even if Japan had never experienced a real-estate and stock-market bubble, the meteoric rise of its giant neighbor China would have been a huge challenge.
At the dawn of the 1990’s, Japan’s dominance in export markets worldwide had already been dented somewhat by the rise of its smaller Asian neighbors, including Malaysia, Korea, Thailand, and Singapore.
But China presents an entirely different challenge, one for which adjustment will take much longer.
Moreover, even if it never had a financial crisis, Japan would have been plagued by adverse demographics, as its population is both aging and shrinking.
Last but not least, Japan’s hyper-growth years were built on a phenomenal rate of investment.
But, because productivity ultimately must be built on innovation, not just on ever more buildings and equipment, it was inevitable that returns on investment would turn south at some point.
In principle, with a healthier financial system, Japan’s economy would have had more flexibility to meet these challenges to its productivity growth.
But, one way or another, Japan’s once sky-high growth rates probably would have fallen sharply.
As is usually the case, financial crisis amplified other causes of economic meltdown, rather than igniting it directly.
The US Great Depression of the 1930’s is another case in point.
Again, a great deal of attention has been lavished on the ebbs and flow of fiscal and monetary policy.
But New Deal economic policies, by expanding the role of the state in an often chaotic and unpredictable fashion, probably also played a role in at least temporarily impeding productivity growth.
The US today seems to be moving towards a gentler and more European-style state, with higher taxes and possibly greater regulation.
Supporters of the US administration might fairly argue that it is undertaking long-deferred maintenance on issues such as income inequality.
But if the US does experience slow growth over the next decade, can it all be blamed on the financial crisis?
Likewise, Europe’s latest existential identity crisis is again creating a great deal of policy uncertainty and unpredictability.
In Europe, too, if there are adverse growth effects over the next decade, they cannot all be blamed on the financial crisis.
In the short term, it is important that monetary policy in the US and Europe vigilantly fight Japanese-style deflation, which would only exacerbate debt problems by lowering incomes relative to debts.
In fact, as I argued at the outset of the crisis, it would be far better to have two or three years of mildly elevated inflation, deflating debts across the board, especially if the political, legal, and regulatory systems remain somewhat paralyzed in achieving the necessary write-downs.
With credit markets impaired, further quantitative easing may still be needed.
As for fiscal policy, it is already in high gear and needs gradual tightening over several years, lest already troubling government-debt levels deteriorate even faster.
Those who believe – often with quasi-religious conviction – that we need even more Keynesian fiscal stimulus, and should ignore government debt, seem to me to be panicking.
Last but not least, however, it is important to try to preserve dynamism in the US and European economies through productivity-enhancing measures – for example, by being vigilant about anti-trust policy, and by streamlining and simplifying tax systems.
For better or for worse, productivity trends are very difficult to extrapolate, depending as they do on hugely complex interactions of social, economic, and political forces.
Nobel Prize winners Robert Solow and Paul Krugman famously once questioned whether the proliferation of computers and technology would lead to bottom-line growth.
(This theme underlies the title of Krugman’s classic 1990 book “The Age of Diminished Expectations.”)
In the end, policymakers must remember that whether or not the US and Europe avoid a lost decade depends on their ability to retain productive vitality in their economies, not simply on short-term demand-stimulation measures.
An Agenda for Growth in Europe
A recent OECD study reminds us, once again, that per capita income levels are roughly 30% lower in the euro area, as well as in the three largest Continental countries – France, Germany, and Italy – that dominate its performance, than in the United States.
That gap is likely to widen as Europe’s demographic profile darkens, and if productivity continues to grow more slowly than elsewhere in the industrial economies.
Why have the large European economies failed to catch up with US income levels?
The bulk of the shortfall is due to less intensive use of labor: employment rates for women and for the oldest and youngest age groups are lower in the euro area than in the US, working hours are far fewer, and, least significantly, unemployment rates are higher.
Some take consolation from this, viewing it as positive that Europeans prefer leisure to work.
But low levels of labor utilization are largely due to heavier income taxes and social security contributions, as well as high social benefit levels introduced at a time when the labor force was growing rapidly and the need to replace involuntary with voluntary unemployment seemed more urgent than today.
These measures will need to be revisited both to increase the supply of labor and to make public finances more sustainable.
This process is already underway, particularly in Italy and France, through cuts in social security contributions for lower-paid workers, tighter conditions for drawing unemployment benefits, and tax credits for “the working poor.”
Since the mid-1990’s, the relative decline in employment in these countries has, indeed, been slightly reversed.
But factors beyond taxes and benefits also contribute to low employment rates in all the three major euro-zone economies: high minimum wages and some features of employment protection legislation slow down the flow of workers through the job market.
Although a long agenda of reforms is beginning to be tackled, first in Germany and, more recently and cautiously, in France, the results are slow in coming and public understanding of the need for change remains limited.
Much can be learned from each country’s experience and from that of smaller EU member states, but labor market reforms inevitably have a strong national flavor.
Employment objectives have been formulated for all EU member states since 1997 in the so-called European Employment Strategy (EES), now part of the “Lisbon Agenda,” the set of goals established to boost EU productivity.
But, with the policy instruments for achieving these goals largely national and the arguments for applying them simultaneously in several member states weak, the EES has created unrealistic public expectations and triggered only limited action by governments.
Nor is the employment gap with the US the only problem for Europe.
Beginning in the mid-1990’s, the rate of growth in output per hour worked – a key factor behind the rise in per capita income – slowed in most European countries while it rose in the US, reversing a decades-long pattern.
Between 2000 and 2004, hourly labor productivity rose more than twice as fast in the US than in the large euro zone economies – 2.8% per year versus little more than 1%.
So why have the Europeans been unable to sustain improvements in both foundations of growth – employment and productivity – at the same time?
This proved possible not only in the US, but also in other advanced economies outside Europe – Australia, Canada, and New Zealand – and, unsurprisingly, in the new EU member states.
The explanation is not capital spending, which is normally linked to productivity growth.
There have been no major differences between the US and the large euro zone economies here.
This leaves the “explanation” to what economists call Total Factor Productivity (TFP), a mix of several important elements, including innovation activity, a well-functioning financial system ready and willing to take risks, and organizational flexibility that facilitates rapid diffusion of new technologies.
The main lapse in TFP growth in Europe over the past decade has been in services (excluding information and communications technologies).
So deregulation and integration of services will be essential if the Euro area’s TFP is to improve, as more than two-thirds of total income in most EU economies is generated in this sector.
While product markets have held center stage in the creation of the single European market, services continue to be fragmented by national regulatory, anti-competitive practices.
Much of the explanation lies in the very heterogeneity of services and the greater difficulties that mutual recognition, or the “country-of-origin principle” – essential in the integration of product markets – implies for services.
Unfortunately, reform was derailed in 2005.
During the referendum campaign in France preceding the vote on the draft EU Constitutional Treaty, the proposed directive was vilified as undermining the rights of labor, symbolized by that dreaded bogeyman, the “Polish plumber.”
These attacks overlooked the fact that the directive makes employment conditions of workers from other EU-member states subject in most respects to host-country rules.
A revised version of the directive that reduces its sectoral scope and makes a number of compromises with the country-of-origin principle is now before the European Parliament.
Even this limited version would constitute progress; most of the gains arise from removing the red tape that complicates cross-border establishment of small and medium-size service enterprises and limits competition in broad sectors of the economy.
It is a sad reflection on the state of the EU that it seems unable to agree on the one clear productivity-advancing piece of legislation when improving productivity is held out as a shared goal.
The failure to mobilize consumer interests in favor of European integration is particularly disappointing for the new member states, which had expected to reap some of the benefits.
An Agenda for the Group of 7
An Alliance of Civilizations?
MADRID – The first International Forum of the Alliance of Civilizations, conceived as an antidote to the idea that the world is doomed to a “clash of civilizations,” recently met in Madrid and revealed that there is more than a grain of truth in Robert Kagan’s idea that Americans are from Mars and Europeans from Venus.
Ever since September 11, 2001, the United States has been engaged in a crusade against the forces of evil in the Muslim world.
By contrast, the March 11, 2004, terrorist attack on Spain, which left 200 dead, triggered an “anti-crusade” that seeks to disarm extremism by building bridges of understanding and reconciliation with Islam.
Co-sponsored by Spain and Turkey, the Alliance of Civilizations initiative is not devoid of political calculation.
To the Spaniards, it helps to justify their abrupt withdrawal from Iraq in 2004; for the Turks, it is yet another vehicle in their struggle, as the vital bridge between Islam and the West, for admission into the European Union.
A loose and somewhat confused project, the Alliance of Civilizations aims to heal the wounds of conflict between Islam and the West through education, viable integration policies, and a better-informed dialogue with the media.
But it suffers from the major global players’ profound skepticism, with the US, Russia, and, for that matter, the EU shown no real enthusiasm for it.
However vague, the alliance of civilizations idea certainly cannot do more harm than war against Islamic extremism.
After all, none of the Muslim world’s problems and conflicts with the West are susceptible to a military solution.
Moreover, the Alliance is not an entirely incoherent proposal if the objective is that the West disengage from the politics of hubris and establish a genuine sphere of cooperation with the Muslim world in economics, culture, and science.
Of course, the idea is held back by the inner workings of both parts of the proposed alliance.
Many in the West question whether Islam is compatible with human rights and Western concepts of liberty.
Many Muslims who have been fighting for years for  their countries’ modernization have so far failed to find a lucid response to the progressive wave of radical Islam.
To claim that Islam is incompatible with human rights is to consider it a civilization too hidebound to change.
This is a historic fallacy.
Nor is the claim that Islam is intrinsically inimical to innovation viable, because Muslim civilization has contributed mightily to science and art throughout history.
Today, Western universities are replete with distinguished Arab scholars in almost every field – the result of a brain drain that itself reflects the Islamic world’s centuries of decline.
In 2005, the 17 countries of the Arab world together produced 13,444 scientific publications, fewer than the 15,455 achieved by Harvard University alone.
Enemies of reason, however, are also to be found in the West.
We live in an age in which many people are disillusioned with secular politics, and are turning to religion instead, not only throughout the Muslim world, but in the core of Western civilization, Christian Europe and Evangelist America.
Nor is the Jewish state of Israel, where Messianic fanatics and religious nationalists have embraced a political theology that questions the very legitimacy of the democratic institutions, immune from this phenomenon.
The current crisis of Islam might not be congenital, but Islam’s predicament is acute.
The question is this: are Muslims ready to accept that Khomeini’s dictum that “Islam is politics or it is nothing” is wrong, that Islam is a religion and not a form of government, and that, as in the Christian world, there is a sphere for Caesar and a sphere for God?
Those in the Muslim world who want to embrace reform must be driven by the conviction that theocracy has never served as a vehicle for human progress.
Of course, the Alliance of Civilizations should not attempt to bridge differences by defending moral relativism.
If it is driven by a Western guilt complex that assumes that the solution simply lies in greater empathy for the Muslim predicament, then the skeptics are bound to be vindicated.
For the Alliance of Civilizations to have any chance of success, the emphasis must be on reciprocity.
Tolerance and religious freedom must be mutual.
Islam’s part in the deal must include a guarantee of human rights and civil liberties, improvement in women’s status, and realistic policies to stem the Islamic world’s demographic explosion.
Some, as usual, will claim that the Arab-Israeli conflict lies at the root of the problems that exist between Islam and the West, and that resolving the Palestinians’ plight will contribute immensely to smoother relations.
But Arabs and Muslims must stop deluding themselves that the Israel-Palestine dispute is what is holding them back.
Ending the American occupation in Iraq and imposing an Arab-Israeli peace would help, but they are no panacea.
The fight to eradicate misery, illiteracy, and corruption, and Islam’s embrace of science, do not depend on the results of the Middle East peace process.
An Alliance of Equals
PARIS – During NATO’s recent 60th anniversary ceremony in Strasbourg, the Alliance welcomed two new members, Albania and Croatia, bringing its total membership to 28.
This expansion is a good thing, for history has tormented these two countries.
Being welcomed within the great international family of the West will reassure them, stabilize them, and contribute to their political, cultural, and economic development.
But the good news was limited, because NATO addressed only a routine agenda.
No core problem was really tackled.
The controversy that arose in France over the country’s return to NATO’s unified military command makes this abundantly clear.
Was France losing its autonomy, perhaps even its sovereignty?
Was it capitulating to American hegemony?
These are real questions, yet at the NATO summit people spoke of them more in terms of symbols than as realities.
But what is the reality here?
NATO is a military alliance composed of 28 countries.
One of them, the United States, has a military budget that is more than three times that of all the other members combined.
Hence, the US runs most NATO civilian and military commands with the consent of the others.
Of course, there is a collective consultation and deliberative process that enables any member to be heard.
But in reality a member’s actual power is what affects common decisions.
This structure harks back to the conditions of NATO’s birth, when it was forged to thwart the Soviet threat to Western civilization.
At the time, no one ever doubted that American power – already endowed with nuclear weapons – was the only counterpart.
For this reason, the US came to preside over the alliance.
During the 41 years of the Cold War, 14 of NATO’s 16 members strictly obeyed and complied with American decisions and policies.
French President Charles de Gaulle was the only one to question whether an American president would actually ever be ready to launch a nuclear attack on the USSR in order to protect one or several Alliance members if vital US interests were not directly at stake.
Based on that doubt, France – a nuclear power since 1960 – withdrew in 1966 from the Alliance’s permanent centralized military command in order to assert its own deterrent capability.
This decision was mainly grounded on the American doctrine, adopted in 1962, of “flexible response,” which said to the Soviets: “As long as you do not use nuclear weapons, we will not use them, either.” This very doctrine left Europe exposed.
Indeed, while it is a much disputed question, de Gaulle was probably right about America’s lack of commitment to the nuclear defense of Europe.
Both Henry Kissinger and Robert McNamara left office admitting that de Gaulle had been correct.
Nevertheless, de Gaulle’s insights left a legacy that still causes some mistrust and dissent within NATO.
France was right on this key strategic point, but it was never able to explain its position to its allies.
This inability to discuss, clearly and forthrightly, this strategic doctrine continues to hamper the Alliance.
At the Strasbourg summit, confidence in the future could have been strengthened if a couple of troubling issues had been discussed.
Instead, once again, there was an extended focus on the past.
The key questions are whether NATO’s doctrine of common defense is currently directed at one country in particular, and whether nuclear force remains the Alliance’s major defensive tool.
In the current global situation, no predictable conflict will require the use of a nuclear weapon.
At the moment, there is no global threat and the Alliance only intervenes in regional conflicts, so why not have NATO admit this?
But the most important matter that went unmentioned in Strasbourg is the relationship with Russia.
NATO was founded to confront the threat that the USSR represented 60 years ago.
But the Warsaw Pact, the Soviet Union’s “anti-NATO” alliance of socialist countries, was dissolved in 1991; communism imploded the same year, with Russia caught ever since in a struggle to build a market economy and define a new global position for itself.
At a time when Russia was taking a more pacific course, NATO – unlike the Warsaw Pact – was not dismantled.
On the contrary, the Allies chose to maintain the pact and to extend it to numerous Russian neighbors.
NATO’s members essentially said: “We Western nations do not trust you.
Even if you become a democracy, we will always be suspicious.”
George Kennan, one of the greatest American diplomats of the post-war years, once wrote that the Western world was committing its biggest mistake in 50 years time by expanding NATO after Soviet communism collapsed.
The resulting humiliation and blatant mistrust that Russia’s elite has felt ever since has led them to their current policy of rearmament.
The only way to resolve this problem is for NATO to assert its pacific intentions before the world.
The most convincing way to do that is to moderate America’s excessive taste for power, which it demonstrated in Iraq.
NATO needs to shift its focus from organizing and administering a unified military command to building real confidence that every member’s voice will be heard.
To that end, all members must stand on an equal footing.
France’s decision to return to full and equal Alliance membership was a good one, and France must now work from within to advance the principles in which it believes.
Avoiding a New American Recession
CAMBRIDGE – The United States may be headed for a recession in 2013.
Even if the country avoids going over the “fiscal cliff,” a poorly designed political compromise that cuts the deficit too quickly could push an already weak economy into recession.
But a gradual phase-in of an overall cap on tax deductions and exclusions (so-called tax expenditures), combined with reform of entitlement spending, could achieve the long-run fiscal consolidation that America needs without risking a new recession.
The US economy has been limping along with a growth rate of less than 2% during the past year, with similarly dim prospects in 2013, even without the shock of the fiscal cliff.&#160; That is much too weak a pace of expansion to tolerate the fiscal cliff’s increase in tax rates and spending cuts, which would reduce demand by a total of $600 billion – about 4% of GDP – next year, and by larger sums in subsequent years.
President Barack Obama’s proposed alternative to the fiscal cliff would substantially increase tax rates and limit tax deductions for the top 2% of earners, who now pay more than 45% of total federal personal-income taxes.
His budget would also increase taxes on corporations, and would end the current payroll-tax “holiday,” imposing an additional 2% tax on all wage earners.
Together, these changes could lower total demand by nearly 2% of GDP.
And the higher marginal tax rates would reduce incentives to work and to invest, further impeding economic activity.
All of that could be fateful for an economy that is still struggling to sustain a growth rate of less than 2%.
The Congressional Budget Office and the Federal Reserve predict that going over the fiscal cliff would cause a recession in 2013, with Fed Chairman Ben Bernanke recently saying that the Fed would be unable to offset the adverse effect on the economy.
He could have said the same thing about the fiscal drag that would be created by Obama’s budget proposal.
Although Congressional Republicans rightly object to raising tax rates, they appear willing to raise revenue through tax reform if that is part of a deal that also includes reductions in the long-run cost of the major entitlement programs, Medicare and Social Security.
Although some Republicans would like to see revenue increased only by stimulating faster economic growth, that cannot be achieved without the reductions in marginal tax rates and improvements in corporate taxation that the Democrats are unlikely to accept.
Raising revenue through tax reform will have to mean reducing the special deductions and exclusions that now lower tax receipts.
The potential recession risk of a budget deal can be avoided by phasing in the base-broadening that is used to raise revenue.
A desirable way to broaden the tax base would be to put an overall cap on the amount of tax reduction that each taxpayer can achieve through deductions and exclusions.
Such an overall cap would allow each taxpayer to retain all of his existing deductions and exclusions but would limit the amount by which he could reduce his tax liability in this way.
An overall cap would also cause many individuals who now itemize deductions to shift to the standard deduction – implying significant simplification in record-keeping and thus an improvement in incentives.
A cap on the tax reductions derived from tax expenditures that is equal to 2% of each individual’s adjusted gross income would raise more than $200 billion in 2013 if applied to all of the current deductions and to the exclusions for municipal-bond interest and employer-paid health insurance.
Even if the full deduction for charitable gifts is preserved and only high-value health insurance is regarded as a tax expenditure, the extra revenue in 2013 would be about $150 billion.
Over a decade, that implies nearly $2 trillion in additional revenue without any increase in tax rates from today’s levels.
Extra revenue of $150 billion in 2013 would be 1% of GDP, and could be too much for the economy to swallow, particularly if combined with reductions in government spending and a rise in the payroll tax.
But the same basic framework could be used by starting with a higher cap and gradually reducing it over several years.
A 5% cap on the tax-expenditure benefits would raise only $75 billion in 2013, about 0.5% of GDP; but the cap could be reduced from 5% to 2% over the next few years, raising substantially more revenue when the economy is stronger.
Slowing the growth of government spending for Medicare and Social Security is necessary to prevent a long-term explosion of the national debt or dramatic increases in personal tax rates.
Those changes should also be phased in gradually to protect beneficiaries and avoid an economic downturn.
America’s national debt has more than doubled in the past five years, and is set to rise to more than 100% of GDP over the next decade unless changes in spending and taxes are implemented.
A well-designed combination of caps to limit tax expenditures and a gradual slowing of growth in outlays for entitlement programs could reverse the rise in the debt and strengthen the US economy.
America’s current budget negotiations should focus on achieving a credible long-term decline in the national debt, while protecting economic expansion in the near term.
An Alternative to Deposit Insurance
Argentina's financial panic and the run on its banks that ensued, as well as Asia's financial crisis of 1997, have forced a number of countries to consider adopting deposit insurance schemes to protect their citizens' savings.
But is deposit insurance the best defense against bank panics?
Deposit insurance was a response to banking crises of the type that plagued the United States until the 1930's.
The first explicit scheme was introduced in America after the Great Depression and initially seemed an unmitigated success.
Panics no longer occurred, which stabilized the financial system and contributed to sustained post-war economic growth.
Deposit insurance did away with financial panics because bank runs are typically driven by a self-fulfilling prophecy. They occur when a bank's clients fear that most of their fellow depositors will withdraw their funds.
Because banks service their depositors on a first-come-first-served basis, those who wait risk being left empty-handed, because the bank may be forced to liquidate its long term-assets at a loss and run out of resources.
So fear of a panic can create a panic.
This is highly inefficient, because while it is individually rational for depositors to want their money immediately, the bank might have been able to service all of them had they been collectively patient.
Economists call such situations "coordination failures," if depositors could talk to each other and coordinate their actions, they would be able to avoid a self-defeating run on the bank.
By guaranteeing that there will be enough resources available for patient clients when they want to withdraw their funds, deposit insurance eliminates the coordination failure.
Patient depositors no longer need to worry about others withdrawing their funds because it has no effect on them.
But deposit insurance leads to other problems, which first appeared with the Savings and Loan crisis in the US during the 1980's.
Deposit insurance creates what economists call "moral hazard," people who are insured against an unpleasant event are not as careful as they would otherwise be in trying to avoid that event.
If my bicycle is insured against theft, I might buy a cheaper lock for it, making it more likely that it will be stolen.
With deposit insurance, clients who no longer risk losing their money have no incentive to monitor their bank, while banks, with no one watching, have incentives to invest in excessively risky projects.
Although many factors contributed to the Savings and Loan crisis, it is generally agreed that moral hazard was a major one.
Following that crisis, deposit insurance in the US was reformed with the objective of mitigating the moral hazard problem.
But did the reforms go far enough?
There are ways to improve the existing system, but is something altogether different and better possible?
As far back as 1873, in his classic book on central banking,
In case of panic, a good policy should help banks that have enough assets to cover their deposits but that can't pay all depositors at the same time because some assets are tied up in real estate or other long-term investments.
These banks are
As with deposit insurance, repurchase agreements solve the coordination failure problem because depositors know that, even if they wait, the bank will be able to accommodate their withdrawals.
In contrast to deposit insurance, however, liquidity provision can avoid moral hazard by helping
Consider a bank that has invested in risky projects and finds itself in trouble.
It can ask the central bank for help and sell some of its assets for cash.
However, under the agreement with the central bank, it must buy its assets back.
If the assets are worthless, it will ultimately be forced out of business.
If it declares bankruptcy and refuses to buy back its assets, bankruptcy laws should give the central bank the first claim on the bank's assets.
This creates a powerful incentive for depositors and investors to monitor their bank's performance.
Implementing liquidity provision policies like those advocated by Bagehot would prevent bank panics without the incentive for undue risk-taking associated with deposit insurance.
Depositors deserve strong, effective protection for their funds--and the banking system requires it in order to maintain confidence.
But neither depositors nor their banks should be given a free ride.
An Arab “Third Way”
AMMAN – Throughout the post-colonial period, Arab countries have consistently failed to produce an efficient – let alone democratic – system of government.
Now, after a half-century of competition between military or royal dictatorships and militant Islamist regimes, many Arabs are again seeking a “third way” – a path toward a credible form of representative democracy.
But will their efforts prove as futile now as they have in the past?
The Middle East – named for its geographic position between Europe and East Asia – was under Ottoman rule for 400 years before the Allied powers, after defeating the Ottomans in World War I, partitioned the region into distinct political units that, under the Sykes-Picot Agreement, fell within spheres of influence carved out by the United Kingdom and France.
But, in response to these new divisions, an Arab awakening – shaped by pan-Arabism and support for Palestine – was occurring.
Charismatic young military rulers-turned-dictators like Egypt’s Gamal Abdel Nasser, Iraq’s Saddam Hussein, Libya’s Muammar el-Qaddafi, Yemen’s Ali Abdullah Saleh, and Syria’s Hafez al-Assad used these popular causes to win public support.
But their failure to deliver better lives to their citizens, together with the discrediting of left-wing ideologies following the Soviet Union’s collapse, fueled the rise of a rival movement: political Islam.
The Muslim Brotherhood – established in the Egyptian town of Ismailia in 1928 and political Islam’s oldest, best organized, and most widespread proponent – was (and is) despised by both secular Arabs and Arab monarchies.
Indeed, secular dictators have worked to suppress the Brothers at every turn – often violently, as when Assad ruthlessly crushed a Brotherhood-led uprising in Hama in 1982.
Forced to operate clandestinely, the Brotherhood built its support base with a social agenda that targeted the needs of the poor, while consistently reinforcing its Islamic ties, even using the compulsory zakat (annual financial contribution to religious causes) to build up its social network.
The Brothers, with the help of a conservative society and the mosques, were prepared to seize power whenever the opportunity arose.
Another Islamist movement, Algeria’s Islamic Salvation Front, almost had such an opportunity in 1991, when it won the first round of a general election.
But the military prevented its victory by canceling the second round, triggering a brutal eight-year civil war in which an estimated 200,000 people died.
Palestine’s Hamas, an offshoot of the Brotherhood, succeeded at the ballot box in 2006, but has since failed to deliver credible governance.
Then the Arab Spring erupted in 2011, creating new opportunities for political renewal.
Within months, Islamist parties shaped by the Brotherhood’s ideology had replaced secular dictators in Tunisia and Egypt, and seemed poised to take over Yemen and Syria, largely because they were the only well-organized political movements on the scene.
Moreover, the Muslim Brotherhood gained control of Egypt, the largest and most influential of the Arab Spring countries.
But their exclusive, rigid ideology was poorly suited to governing such a large and diverse country.
As a result, after only a year in power, the military – backed by the same secular, liberal young people who had opposed it in 2011 – drove President Mohamed Morsi out of power.
Unable to mount a political alternative, however, the protesters’ rejection of the Islamist government served only to put the army back in charge.
Some argue that the absence of a secular liberal option in Arab politics stems from fear of political Islam.
For decades, Western powers backed military regimes in the Arab world, willingly ignoring their systematic repression of democratic movements and rights, in order to ensure that Islamists did not gain power.
Now that both the military- and Islamist-led systems have been discredited, an ideological vacuum has appeared in Arab politics.
But Arabs today – most of whom are under the age of 30 – are less interested in an overarching political ideology than they are in an efficient representative government that implements sound policies aimed at creating jobs and bolstering economic growth.
In short, they want a government that is focused on improving citizens’ lives.
In fact, the absence of a specific ideology was essential to the Arab Spring’s initial success in Egypt and Tunisia, for it allowed a large number of young activists to forge loose alliances.
But mass movements can take a country only so far; establishing a credible representative government requires political parties organized around clearly defined principles.
While the Muslim Brotherhood has such an organizing principle, its internal rigidity – at least with Morsi at its helm – made it unfit to govern.
Meanwhile, infighting among Egypt’s liberals prevented them from establishing a disciplined, reliable alternative to the Brotherhood based on principles like diversity, plurality, respect for women, and freedom of expression.
So when the Islamist government’s credibility collapsed, the military was Egypt’s only remaining option.
In order to make progress, the youth-led movements that drove the Arab Spring must translate their shared principles into effective political structures, and choose leaders who are capable of placing the search for consensus ahead of personal ambition.
If they succeed, the Arab world may finally have an alternative to rule by generals or mullahs.
Even if they fail to gain power, the emergence of such an alternative would surely influence the Arab world’s agenda for years to come.
An Antitrust Counter-Revolution?
BARCELONA – The current global financial crisis has made evident the tremendous pressures to which competition policy is subject on both sides of the Atlantic.
In particular, competition policy has suffered a setback mostly because of the distortional aid measures to financial intermediaries, as well as a suspension of merger rules to save institutions.
Indeed, public provision of capital and other subsidies have made the playing field uneven, with weaker institutions ending up much better capitalized than healthier ones.
This is crucial in a sector like banking, where perceptions about the soundness of an institution are fundamental to its ability to compete.
For example, Lloyds TSB took over the troubled HBOS, Britain’s largest mortgage lender, in a merger opposed by the country’s Office of Fair Trading, whereas it was barred from taking over Abbey National bank in 2001.
In the United States, the investment banking business has been consolidated with the forced takeovers of Bear Stearns by JP Morgan and of Merrill Lynch by Bank of America.
The result is very weak competition among the players left.
Competition policy was attuned to deal with individual crises, but a systemic crisis has almost broken its back.
Not only in banking, but in other sectors as well – with automakers at the forefront – massive subsidies are keeping inefficient incumbents in place, limiting the growth of efficient firms or, perhaps even worse, preventing market entry by new firms.
In the European Union, national governments maneuver in a subsidy race to shift the costs of capacity adjustment in the car industry to neighbors, as the case of Opel shows.
But consolidation to reduce perceived excess capacity in banking and the automotive sector may create long-term anti-competitive market structures.
As long as those structures manage to keep new entrants out, market discipline will be suppressed and the consumer will suffer.
It is precisely the size and power of large financial, automotive, and other firms that have conditioned the scope of regulation and public intervention.
Indeed, the influence of the US investment-banking industry’s lobbying efforts on the relaxation of prudential standards in financial regulation is widely recognized as a factor leading to the current crisis.
And many would argue that the industry has had a substantial impact on the measures to resolve the crisis itself.
The clout of the “big three” automakers in the US is also evident, despite their relatively poor record in terms of efficiency and delivering value to consumers.
Indeed, it is remarkable that, with General Motors seemingly unresponsive to consumer demand, there is now a debate about whether it should be forced to produce more fuel-efficient cars.
If large firms can shape the playing field in their favor through their influence on the political process and regulation – thereby keeping out new entrants in their industries and shifting costs to society – a whole new perspective on competition policy follows.
Or perhaps it is not so new after all.
Antitrust policy started in the US at the end of the nineteenth century with a deep suspicion about large firms, owing to the concentration of power that largeness entails.
This somewhat populist view later gave way to a view of antitrust that focused on efficiency.
What it sought to address was market power in a particular sector, not size
But the current crisis might pose the question of whether the populist view of antitrust – limiting the size of firms because of the excessive influence they may wield – has some merit.
The issue is not only that firms that become systemically vital may blackmail society, but also that very large firms can tilt the playing field to further their interests at society’s expense.
The saying that what is good for GM is good for the US, if it was ever valid, seems hardly tenable today.
It is, however, one thing to recognize the problem, and another to think about measures to address it.
Firms can be made to internalize the costs they impose on society with appropriate regulation (for example, capital requirements with a systemic charge for financial institutions), but it is not so obvious what to do with “excessive” influence that comes with size.
To limit the size of firms to check the concentration of power is a very blunt instrument – one that highlights the failure of other controls in the democratic process aimed at ensuring that strong lobbies do not end up imposing regulation that is not aligned with social welfare.
But if effective checks and balances are not put in place, nineteenth-century antitrust may be back in fashion sooner rather than later.
An Arab Spring?
PARIS – Is Tunisia the first Arab authoritarian domino to fall?
Or is it a unique case that should not be viewed as a precedent for either the Arab world in general or the Maghreb in particular?
The region’s dictators have sought to dismiss the “Jasmine Revolution,” but the spark that started in Tunisia could spread – perhaps in a matter of months or years – to the entire Arab world.
Indeed, the wall of fear has crumbled, the people have spoken, and an “Arab spring” could be at hand.
The message from Tunisia, at least so far, is clear: corrupt and authoritarian regimes, beware: unless you reform deeply and quickly, your days are numbered.
The greatest danger is that the Jasmine Revolution could go the way of Romania’s anti-communist uprising of 20 years ago, with the old regime’s underlings expelling their bosses in order to stay in power.
But the best analogy for Tunisia today is Spain in the years preceding and following the death of Francisco Franco.
By opening itself to the world through tourism, and with its emphasis on education and women’s rights, Ben Ali’s regime created something unique in the Middle East: a vibrant middle class.
But the regime, like Franco’s dictatorship, did not treat the members of this new middle class like adults, thereby encouraging widespread frustration.
Given this, it would seem wrong, if not dangerous, to compare Tunisia and its Jasmine Revolution to other national contexts in the region.
Nevertheless, if Morocco looks stable today, this largely reflects two factors: monarchy and reform.
Led by a group of technocrats surrounding the young King Mohammed VI, a reform process – including political liberalization – has begun in earnest, even if the results still seem modest.
Moreover, Mohammed VI, as “Commander of the Believers,” benefits from a “Muslim” legitimacy that the leaders of Algeria and Egypt, two of the region’s most vulnerable regimes, do not possess.
And Morocco, contrary to Algeria, does not suffer from the curse of oil.
Even if the case of Tunisia is largely unique, it would be shortsighted to dismiss its potential influence elsewhere in the region, where many young Arabs in this age of Facebook and Twitter now “feel Tunisian.”
They, too, are humiliated by their leaders’ performance and, more deeply, their vulgar despotic essence.
They, too, thirst for freedom.
Whatever the Jasmine Revolution’s outcome, and even if it cannot become for the Arab world what the fall of the Berlin Wall was for Europe, it will establish a “before” and an “after.”
The “after” is likely to highlight two potential models of political development for the Arab world: Turkey and Iran.
If the revolutionary wave that began in Tunisia spreads to the rest of the Arab world, how many countries will be tempted by Turkish openness, and how many by Iranian fundamentalism?
Of course, that is a somewhat simplistic dichotomy.
There are grey areas in the Turkish experiment with “moderate Islam,” and, beyond Iran’s Mullahs, there are reasons for hope in the vibrant and resilient character of that country’s civil society.
What is clear is the West’s preference for the Turkish model.
Most Europeans may want to keep Turkey at a reasonable distance, but, confronted with changes and possible disorder, if not chaos, in the Arab world, they look favorably on Turkey’s potential to play a stabilizing role.
To be sure, history never repeats itself, but could some kind of neo-Ottoman order be the best answer to the risk of “Arab chaos”?
Prime Minister Recep Tayyip Erdoğan’s Turkey already plays a growing role in the region, and has strengthened its image with ordinary Arabs by taking a muscular diplomatic position against Israel’s deadly military assault in June 2010 on a Gaza-bound aid flotilla that had been organized by a Turkish charity.
But it is one thing to be popular and another to serve as a model.
Turkey is demonstrating that Islam and modernity are compatible.
But the Turks are the Ottoman Empire’s heirs, and the Arab world, contrary to Western hopes, may not be ready to exchange its current frustration for the humiliating admission that it requires its former rulers’ model to progress toward modernity.
It would be dangerous to assume that after Tunisia, democracy in the Arab world is just around the corner.
But the belief that nothing will change is equally illusory.
For better or worse, history is on the move in the Arab world – and there is very little the West can do about it.
An Asia Strategy for Iran
SINGAPORE − When the ongoing turmoil surrounding the Iranian elections finally ends, the West is likely to walk away with a simple black and white judgment: the bad guys won.
Of course, the West did the right thing by supporting the good guys, the street demonstrators.
Hence, the West need not bear any responsibility for the outcome.
The tragedy of such thinking is that it does not allow for any moral and political complexity or nuance, yet that is exactly what will be needed if the many problems surrounding Iran are to be resolved.
Moreover, with Mahmoud Ahmadinejad remaining as Iran’s president, the West will once again resort to its usual method of dealing with unfriendly regimes: impose more sanctions.
But this would lead to an even greater tragedy.
The only clear lesson to emerge from Iran’s disputed presidential election is that the country has a vibrant and indeed dynamic civil society.
Many brave Iranians were prepared to risk their lives to defend their beliefs.
Their ability to do so confirms that Iran is not a closed totalitarian state like North Korea.
Despite many years of rule by a theocratic establishment (or perhaps because of it), Iranian minds remain open and engaged.
So there is real hope that Iran can change, modernize, and open up as the rest of Asia has.
Indeed, the only viable long-term strategy to adopt, therefore, is to stop trying to isolate Iran and instead nudge Iranians into engaging more with modern Asia.
In the Iranian worldview, there are three great ancient Asian civilizations: Chinese, Indian, and Persian (with Persia being the greatest).
Iranians expect to perform on par with China and India.
So, while Western hectoring of Iran will not work, when Iranians see their society falling far behind China and India as those countries open up to the world, they may become motivated to reconsider their path.
The more Iranians visit China and India, the more likely that Iran will change.
Similarly, the West should find ways to re-engage with Iranian society, a major obstacle to which is the absence of diplomatic relations between the United States and Iran.
American foreign policy assumes that diplomatic relations with Iran are somehow an act of approval.
In fact, the exact opposite is true.
Diplomacy was invented precisely in order to enable relations between adversaries, not friends.
No one needs diplomatic immunity to talk to their friends.
They need it to talk to their adversaries.
Unfortunately, no US politician appears willing to explain this bit of common sense to the American public.
The US might also learn from other examples.
Many Americans applauded Egyptian President Anwar el - Sadat for his political courage in visiting Jerusalem three decades ago – a decision for which he ultimately paid with his life − even though the vast majority of Egyptians strongly disapproved.
It is useful to recall President Richard Nixon’s words when, prior to restoring diplomatic relations China, he visited Beijing: “We have at times in the past been enemies.
We have great differences today.
What brings us together is that we have common interests which transcend those differences.
As we discuss our differences, neither of us will compromise our principles.
But while we cannot close the gulf between us, we can try to bridge it so that we may be able to talk across it.”
In engaging Iran, the West should ignore the nature of its regime.
It is almost impossible for any outsider to understand Iran’s real internal political dynamics.
Just when the world reached a consensus that Ahmadinejad was merely an instrument of the Supreme Leader, Ayatollah Khamenei, Ahmadinejad appointed a Vice-President against Khamenei’s wishes (though he later retracted the appointment).
What we do know with certainty is that the regime is divided.
These divisions will allow new forces to emerge in Iranian society.
So all means should be found to reach out to Iranian society at all levels.
Iranian students should be encouraged to visit and study in Asian universities, where they would discover how confident young Chinese and Indian students are about the future − which might well cause them to reflect on why young Iranians do not share that optimism.
A final reason for the West to change course is that Western sanctions are proving increasingly useless.
Only 12% of the world’s population lives in the West, and power is slipping steadily away from it.
The July 2009 decision by the Non-Aligned Movement (comprising 118 member states) to hold its next meeting in Tehran provides a powerful demonstration of non-Western perceptions about Iran.
If the West persists with its sanctions, it will not do any good. It will only make Western leaders feel good.
But what is ultimately more important: doing good or feeling good?
An Assassination in Belgrade
Not since Archduke Franz Ferdinand's assassination has a murder shaken Belgrade as much as the killing of Serbian Premier Zoran Djindjic.
The bullets that killed Djindjic may also have slain Serbian hopes for normalcy at the very moment that we were emerging from the nightmare of Slobodan Milosevic's long misrule.
With the bloody wars of the Yugoslav succession still etched deeply in everyone's minds, does Djindjic's assassination herald the end of an era of political violence or the dawn of a new one?
Milosevic's ouster two years ago was turbulent, but no one was killed.
Serbs were justly proud: a dictatorship was ended in a democratic, peaceful way.
Milosevic's extradition to face charges of war crimes before the Hague Tribunal--a trial that has proceeded without incident in Serbia--was also peaceful.
With relations in the region and with the West approaching something like normalcy, Serbs were beginning to feel, at long last, that they were finding peace with themselves and the world.
Of course, assassinations are nothing new in Serbia. "Arkan," the leader of the most murderous paramilitary group in the wars in Bosnia and Kosovo, and a political power even after Milosevic's fall, was murdered in Belgrade last year.
Djindjic himself narrowly escaped a highway assassination attempt only last month.
But most Serbs were beginning to believe that the ballot and not the gun was becoming the dominant tool of politics.
Djindjic's effective leadership brought about this change.
Although the most popular politician of the uprising against Milosevic was Vojislav Kostunica, who replaced him as president, it was Djindjic who skillfully coordinated the volatile coalition that opposed the regime.
His boundless energy and quick thinking delivered success from behind the scenes.
As Serbia's prime minister after Milosevic, he resembled a corporate CEO more than the Heidelberg-educated philosophy professor that he was.
Djindjic remained pragmatic, never doctrinaire.
As a result of Serbia's predicament, he accumulated more power than prime ministers typically wield.
Milosevic's regime left behind crippled institutions, with large sections of the police and judiciary and many state-owned companies remaining under the control of Milosevic's clique.
With little trust in existing institutions to implement reforms, Djindjic often took shortcuts, using extra-legal means and improvised parliamentary majorities to push through legislation.
Only prosperity and a "European Serbia" mattered.
Did these short cuts help incite his death?
Who can say?
They certainly did little to build respect for the rule of law.
Yet the immediate consequences of Djindjic's death will be tragic.
He was seen in the West as a reformer, and reform may not proceed without him.
If it does not, urgently needed Western investment won't materialize.
Serbia will again seem a benighted and lawless land.
Although Djindjic was not popular, only extreme nationalists and die-hard Milosevic supporters are cheering.
They regard his murder as just punishment for the "traitor" Djindjic's decision to extradite Milosevic--and other Serbian "heroes"--to The Hague.
The more dangerous outcome is that the assassination may reinforce the belief in Serbia that only authoritarian rule is possible.
Given the prevalence of this belief, Djindjic's death creates a serious power vacuum precisely because his vast personal power was moving Serbia in some of the right directions.
Now, it is feared, organized crime will intimidate his less talented successors.
For now, Serbia's government has imposed a state of emergency.
But effective or quick suppression of the organized criminals who were almost certainly behind Djindjic's murder is unlikely.
The reason for this also explains why Djindjic could not rely on the Serb state to carry out his policies.
Many policemen and intelligence officers are on the crime bosses' payrolls.
The fact that a former president of Serbia, Ivan Stambolic, could disappear without a trace in 1999 is grim testimony to the power of Serbia's criminal underworld.
Indeed, Djindjic may well be a victim of his recent moves to root out organized crime.
He was initially slow in fighting organized crime, because he did not want to alienate the bulk of Milosevic's mafia-infested establishment at once.
He preferred to confront corrupt institutions one at a time as he consolidated his rule.
Sadly, he may also have needed the support of some crime bosses at the outset.
Djindjic's murder will make the fight against crime the country's main political goal.
In this, politicians will at last have something like united public support.
But crime would not be as powerful as it is, and the police and judiciary would not be as corrupt, if Serbia's economy were in better shape.
Serbia is poor and Western aid is desperately needed.
Djindjic's murder shows that the situation is so dire that aid should no longer be strictly conditional on harsh reforms.
For the moment, extreme nationalists and Milosevic supporters may feel triumphant.
But the one certain success of Djindjic's era is that they will never return to power.
Their vision of a chauvinistic, inward-looking Serbia has been discredited, while Djindjic's stance may become more popular due to his martyrdom.
Moments of defeat have always been history's turning points in Serbia.
Once again, Serbs face such a moment.
This time, however, we must resolve to remember Zoran Djindjic's cause--political and economic liberty--more than his blood sacrifice.
An Earthquake in Chinese Politics?
BEIJING – Now that the aftershocks from the great Sichuan earthquake appear to have dissipated, it is time to ask what shocks, if any, the earthquake delivered to China’s political system.
Has the quake given birth to some new, positive political force that will accelerate reform?
It has happened before. After all, dramatic political changes – the fall of the “Gang of Four” and Deng Xiaoping’s consolidation as China’s supreme leader – did follow shortly after the devastating Tangshan earthquake in 1976.
Given the sharp contrast between Premier Wen Jiabao’s caring attitude during the earthquake and President Hu Jintao’s mediocre political performance, some people could not help but imagine that the earthquake may have tipped the balance at the Communist Party’s highest levels, pushing the liberal forces represented by Wen to the center of power.
But this is naive.
Unlike 30 years ago, no strong force for political reform now exists in China’s vast bureaucratic system.
Back then, Mao’s Cultural Revolution had forced large numbers of his revolutionary comrades onto a reformist path.
In today’s China, the overwhelming majority of bureaucrats like the status quo and have enough resources to protect themselves.
Although Wen has won popular support through his tireless efforts for earthquake victims, he remains isolated in official circles.
And, although Hu can barely hide his mediocrity, the bureaucrats are unconcerned. After all, they don’t want someone controlling them who is both able and serious.
But the Sichuan earthquake was not completely irrelevant to China’s political progress.
Wen, who had been bogged down by the bureaucracy, had been seeking to counter it by expanding the media’s openness and transparency.
He had sought to take advantage of the Beijing Olympics to give the foreign media unprecedented freedom, but the bureaucrats succeeded in reversing his decision.
The earthquake gave Wen an unexpected second opportunity.
He used television and his outstanding performance to prove that modern media and information tools can curb China’s bureaucracy.
This precedent will not be easy to roll back, and will have a far-reaching positive influence on China’s political progress.
The earthquake, together with the media transparency that accompanied it, has made the bureaucrats more accountable.
Thousands of people, including nearly 10,000 school children, whose parents will not be easily placated, lost their lives.
Millions of dispossessed people must be re-housed in a process that will last for several years.
Bureaucrats must not be allowed to spend the huge donations collected and state relief funds allotted in an arbitrary manner.
As a result, a new political culture conducive to accountability may have a realistic opportunity to grow.
But this does not mean that someone will emerge from the Party with the courage and ability to assume bold political leadership.
In fact, I believe that China’s future leaders, are more likely to come from China’s burgeoning, but still limited, civil society than from the bureaucracy.
One source of China’s future political leadership could well be its growing NGO sector.
Although the Party uses various means to suppress their development, the Sichuan earthquake demonstrated that it has failed to eliminate NGOs as a social force.
The quake gave them an opportunity to be seen, and an unprecedented number of people had a chance to perceive this nascent civil society as a positive force that serves their own interests.
There is an even greater silent force which may produce a new generation of political leaders: the rapidly growing army of Christian believers, now estimated at 20 million.
With a population of 1.3 billion, China has no lack of people with leadership potential, and I believe that more and more of this talent is situated outside the Party bureaucracy in NGOs, startup enterprises, philanthropy, and even missionary work.
In today’s mostly closed environment, they mostly lack awareness of their political skills and vision.
A more open and transparent public environment will help awaken their sense of political mission.
Yet we are left to ask: when will the time for major political change come?
Wen Jiabao wrote recently in Sichuan that “more hardship will arouse the country,” evidently believing that the Chinese may still need to suffer further in order to realize political progress.
That may be true, but I also believe that a new generation of political leaders can grow up in a more open information environment.
And, in any coming showdown, we must hope that all leaders will refuse to use innocent people’s lives as bargaining chips.
An Economic Agenda for Italy
MILAN – At the end of this month, Italian voters will choose their next government, from which they expect jobs and a more level economic playing field – and from which Italy’s European partners expect structural reforms and fiscal probity.
What should the new government’s economic-policy agenda be?
To reduce public debt, which stands above 120% of GDP, while minimizing painful adjustments, Italy needs economic growth – something that has eluded policymakers in recent years.
Indeed, Italy’s average annual GDP growth rate since joining Europe’s economic and monetary union in 1999 has been an anemic 0.5%, well below the eurozone average of nearly 1.5%.
In the four years since the global financial crisis struck, the growth rate fell to -1.2%, compared to the eurozone average of -0.2%, and it is expected to remain negative this year.
The new government’s biggest challenge will be to implement reforms that enable Italy’s economic performance to catch up to that of its neighbors after years of bad policies and neglect.
This requires increased investment in innovation and human capital.
From 1992 to 2011, labor productivity grew at an average annual rate of 0.9%, the lowest in the OECD.
Since 2001, unit labor costs have been growing faster than real GDP and employment, undermining the economy’s competitiveness vis-à-vis developing countries.
In the last decade, Italy’s share of global exports dropped from 3.9% to 2.9%.
Persistently weak labor-productivity growth has created a situation in which unit labor costs do not fall, even if real wages remain stagnant or decline.
Indeed, despite a 1.3% drop in real wages in 2011, unit labor costs remained unchanged.
Italy’s new leaders must address this situation by decoupling labor’s contribution to productivity growth from that of capital and total factor productivity.
According to the OECD, lower regulatory costs and more efficient public administration (building upon measures introduced by the previous government, led by Mario Monti) could add 0.3-0.4% to average annual GDP growth by 2020.
Likewise, labor-market reform, improved education, and enhanced human capital could contribute an additional 4% to GDP growth in the next decade.
Moreover, Italian policymakers should strive to boost the female labor-force participation rate, which, at 49%, is one of the lowest in the OECD.
Doing so would raise per capita income by 1% annually through 2030.
At the same time, fiscal adjustment remains essential to Italy’s short- and long-term stability.
According to the International Monetary Fund, the budget deficit is declining, and the primary surplus (net revenues minus interest payments) is growing.
Italy’s new leadership must sustain this progress.
Despite positive developments, the road ahead is bumpy.
Navigating it will require Italy to retain its credibility with other European Union member states and international investors.
The new prime minister will need to persuade Germany, financial markets, and the European Council that Italy is a reliable partner.
The ability to refinance government debt and keep costs down is essential to strengthening public finances and boosting GDP growth.
Furthermore, attracting more direct investment is crucial, given that capital inflows, while recovering, remain 30% below their pre-crisis level; with outflows exceeding inflows, Italy has become a net capital exporter.
“Selling” Italy in Europe should entail more than photo opportunities with other leaders in Brussels and the occasional road show to financial institutions in London.
Italy’s leaders should engage actively in commercial diplomacy, using the country’s embassies and trade agencies to promote Italy globally, while working to build strong bilateral relations with other EU members, particularly southern countries like Spain.
At the same time, the new leaders need to “sell” Europe in Italy, where Euro-skepticism is rampant.
According to the Pew Research Global Attitudes Project, only 30% of Italians view the euro positively.
In the country’s wealthier north, where average per capita income, at €30,000 ($40,500), approaches that of Germany, people are questioning the rationale of EU membership.
The costs are evident, they argue, but what are the benefits?
Meanwhile, fears of structural decline pervade the country.
The crisis has lasted for a long time, and people are tired.
Unemployment has risen to a record 11.2%, with 35% of young people jobless.
And the tax burden, which has exceeded 40% of GDP since 1990, now stands at almost 43% of GDP.
A Scandinavian level of taxes would be bearable if public services did not remain inferior to those offered in Scandinavia.
For example, per capita health-care spending in Sweden, Denmark, and Finland exceeds $3,000, compared to only $2,300 in Italy, where households must contribute roughly 20% of total health-care spending.
Moreover, Italy spends around 4.5% of GDP on education, while the Scandinavian countries spend more than 6% of GDP.
As a result, Italian students’ scores in the Program for International Student Assessment are significantly lower than those of their counterparts in many other OECD countries.
Italy’s new government will have to display leadership and vision to guide the economy toward stable growth, avert a race to the bottom, and stem growing social tension.
Most important, economic renewal depends on the next government’s willingness and ability to address the institutional weaknesses that have made concerted action increasingly urgent.
An Egyptian Sakharov
Saad Eddin Ibrahim is Egypt's most prominent social scientist--and the most independent-minded in a conformist society ruled by President Hosni Mubarak's authoritarian regime.
For years, Prof. Ibrahim headed the Cairo-based Ibn-Khaldun Institute, which undertook, with the European Union's encouragement, pioneering studies on women and minority rights, as well as electoral practices, in Egypt.
In a country where the President has been consistently re-elected with 97% of the vote since 1980, Ibrahim's institute is the only academic research organization that dares to ask troubling questions about the way Egypt is run.
Two years ago, Prof. Ibrahim, together with practically all of the Ibn-Khaldun Institute staff, were arrested and put on trial before a State Security Court on trumped up charges.
The allegations included financial irregularities, receiving EU funds without the proper ministerial authorization, and "tarnishing Egypt's image."
Prof. Ibrahim was sentenced to seven years imprisonment.
After diplomatic pressure was applied by the United States (through his American-born wife, Prof. Ibrahim holds US citizenship) and the EU, he was granted a re-trial.
This ended days ago with the old verdict reaffirmed: seven years in prison.
Twenty-seven of the Institute's staff members also received jail sentences, and the Institute is now practically destroyed.
Any dictator, from Saddam Hussein to Robert Mugabe, could take pride in this abuse of power.
But because Mubarak regime's is considered moderate, pro-Western, and helpful in the context of Israeli-Palestinian relations, the West's response to this and other abuses remains muted.
Indeed, the US Charge d'Affaires in Cairo expressed mere "disappointment" at the verdict--a response that gives understatement a bad name.
Since the terrorist attacks on New York and Washington last year, America and the EU recognize (or say that they do) that the lack of legitimate channels of opposition in Arab countries pushes people who might otherwise be mere critics of governments into the arms of extreme Islamic fundamentalists.
Saad Eddin Ibrahim is a liberal: he is also a staunch Egyptian and Arab nationalist.
He has vehemently condemned Israeli policies vis-à-vis the Palestinians, and is a critic of many aspects of US foreign policy.
But his has always been the voice of a
Indeed, his is the type of voice that Egyptian civil society needs if there is ever to be a chance that the country's Pharaonic authoritarian regime--symbolized by President Mubarak's high-handedness--is to be reformed.
Just because Mubarak's government persecutes Islamic terrorists, and is an ally in the war against fundamentalist extremism, is no reason to give him
Western intellectuals, who were instrumental in pressuring the Soviet Union in support of Andrei Sakharov, have been singularly quiet when it comes to Ibrahim.
An Arab intellectual persecuted by an Arab regime, it seems, is nowhere near the top of their agenda.
But it is the EU that is proving most complicit.
After all, it was the EU's effort to stimulate Egyptian civil society with its grant of funds to the Ibn-Khaldun Institute that incited Ibrahim's persecution.
The EU's silence in the face of his arrest and imprisonment is shameful.
For not just Ibrahim, but the values that the EU professes to uphold, have been on trial in Egypt, and they have been mocked by the Mubarak's regime idea of justice.
Europe must work--promptly--to overturn Ibrahim's conviction.
The EU should consider blocking all its educational and cultural programs in Egypt if the verdict on Ibrahim and his associates is not overturned and the Ibn Khaldun Institute not re-opened and restored to full vigor.
Just as the fight for Andrei Sakharov was also a fight for an open society in Russia and thus helped dismantle Communist tyranny, so the fight for Ibrahim's freedom is a fight to put an end to Egypt's oppressive authoritarian regime.
An Energy Tax for Europe
George W. Bush’s disastrous war in Iraq has put Europe in a bind.
The United States long has been Europe’s protector.
Now, because of a war it wanted no part of, Europe finds its security undermined.
Chaos in Iraq has empowered Iran – a much more dangerous country for Europe than Iraq ever was.
And, with America bogged down in Iraq, Russian President Vladimir Putin has resurrected Soviet-style bullying tactics.
Would Russia otherwise have dared to threaten to re-direct its nuclear missiles at European cities?
Not only has Bush destroyed Iran’s most formidable enemy and bogged down US troops in a hopeless cause; he also has enriched energy-abundant Iran and Russia by pursuing a war that has dramatically raised energy prices.
High crude oil prices make it easier for Iran to build nuclear weapons and for Russia to use energy blackmail to threaten Europe.
But Europe can fight back.
By imposing a stiff tax on energy consumption, Europeans would reduce both consumption of energy and its price in world markets, in turn cutting the flow of funds to Russia and Iran.
Because crude oil is priced in US dollars, and the dollar has depreciated against the euro, European consumers have gotten off relatively easy from rising energy prices.
So an energy tax roughly equal to the euro’s 33% appreciation in recent years would be about right.
Europeans might be forgiven for thinking that the Americans, who pumped up oil prices in the first place with their military misadventure in Iraq, should be the ones who “pump it down” with an energy tax.
But, with a “Texas oil man” in the White House, it won’t happen.
Perhaps after 2008, the politics in America will change in favor of an energy tax, but such a tax is needed now.
Besides, given the strength of environmentalism in Europe, the issue is tailor-made for Europeans to take the lead.
Moreover, Europeans do not narrowly equate national security with military spending.
They know that confiscating the checkbooks of Russia and Iran would probably make the world a lot safer than building another submarine or aircraft carrier.
Indeed, an energy tax would not only effectively counter the argument that Europeans are “free riders” when it comes to defense; it would be tantamount to defense leadership.
Still, with the amount of real resources transferred to their governments already high, Europeans might balk at a further increase.
That is why the energy tax must be imposed as a tax substitution, with income or payroll taxes simultaneously reduced to keep real resource transfers to government at a constant level.
This would increase economic growth as well as strengthen national security.
Critics who worry about the cost of the energy tax have not thought about tax substitutions.
They also do not seem to realize that an energy tax is a much cheaper way for Europe to protect itself from Iran and Russia than alternative means, such as a defense buildup.
Europe currently lacks military muscle because it made a decision a half-century ago to be protected by the US and devote the saved resources to building up its welfare state.
This strategy – which worked well for decades – always carried the risk that at some point America’s resources might be tied up elsewhere, leaving Europe under-protected.
That risk materialized with the Iraq war.
But Europeans are showing little taste for increased defense spending, Iraq or no Iraq.
Even France’s new president, Nicolas Sarkozy – thought by many to be a pro-American foreign policy hawk – is backing away from his campaign promise to maintain defense spending at 2% of GDP.
In a recent speech to the French defense industry, Sarkozy conspicuously failed to repeat the pledge, instead warning that he soon might cut France’s defense budget.
According to a respected defense industry publication, Sarkozy changed his mind after his party’s smaller-than-anticipated victory in June’s parliamentary election.
The reason Europeans are reluctant to increase defense spending is expense.
Cutting welfare spending – where the big money is – would be painful.
Solemn promises made over the years would have to be broken (people would not get the social services that they paid for with a lifetime of high taxes), lives would be shortened (less money for hospitals and nursing homes), and overall hardship increased.
Even economic growth will not prevent a tradeoff between defense and welfare spending for Europeans.
Fifty years of defense dependence on the US has created a powerful “peace industry” in Europe whose primary business is to fight defense spending tooth and nail.
They will want to protect all social spending, regardless of the consequences for foreign policy.
A counterweight to the “peace crowd” may be new migrants from Eastern Europe, for whom cuts in social services would break no promises, and for whom job availability and wage levels are more important.
But it will take some time before the new migrants gain decisive political influence, and the problems of Iran and Russia for Europe require immediate attention.
In short, Europeans will not allow Bush’s Iraq war to become a war on their welfare state.
What makes the energy imposed as a tax substitution tax particularly attractive as a defense measure is that it leaves the welfare state intact while making Europe safer, greener, and richer.
Why wait?
An Epidemic of Politics
Americans, like citizens in countries throughout the world, have come to accept that politics plays an important role in the appointment of certain kinds of public officials.
Few of us are surprised (though some may be disappointed) when a federal judgeship is awarded or a senior diplomat appointed because the candidate passes a litmus test of loyalty to some principle that is important to the President's or Prime Minister's party.
But science, almost everyone agrees, is different, and here the United States is beginning to stand as a cautionary example to the rest of the world.
Scientific appointments should rest on objective criteria of training, ability, and performance.
Clearly, it is legitimate to interrogate a future Secretary of Health and Human Services (HHS) about his views on abortion.
But it is entirely out of place when appointees to scientific advisory committees are subjected to tests of political loyalty.
Similarly, membership of bodies that conduct peer review of scientific proposals - a process that is fundamental to scientific progress - surely ought to be free of all barriers to entry that are unrelated to professional qualifications.
Unfortunately, scientists in the US are running up against such barriers more and more often.
During the past fall, the journal Science published several news stories related to the issue.
One involved the wholesale replacement of members of the advisory committee to the National Center for Environmental Health, a part of the Centers for Disease Control and Prevention (CDC), without consulting the center's director.
Similar cases involved the CDC's Advisory Committee on Lead Poisoning and Prevention, the Advisory Committee on National Human Research Protections, and the Advisory Committee on Genetic Testing.
The current epidemic of ideology, in which advisory committees are shut down and reassembled with new members, and candidates are subjected to loyalty tests, seems old hat to some observers.
Officials at the HHS call it "fairly standard practice."
Well, it isn't standard practice in America - or at least it wasn't.
In any case, what's really worrisome is not that the Bush administration examines candidates for compatibility with its "values."
The most alarming development is how deep the ideological vetting now cuts, invading areas that once were immune to this kind of manipulation.
Indeed, perhaps the most telling case in the widening political epidemic was a membership re-shuffle of the study section at the National Institute of Occupational Safety and Health that evaluates grants for studying workplace injuries.
Advisory committees might have been vulnerable to occasional stacking of this kind in the past.
After all, they recommend the policies that politicians may or may not want to consider.
But study sections?
In October 2002,
Their piece was a story in itself, but what followed was even more interesting.
It set off a volley of letters in which scientists told of similar experiences.
A nominee for the National Institutes of Health's Muscular Dystrophy Research Coordinating Committee told of being vetted by a White House staff member.
After being asked about her views on various Bush administration policies, none of them related to the work of the committee, she was asked whether she supports the president's policy on embryonic stem cells.
Another letter writer, a distinguished professor of psychiatry and psychology, reported receiving a call from the White House about his nomination to serve on the National Council on Drug Abuse.
The caller declared that he must vet him to "determine whether he held any views that might be embarrassing to the president."
According to the professor, a series of questions followed, with the White House official keeping a running score.
One example: "You're two for three; the president opposes needle exchange [for intravenous drug users] on moral grounds, regardless of the outcome."
Then the exchange took an even more chilling turn.
The official asked the nominee whether he had voted for Bush, and, on being informed that he had not, asked: "Why didn't you support the president?"
This is the stuff of dictatorship, not democracy.
The purpose of scientific advisory committees is to provide balanced, thoughtful advice to the policy process.
Nothing is gained - and much is lost - when a desired policy outcome is put first.
This is why deciding which research projects to support has always been a matter for objective peer review, not politicians. In fact, the applicable statute for all this - the Federal Advisory Committee Act - specifically

US Health and Human Services Secretary Tommy Thompson and the White House Personnel Office ought to set an example to the rest of the world.
They can do so very easily: by following the law.
An External Stability Pact for Europe
BERLIN – The current economic crisis has exposed two fundamental problems in the design of the European Monetary Union.
The first concerns the sustainability of public finances in a number of euro-zone member states.
Second, inadequate macroeconomic policy coordination has resulted in divergences in the international competitiveness of euro-zone members, threatening the very existence of the euro.
Countries whose public finances seemed fundamentally sound as late as last year have come under severe fiscal pressure.
Ireland’s government debt is expected to rise to almost 80% of GDP by 2010, whereas just a year ago the European Commission projected that Ireland’s government debt would be below 30% of GDP.
Likewise, whereas Spain was expected to decrease its debt ratio, its debt-to-GDP ratio is now likely to double between 2007 and 2010, to more than 60%.
The EU’s fiscal surveillance mechanisms failed to predict these developments because they neglect a crucial variable: the dynamics of private-sector debt.
Given the high economic costs of a banking crisis, governments are likely to take on the liabilities of their financial sector when a crisis hits – as recently occurred in the United Kingdom and Ireland, and in financial crises in Latin America and Asia in the 1990’s.
The same is probably true when key business sectors near insolvency.
A country with sound public finances can thus become a fiscal basket case practically overnight.
Given the increasingly close financial and economic linkages between euro-zone members, rising government debt in even one EMU country can have serious consequences for all members, because no member state will allow another to default.
Thus, EMU members indirectly share the liability for fellow countries’ private-sector debt, which for this reason should be monitored within the EMU’s surveillance framework.
Another apparent problem is that EMU member states – at least until now – do not coordinate their economic policies effectively.
Even before the crisis, this resulted in divergences in competitiveness and in the business cycle.
The persistent loss in competitiveness over the past decade is one reason why the crisis is hitting some southern European EMU countries such as Spain and Italy so hard.
The inefficiency of fiscal-policy control and the lack of economic convergence are a matter of increasing concern to both the European Central Bank and euro-zone finance ministers.
While no initiative for coping with these problems has been tabled so far, the issue is certain to become a matter of debate within the EMU.
One way to tackle the problems associated with government debt, as well as to improve economic policy coordination, is through a simple extension of existing rules: an “External Stability Pact” could be introduced to complement current EMU regulations.
This pact would monitor current-account imbalances and penalize excessive deficits or surpluses in the external account.
Monitoring external balances can be an effective tool to measure future default risks, since sustained current-account deficits lead to a growth in net foreign debt.
Moreover, there is a direct relationship between the EMU countries’ private-sector debt dynamics and their current-account imbalances within the euro zone.
So long as a national government is not running more than a modest deficit, a current-account deficit reflects the private sector’s borrowing from abroad (or the sale of previously accumulated foreign assets).
If the current-account balance is assessed together with the fiscal position, it becomes possible to draw conclusions about risky debt trends within the private sector.
The mathematics of debt dynamics suggest that no euro-zone country should have a current-account imbalance, whether a deficit or a surplus, of more than 3% of GDP.
Exceptions could be granted for countries with large inflows of foreign direct investment in greenfield projects.
The rule should apply both to debtor and creditor countries.
After all, payment imbalances always have two sides, and the burden of adjustment should not be borne only by deficit countries.
Such a pact would oblige governments to use fiscal and wage policies as well as overall economic policy to achieve external balance.
It would also lead to broader economic-policy coordination, particularly with respect to wage-setting, because governments would be compelled to use national legislation and public-sector wage settlements to influence wage policy in such a way that imbalances among euro-zone countries are reduced.
Furthermore, an External Stability Pact would oblige governments to take into account the consequences for other member states when designing national economic reforms.
If a “surplus country” such as Germany wanted to lower non-wage labor costs and increase value-added tax in order to boost its competitiveness, it would simultaneously have to adopt an expansive fiscal policy to compensate for the negative effects on its partners’ foreign trade.
Within the framework of these rules, individual countries would retain the authority to design their policies.
The Spanish government, for example, could have met Spain’s building boom and foreign-trade deficit with tax increases or by urging domestic wage restraint.
Alternatively, it could have intervened by instituting planning regulations or imposing limits on mortgage loans.
An External Stability Pact would not only detect risks to fiscal stability early on; it would also help make a reality of a fundamental principle of EU law, namely that member states finally treat economic policy as a “common interest.”
An Honest Man?
In his gushing account of President George W. Bush, the former presidential speechwriter David Frum tells us that his boss "scorned the petty untruths of the politician."
We learn, for example, that when asked to prepare a radio broadcast for the following day, he would begin reading, "Today I am in California" and quickly break off, saying with exasperation, "But I'm not in California."
Frum thought this a bit pedantic, but concluded that it was emblematic of the President's character and that "the country could trust the Bush administration not to cheat and not to lie."
How wrong Frum now seems.
Bush may naively consider it lying, and therefore wrong, to say that he is in California when he is recording a speech in Washington.
But he fails to see anything gravely wrong about misleading his country and the world concerning Iraq's weapons of mass destruction.
As we have seen, the White House built its case for war on a highly selective dossier of evidence, and Bush made statements about Iraq's attempt to purchase uranium from Africa that he and his staff knew to be highly doubtful, if not false.
When questions were raised about how the statement about uranium was allowed to remain in Bush's State of the Union address, both National Security Advisor Condoleeza Rice and Secretary of Defense Donald Rumsfeld argued that it was not a lie.
Their reasoning indicates that they, like the President, have a childishly literal notion of what it is to lie.
Bush's actual words were these: "The British government has learned that Saddam Hussein recently sought significant quantities of uranium from Africa."
Bush's statement took this form because the CIA objected to the original version, which flatly stated that Saddam Hussein had sought to buy uranium from Africa.
The White House staff member who discussed it with the CIA then suggested changing the sentence so that it stated that the British reported that Saddam Hussein had
This was literally true, because the British had reported that.
It was nevertheless misleading, for the CIA had informed the British that their information was not reliable.
The fact that Bush only referred to a British statement is the basis for Rice and Rumsfeld's defense of it.
Rice said that "the statement that [Bush] made was indeed accurate.
The British government did say that."
Rumsfeld said that Bush's statement was "technically accurate."
In fact, even on the most literal interpretation, Bush's statement was not accurate.
Bush did not say merely that the British had "reported" that Iraq had sought to buy uranium from Africa, but that the British had ``learned'' this.
To say that someone has learned something is to endorse what they say they have learned as true.
Imagine that the British had said that Saddam Hussein was a peace-loving man about to bring democracy to his country.
Would Bush have said that the British had
Quite apart from these weak attempts to justify Bush's statement as "technically accurate," the more serious charge is that even if what Bush said really were technically accurate, it still would have been designed to mislead the world into thinking that Iraq had been trying to buy uranium in Africa.
Bush and his staff had good reason to believe that this was not true.
Bush's response to the issue after it became public shows him to be focused on the trivial and morally reckless about the essential.
A person who is morally sensitive to the seriousness of starting a war on the basis of misleading information would take appropriate steps.
He would ensure that the American public knew how the error occurred, and that whoever was responsible for it suffered the usual consequences that befall senior officials who make what was--to put the best possible interpretation on it--a grave error of judgment.
But Bush did nothing of the sort.
When the issue became public, Bush's response was to condemn his critics as "revisionist historians" and to evade questions about the credibility of the information he had provided by asserting that the removal of Saddam was a good outcome.
Then he said that the CIA had cleared his speech, as if that absolved him of all responsibility.
After CIA Director George Tenet took responsibility for the inclusion of the misleading material, Bush said that he "absolutely" had confidence in Tenet and the CIA, and that he considered the matter closed.
Belief in Bush's honesty led many voters to prefer him to Albert Gore in the 2000 presidential election.
Among voters who rated "honesty" as an important factor influencing their choice of candidate, 80% said that they voted for Bush.
These voters were disgusted with Clinton, not only for his sexual relationship with White House intern Monica Lewinsky, but for lying about it.
That Clinton did lie about his sexual activities is clear, and he was wrong to do so.
But his lies did not lead his country into a war that has cost thousands of lives.
Bush's excessively literal interpretation of the requirements of honesty conceals a deeper dishonesty whose consequences have been far more morally serious.
An IMF We Can Love?
CAMBRIDGE – What a difference the crisis has made for the International Monetary Fund.
It was just a few months ago that this important but unloved institution, a landmark of post-war global economic arrangements, seemed destined to irrelevance.
The IMF has long been a whipping boy for both left and right – the former because of the Fund’s emphasis on fiscal rectitude and economic orthodoxy, and the latter because of its role in bailing out indebted nations.
Developing nations grudgingly took its advice, while advanced nations, not needing the money, ignored it. In a world where private capital flows dwarf the resources at its disposal, the IMF had come to seem an anachronism.
And, when some of the IMF’s largest debtors (Brazil and Argentina) began to prepay their debts a few years ago with no new borrowers in sight, it looked like the final nail in the coffin had been struck.
The IMF seemed condemned to run out of income, in addition to losing its raison d’être .
It shrank its budgets and began to downsize, and, while it was handed some new responsibilities in the meantime – surveillance over “currency manipulation,” in particular – its deliberations proved largely irrelevant.
But the crisis has invigorated the IMF.
Under its capable managing director, Dominique Strauss-Kahn, the Fund has been one of the few official agencies ahead of – instead of behind – the curve.
It moved quickly to establish a fast-disbursing emergency line of credit for countries with “reasonable” policies.
It ardently championed global fiscal stimulus on the order of 2% of world GNP – a position that is all the more remarkable in view of its traditional conservatism on all fiscal matters.
And, in the run-up to the G-20 summit in London, it thoroughly overhauled its lending policies, de-emphasizing traditional conditionality and making it easier for countries to qualify for loans.
Even more significantly, the IMF has emerged from the London meeting with substantially greater resources, as well as new responsibilities. The G-20 promised to triple the Fund’s lending capacity (from $250 billion to $750 billion), issue $250 billion of new Special Drawing Rights (a reserve asset made up of a basket of major currencies), and permit the Fund to borrow in capital markets (which it has never done) if necessary.
The IMF was also designated as one of two lead agencies – along with an expanded Financial Stability Forum (now renamed the Financial Stability Board) – charged with providing early warning of macroeconomic and financial risks and issuing the requisite policy recommendations.
Another piece of good news is that the Europeans have now given up their claim on naming the IMF’s managing director (as have the Americans their corresponding claim on the World Bank presidency).
These senior officials are henceforth to be selected “through an open, transparent, and merit-based selection process.”
This will provide for better governance (although Strauss-Kahn’s leadership has been exemplary), and will enhance both institutions’ legitimacy in the eyes of developing nations.
So the IMF now finds itself at the center of the economic universe once again.
How will it choose to deploy its newfound power?
The greatest risk is that it will once again over-reach and over-play its hand.
That is what happened in the second half of the 1990’s, as the IMF began to preach capital-account liberalization, applied over-stringent fiscal remedies during the Asian financial crisis, and single-handedly tried to reshape Asian economies.
The institution has since acknowledged its errors in all these areas.
But it remains to be seen if the lessons have been fully internalized, and whether we will have a kinder, gentler IMF in lieu of a rigid, doctrinaire one.
One encouraging fact is that developing countries will almost certainly get a larger say in how the Fund is run.
This will ensure that poorer nations’ views receive a more sympathetic hearing in the future.
But simply giving developing nations greater voting power will make little difference if the IMF’s organizational culture is not changed as well.
The Fund is staffed by a large number of smart economists, who lack much connection to (and appreciation for) the institutional realities of the countries on which they work.
Their professional expertise is validated by the quality of their advanced degrees, rather than by their achievements in practical policymaking.
This breeds arrogance and a sense of smug superiority over their counterparts – policymakers who must balance multiple, complicated agendas.
Countering this will require proactive efforts by the IMF’s top leadership in recruitment, staffing, and promotion.
One option would be to increase substantially the number of mid-career recruits with actual practical experience in developing countries.
This would make the IMF staff more cognizant of the value of local knowledge relative to theoretical expertise.
Another strategy would be to relocate some of the staff, including those in functional departments, to “regional offices” in the field.
This move would likely face considerable resistance from staff who have gotten used to the perks of Washington, DC.
But there is no better way to appreciate the role of context than to live in it.
The World Bank, which engaged in a similar decentralization a while back, has become better at serving its clients as a result (without facing difficulties in recruiting top talent).
This is an important moment for the IMF.
The international community is putting great store in the Fund’s judgment and performance.
The Fund will require internal reforms to earn that trust fully.
An Inconvenient Peace Prize
This year’s Nobel Peace Prize justly rewards the thousands of scientists of the United Nations Climate Change Panel (the IPCC).
These scientists are engaged in excellent, painstaking work that establishes exactly what the world should expect from climate change.
The other award winner, former US Vice President Al Gore, has spent much more time telling us what to fear.
While the IPCC’s estimates and conclusions are grounded in careful study, Gore doesn’t seem to be similarly restrained.
Gore told the world in his Academy Award-winning movie (recently labeled “one-sided” and containing “scientific errors” by a British judge) to expect 20-foot sea-level rises over this century.
He ignores the findings of his Nobel co-winners, the IPCC, who conclude that sea levels will rise between only a half-foot and two feet over this century, with their best expectation being about one foot.
That’s similar to what the world experienced over the past 150 years.
Likewise, Gore agonizes over the accelerated melting of ice in Greenland and what it means for the planet, but overlooks the IPCC’s conclusion that, if sustained, the current rate of melting would add just three inches to the sea level rise by the end of the century.
Gore also takes no notice of research showing that Greenland’s temperatures were higher in 1941 than they are today.
Gore also frets about the future of polar bears.
He claims they are drowning as their icy habitat disappears.
However, the only scientific study showing any such thing indicates that four polar bears drowned because of a storm.
The politician-turned-movie maker loses sleep over a predicted rise in heat-related deaths.
There’s another side of the story that’s inconvenient to mention: rising temperatures will reduce the number of cold spells, which are a much bigger killer than heat.
The best study shows that by 2050, heat will claim 400,000 more lives, but 1.8 million fewer will die because of cold.
Indeed, according to the first complete survey of the economic effects of climate change for the world, global warming will actually save lives.
The IPCC has magnanimously declared that it would have been happy if Gore had received the Nobel Peace prize alone.
I am glad that he did not, and that the IPCC’s work has rightfully been acknowledged.
Gore has helped the world to worry.
Unfortunately, our attention is diverted from where it matters.
Climate change is not the only problem facing the globe.
Our blinkered focus on it – to the detriment of other planetary challenges – will only be heightened by the attention generated by Gore’s Nobel Peace Prize.
Gore concentrates above all else on his call for world leaders to cut CO2 emissions, yet there are other policies that would do much more for the planet.
Over the coming century, developing nations will be increasingly dependent on food imports from developed countries.
This is not primarily a result of global warming, but a consequence of more people and less arable land in the developing world.
The number of hungry people depends much less on climate than on demographics and income.
Extremely expensive cuts in carbon emissions could mean more malnourished people.
If our goal is to fight malnutrition, policies like getting nutrients to those who need them are 5,000 times more effective at saving lives than spending billions of dollars cutting carbon emissions.
Likewise, global warming will probably slightly increase malaria, but CO2 reductions will be far less effective at fighting this disease than mosquito nets and medication, which can cheaply save 850,000 lives every year.
By contrast, the expensive Kyoto Protocol will prevent just 1,400 deaths from malaria each year.
While we worry about the far-off effects of climate change, we do nothing to deal with issues facing the planet today.
This year, malnutrition will kill almost four million people.
Three million lives will be lost to HIV/AIDS.
Two and a half million people will die because of indoor and outdoor air pollution.
A lack of micronutrients and clean drinking water will claim two million lives each.
With attention and money in scarce supply, what matters is that we first tackle the problems with the best solutions, doing the most good throughout the century.
If we focus on solving today’s problems, we will leave communities strengthened, economies more vibrant, and infrastructures more robust.
This will enable these societies to deal much better with future problems – including global warming.
Committing to massive cuts in carbon emissions will leave future generations poorer and less able to adapt to challenges.
Gore has an unshakable faith that climate change is the biggest challenge facing the world.
To be fair, he deserves some form of recognition for his resolute passion.
However, the contrast between this year’s Nobel winners could not be sharper.
The IPCC engages in meticulous research where facts rule over everything else.
Gore has a very different approach.
An India-China Axis?
Is a new alignment between India and China rising to balance America’s global power?
Chinese Premier Wen Jiabao just completed a four-day visit to India during which 11 agreements were signed, including a comprehensive five-year strategic cooperation pact.
In addition, Wen announced that China would support India’s bid for a permanent seat on an expanded UN Security Council, and opposed the inclusion of Japan, which the United States supports for a Council seat.
With over a third of the world’s population and two of the globe’s highest economic growth rates, an alliance between China and India could be a serious factor in world politics.
While both are developing countries – many of whose people remain impoverished – they also boast impressive capabilities in information age technologies both for civilian and military purposes.
As Indian Prime Minister Manmohan Singh put it during Wen’s visit, “India and China can together reshape the world order.”
The two countries’ recent rapprochement marks a huge change from the hostility that bedeviled their relations following their 1962 war over a disputed border in the Himalayas.
When I first visited India as an American government official in the late 1970’s, I was struck by my Indian hosts’ fixation on gaining equal status with China.
In 1998, when India tested its nuclear weapons, the defense minister referred to China, and then Prime Minister Atal Bihari Vajpayee spoke of China as India’s number one enemy.
By contrast, on more recent visits to India, I have found my hosts referring to the need to learn from China.
Trade between the two giants has grown from $100 million in 1994 to nearly $14 billion last year, and India’s minister of commerce and industry has predicted that it will double by this decade’s end.
One agreement signed during Wen’s visit was a new set of guiding principles on how to settle boundary disputes between the two countries.
While improved relations and diminished prospects for conflict are welcome, relations between India and China are more complex than they appear at first.
Not long before the visit of the Chinese premier, India hosted US Secretary of State Condoleezza Rice.
Ever since President Bill Clinton’s visit to India, but especially under President George W. Bush, the US has moved from relative indifference to India to the development of a strong strategic relationship.
This new approach might have seemed threatened by Al Qaeda’s attacks on America, which led to a strengthening of US relations with Pakistan’s General Parvez Musharaff.
But the US reassured India that they faced a common threat from transnational terrorism, and that the old Cold War pairings of India and Pakistan were outdated.
Secretary Rice made this plain during her March visit, stressing the importance of a strategic relationship, including a willingness to consider trade in high technology, nuclear energy, and co-production of fighter aircraft such as F-16’s and F-18’s.
Shortly after Rice’s visit, the US announced that it would honor a long-standing promise to sell F-16’s to Pakistan.
While the announcement incited Indian protests, they were relatively muted compared to the past.
One reason is that the State Department also issued a statement that America would help India to become a major world power in the twenty-first century, involving both a strategic and economic dialogue.
Several factors underpin this new American attitude toward India. Rhetoric about “the world’s two largest democracies” is not new, but it fits with the Bush administration’s new emphasis on promoting democracy.
The increasing role of the Indian diaspora in the US, particularly in the information industries, also had an influence, as has the rise in bilateral trade accompanying India’s surging economic growth.
Equally important are strategic concerns about transnational terrorism and the rise of Chinese power.
The rise of China is a major factor in the politics of the twenty-first century.
China has tripled the size of its economy in the past two decades, and has been increasing its military strength.
While both India and the US seek trade and good relations with China, both are aware – and wary – of China’s growing strength.
Thus, both seek to hedge their bets, and what better way to do so than by improving their strategic relationship?
Neither country aims to restrain China in the way the “containment” strategy aimed at an aggressive Soviet Union during the Cold War, but both want to create an international structure that does not tempt China to throw its weight around.
India has a 3,000-kilometer border with China, a 2,000-kilometer border with Pakistan (which has been the beneficiary of Chinese military and nuclear assistance), and growing concerns about the security of sea routes in the Indian Ocean over which oil and other trade move.
As one Indian strategist put it to me during a recent visit, “By 2030, we envisage the US, China, and India as the three largest powers in world politics.
We don’t want a China- or a US-dominated world, but if we had to choose, it would be easier for us to live with the latter.”
So, while improvement in India-China relations is welcome, it is unlikely to herald the beginning of an India-China alliance against the US.
Rather, it more likely represents another move in India’s age-old tradition of managing regional balances of power.
An Indirect Route to a Palestinian State?
RAMALLAH – Palestinians and Israelis have different and possibly contradictory expectations from the indirect negotiations that the United States has pushed both sides into beginning.
Israel was among the first parties to welcome the Arab League’s reluctant decision to back Palestinian President Mahmoud Abbas’s call for Arabs to give their blessing to the talks.
It is clear that for Israeli Prime Minister Binyamin Netanyahu’s right-wing government, the start of indirect talks without freezing settlement activities in the West Bank and Jerusalem is a sort of victory.
Just to remind the world of this, as the indirect talks were preparing to get off the ground, Israel’s government approved a decision to break ground on 112 housing units in a settlement south of Bethlehem, and 1600 new settlement units in East Jerusalem.
For Palestinians, the return to talks, albeit indirect, is focused on one strategic issue: borders.
The idea, a new one, aims at getting the Israelis and Palestinians to agree to the borders of the Palestinian state that both sides and the rest of the world have said is the way out of the decades-old conflict.
Palestinians want the areas occupied by Israel following the June 1967 War to be the territory of the Palestinian state.
This fits with United Nations Security Council resolutions, among them Number 242, which stated the &quot;inadmissibility of the acquisition of territory by war.&quot;
But a return to the 1967 borders would mean that large settlement blocks – as well as smaller settlements and East Jerusalem – would be part of the Palestinians state.
Few expect that to happen.
Previous talks have included an allowance for land exchanges, which would permit Israel to keep many large settlement blocks by giving land inside Israel to the Palestinians.
The most likely swap would probably involve territory to create a West Bank-Gaza land corridor.
Jerusalem will be much more difficult to demarcate.
Palestinians and Israelis have publicly said that they do not want a wall separating West and East Jerusalem.
Among the various ideas in circulation, most incorporate former US President Bill Clinton’s call for Jerusalem’s Jewish communities to be part of Israel and the Arab communities to be part of Palestine.
But this plan has been put to the test lately by right-wing Israelis’ forcible takeover of Palestinian properties in the heart of East Jerusalem’s Sheikh Jarah neighborhood.
Hundreds of Israeli peace supporters, along with some international activists, have joined evicted Palestinians to protest the actions of these radical settlers, which have been supported by municipal and government officials.
Unfortunately, therefore, the indirect negotiations now being launched are unlikely to produce any tangible result on the borders of the Palestinian state.
Indeed, to expect such results by the proposed four-month deadline is highly implausible.
Nevertheless, for both sides, the process can be as important as the results.
For Israelis, these talks will relieve US and other international pressure, while at the same time providing some legitimacy to Netanyahu’s position of talking peace without giving up on settlements and Jerusalem.
Many will say that this appearance of supporting peace without surrendering land has been Israel’s successful position for decades.
For Palestinians however, this process is different from negotiations in the past.
Stubbornly refusing to talk face to face while settlement activities are not completely frozen has focused attention on what many believe is the crux of Israel’s colonial occupation regime.
For many Palestinians and Israelis, as well as for the international community, the shape and details of what would be a settlement acceptable to majorities on both sides is well known. By focusing on the need to reach agreements on borders within a short time period, Palestinians are saying that they do not see any need to negotiate gradual steps, preferring to agree on the final settlement first and then work back on issues of implementation.
Perhaps the most interesting new aspect in the upcoming indirect talks is what has been happening on the ground in the occupied territories.
Palestinian Prime Minister Salam Fayyad has been active in executing a strategic plan that is expected to lead to a
The American negotiators who are planning to play an active role in the indirect talks, and will for the first time sit at the negotiating table if face-to-face talks do take place, have apparently promised the Palestinians that the US will point its finger at the party that dares to derail the negotiations.
Such a US declaration (if it declares Israel at fault) would give Palestinians the opportunity to declare the talks a failure and thus move toward a unilateral declaration of statehood in the hope that the world community will recognize such a state.
Europe has already said that it would recognize such a unilateral declaration.
In that case, the Americans would have a hard time refusing to recognize a Palestinian state that fits what the international community has said is the only acceptable solution to this intractable conflict.
An Inequality Tax
The economic booms in China and India have helped to reduce global inequality.
Over the two last decades, masses of Indians and Chinese have closed the gap (in relative terms) with the rich world.
But, at the same time, many of the world’s truly poor countries have fallen further behind (particularly in Africa, where developments are often described as catastrophic), and inequality within most countries has risen.
Widening inequality has been recorded in the United States (starting with Ronald Reagan’s administration), the United Kingdom (starting with Margaret Thatcher), Russia during its privatization, and more recently in China and India.
These developments seem to add to global inequality.
So, on balance, it seems that global inequality has been relatively stable during the last two decades.
Should anything be done about this?
Many think that no global action to fight economic inequality is necessary.
They argue that only poverty reduction matters.
In the words of Anne Krueger, the Deputy Managing Director of the IMF, “Poor people are desperate to improve their material conditions…rather than to march up the income distribution [ladder].”
Thus, even if the absolute income gap between an average American and an average African increases, why worry?
After all, such people argue, the average African would be a bit less poor.
But this assumes that our income relative to the income of others does not matter.
On the contrary, psychological studies invariably show that people care not only about their absolute income, but also about where they stand in the social pyramid and whether their position is fair.
In the past, a poor African might have looked at his compatriots and resented their wealth; now, both he and his better-off compatriots look at the rich world and resent the huge income gaps they see.
The gaps are most obvious where people from different countries work together, as in many multinational companies.
An “expatriate” may be paid ten times more than local staff for the same job.
A wage premium based solely on citizenship is grating.
But even when people do not work together, globalization, by bringing the world to everyone’s living room (or hut), enables them to make much wider comparisons of their living standards.
It erodes the relative security in which the rich world could shelter itself, as in a cocoon.
Now, all can see these income differences.
This is why international action to address both global poverty and global inequality is needed.
Global redistribution through taxes that would be levied by an international body may seem far-fetched today, but the logic of development that we are witnessing – particularly the move away from nation-states as the locus of sovereignty – suggests that it may eventually come to pass.
One such opportunity was missed in the early 1990’s.
When Russia faced its worst crisis, aid was given to the corrupt Yeltsin regime.
But it should have been disbursed directly in cash to the most needy Russians: pensioners whose earnings plummeted due to inflation and economic contraction.
An international organization could have simply used the existing infrastructure of the Russian state to distribute cash grants to some 20 million pensioners – money that would have been much better targeted and spent than by giving the same amount to the government.
If this had been done, Russians would have fondly remembered receiving cash aid from the international community rather than blaming it for transferring funds to corrupt leaders.
But the same or a similar approach could be taken in many countries today, from Angola to Zimbabwe.
The approach is simple and powerful. It involves three steps: raise money from the globally rich, do not deal with governments, and transfers funds in cash to the poor.
Those who advocate leaving globalization exclusively in the hands of the private sector may resent the idea of vesting tax-raising authority in a global agency.
But they cannot fail to notice that the processes they support undercut their own position by rendering the wealth gap more obvious and the fairness of the actual global distribution more questionable.
They will ultimately realize that their self-interest lies in supporting some form of global action to deal with both poverty and inequality.
An Inflation Reality Check
CAMBRIDGE – As inflation continues to soar everywhere, maybe the world’s central bankers need a jolt to awaken them from complacency.
How about holding one of their bi-monthly meetings in hyperinflationary Zimbabwe?
It might not be comfortable, but it would be educational.
According to Zimbabwe’s official statistical agency, inflation topped 66,000% in 2007, which looks more like Weimar Germany than modern-day Africa.
While no one is quite certain how the government managed to estimate prices, given that there is virtually nothing for sale in the shops, most indicators suggest that Zimbabwe does have a good shot at breaking world records for inflation.
Of course, curious as they might be, central bankers could decide that meeting in Harare would be too inconvenient and politically unpalatable.
Fortunately, there are lots of other nice – albeit less spectacular – inflation destinations.
Inflation in Russia, Vietnam, Argentina, and Venezuela is solidly in double digits, to name just a few possibilities.
Indeed, except for deflation-ridden Japan, central bankers could meet just about anywhere and see high and rising inflation.
Chinese authorities are so worried by their country’s 7% inflation they are copying India and imposing price controls on food.
Even the United States had inflation at 4% last year, though the Federal Reserve is somehow convinced that most people won’t notice.
Many central bankers and economists argue that today’s rising global inflation is just a temporary aberration, driven by soaring prices for food, fuel, and other commodities.
True, prices for many key commodities are up 25% to 50% since the start of the year.
But if central bankers think that today’s inflation is simply the product of short-term resource scarcities as opposed to lax monetary policy, they are mistaken.
The fact is that around most of the world, inflation – and eventually inflation expectations – will keep climbing unless central banks start tightening their monetary policies.
The US is now ground zero for global inflation.
Faced with a vicious combination of collapsing housing prices and imploding credit markets, the Fed has been aggressively cutting interest rates to try to stave off a recession.
But even if the Fed does not admit it in its forecasts, the price of this “insurance policy” will almost certainly be higher inflation down the road, and perhaps for several years.
America’s inflation would be contained but for the fact that so many countries, from the Middle East to Asia, effectively tie their currencies to the dollar.
Others, such as Russia and Argentina, do not literally peg to the dollar but nevertheless try to smooth movements.
As a result, whenever the Fed cuts interest rates, it puts pressure on the whole “dollar bloc” to follow suit, lest their currencies appreciate as investors seek higher yields.
Looser US monetary policy has thus set the tempo for inflation in a significant chunk – perhaps as much as 60% – of the global economy.
But, with most economies in the Middle East and Asia in much stronger shape than the US and inflation already climbing sharply in most emerging-market countries, aggressive monetary stimulus is the last thing they need right now.
The European Central Bank is staying calm for the moment, but it, too, is probably holding back on interest-rate hikes partly out of fear of driving the euro, already at record levels, even higher.
And the ECB worries that if the US recession proves contagious, it may have to turn around and start slashing rates anyway.
So what happens next?
If the US tips from mild recession into deep recession, the global deflationary implications will cancel out some of the inflationary pressures the world is facing.
Global commodity prices will collapse, and prices for many goods and services will stop rising so quickly as unemployment and excess capacity grow.
Of course, a US recession will also bring further Fed interest-rate cuts, which will exacerbate problems later.
But inflation pressures will be even worse if the US recession remains mild and global growth remains solid.
In that case, inflation could easily rise to 1980’s (if not quite 1970’s) levels throughout much of the world.
Until now, most investors have thought that they would rather risk high inflation for a couple of years than accept even a short and shallow recession.
But they too easily forget the costs of high inflation, and how difficult it is to squeeze it out of the system.
Maybe they, too, should try holding a few conferences in Zimbabwe, and get a reality check of their own.
An Intelligent War on Terror
Terrorism is an existential threat.
In our European Security Strategy, it was deemed one of the key strategic threats facing the European Union, and to fight it we are using all instruments at our disposal, particularly in the intelligence area.
The first objective of intelligence is to find terrorists, prevent them from acting, and track them after they do attack.
This is the kind of operational intelligence that is best done at the national level.
Many arrests and disruptions of terrorist operations in Europe result from cooperation between EU members' intelligence services.
I was recently asked by journalists whether inter-agency cooperation is sufficient and whether European mechanisms for sharing operational intelligence should be created.
Later that very day, a joint operation resulted in simultaneous arrests in five European countries.
The operation's success was no accident.
Last year, the Union concluded two Europol agreements, as well as an Extradition and Mutual Legal Assistance Agreement.
Europe's security services are working closely together within the Counter-Terrorist Group, and Europol's Counter-Terrorist Task Force has been re-established.
A high-level group on border and transport security is at work, and links between member states' police chiefs are strengthening.
But widespread sharing is not always needed or appropriate.
Member states also need intelligence derived from ongoing casework, not to inform policy, at least not directly, but to disrupt and dismantle networks and prevent attacks.
This information is in many ways more sensitive, and services share it on a "need to know" basis, not for the sake of promoting cooperation.
I see another role for intelligence: to inform political action.
Intelligence services can educate the public, explaining the origins of the alienation that underpins terrorism, how radicalization and recruitment occur, and highlight terrorists' goals, methods, and targeting strategies.
Only when we understand this can we develop appropriate and concrete policies.
For this we need good strategic assessments of intelligence.
The EU's members have structures to provide this, and with their support and input we are building structures at a Europe-wide level, to bring this information to EU policymakers.
Europol is performing a similar function with material derived from police work, and we are working to ensure synergy between these two efforts.
This is a different level of intelligence, more analytical, where close collaboration adds significant value.
In the aftermath of the Madrid bombings, the EU focused on internal aspects of the fight against terrorism.
But this does not mean that the Union has become introverted. On the contrary, the EU regards international cooperation as fundamental in the fight against terrorism.
Generally, counter-terrorism is very high on our international agenda and is becoming better integrated into the Union's political dialogue with other countries.
We are better targeting our external assistance and capacity building programs, and we are ready to use our trade and economic muscle, when necessary, by demanding counter-terrorism clauses in bilateral treaties.
There has also been a sea change in transatlantic cooperation between the EU and the US.
Deeds speak louder than words, and deeds on the transatlantic level have been swift and decisive - for example, joint efforts aimed at choking off terrorist financing - even when we had strong divergences over Iraq.
Still, I am not complacent.
To facilitate the extremely complex task of counter-terrorism policymaking in the EU, we now have a Plan of Action, approved by the European Council, which clearly specifies who does what, and by when.
This will also help national parliaments understand EU objectives and facilitate their legislative planning.
I have recently appointed a counter-terrorism coordinator to assist me in following through on the Plan of Action.
We also have a considerable number of new instruments in the area of justice and home affairs.
The European Arrest Warrant is already producing concrete results, and we are moving towards the "free movement of judicial decisions" in the EU, through which judicial decisions - such as arrest and surrender of suspects, confiscation, and freezing of assets - will be mutually recognized.
Furthermore, the European Border Agency will become operational in 2005.
As requested by the European Council, I am developing, in cooperation with the European Commission, a strategy to shut down terrorist financing.
This is where the real test of cooperation lies, for our success will rely on securing the appropriate interaction and flow of intelligence between the relevant services and the financial and banking communities.
I firmly believe that the military option alone cannot defeat terror.
Judicial, police, and intelligence cooperation should be the focal point for action.
This does not mean that we are not working on how European Security and Defense Policy (ESDP) can offer a meaningful contribution.
But ESDP is not at the core of our efforts.
Aside from security and intelligence efforts, we must also work to deny "oxygen" to the terrorists.
This means addressing the factors that contribute to support for and recruitment by terrorist groups.
Regional conflicts cause anger and resentment.
The unresolved Arab-Israeli problem leads to the rise of radicalism and extremism.
There is entirely too much fuel for terrorist propaganda.
The EU will be tough on terrorism.
But it must also be tough on the causes of terrorism.
These are not two fights, but one.
An Iraqi Film Hero in America
NEW YORK –&nbsp;One of Iraq’s only working filmmakers, Oday Rasheed – whose brilliant film&nbsp;2005 Underexposure followed a group of characters in Baghdad after the United States-led invasion&nbsp;in 2003, and whose new film Qarantina is now premiering – is in Manhattan.
The glamorous settings in which he is now showing Qarantina – a screening at the Museum of Modern Art, for example, and in the private homes of American directors and stars – could not be further removed from the violence-riddled context of his daily life.
In Baghdad, Rasheed has gained fame – and notoriety – by seeking to inspire a new generation of Iraqi filmmakers and other young artists.
Qarantina is one of only four feature films completed in Iraq in the past 12 years.
A member of a collective called Najeen (Survivors), Rasheed is part of a vanguard of younger artists, writers, and filmmakers whose&nbsp;work attests to their commitment to art in the midst of crisis.
It is startling to see him walk into a New York living room: his demeanor is quiet and dignified. An air of solemnity envelops him.
He has experienced unthinkable trauma, and is still exposed to it.
“Of seven close friends I had growing up,” he tells me, “five are dead.” One was recently murdered by a gunshot to the head while he was standing in his kitchen.
Some days, he says, “you wake up and the radio or TV reports five car bombings,” leading to a kind of claustrophobia – part of the subject matter of his film.
I noted that he might be experiencing post-traumatic stress from the loss of his friend. “I have had that – have done that already,” he smiled.
Rasheed is just turning 40, and his life reflects his country’s dramas: part of what has been called a “lost generation” of Iraqi artists and intellectuals, he and his friends were isolated for years by sanctions.
But he also describes the Saddam years as an era in which, while there was no freedom, intellectuals had room to maneuver, as long as they “knew what to leave alone.”
He lived through the US-led invasion during a formative time in his creative life – he was writing for television and engaged in film criticism and commentary while trying to survive bombardment, looting, and chaos.
But he also had to maintain his intellectual integrity.
When the US military sought to showcase the fact that a filmmaker was at work in occupied Iraq, Rasheed was swept to a formal dinner in one of Saddam's former palaces in the Green Zone, attended by senior US officials and military contractors – an invitation that one would not want to receive, and would not be able to turn down.
Now Rasheed reflects on his country’s turn toward religious extremism: he describes a pre-invasion Iraq in which women were professionals and fairly emancipated, whereas now women wear headscarves under pressure, “for a peaceful life.”
His friend, a young Iraqi actress named Zahra Zubaidi, had to flee the Middle East after having played a rape victim in the Brian de&nbsp;Palma film Redacted; she has since emigrated to New York.
Constant&nbsp;intimidation by religious extremists and political factions is the intellectual’s fate in Iraq today.
And yet Rasheed refuses to be discreet: “Everything I believe, I believe in it,” he says. “I cannot lie or not answer the questions.”
Rasheed is in New York mainly because it is the location of his next film, which “deals with the influence of&nbsp;the US contractors after the invasion of Iraq, not only on the lives of Iraqis, but also on the life of the US.” As for Iraq today, Rasheed says, “I do not think that Americans are indifferent to what happened and what is happening, but the daily details of cruelty do not give them either the time or the energy to think about larger issues.”
Indeed, Rasheed notes that at every US screening of his film, audiences need to apologize before they begin to relate to Rasheed as a filmmaker rather than as a representative of his country. “Personally, I do not ask anything; I’m here to clear up some confusion by the medium of film.”
Iraq, ravaged by war and now shaken daily by violence, is known as the most intellectually inclined of the Arab countries.
As Iraqi and other Muslim intellectuals in the region often repeat: “Books are written in Egypt, printed in Lebanon, and read in Iraq.”
Here is hoping that Raheed and his colleagues continue to build up an Iraqi culture that is vibrant and free; and here is hoping that the relationship of US and international audiences to Rasheed goes from one of expiation to one of engagement with his work.
His embrace of the right to his truth, which is the artist’s task, is nonetheless remarkable, given that he is working in an environment in which part of the creative process involves trying to stay alive.
An Obama Moment for India’s Untouchables
NEW DELHI – Among the many international consequences of Barack Obama’s stunning victory in the United States is worldwide introspection about whether such a breakthrough could happen elsewhere.
Could a person of color win power in other white-majority countries?
Could a member of a beleaguered minority transcend the circumstances of his birth to lead his or her country?
While many analysts in a wide variety of nations, especially in Europe, have concluded that such an event could not occur there in the foreseeable future, India is an exception.
Minority politicians have long wielded authority, if not power, in its various high offices.
Indeed, India’s last general election, in 2004, was won by a woman of Italian heritage and Roman Catholic faith (Sonia Gandhi) who made way for a Sikh (Manmohan Singh) to be sworn in as Prime Minister by a Muslim (President Abdul Kalam) in a country that is 81% Hindu.
Not only could it happen here, Indians say, it already has.
Such complacency is premature.
The closest Indian analogy to the position of black Americans is that of the Dalits – formerly called “Untouchables,” the outcastes who for millennia suffered humiliating discrimination and oppression.
Like blacks in the US, Dalits account for about 15% of the population; they are found disproportionately in low-status, low-income jobs; their levels of educational attainment are lower than the upper castes; and they still face daily incidents of discrimination for no reason other than their identity at birth.
Only when a Dalit rules India can the country truly be said to have attained its own “Obama moment.”
In theory, this already has happened: K. R. Narayanan, born into a poor Dalit family, served as India’s president, the highest office in the land, from 1997 to 2002.
But the Indian Presidency is a largely ceremonial position: real power is vested in the office of prime minister, and no Dalit has come close to holding that post.
Since independence in 1947, a majority of India’s prime ministers have been Brahmins, the highest Hindu caste.
Yet the next national elections, due before May 2009, may produce a plausible Dalit contender for the job of prime minister – Kumari Mayawati, the female chief minister of India’s largest state, Uttar Pradesh.
Since 1991, no Indian governing party has enjoyed a secure parliamentary majority on its own, necessitating multi-party coalition governments.
The current Congress Party-led government of Manmohan Singh comprises 20 parties; it succeeded a 23-party coalition headed by the Bharatiya Janata Party’s Atal Bihari Vajpayee.
When the election results are declared next year, no one doubts that the first challenge will be to cobble together another coalition.
Both the Congress and the BJP will seek to make alliances with the dozens of smaller parties likely to be represented in parliament.
But this time they are likely to face a third alternative: Mayawati, whose Bahujan Samaj Party (BSP) may command a bloc of at least 50 seats.
She has publicly expressed her disdain for both large national parties; she would much rather lead a coalition than join one.
And if the electoral numbers break down right, she could conceivably assemble a collection of regional and left-wing parties and stake a claim to rule India.
This is a remarkable development: the idea that a Dalit woman could lead India has been inconceivable for 3,000 years.
But India’s democracy has opened new pathways to empowerment for its underclasses.
The poor and the oppressed may not have much, but they do have the numbers, which is what matters at the ballot box.
Dalits and India’s aboriginals (listed in the Constitution as “Scheduled Castes and Tribes”) are entitled to 85 seats in India’s 543-member parliament that are “reserved” for candidates from their communities.
Mayawati’s shrewd alliances, including with some members of the upper castes, which propelled her to power in Uttar Pradesh, give her party a fighting chance to win a number of other seats as well.
In a coalition-dependent parliamentary system, that could be all she needs to become prime minister.
The daughter of a government clerk, Mayawati studied law and worked as a teacher before being spotted by the BSP’s founder, the late Kanshi Ram, and groomed for political leadership.
Her ascent has been marked by a heavy emphasis on symbolism – her rule in Uttar Pradesh has featured the construction of numerous statues of Dalit leaders, notably herself – and a taste for lavish celebrations.
Mayawati’s weakness for “bling” has been demonstrated at her extravagant birthday parties, which she presides over laden with diamonds, saying (rather like Evita Peron) that her luster brings glamour and dignity to her people.
She takes pride in being the Indian politician who pays the highest income taxes – about $6 million last year – though the sources of her income are shrouded in controversy.
She has been accused, but not convicted, of corruption several times, with one notable case involving the construction of an elaborate shopping complex near the Taj Mahal, in violation of zoning laws.
Critics argue that Mayawati’s promotion of Dalit welfare seems to start with herself. But there is no denying that her rise to power in India’s largest state, which sends 80 members to parliament, has given her a vital platform to bid for India’s most powerful job.
With her diamonds and her statues, and a reputation for dealing imperiously with her subordinates, she’s clearly no Obama.
But if she succeeds, she will have overcome a far longer legacy of discrimination.
An Old Problem on China’s New Frontier
WARSAW – Had the August 1991 putsch against Mikhail Gorbachev not failed, the riots and death recently seen in Xinjiang could have been taking place in Russia.
Instead of hearing about a crackdown in Urumqi, Xinjiang’s capital, we might be reading about hundreds killed on the streets of Almaty, and columnists would be making comparisons to the bloody crushing of Ukrainian independence demonstrations in Lvov the previous year.
As with China today, there would have been some feeble international condemnation, and some speculation about possible links between Kazakh militants and exile groups, or Islamic fundamentalists.
Experts would remind us that Kazakhstan had never been a country, and that Ukrainian claims to independence are historically dubious.
Substitute Xinjiang for Kazakhstan and Tibet for Ukraine and you get the picture.
But that putsch, thankfully, ended as a farce.
The decaying Soviet regime was unable to crush Russia’s growing democratic movement – it would take Vladimir Putin to do that a decade later.
By opting for the Tiananmen Square massacre in 1989, the Chinese Communist leadership set their country on a road starkly different from the one on which Russia subsequently embarked.
Though China’s policies have brought about Pinochet-style economic growth, if on the scale of a country that is almost a continent unto itself, they have also ensured that there is in no freedom for anyone, including the Han majority.
This, in turn, means that, while Kazakhstan and Ukraine are independent, Tibet and Xinjiang alternate between phases of violent agitation and bloody repression.
Though Russia today is autocratically governed, the introduction of a Chinese-style dictatorship seems hardly plausible, while GDP per capita was $15,800 last year, or almost three times that of China.
Yet a majority of the Chinese population seems to support its’ government’s policies, including its brutal suppression of minorities and denial of democratic freedoms.
In fact, the latter seems to be the price paid for the success of the former.
This is not a novel phenomenon.
In 1863, the Russian democratic émigré thinker Alexander Herzen, commenting on the brutal crushing of the Polish uprising by the Tsarist army, wrote in his publication
When Herzen was writing his words, Moscow was not only busy successfully putting down the Poles, reasserting its rule there for another half-century, but also, together with China, carving up Central Asia, known then as Turkestan.
The eastern part of the region fell under Chinese rule, and was renamed Xinjiang, or New Frontier.
Each time Chinese rule weakened, as in the 1930’s and 1940’s, short-lived East Turkestan Republics were established, with Russian support, only to flounder when Russia and China struck new deals.
The leadership of the second East Turkestan Republic was presumably murdered on Stalin’s orders, when the plane carrying it to Beijing for talks allegedly crashed in Soviet airspace.
Since then, East Turkestan has existed solely on paper, as a member of the Unrepresented Nations and Peoples Organization (UNPO), a would-be competitor of the United Nations set up in 1991.
In Xinjiang itself, the current agitation is more social than nationalist in character, and targets cultural oppression (Han Chinese by now make up half of the region’s population) rather than expressing aspirations for independence.
Yet the recent bloodbath there is almost sure to change that, as violence unavoidably breeds radicalization.
In the short and medium term, China’s rule in Xinjiang and Tibet seems secure: the international community will not challenge a Security Council member state.
Only its own citizens could do that, but Herzen’s package deal seems to prevent that: just like the Tibetans, the Uighurs elicit not Han solidarity, but a braying for their blood – somewhat understandable, given that ordinary Han in Lhasa and Urumqi were made to pay with their own for China’s misdeeds.
In the longer term, however, the Chinese authorities have every reason to be worried: Xinjiang will grow to be a problem like Tibet.
Indeed, though the UNPO, to which both belong – alongside Assyria and the Buffalo River Dene Nation – has a vaguely Marx Brothers’ air to it (one expects Freedonia, the mythical country of which Groucho Marx was prime minister, to be on the roster), six member states already have left it to join the UN, and Kosovo, now independent if lacking UN recognition, will eventually follow.
Political maps are never carved in stone.

It is therefore safe to assume that not only obscure academics and correspondents, but officials in Beijing as well, are now busy studying the history of the Ghulja uprising and of Osman Batur’s guerillas.
Come to think of it: whatever happened to the Poles, whom Russia so successfully put down in 1863?
An Open Letter to Ehud Olmert
Dear Mr. Olmert,
I am writing you in the hope that you will take time from your busy schedule as Israel’s acting Prime Minister to hear one Palestinian’s hopes.
Even though your ascension to the position of Prime Minister came in an awkward way because of Ariel Sharon’s stroke, I believe that you have an opportunity to be part of a historic reconciliation.
While I am sure you will insist that you are going to follow in the political legacy of Sharon, you have some important advantages with Palestinians that Sharon did not have.
The first advantage is that you’re not burdened with Ariel Sharon’s negative image among Palestinians and Arabs.
Having been the mayor of Jerusalem for 10 years, you know the situation of Palestinians close up.
I believe that the chances for a political breakthrough in our region have never been better.
On the Israeli side, your faith in the political process was demonstrated recently when you and Sharon decided unilaterally to go against your own ideology and take on the powerful settler movement.
The two of you also went against conventional Israeli thinking by breaking away from your Likud party, greatly weakening the ideological stranglehold that Likud’s far-right central committee held on Israeli politics.
The realization that withdrawal from populated areas, and thus an end to holding another people under permanent occupation, was necessary to preserve the Jewish nature of Israel clearly brought the two of you to the center of Israeli thinking.
On a much smaller scale, significant change has been taking place on the Palestinian side as well.
While I believe that the occupation, rather than the reaction to it, is the main cause of our conflict, the unilateral tahdia (“declared calm”) decision by Palestinian militant groups has reduced anti-Israeli attacks mightily, which shows that Palestinians also realize the limits of their military actions.
The decision by Hamas to join the political process by participating in the upcoming legislative elections shows that even this hardline Islamic movement has concluded that our conflict needs to be addressed by political rather than military means.
While I understand that you are an Israeli patriot, I believe that much can be done to reduce the tensions between our two peoples, eventually leading to genuine reconciliation and peace.
As a start, priority must be given to face-to-face negotiations.
Sharon and you might have felt that unilateral action was needed in Gaza, but the withdrawal from Gaza could have produced many more benefits for both sides had it been done bilaterally.
Direct talks should concentrate on two parallel tracks.
They should attempt to produce an immediate cessation of violence from both sides while simultaneously focusing on a permanent settlement of our conflict.
Contrary to territorial withdrawal, cessation of violence can be achieved only bilaterally.
Both sides should commit to an end to assassinations, shelling, bombings, and any other form of attacks on the other side’s military targets and citizens.
To be effective, such a cease-fire must contain a monitoring mechanism.
Neutral foreign observers should be asked to be deployed in major hot spots and be asked to identify anyone on either side who violates any of the agreement’s clauses.
Alongside this effort, vigorous negotiations on a permanent settlement should start immediately.
Historically, cease-fires have survived only when they are backed by talks that both parties believe are genuine and serious.
At the same time, the atmosphere among Palestinians and their attitude towards Israel must be improved, so that we can have a political environment that supports negotiations.
Improving the daily conditions of life, particularly increasing Palestinians’ freedom of travel both between Gaza and the West Bank and within the West Bank, will also go a long way in helping to create a positive atmosphere.
I truly wish you success in your responsibilities as acting Prime Minister and acting head of Kadima.
Your efforts to move forward towards resolving the Palestinian-Israeli conflict will generate significant improvement in the political atmosphere in the entire Middle East.
But, whatever you do in the next few months to win the forthcoming parliamentary elections, please remember that the support that Kadima has received from the Israeli public derives precisely from the fact that it has taken a moderate centrist position.
So please don’t allow yourself to be drawn into pandering to Israel’s radicals and hawks.
The support that you and your colleagues will get from Israelis and Arabs will depend on the resolve that you show in making serious progress in the peace process.
That process, now as before, must culminate in an independent and democratic Palestine alongside a safe and secure Israel.
An Ugly Peace for Sudan
STANFORD – Well, America is involved at last.
President Barack Obama has dispatched Senator John Kerry to Sudan with a proposal for peace between the country’s North and South.
It’s a giant step toward avoiding the kind of bloodshed that killed more than two million people in Sudan’s previous 20-year North-South civil war, which ended only in 2005 – and is threatening to erupt once again.
In recent months, Obama has stepped up his own involvement and that of senior figures in his administration in support of a peace strategy for Sudan.
On his behalf, Kerry has delivered a package of proposals designed to break the logjam that has brought the North and South to a dangerous crossroads.
We have written a memo that spells out some of the essential elements of what a grand bargain for peace in Sudan could look like.
If you’re interested in the specifics of a possible peace deal – and in actions that you can take to support it – go to www.sudanactionnow.org.
There is little time to waste.
On January 9, 2011, the people of Southern Sudan will vote for independence from the North, taking with them up to three-quarters of the country’s known oil reserves and placing millions of civilians in the direct path of war.
The government in Khartoum (the capital in the North) is led by Omar al-Bashir, whose accomplishments, which include overseeing war crimes during the previous North-South war and engineering the atrocities in Darfur, have brought him arrest warrants for war crimes and genocide from the International Criminal Court.
And yet renewed war in Sudan is not inevitable.
A complex but workable peace can be brokered if all interested parties become more deeply involved.
The current moment requires robust diplomacy – the kind that can leave a bad taste in your mouth, but that gets the job done.
We believe that Kerry is a skilled emissary and can help the parties find the compromises necessary for peace.
Any agreement preventing a return to war would necessarily involve the National Congress Party, representing the North, and the Sudan People’s Liberation Movement, representing the South.
But it would also involve the United States, whose post-referendum relationship with the two parties will have enormous influence over whether a deal gets done.
We believe that a grand bargain to lay the foundation for lasting peace between the North and South would oblige the parties to:
·        hold the Southern Sudan referendum on time and fully respect and implement the results;
·        reach a mutually satisfactory agreement concerning the territory of Abyei, a key disputed border area;
·        craft a multi-year revenue-sharing arrangement in which the oil wealth of Abyei and key border areas could be divided equitably between the North and South, with a small percentage going to the Arab Misseriya border populations for development purposes;
·        demarcate the uncontested 80% of the border and refer the remaining 20% to binding international arbitration;
·        create serious protections for minority groups, with consideration of joint citizenship for certain populations, backed by significant international consequences for attacks on southerners in the North or northerners in the South.
The US role as the invisible third party to the agreement involves a series of incentives offered to the regime in Khartoum to ensure agreement and implementation of a peace deal.
In exchange for action on the North-South and Darfur peace efforts, the US would implement a clear, sequenced, and binding path to normalization of relations.
This would involve – in order – removal of Sudan from the State Sponsors of Terrorism list, exchange of ambassadors, lifting of unilateral sanctions, and support for bilateral and multilateral debt relief, together with other economic measures by international financial institutions.
Conversely, the US must be prepared to lead international efforts to impose severe consequences on any party that plunges the country back into war.
Peace and security in Darfur should be an essential benchmark for normalized relations between the US and Sudan.
The Obama administration should hold firm on this through the coming rounds of negotiation, and should appoint a senior official to help coordinate US policy on Darfur in order to ensure that peace efforts there receive the same level of attention as the North-South efforts.
What is needed now is political will – and not only in the US – to sustain this diplomacy.
The European Union and Sudan’s neighbors – in particular Egypt, Ethiopia, Kenya, and Uganda – will also need to play a robust role.
And China’s diplomacy in Sudan, where it has invested massively in developing the country’s oil resources, will be a test of whether or not it intends to be a responsible stakeholder in Africa and the wider world.
Ensuring that governments work toward peace is where you come in.
Keep the pressure on them.
Support the peace process.
Your voice can prevent a war.
Not guns. Not money.
Just our voices.
The way to peace in Sudan is not simple, but it is achievable.
There are hard choices to be made.
We can make those choices now, or we can persuade ourselves that peace is too hard or too complex, and then look on resignedly from the sidelines as hundreds of thousands of innocent men, women, and children needlessly die.
It’s up to us.
The Uses of Nuclear Ambitions
MADRID – The agreement reached in Geneva in the wee hours of November 24 between Iran and the P5+1 (the five permanent members of the United Nations Security Council, plus Germany) on Iran’s nuclear program proves a crucially important point: the sanctions regime worked.
The interim deal is Iran’s first compromise on its nuclear program in more than a decade, and a diplomatic victory in a field long overshadowed by the looming cloud of military intervention.
Yet the euphoric reaction seen in some quarters is misplaced.
Beyond the ambiguities and limitations of the six-month agreement, the negotiations have clearly exposed Iran’s nuclear-weapons program and, more broadly, its understanding that nuclear weapons remain a geostrategic status symbol.
This points to the difficulty of achieving a comprehensive agreement and the possibility that the international effort could result only in a series of small deals aimed at delaying Iran’s acquisition of a nuclear weapon rather than removing the threat of it altogether.
Beneath the headlines of the historic deal lies a limited and ambiguous agreement.
The joint statement released by European Union High Representative Catherine Ashton and Iranian Foreign Minister Javad Zarif referred to the agreement as “a joint plan of action” that “sets out an approach toward reaching a long-term comprehensive solution.” While it includes a first step that “creates the time and environment needed for a comprehensive solution,” the interim accord is really about confidence-building measures.
Indeed, the obligations that it lists are referred to as “voluntary measures.”
At best, the agreement maintains the current status quo, and in some respects even allows for further development of Iran’s nuclear program.
In this sense, perhaps the most troubling aspect of the interim deal concerns Iran’s yet-to-be-opened Arak plant, which would offer a path to domestic plutonium production and weaponization.
Though the agreement reached in Geneva includes Iran’s pledge not to transfer fuel or heavy water or commission its Arak reactor, there does not appear to be any overarching moratorium on construction at the site.
According to the International Atomic Energy Agency, the Arak plant still lacks several major reactor components, such as control-room equipment and cooling pumps. So, Iran, it seems, will be able to advance its plutonium program during the six-month confidence-building period.
That loophole is all the more troubling in light of French press reports this week concerning Western intelligence on the construction of facilities in Shiraz that may be used to separate plutonium in order to create the fissile material needed for nuclear weapons.
That Iran’s push to acquire the capacity to produce nuclear weapons is partly motivated by security concerns cannot be denied.
Nationalism, however, is a more important factor.
It is not just that all the great powers have nuclear weapons; the problem, from Iran’s perspective, is that lesser powers – particularly neighboring states such as Pakistan and Israel – have them. The Iranians regard themselves as the heirs to a great and ancient civilization, and their ambition of achieving regional preeminence reflects this.
At the same time, they perceive their country to be marginalized, discriminated against, and the target of aggressive international condemnation.
Nearly 70 years after the bombing of Hiroshima and Nagasaki, the view persists globally that gaining a seat at the grownup table of geopolitics requires nuclear weapons.
Germany is an exception, though hardly a geostrategic heavyweight; and though Japan knows the horror of nuclear war, important domestic voices there are calling for a change of its non-nuclear status.
This view of nuclear weapons as a shorthand for national greatness is reinforced by the architecture of the non-proliferation regime, which firmly divides states into two camps: nuclear haves and have-nots. That nuclear chauvinism is an attitude reinforced by the “haves” of the Nuclear Non-Proliferation Treaty – China, France, Russia, the United Kingdom, and the United States – which also constitute the P5.
As long as possessing nuclear weapons remains a state’s clearest way to demonstrate its bona fides as a great power, maintaining the potential to develop such weapons will be too tempting for countries like Iran to forswear.
What is needed is a global shift away from the equation of nuclear weapons with geopolitical greatness. Progress on various efforts to sever this link have not been very encouraging, as was recently demonstrated by the Kremlin’s negative reaction to US President Barack Obama’s proposal that both sides cut their nuclear stockpiles.
Meanwhile, non-P5 nuclear-weapons states continue to expand their arsenals, with Pakistan and India estimated to have nearly tripled their stockpiles during the past decade.
The interim agreement with Iran marks an important juncture.
Above all, it shows that international sanctions can bear fruit, and that a diplomatic way forward – even if proves to be a narrow one – is possible.
We can remain both ambitious and realistic.
But a comprehensive deal with Iran – and the need to preempt future epigones – requires a broader change: a world that not only excludes the offensive use of nuclear weapons but also acknowledges the ultimate unsustainability of their deterrent power.
Insecure Europe
MADRID – For the last five years, Europe has been shaken by financial and economic convulsions that have wreaked havoc on many of its citizens’ livelihoods.
The good news is that progress is finally being made in redeveloping the European Union’s economic and monetary architecture, which should help to bring about a return to growth.
But EU leaders’ focus on internal problems has caused them largely to neglect external policies, particularly in the area of security.
As 2014 begins, economic insecurity is giving way to worries about the EU’s strategic position.
There were expectations that the European Council’s December meeting would signal a return to a more outward-looking approach, especially on security matters.
Unfortunately, these hopes were quickly dashed.
Indeed, the disparate assortment of initiatives that were agreed at the meeting, though interesting, lack the needed breadth and scope, and will have to be integrated within a weak and outdated strategic framework.
The flawed nature of the current European Security Strategy – drafted in 2003, with a token revision in 2008 – reflects the circumstances surrounding its conception.
The ESS was developed in the aftermath of the Iraq war, amid heated debate over a proposed European constitution, in a hasty and reactive process hijacked by those who sought to position Europe as a counterweight – or even a rival power – to the United States.
Making matters worse, the geopolitical environment has changed fundamentally in the decade since the ESS was ratified, owing to economic rebalancing toward Asia, the upheavals in the Arab world, the revival of Russian assertiveness, and the rise of isolationist tendencies in the US.
As a result, the ESS does not capture the reality of today’s world – a fact that is obvious from its opening declaration that “Europe has never been so prosperous.”
To be sure, the ESS’s three basic tenets – development assistance, soft power, and effective multilateralism – remain important.
But Europe’s leaders must reconceive these concepts in light of today’s challenges.
In terms of development, Europe must move away from the idea that aid should be used to bolster trade linkages and acknowledge the importance of foreign investment.
In fact, net private capital flows to developing countries now outweigh official development assistance by nearly ten to one worldwide.
As the world’s second-largest source of foreign direct investment, the EU wields considerable influence, with European investors bringing credibility to projects and regions, thereby serving to attract further investment.
For example, Morocco’s Ouarzazate Solar Power Plant and its Drinking Water Efficiency Program were launched with €37 million ($50.6 million) from the EU’s Neighborhood Investment Facility; these projects subsequently gained additional funding totaling more than €600 million.
The ESS’s emphasis on soft power is also in urgent need of reassessment.
The upsurge of protest across the Arab world raised expectations among Europeans that these countries would, to some extent, emulate Western institutions, values, and norms.
But, while that did not occur, European principles certainly have not lost their allure, as recent protests in Ukraine, triggered by President Viktor Yanukovych’s decision to shun closer ties with Europe, have shown.
Nonetheless, the ESS’s soft-power vision should not be allowed to obscure the security challenges that Europe faces.
With the rise of non-traditional threats, Europeans are increasingly overlooking classical security risks like inter-state warfare, believing that they are no longer relevant – a notion that is reflected in the ESS.
But, as China’s increasingly assertive stance in the South and East China Seas starkly demonstrates, this idea is not only wrong; it can be very dangerous.
This brings us to the ESS’s third tenet: advancing “the development of a stronger international society, well-functioning international institutions, and a rule-based international order.” In this case, the problem comes down to a lack of commitment, with the EU choosing the convenience of informal and ad hoc groupings over the challenge of reforming key institutions like the United Nations, the International Monetary Fund, and the World Bank, which are essential for effective multilateralism.
Indeed, the EU is among the leading actors in the current “G” fad, which has culminated most recently in the G-20.
And, despite being an embodiment of international law, the EU indulges in soft-law approaches, whether at the recent COP-19 climate-change meeting in Warsaw, or by supporting the “Geneva agreement” on Iran’s nuclear program, which, it is now clear, is nothing more than two aspirational declarations linked by a press release.
In developing its new security strategy, Europe must consider America’s role as an essential component of the geopolitical environment, viewing the US not as a foil, but as a nuanced partner.
Beyond NATO, which remains important even at a low ebb, the proposed Transatlantic Trade and Investment Partnership offers a potent opportunity to shape a rule-based international order.
The shine may have come off the EU, but the gripping scenes from Kyiv’s Maidan Square are a powerful reminder of the enduring appeal of Europe’s core values.
What the EU needs now is an updated external strategy that capitalizes on this allure to bolster its influence, security, and prosperity, thereby halting its slide toward irrelevance.
America’s Strategic Blindness
MADRID – The recriminations over US spying activities, triggered by the revelations of the former American intelligence contractor Edward J. Snowden, have now reached fever pitch.
Questions abound – about what President Barack Obama knew and when, about the legitimacy of eavesdropping on friendly foreign leaders’ conversations, about the future of transatlantic relations, and even about the meaning of the term “ally.”
But the current firestorm, like other recent diplomatic crises for the United States, reflects a more fundamental problem: the lack of strategic vision in American foreign policy.
Until the US is able to establish an overarching, purpose-oriented framework through which it relates to the world, a reactive approach is inevitable, with high-intensity incidents such as we have seen this month continuing to be the norm.
For more than 40 years, the Cold War policy of containment of Soviet influence provided America its strategic framework.
Though US tactics were debated and shifted from administration to administration, the overarching approach remained consistent, because it was broadly supported by Republicans and Democrats alike.
Of course, an overarching national-security strategy provided no guarantee against problems or even major disasters in countries like Vietnam and Nicaragua.
Nonetheless, in hindsight, containment infused an order and organization on US foreign policy that is absent today.
After the fall of the Berlin Wall, the necessity that had been driving containment disappeared.
The US, inebriated by victory, saw in the triumph over the Soviet bloc another sign of its exceptionalism, and found itself taken in by the mirage that its Cold War success was itself a strategy.
What followed was a decade of scattershot foreign policy marked by notable cases of inaction, together with individual initiatives taken largely without reference to a broader doctrine.
Unchallenged in the world’s unipolar moment, the US had the luxury of not knowing its strategic goals.
Shocked by the attacks of September 11, the US forced a new framework onto its still-unquestioned belief in the inexorable movement of history toward freedom.
Unfortunately, what emerged was a deeply flawed approach, not least because in declaring a “war on terror,” America positioned itself against a tactic, not an entity or an ideology.
Under Obama, the US has begun to depart from this approach.
The problem is that it remains a departure without any meaningful destination.
As in the 1990’s, the US has no organizing imperative, and the result is the same: a combination of inactivity and incoherent initiatives.
And, at a time of domestic political polarization, the lack of a global strategy denies a potential rallying point around which Democrats and Republicans can unite.
Two decades ago, geopolitical conditions limited blowback from America’s foreign-policy vacuum.
Today, the US remains the world’s essential power, but it is no longer the exclusive power.
It cannot solve problems that directly affect it by acting on its own, though its leadership remains indispensable.
That is all the more true given that the nature of such problems has also changed.
America, like the rest of us, is vulnerable to climate change, pandemics, and terrorism – challenges that require coordinated global solutions.
For the US, however, the utility of multilateralism is purely situational.
Above all, multilateralism is never preferable to a “good” bilateral solution – a view that has reinforced behavior that undermines, rather than strengthens, the capacity for effective international action.
Indeed, always ready to negotiate treaties but rarely prepared to sign – and even less likely to ratify – them, the US remains absent from such key global agreements as the Kyoto Protocol, the Mine Ban Treaty, and the UN Convention on the Law of the Sea.
Its inspired creativity and support in building formal institutions like the United Nations and World Bank has given way to a predilection for weak, informal, and ad hoc groupings, such as the various G-somethings and “coalitions of the willing.”
Establishing effective multilateralism requires an emphasis on rules and institutions that facilitate coordination.
The recent decision by the US to sign the Arms Trade Treaty could be a good start – if only Congress could marshal the bipartisan support needed to ratify it.
But scattered moves in the right direction will not suffice.
What is really needed is a change in vision and mentality – a shift from viewing multilateralism as a tactic to embracing it as a strategic imperative.
The current spying scandal is the product of a rudderless US foreign policy focused on narrowly drawn tactical objectives that exist outside the conceptual funnel of a comprehensive vision.
The result in this case has been damage to the transatlantic relationship, with some in Europe even calling for a halt to the talks on the proposed Transatlantic Trade and Investment Partnership (TTIP).
Suspending the trade talks would be folly, not just in terms of the regional impact, but also because the TTIP should be an exercise in rule-making that echoes globally.
The current diplomatic crisis, too, is an opportunity to ensure that transatlantic discussions about privacy and surveillance reverberate in a multilateral setting; seizing it would represent a small but significant contribution to the strategic vision that has been sorely lacking for the last quarter-century.
Europe’s Juncker Revolution
MADRID – Before his appointment as EU Commission President, Jean-Claude Juncker was pilloried as an old-school federalist who would do little to alter the status quo.
But the new structure that he has imposed on the Commission implies a radical overhaul of how things are done in Brussels.
Up to now, a focus on who has been appointed to what post – in particular, the appointment of the relatively inexperienced Federica Mogherini as EU High Representative for the Common Foreign and Security Policy – has overshadowed the Commission’s structural transformation.
But individual commissioners are far less important than the trends that have caused the Commission to shift its priorities from enlargement and the internal market toward energy and monetary union.
One such trend is Europeans’ growing skepticism toward integration, exemplified in May’s European Parliament election.
With newer European Union members backsliding – Romania on the rule of law, Bulgaria in corruption, and Hungary on democratic norms under Viktor Orbán’s government – now is the time, or so it seems, to focus on existing members.
Reinforcing this shift is Turkey’s drift toward authoritarianism, which is undermining the viability of its candidacy for EU membership.
As for Ukraine, recent gestures of solidarity, such as the signing of an association agreement, are unlikely to develop into anything substantial in the foreseeable future.
In downgrading EU enlargement as a formal policy priority, the Commission is preparing itself to take other important steps.
The upheaval among Europe’s southern and eastern neighbors may well bring about a long-overdue revamping of the EU’s Neighborhood Policy.
And, in pursuit of other avenues for expanding the EU’s reach, European leaders might reinvigorate the European Economic Area.
Another policy area that has lost its centrality is the internal market – a notable decision, given that it has been the centerpiece of the European project since the Commission was created in 1958.
The internal market’s four pillars – the free movement of goods, services, capital, and people – have underpinned broader EU measures, in areas like foreign policy and justice and home affairs, and will now be subsumed under new policy labels, from economy and financial affairs to the digital agenda.
This move away from the internal market can be explained partly by member governments’ aversion to more EU-level legislation.
Though complaints about the “bloated” acquis communitaire (the body of EU law) are often unfounded, the EU legislative process is not without its shortcomings, as recent attempts at harmonization clearly demonstrate.
For example, for the EU-wide statutory audit that was completed in April, the European Parliament agreed to a revised directive and new regulation that should have been directly applicable in all 28 member countries.
But, in more than 20 cases, member states were given discretion over its implementation and interpretation.
The new Commission will attempt to change this by focusing on rule implementation and oversight, rather than creation.
This effort will be coordinated by representatives in seven newly established vice-presidential positions, and spearheaded by the first vice president to have a portfolio focused on “better regulation.”
To be sure, easing regulatory burdens is a longstanding leitmotif of the EU.
Though the last two Commissions, led by José Manuel Barroso, espoused a commitment to rationalizing, clarifying, and compiling rules, little concrete action has been taken.
Juncker’s changes, however, may portend genuine progress on this front, as well as toward monetary and energy union.
Indeed, the new Commission’s structure suggests that Juncker hopes to enhance its role in guiding the European Monetary Union and related policies, control over which largely rested with the European Council and EU member governments (especially Germany) during the crisis.
Similarly, a new vice president has been introduced for energy, which has been reframed as “energy union.”
The lack of progress on this front during the last two Commissions was rooted mainly in Germany’s Russian modernization project, which has shaped its approach to energy security.
For its part, France has been reluctant to build an interconnected European grid, owing to its heavy reliance on nuclear energy.
Given Russian behavior in Ukraine, however, EU leaders have been rethinking their approach.
In this context, the Commission’s new structure – not to mention the fact that the new European Council president, former Polish Prime Minister Donald Tusk, has long sought an energy union – may well push the policy forward.
Though it is impossible to understand fully the implications of the Commission’s new structure at this early stage, some of its institutional ramifications are already emerging.
Beyond inciting a kind of tug-of-war with the European Council, the Commission’s shift away from lawmaking will alter the European Parliament’s role, which it has forged over the last five years on the back of the Commission’s active legislative agenda.
With little authority to initiate legislation, the Parliament, too, will have no choice but to pivot toward oversight.
Precisely how all of this all plays out in the coming months and years will determine whether the European project progresses or stagnates.
Perhaps observers should be paying a little less attention to the “who” and a bit more to the “what.”
Africa Beyond Ebola
MADRID – Among this summer’s grave global worries, the spread of the Ebola virus has monopolized the discussion of Sub-Saharan Africa and reinvigorated hoary notions of disorder and despair – at a time when a new image of a dynamic Africa was emerging.
In fact, there is still strong reason for optimism about the region’s prospects.
The Ebola outbreak overshadowed three key events affecting the region. On July 1, a major organizational restructuring at the World Bank Group was implemented.
Two weeks later, the BRICS (Brazil, Russia, India, China, and South Africa) announced the establishment of the New Development Bank.
And, in early August, African government and business leaders gathered in Washington, DC, for a summit that could portend transformative private investment in Africa.
Such investment is essential in a world in which net private capital flows to developing countries outstrip official development assistance by a margin of ten to one.
If this is to be a turning point for Africa, rather than another false dawn, this summer must be the start of a prolonged effort to stimulate private-sector engagement.
The reorganization of the World Bank is a central part of a larger effort under its president, Jim Yong Kim, to reposition the Bank as a facilitator vis-a-vis the private sector, rather than a primary provider.
From 2009 to 2013, new investment commitments by the International Finance Corporation, the World Bank’s private-sector lending arm, have risen 73%.
Meanwhile, the Multilateral Investment Guarantee Agency, the Bank’s provider of political risk insurance covering investments in developing countries, has moved to expand its activities, both by broadening the types of projects that it supports and widening existing definitions to allow greater coverage.
July’s restructuring occurs within the context of these broader moves.
In reorganizing the World Bank Group’s central component, the International Bank for Reconstruction and Development, Kim has adopted a management-consulting model that unites expertise with regional coverage.
Seeking to eliminate the bureaucratic “silos” that have isolated regional experts from one another, 14 global practice groups in areas such as energy, water, and education have been established to bring to bear the full force of the World Bank’s considerable knowledge on projects and partnerships.
Just as the World Bank was repositioning itself, the BRICS agreed to establish their own bank.
There are significant outstanding issues about how the New Development Bank will operate, but early indications suggest that infrastructure will be central to its activities, with an emphasis on Africa.
The World Bank estimates that insufficient infrastructure reduces productivity in Africa by approximately 40%.
The entrance of a new player with initial authorized capital of $100 billion – along with the United States’ Power Africa program, which has garnered $26 billion in commitments since its launch last year, and the World Bank’s new Global Infrastructure Facility – promises to help ease infrastructure financing significantly.
But, as of now, the New Development Bank is little more than a statement of political solidarity, and whether it comes into existence remains to be seen.
Even if it does begin to function, the BRICS lack what gives development banks, and the World Bank in particular, legitimacy and weight: a staff composed mostly of dedicated experts who are among the world’s best.
Finally, the high profile of the US-Africa Leaders Summit, with more than 40 heads of state in attendance, as well as President Barack Obama’s direct involvement, generated buzz about Africa.
US businesses and investors certainly gained more awareness about Africa’s potential and a deeper understanding of the variety of investment climates throughout the continent.
But, though the summit may be called a success, its long-term implications are unclear, particularly given the uncertainty about what will follow.
At the moment, there does not seem to be a plan to institutionalize the summit.
Moreover, the participation of so many heads of state overshadowed that of African business leaders.
The practical connections that US companies will need when deciding whether to invest could have been cultivated on the summit’s margins, or in its aftermath, but were not.
Laying a foundation for future engagement requires ongoing commitment and effort that goes beyond mere publicity.
The same could be said about the World Bank.
There is much work to be done in integrating the new organizational model with existing Bank structures and practice areas.
Even if this transition occurs seamlessly, the Bank faces a serious internal struggle against entrenched bureaucratic interests and a pervasive institutional mindset that is overly risk-averse and fixates on processes rather than outcomes.
In recent years, Africa, once a land of pity, has emerged as a land of opportunity.
If it is to become a land of performance, the goal must be to facilitate investment, both domestic and foreign.
That will demand effort and commitment; given that a stable international order increasingly depends on a prosperous and growing Africa, it is a goal that the world cannot afford to miss.
Europe’s Iranian Imperative
MADRID – Last month, with the world’s attention fixed on the crisis in Crimea and the search for Malaysian Airlines Flight 370, the latest round of negotiations between Iran and the P5+1 (the United States, China, France, Russia, and the United Kingdom, plus Germany) passed quietly in Vienna.
Even with discussions set to continue next week, the talks’ outcome remains far from certain – and world leaders cannot afford to become distracted.
This is especially true for Europe, whose unified approach to Iran has been invaluable up to this point.
Indeed, it was the bite of European sanctions that ultimately brought Iran to the negotiating table, and the force of unified European diplomacy facilitated the “joint plan of action,” which set out the terms for reaching a comprehensive long-term agreement within six months.
But now, at the plan’s halfway point, there has been little concrete progress, with last month’s negotiations producing no headway on two key issues being discussed: the acceptable level for uranium enrichment in Iran and the future of the heavy-water reactor at Arak.
The sharp contrast between this lack of achievement and Iran’s recent declarations about reaching a final deal by July raises important questions about Iran’s strategy and goals – questions that negotiators must consider carefully when determining the best approach.
The key to success is the background against which the process plays out.
Iran is a land of contrasts.
On a recent visit organized by the European Council on Foreign Relations (ECFR), the coexistence of entrenched tradition and rapid transformation was starkly apparent.
Central Tehran – ebullient with young people and high-heeled women donning testimonial headscarves and mid-thigh jackets over pants – embodies a thirst for openness.
More than 60% of Iranians were born after the 1979 Islamic Revolution, and more than 40% were born after the Iran-Iraq War of the 1980’s.
For them, the revolution is a part of history, not the main source of their personal values.
The toll taken by years of tough economic sanctions is also apparent.
Despite Iranian officials’ best efforts to downplay the sanctions’ impact, it is difficult to spin inflation in excess of 30% and projected GDP growth of just 1% this year.
The combination of a young population and a crumbling economy is a combustible mix, one that amounts to an existential threat to the regime – and the regime knows it.
In this sense, the imperative to reach a prosperity-enhancing agreement with the international community is greater than ever for Iran’s leadership.
Furthermore, Iran’s negotiating style, like its capital city, can be both fatiguing and confusing.
Just moments after elaborating at length on the Koran’s prohibition of nuclear weapons, an interlocutor would declare that the underground Fordow nuclear facility’s impregnability to airstrikes must be central to any deal.
The reality is that Iran does not envisage giving up its nuclear breakout capacity.
The negotiations are aimed not at eradication, but at lengthening lead-time – specifically, limiting uranium-enrichment levels to 3.5%, establishing a strong inspections regime, and reaching an agreement on the Arak nuclear facility.
But even this may not happen.
After all, Iranian officials have thus far not demonstrated their commitment to accepting stringent and verifiable checks.
Moreover, Iran has managed to separate the nuclear negotiations from broader, related issues like its ballistic-missile program, its support for groups like Hezbollah, and its domestic human-rights record.
With the US loath to introduce potential spoilers into the mix, there is no chance that any of these issues will be up for discussion.
In this context, EU High Representative Catherine Ashton’s meeting with dissidents during her most recent trip to Tehran was merely a symbolic gesture.
This leaves Iran the opening it needs to place a strategic bet that the Syrian conflict will generate increasing friction between the West and Iran’s regional archrival, Saudi Arabia.
For Iran, a staunch supporter of Syrian President Bashar al-Assad’s regime, a weaker US-Saudi relationship is key to shifting the regional balance of power – especially if it is accompanied by the easing of Western economic sanctions.
To some degree, this hope is reinforced by Iran’s perception of US President Barack Obama as a motivated partner in the nuclear talks.
After all, a long-term agreement would be both a singular foreign-policy achievement for Obama and a boon to his efforts to disentangle the US from the Middle East.
But Iran also recognizes that the clock is ticking.
Obama’s presidency is coming to an end, the Republicans are poised to regain control of the Senate in November’s mid-term election, and Democrats are increasingly reticent to be viewed as “soft on Iran.”
As a result, the US Congress appears to be growing more hostile toward a deal; indeed, the longer it takes to conclude a final agreement, the more likely Congress is to scupper it.
In this context, Europe has a key role to play.
While Europe’s reputation for foreign-policy “softness” continues to shape Iranian perceptions, the EU’s role in compelling Iran to negotiate underpins the current talks.
Likewise, it was France’s insistence on more stringent controls that initially blocked the agreement in Geneva last November.
A decade ago, Europe disappointed Iran by withdrawing from negotiations, under pressure from the US – a move that some have suggested aided former Iranian President Mahmoud Ahmadinejad’s rise to power.
Today, Europe will be critical to driving progress, particularly in the event that the US Congress torpedoes a sensible agreement.
Indeed, on Iran, Europe’s unified approach has enabled it to have a greater impact than on any other significant foreign-policy issue.
This should be regarded as a model for the future and a lesson for the present.
By preserving its unity of purpose and maintaining the pressure and negotiating momentum that it has generated, Europe can demonstrate to Iran, the US, and itself that it has what it takes to be a major global actor.
Forsaken Syria
MADRID – In this year of ubiquitous commemorations, the centennial of Jan Karski’s birth has been largely overlooked.
And yet Karski’s legacy is more important than ever – nowhere more so than in Syria.
As the Geneva II peace process slogs along – leaving cadavers and atrocities to pile up – Karski’s dedication to bringing the plight of Poland’s Jews to the world’s attention during World War II, despite the inertia of governments and publics, embodies exactly what Syria desperately needs.
In 1942, Karski, a Polish-born diplomat, traveled to the United Kingdom to report on what came to be called the Holocaust.
The next year, he embarked on a mission to the United States to brief President Franklin D. Roosevelt and other dignitaries on the horrors that he had witnessed.
In both cases, he was met with skepticism and apathy.
Indeed, it was only toward the end of the war that action was taken to stop the slaughter.
Although the Holocaust is a category of persecution sui generis, one cannot avoid thinking of Karski in light of the international community’s approach to Syria today.
Expectations for the Geneva talks are so low that trivial matters – such as the fact that President Bashar al-Assad’s negotiators and the opposition are sitting together in the same room (though not at the same table) – are being hailed as successes.
Even the agreement to allow women and children to leave blockaded areas of the city of Homs – an anti-Assad stronghold – fell far short of international mediators’ vision (and even this achievement seems to be in doubt).
Instead of allowing a United Nations aid convoy to bring humanitarian aid to the area, the government agreed to release women and children on an as-yet-uncertain timeline, while men can leave only after their names had been cleared, raising fears of arrest.
Meanwhile, amid plodding deliberations of incremental steps that are clearly inadequate, Syrians are being displaced, wounded, tortured, and killed in droves.
By any measure, the level of suffering in Syria is shocking.
Although figures do not convey the cruelty by all sides, it has become de rigueur to cite the numbers: more than 100,000 dead, 2.3 million refugees, and four million people internally displaced.
But a year ago, the figures were already dire: 60,000 dead, 700,000 international refugees, and two million internally displaced.
If there were a threshold of misery that would cause the world to say, “Enough is enough,” it surely would have been crossed by now.
The ugly truth is that the world’s response to this crisis has been shaped by geopolitical interests, not the need to put an end to appalling human suffering.
Indeed, it is no secret that the conflict serves as a proxy for larger struggles – between Saudi Arabia and Iran, Saudi Arabia and Qatar, the US and Iran, Russia and the US, Shia and Sunni Muslims, and moderates and extremists – and that resolving it will require significant effort on all of these fronts.
From an American perspective, Syria is not strategically critical.
President Barack Obama’s administration has maintained an intensely inward-looking focus, reinforced by a public wary of foreign engagements.
Nothing short of a drastic change in the conflict’s nature that threatened America’s core interests would lead to direct US involvement.
Guilt, after all, is a poor motivator for international action.
Even the UK and France – the only two countries that were not shy about threatening military action against Assad’s regime – got cold feet when confronted with the possibility of going it alone.
Instead, the world is responding to graphic images of unspeakable brutality – torture by the regime or executions carried out by the opposition – with sterile shows of outrage.
The stream of statements, half-measures, and clumsy initiatives has done little to improve the situation – and, in some instances, has made things worse.
Consider Obama’s call, backed by no action, for Assad to “step aside,” and his repeated promises, dating to early 2012, to provide non-lethal aid to the Syrian opposition – promises that were finally fulfilled late last year, and then only temporarily.
This gap between rhetoric and action left a vacuum; Saudi Arabia, Qatar, and private donors subsequently filled it by channeling support to extremist elements of the opposition, strengthening their hand at the expense of those being called moderates.
But the most infamous example of this policy paralysis was Obama’s 2012 declaration that the use of chemical weapons was the “red line” beyond which the US would be forced to intervene.
His ultimate failure to follow through on his proclamation emboldened and, in a way, re-legitimized Assad.
It remains to be seen whether Geneva II will follow this pattern.
The price of the talks has already been high, with all sides having ramped up violence to strengthen their respective positions ahead of the negotiations.
This is to say nothing of the fiasco surrounding the withdrawn invitation to Iran, whose buy-in will be essential for any resolution.
In any case, the incremental nature of the talks belies the situation’s urgency.
Amid the current focus on regime change, a transitional government, and negotiating delegations, there is a real danger that the desperate humanitarian situation will be overlooked.
Here, citizens have a critical role to play.
But, like their leaders, publics everywhere have been reticent to act.
Indeed, opinion polls show that, despite near-universal awareness of the situation in Syria, there is very little public support for intervention.
But handwringing will not help; we – individuals – must accept real responsibility for ending the tragedy and press our leaders to act.
It has been more than 70 years since Karski presented his report to the world.
In that time, we have created the United Nations, adopted the Universal Declaration of Human Rights, and discussed endlessly governments’ “responsibility to protect” their citizens.
Yet, watching the Syrian tragedy develop, one might conclude that nothing has changed.
How many times must we say, “Never again”?
Anatomy of a Crisis
BERKELEY – Getting out of our current financial mess requires understanding how we got into it in the first place.
The fundamental cause, according to the likes of John McCain, was greed and corruption on Wall Street.
Though not one to deny the existence of such base motives, I would insist that the crisis has its roots in key policy decisions stretching back over decades.
In the United States, there were two key decisions.
The first, in the 1970’s, deregulated commissions paid to stockbrokers.
The second, in the 1990’s, removed the Glass-Steagall Act’s restrictions on mixing commercial and investment banking.
In the days of fixed commissions, investment banks could make a comfortable living booking stock trades.
Deregulation meant competition and thinner margins.
Elimination of Glass-Steagall then allowed commercial banks to encroach on the investment banks’ other traditional preserves.
In response, investment banks branched into new businesses like originating and distributing complex derivative securities.
They borrowed money and put it to work to sustain their profitability.
This gave rise to the first causes of the crisis: the originate-and-distribute model of securitization and the extensive use of leverage.
It is important to note that these were unintended consequences of basically sensible policy decisions.
Other things being equal, deregulation allowed small investors to trade stocks more cheaply, which made them better off.
But other things were not equal.
In particular, the fact that investment banks, which were propelled into riskier activities by these policy changes, were entirely outside the regulatory net was a recipe for disaster.
Similarly, eliminating Glass-Steagall was fundamentally sensible.
Conglomerates allow financial institutions to diversify their business, and combining with commercial banks allows investment banks to fund their operations using relatively stable deposits instead of fickle money markets.
This model has proven its viability in Europe over a period of centuries, and its advantages are evident in the US even now with Bank of America’s purchase of Merrill Lynch.
But conglomeratization takes time.
In the short run, Merrill, like the other investment banks, was allowed to double up its bets.
It remained entirely outside the purview of the regulators.
As a stand-alone entity, it was then vulnerable to market swings.
A crisis sufficient to threaten the entire financial system was required to precipitate the inevitable conglomeratization.
The other element in the crisis was the set of policies that gave rise to global imbalances.
The Bush administration cut taxes.
The Fed cut interest rates in response to the 2001 recession.
Financial innovation, meanwhile, worked to make credit even cheaper and more widely available.
This, of course, is just the story of subprime mortgages in another guise.
The result was increased US spending and the descent of measured household savings into negative territory.
Of equal importance were the rise of China and the decline of investment in Asia following the 1997-1998 financial crisis.
With China saving nearly 50% of its GNP, all that money had to go somewhere.
Much of it went into US treasuries and the obligations of Fannie Mae and Freddie Mac.
This propped up the dollar and reduced the cost of borrowing for US households, encouraging them to live beyond their means.
It also created a more buoyant market for the securities of Freddie and Fannie, feeding the originate-and-distribute machine.
Again, these were not outright policy mistakes.
Lifting a billion Chinese out of poverty is arguably the single most important event in our lifetimes.
The fact that the Fed responded quickly prevented the 2001 recession from worsening.
But there were unintended consequences.  The failure of US regulators to tighten capital and lending standards when abundant capital inflows combined with loose Fed policies ignited a furious credit boom.
The failure of China to move more quickly to encourage higher domestic spending commensurate with its higher incomes added fuel to the fire.
Now, a bloated financial sector is being forced to retrench.
Some outcomes, like the marriage of Bank of America and Merrill Lynch, are happier than others, like the bankruptcy of Lehman Brothers.
But, either way, there will be downsizing.
Foreign central banks are suffering capital losses on their unthinking investments.
As they absorb their losses on US treasury and agency securities, capital flows toward the US will diminish.
The US current-account deficit and the Asian surplus will shrink.
US households will have to start saving again.
The one anomaly is that the dollar has strengthened in recent weeks.
With the US no longer viewed as a supplier of high-quality financial assets, one would expect the dollar to have weakened.
The dollar’s strength reflects the knee-jerk reaction of investors rushing into US treasuries as a safe haven.
It is worth remembering that the same thing happened in August 2007, when the sub-prime crisis erupted.
But once investors realized the extent of US financial problems, the rush into treasuries subsided, and the dollar resumed its decline.
Now, as investors recall the extent of US financial problems, we will again see the dollar resume its decline.
Emphasizing greed and corruption as causes of the crisis leads to a bleak prognosis.
We are not going to change human nature.
We cannot make investors less greedy.
But an emphasis on policy decisions suggests a more optimistic outlook.
Unintended consequences cannot always be prevented. Policy mistakes may not always be avoidable.
But they at least can be corrected.  That, however, requires first looking more deeply into the root causes of the problem.
Anatomy of a Financial Meltdown
NEW YORK – A vicious circle is currently underway in the United States, and its reach could broaden to the global economy.
America’s financial crisis has triggered a severe credit crunch that is making the US recession worse, while the deepening recession is leading to larger losses in financial markets – thus undermining the wider economy.
There is now a serious risk of a systemic meltdown in US financial markets as huge credit and asset bubbles collapse.
The problem is no longer merely sub-prime mortgages, but rather a “sub-prime” financial system.
The housing recession – the worst in US history and worsening every day – will eventually see house prices fall by more than 20%, with millions of Americans losing their homes.
Delinquencies, defaults, and foreclosures are now spreading from sub-prime to near-prime and prime mortgages.
Thus, total losses on mortgage-related instruments – include exotic credit derivatives such as collateralized debt obligations (CDOs) – will add up to more than $400 billion.
Moreover, commercial real estate is beginning to follow the downward trend in residential real estate.
After all, who wants to build offices, stores, and shopping centers in the empty ghost towns that litter the American West?
In addition to the downturn in real estate, a broader bubble in consumer credit is now collapsing: as the US economy slips into recession, defaults on credit cards, auto loans, and student loans will increase sharply.
US consumers are shopped-out, savings-less, and debt-burdened.
With private consumption representing more than 70% of aggregate US demand, cutbacks in household spending will deepen the recession.
We can also add to these financial risks the massive problems of bond insurers that guaranteed many of the risky securitization products such as CDOs.
A very likely downgrade of these insurers’ credit ratings will force banks and financial institutions that hold these risky assets to write them down, adding another $150 billion to the financial system’s mounting losses.
Then there is the exposure of banks and other financial institutions to rising losses on loans that financed reckless leveraged buy-outs (LBOs).
With a worsening recession, many LBOs that were loaded with too much debt and not enough equity will fail as firms with lower profits or higher losses become unable to service their loans.
Given all this, the recession will lead to a sharp increase in corporate defaults, which had been very low over the last two years, averaging 0.6% per year, compared to an historic average of 3.8%.
During a typical recession, the default rate among corporations may rise to 10-15%, threatening massive losses for those holding risky corporate bonds.
As a result, the market for credit default swaps (CDS) ­– where protection against corporate defaults is bought and sold – may also experience massive losses.
In that case, there will also be a serious risk that some firms that sold protection will go bankrupt, triggering further losses for buyers of protection when their counterparties cannot pay.
On top of all this, there is a shadow financial system of non-bank financial institutions that, like banks, borrow short and liquid and lend to or invest in longer-term and illiquid assets.
This shadow system includes structured investment vehicles (SIVs), conduits, money market funds, hedge funds, and investment banks.
Like banks, all these financial institutions are subject to liquidity or rollover risk – the risk of going belly up if their creditors do not rollover their short-term credit lines.
But, unlike banks, they do not have the safety net implied by central banks’ role as lender of last resort.
Now that a recession is underway, US and global stock markets are beginning to fall: in a typical US recession, the S&amp;P 500 index falls by an average of 28% as corporate revenues and profits sink.
Losses in stock markets have a double effect: they reduce households’ wealth and lead them to spend less; and they cause massive losses to investors who borrowed to invest in stock, thus triggering margin calls and asset fire sales.
There is thus a broader risk that many leveraged investors in both equity and credit markets will be forced to sell illiquid assets in illiquid markets, leading to a cascading fall in asset prices to below their fundamental values.
The ensuing losses will aggravate the financial turmoil and economic contraction.
Indeed, adding up all these losses in financial markets, the sum will hit a staggering $1 trillion.
Tighter credit rationing will then further hamper the ability of households and firms to borrow, spend, invest, and sustain economic growth.
The risk that a systemic financial crisis will drive a more pronounced US and global recession has quickly gone from being a theoretical possibility to becoming an increasingly plausible scenario.
Anatomy of a Revolution Delayed
The ongoing conflict between Iran’s rulers and the Iranian public is the result of a head-on collision between two contradictory forces.
In recent years, public attitudes in Iran have become more liberal.
At the same time, power has shifted from conservative pragmatism toward a much more militant fundamentalism.  The call by the most important group of Iran’s clerics for the election results to be thrown out is but the latest sign of the fight back of both the reformist and pragmatic conservative factions.
Thirty years after the Islamic revolution, Iranians are growing demonstrably less religious and more liberal.
Two face-to-face surveys of more than 2,500 Iranian adults, conducted in 2000 and 2005, clearly show the trend.
The percentage of those who “strongly agree” that democracy is the best form of government increased from 20% to 31%.
Similarly, on a number of questions concerning gender equality – including political leadership, equal access to higher education, and wifely obedience – the numbers continued a downward trend.
Those who considered love as the basis for marriage increased from 49% to 69%, while those who depended on parental approval fell from 41% to 24%.
In 2005, a much higher percentage than in 2000 defined themselves as “Iranian, above all” rather than “Muslim, above all.”
This trend is not hard to understand.
The imposition of a monolithic religious discourse on society has made liberal values attractive to Iranians.
But, while this was reflected in reformist trends in the country’s wider political life, a movement toward militant fundamentalism took shape within the regime’s power structure.
Reform-minded politicians were partly to blame for this change.
Far from opposing absolutist power as an impediment to religious democracy, they tried to persuade the Supreme Leader, Ayatollah Ali Khamenei, of the value of reform.
But Khamenei had no interest in reform, as he made plain in dismantling the reform movement.
The presidency of Mohammad Khatami, an avowed reformer, who served eight years, beginning in 1997, convinced the Supreme Leader that his authority would be assured only if the presidency was held by a subservient fundamentalist such as the current president, Mahmoud Ahmadinejad.
In this, Khamenei was following the lead of the late Shah, who kept Amir Abbas Hoveyda, a loyal retainer, as prime minister from 1965 until the Shah was overthrown in 1979.
The problem with the Supreme Leader’s calculation, however, is that Ahmadinejad is a loose cannon.
His populist rhetoric and religious fundamentalism have alienated a large section of conservative-pragmatist clerics and their supporters.
Many members of this group honor the institution of private property, and Ahmadinejad’s talk of redistributing wealth is not to their liking.
More disturbing to them is his apocalyptic conviction regarding the imminent advent of the Hidden Imam, the Mahdi, whose appearance is believed to lead to the destruction of the world and the end of time.
Generally, Ahmadinejad begins his public speeches with prayers for the Mahdi’s immediate return.
For the Shia religious hierarchy, long accustomed to relegating the advent of the Mahdi to a distant future, Ahmadinejad’s insistent millenarianism is troublesome.
They have often dismissed as unorthodox, if not heretical, any claim of personal contact with the Imam or speculation about his arrival.
Several ayatollahs opined that such talk about the Mahdi is unbecoming of a president or, worse, indicative of an unstable leader.
These concerns were reflected in the fact that the Society of Combatant Clergy, a conservative body, was unable to endorse Ahmadinejad’s candidacy.
Defiance of the Supreme Leader by millions of Iranians just a day after he firmly endorsed Ahmadinejad threw the country into a political crisis.
Worldwide broadcasts of the beating and killing of protesters have undermined the regime’s religious credentials.
Seeking a way out of this difficult situation, the Supreme Leader declared that the electoral disputes must be settled in through legal channels, not on the street.
Given his role in justifying electoral fraud, this argument seems like an effort to buy time to clear the streets of demonstrators, put opposition leaders under severe physical and psychological stress, and isolate Mir Hossein Mousavi, the presumed winner of the real vote.
Nonetheless, Khamenei’s invocation of the law echoes the demands of many conservative-pragmatists who lean toward Mousavi, who is not in a position to challenge Khamenei’s authority directly.
Mousavi must carefully continue his legal campaign, without compromising the trust he has gained from the majority of Iranians.
He must stand by his two principal demands: nullification of the election and establishment of an impartial committee to rule on the government’s violations of the electoral law.
Should Mousavi persuade Khamenei to reconsider his position, the Supreme Leader’s hold on power will be shaken.
If Khamenei holds fast, Mousavi cannot gain the presidency, but he will continue to represent the hopes of the majority of Iranians who differ dramatically with their government.
For now, what will happen depends on Mousavi’s perseverance.
Anatomy of Chavez
Hugo Chavez's almost 8 years in power in Venezuela – which he will seek to extend in presidential elections next month &#45;&#45; seems to defy economic analysis.
Indeed, any and all economic examination of Chavez’s Venezuela confirms Edgar R. Fiedler’s quip that if you &quot;ask five economists something, you will get five answers...or six if one of them is a Harvard graduate.&quot;
Some people see in Chavez an innovative statesman who has seized an almost magical moment – the windfall Venezuela has received from today’s sky high oil prices &#45;&#45; to change the rules of the game in his country.
A few key indicators appear to support this.
Foreign investment has grown recently from $1.5 billion (2004) to $2.5 billion (2005).
In that two year period, Chavez stepped on the gas for his social reforms – education, health care, etc. – and also in regard to breaking down the country’s excessive concentrations of wealth.
Although over 70% of national income remains in the hands of just 20% of the population, Chavez has forced big foreign oil companies to pay much higher royalties and has started expropriating unproductive land and industrial facilities.
With oil prices now six times higher than they were when he came to power, Chavez presided over economic growth of 9% in 2005 and as much again in the first quarter of 2006.
Above all, however, he has achieved a 6.3% effective reduction of poverty, after taking over a country whose vast majority - 80% - was perched between poverty and squalor.
Seen in this angle, Chavez appears to have real achievements.
But there is another, darker, angle from which to view his presidency.
It is possible to see in Chavez but another Latin American populist sorcerer's apprentice, one whose political shelf life will expire whenever oil prices begin their inevitable shift backward.
To those who think that this is the case, Chavez is not an innovator but someone who is merely squandering Venezuela’s oil wealth in the same way that governments did following the oil shocks of the 1970's.
The notion of specific &quot;Chavist&quot; growth can also be challenged.
The highest growth achieved in the Chavez years is lower than Venezuela’s average during the second half of the 1990's, when oil was the exclusive domain of the private sector.
Moreover, growth under Chavez seems to reflect an increase in domestic consumption resulting from the flow of petrodollars and nothing more fundamental, as oil remains the economy’s only real engine.
So nothing Chavez has done translates into a fundamental improvement in, or diversification of, Venezuela’s economy.
Private investors appear to understand this, as such investment in Venezuela grew by a mere 3% between 2000 and 2004.
Suspiciously, the country’s central bank refuses to publish that figure for 2005.
Only one out of every ten Venezuelan companies polled states any intention of making middle or long term investments such as renovating existing industrial plants or building new ones.
True, businessmen have tempered their criticisms of Chavez and seem eager to participate in the profit feast brought about by increased consumption.
But they may also be waiting for the first external shock to puncture the Chavez balloon before they pounce.
These two versions of the Chavez years are both distorted &#45;&#45; to a certain degree &#45;&#45; by nostalgia.
Those who see him as successful have the 1960's and 1970's as their dream fantasy.
Their main arguments are reminiscent the arguments put forward by those who backed the Cuban Revolution.
Those who revile Chavez often do so in the name of the ‘Washington Consensus,’ that mix of capitalism and democracy that was almost hegemonic across the continent in the 1980's and 1990's.
Thus, Chavez is portrayed as a return to the Latin American populist heresy, a heresy that must be resisted because it affects not only the country with the largest oil reserves outside the Middle East, but also because it may tempt the rest of Latin America down that road.
But history never truly repeats itself.
The years of the biggest transformation demands in Latin America or those of its docility to economic orthodoxy will not come back because we can remember them.
Especially, the view of the Washington Consensus seems irretrievable; its &quot;grand tale&quot; is now beyond the pale in the region's societies after it did not deliver the promised prosperity.
Yet one thing is clear: Chavez was the first ruler of his generation to recognize the region’s fatigue and disillusion with neo-liberalism, and to propose new rules of the game.
In the end these may not be the rules he envisions today, but neither are they a spent force.
To believe that one can accurately foresee what will become of Chavez and Venezuela brings to mind another warning by Fiedler: &quot;He who lives by the crystal ball must sooner or later learn to chew glass.&quot;
Anatomy of Fear
How does your brain form its most significant memories?
Studies of fear in rats have helped us learn much here.
Although people and rats fear different things, the manner in which the rat and human brain and body respond to danger is similar.
Because fear is at the core of many human pathologies, from panic attacks to posttraumatic stress disorder, breakthroughs in understanding the brain's fear system may lead to new ways to treat these disorders.
The core of the brain's fear system is found in a region called the "amygdala".
This region receives information from all the senses and in turn controls the various networks that inspire the speeding heart, sweaty palms, wrenching stomach, muscle tension and hormonal floods that characterize being afraid.
A rat's amygdala responds to natural dangers (rats fear cats without having to learn to do so) and learns about new dangers (sounds, sights and smells that occur in anticipation of cats and other threats).
It is through studies of the way the brain learns about stimuli, such as the sounds that precede danger, that our systems for learning about fear, and memory as a whole, have been elucidated through rat studies.
There is also evidence that amygdala of reptiles and birds have similar functions.
Studies of humans with damage to the amygdala, due to neurological disease or as a consequence of surgery to control epilepsy, show that our brains also work in this same basic way.
The implication of these findings is that early on (perhaps since dinosaurs ruled the earth, or even before) evolution hit upon a way of wiring the brain to produce responses likely to keep an organism alive in dangerous situations.
The solution was so effective that it has not changed much over the ages.
Obviously, this is not the whole story. Once the fear system detects and starts responding to danger, a brain such as the human brain, with its enormous capacity for thinking, reasoning, and musing, begins to assess what is going on and tries to determine what to do.
This is when feelings of fear arise.
But in order to be consciously fearful you have to have a sufficiently complex kind of brain, one aware of its own activities.
While this is undoubtedly true of the human brain, it is not at all clear which (if any) other animals have this capacity.
So, in evolutionary terms, the fear system of the brain is very old.
It is likely that it was designed before the brain was capable of experiencing what we humans refer to as "fear" in our own lives.
If true, then the best way to understand how the fear system works is not to chase the elusive brain mechanisms of feelings of fear, but to study the underlying neural systems that evolved as behavioral solutions to problems of survival.
In order to understand feelings, we need to step back from their superficial expression in our conscious experiences and dig deeper into how the brain works when we have these experiences.
A fundamental discovery has been that the brain has multiple memory systems, each devoted to different kinds of memory functions.
For memories of fear arousing experiences, two systems are particularly important.
Take this example: if you return to the scene of a recent accident, you are likely to have a physical reaction that reflects activation of memories stored in the amygdala.
At the same time, you will be reminded of the accident, will remember where you were going, who you were with, and other details.
These are explicit (conscious) memories mediated by another system, the "hippocampus".
In contrast, memories mediated by the amygdala are unconscious.
These are memories in the sense that they cause your body to respond in a particular way as a result of past experiences.
The conscious memory of the past experience and the physiological responses elicited thus reflect the operation of two separate memory systems that operate in parallel.
Only by taking these systems apart in the brain have neuro-scientists been able to figure out that these are different kinds of memory, rather than one memory with multiple forms of expression.
Many of the most common psychiatric disorders that afflict humans are emotional disorders; many of these are related to the brain's fear system.
According to America's Public Health Service, about 50% of mental problems reported in the US (other than those related to substance abuse) are accounted for by anxiety disorders, including phobias, panic attacks, post-traumatic stress disorder, obsessive compulsive disorder, and generalized anxiety.
Research into the brain mechanisms of fear helps us to understand why these emotional conditions are so hard to control.
Neuro-anatomists have shown that the pathways that connect the amygdala with the thinking brain, the neocortex, are not symmetrical - the connections from the cortex to the amygdala are considerably weaker than those from the amygdala to the cortex.
This may explain why, once an emotion is aroused, it is so hard for us to turn it off at will.
The asymmetry of these connections may also help us understand why psychotherapy is often such a difficult and prolonged process, for it relies on imperfect channels of communication between brain systems involved in cognition and emotion.
Studies of the basic biology of the fear system are likely to continue to reveal important information both about where our emotions come from and what goes wrong in emotional disorders.
As we learn more, we may begin to figure out how to better treat - and even prevent - these conditions.
Anatomy of Thatcherism
London – Thirty years ago this month, Margaret Thatcher came to power.
Although precipitated by local conditions, the Thatcher (or more broadly the Thatcher-Reagan) revolution became an instantly recognizable global brand for a set of ideas that inspired policies to free markets from government interference.
Three decades later, the world is in a slump, and many people attribute the global crisis to these very ideas.
Indeed, even beyond the political left, the Anglo-American model of capitalism is deemed to have failed.
It is held culpable for the near financial meltdown.
But 30 years of hindsight enable us to judge which elements of the Thatcher revolution should be preserved, and which should be amended in the light of today’s global economic downturn.
Most obviously in need of amendment is the view that minimally managed and regulated markets are both more stable and more dynamic than those subject to extensive government intervention.
The Thatcherite assumption, in other words, was that government failure is far more menacing to prosperity than market failure.
This was always bad history.
The record shows that the period 1950-1973, when government intervention in market economies was at its peacetime height, was uniquely successful economically, with no global recessions and faster rates of GDP growth – and growth of GDP per capita – than in any comparable period before or since.
One can argue that economic performance would have been even better with less government intervention.
But perfect markets are no more available than perfect governments.
All we have are comparisons between what happened at different times.
What these comparisons show is that markets plus government have done better than markets minus government.
Nevertheless, by the 1970’s the pre-Thatcher political economy was in crisis.
The most notorious symptom of this was the emergence of “stagflation” – simultaneously rising inflation and unemployment.
Something had gone wrong with the system of economic management bequeathed by John Maynard Keynes.
In addition, government spending was on the rise, labor unions were becoming more militant, policies to control pay kept breaking down, and profit expectations were falling.
It seemed to many as though government’s reach had come to exceed its grasp, and that either its grasp had to be strengthened or its reach had to be reduced.
Thatcherism emerged as the most plausible alternative to state socialism.
Nigel Lawson was Thatcher’s second Chancellor of the Exchequer, or finance minister.
Out of the government’s anti-inflationary efforts emerged the “Lawson doctrine,” first stated in 1984 and broadly accepted by governments and central banks ever since. “The conquest of inflation,” Lawson said, “should...be the objective of macroeconomic policy.
And the creation of conditions conducive to growth and employment should be...the objective of microeconomic policy.”
This proposition overturned the previous Keynesian orthodoxy that macroeconomic policy should aim at full employment, with the control of inflation left to wage policy.
Yet, despite all the “supply side” reforms introduced by Thatcherite governments, unemployment has been much higher since 1980 than in the 1950’s and 1960’s – 7.4% on average in the United Kingdom, compared to 1.6% in the earlier decades.
What about inflation targeting?
Here, too, the record since 1980 has been patchy, despite the huge deflationary pressure exerted by low-wage competition from Asia.
Inflation in 1950-1973 and 1980-2007 was about the same – just over 3% – while inflation targeting has failed to prevent a succession of asset bubbles that have brought recessions in their wake.
Nor has Thatcherite policy succeeded in one of its chief aims – to reduce the share of government spending in national income.
The most one can say is that it halted the rise for a time.
Now public spending is on the increase again, and record peacetime deficits of 10% or more of GDP stretch ahead for years.
In de-regulating financial markets worldwide, the Thatcher-Reagan revolution brought about the corruption of money, without improving on the previous growth of wealth – except for the very wealthy.
The average world citizen would have been 20% richer had world GDP per capita grown at the same rate between 1980 and 2007 as it did between 1950 and 1973 – and this despite China’s high growth rates in the past 20 years.
Furthermore, in unleashing the power of money, the Thatcherites, for all their moralizing, contributed to the moral decay of the West.
Against these formidable minuses are three pluses.
The first is privatization.
By returning most state-owned industries to private ownership, the Thatcher revolution killed off state socialism.
The British privatization program’s greatest influence was in the former communist states, to which it gave the ideas and techniques needed to dismantle grossly inefficient command economies.
This gain must be preserved in the face of the current clamor to “nationalize” banks.
Thatcherism’s second success was to weaken trade unions.
Set up to protect the weak against the strong, labor unions had become, by the 1970’s, enemies of economic progress, a massive force of social conservatism.
It was right to encourage a new economy to grow outside these congealed structures.
Finally, Thatcherism put paid to the policy of fixing prices and wages by central diktat or by tripartite “bargains” between governments, employers, and trade unions.
These were the methods of fascism and communism, and they would, in the end, have destroyed not just economic, but political, liberty.
Political pendulums often swing too far.
In rebuilding the shattered post-Thatcherite economy, we should be careful not to revive the failed policies of the past.
I still find fruitful Keynes’s distinction between the agenda and the non-agenda of politics.
As long as central government takes responsibility for maintaining a high and stable level of employment, Keynes thought, most of the rest of economic life can be left free of official interference.
Building a proper division of responsibility between state and market from this insight is today’s main task.
Anatomy of the Party of Power
More than anything else, Vladimir Putin understands power: how to get it; how to consolidate it.
His predecessor, Boris Yeltsin, knew how to seize power but not how to consolidate it, which partly explains why power seeped away throughout his presidency.
President Putin's success, however, has bred its own problem: he consolidated power at the center so well that opposition is brewing in Russia's regions.
Yeltsin's biggest failing was in not creating a viable, non-ideological party - a "party of power" - to buttress his regime.
He tried to do so in 1995, but the Chechen War drove Russia's democrats away from him.
Moreover, his efforts here were amazingly clumsy.
Yeltsin once spoke about his scheme to link two centrists.
With "Ivan Rybkin (then Duma's speaker)," Yelstin said on TV, "leading the left flank, and Viktor Chernomyrdin (then prime minister) leading the right, we will encircle everyone."
But by linking both parties to his very unpopular self, Yeltsin damaged both.
Perhaps if both wings had united, that single party would have appeared as an unbeatable juggernaut.
Such unity, however, was impossible, for an obvious Russian reason: the faction leaders hated each other too much to get together, even for their own good.
Indeed, Rybkin was told to pretend to be opposed to Yeltsin's policies, but when he did object, Chernomyrdin summoned Rybkin to his office for "clarifications."
When businessmen learned about this "dressing down," they became afraid to finance Rybkin's party.
In the end, Rybkin went unelected and Chernomyrdin's `Our Home Is Russia' (NDR) came third.
Yeltsin failed to consolidate political support for other reasons as well, the most important being his unwillingness (or inability) to forcefully manipulate the media.
Of course, transformation of the presidential administration into a public relations machine began under Yeltsin when Anatoli Chubais directed the 1996 election campaign.
Before that, the Kremlin had little idea about how to manipulate the new media outlets that Russia's infant democracy had produced.
Today's Kremlin, however, is full of clever ideas about how to control and intimidate newspapers, radio, and television.
In the 1995 election, Yeltsin would have been happy if the NDR secured 25% to 30% of the vote.
Putin is far more ambitious.
He will be displeased if `United Russia' - the "party of power" he has built - wins less than 50% of the seats in the next Duma.
But are the results of the parliamentary elections due this coming January truly a foregone conclusion?
Or are surprises in store for Putin?
Surprises seem likely because Russia's political dividing line has shifted, but the President's political strategy hasn't recognized that fact.
Indeed, he appears set to be waging battles against the communists that are already won.
Putin's re-consolidation of power within the Kremlin, after much of it escaped to the regions during the Yeltsin years, dramatically shifted Russia's political dividing line.
In the past, that dividing line separated right and left, but the line at the forthcoming elections will run between the federal center and the regions.
The loss of political power in the regions (regional governors, for example, were evicted from the Duma's upper house) has incited serious discontent that is spilling over into the public sphere.
That discontent will likely gather momentum as elections near, which may be enough to stop the federal authorities from meeting their strategic goal of winning an unchallengeable majority of seats in the new Duma.
Vast administrative resources are being used to secure the desired result.
But Russia's bureaucracy is no disciplined machine, and the lower reaches of the state's `vertical' power structure may well ally themselves - quietly - with regional authorities to prevent the center from gaining too many votes.
Regional administrations also possess their own instruments of obstruction, including propaganda outlets in the regional media, as well as the ability to manipulate ballot papers.
Indeed, President Putin's failure to "reconquer" his home city of St. Petersburg, now controlled by a bitter political opponent of the President, Vladimir Yakovlev, demonstrates the bureaucratic powers that local leaders retain.
So the real issue in the forthcoming Duma elections will be how powerfully regional elites confront Putin.
Their ability to defy the president may be aided by the fact that the Kremlin is failing to recognize the potential of their challenge.
So far, the main target of its campaign is the communists, whom Kremlin political operatives hope to destroy in the way they destroyed Moscow Mayor Yuri Luzhkov and former Prime Minister Yevgeny Primakov, head of the Fatherland party, who were the leading non-communist challengers during Putin's first presidential campaign.
That focus on the battle with the communists may allow other forces to sneak into the Duma by the back door.
The Boris Nemtsov/Sergei Kiriyenko `Union of Right Forces' (SPS) is one party that seems certain to benefit in this way.
Indeed, the SPS electorate is growing faster than that of other parties.
In principle, all of Russia's political elites appear to have - or pretend to have - resigned themselves to a political landscape with Putin alone on the mountaintop and everyone else consigned to the valley below.
The upcoming elections won't knock the president off that mountain, but his `party of power' is not omnipotent enough to silence the dissenting echoes rising from below.
And Free Flows the Nile
NEW DELHI – For 18 days, during the ebb and flow of protest, it did not seem possible that the end of the Egyptian Revolution would come so suddenly, in a terse announcement that lasted no more than a half-minute: “President Hosni Mubarak has relinquished office….” With that, amidst roars of victory, an era was ended, reaffirming the old saying that “the graveyards of the world are full of those who considered themselves indispensable to their nations.”
In the days and weeks ahead, there could arise occasions when the news from Cairo is not uplifting, but let us never forget that Egypt has taken a giant step, which in reality is a giant step for all Arabs.
After all, Egypt is the heart, brain, and nerve center of the Arab world.
True, it once spawned the radical Muslim Brotherhood, but it also gave birth to Islamic socialism and anti-colonialism, Arab unity, and now a democratic affirmation of the people’s will.
Pernicious talk that Arabs do not want democracy has been exposed as the big lie it is.
Egypt, in the great Bengali poet Rabindranath Tagore’s memorable words, is the land “where the head is (now) held high and the mind is (now) without fear…” The consequences will be vast.
Ancient Arab lands are bestirred.
Decades-old, apparently immovable autocracies are finding their hold on power unhinged; change is invading their static environs.
Yesterday’s treaties, particularly those with the United States and Israel, will no longer inspire the same type of confidence they have long had as instruments of state policy.
Memory of these 18 days is so crowded that it is difficult to separate one event from another, one phase from the next: the dramatic, the moving, the bizarre, and the unreal from the bathetic.
But the thread that united all, the theme that remained unerringly constant, was the yearning for “change” – immediate, real, and tangible, not a promise or a tantalizing, unreachable mirage.
Will this yearning travel beyond the Nile, as it did from Tunis to Cairo?
This question haunts other Arab portals of power.
And not just Arab; globally, foreign policies are being hurriedly – and somewhat confusedly – revised and rewritten.
This is why US policy oscillated so disconcertingly from Secretary of State Hillary Clinton’s “Do not rush the pace or else the pro-democracy movement could well be hijacked” to President Barack Obama’s emphatic call for “change now.”
Of course, a grave question arises about the now-ruling Supreme Council of the Military High Command in Egypt: How can the enforcers of the status quo become the agents of change?
But, then, military rule is only a temporary measure, or so we reason.
The great Tunisian poet Abul-Qasim Al Shabi has captured poignantly the spirit of Egypt’s saga: “If one day the people want life, then fate will arise…night fade away, chains broken…” That, in essence, is what the young in Egypt have done.
Their idiom is current; their instruments of change are today’s electronic media.
They – and we – are very far from the world that Mubarak, or the great Gamal Abdel Nasser, knew and understood.
The Egyptian revolution now faces the exacting task that confronts all successful revolutions: how to define the future.
Like the Ottoman Empire’s fragmentation in 1922 or Nasser’s overthrow of King Farouk’s regime in 1952, the current transformation, too, must be shaped.
And how that future is shaped will determine whether or not Mubarak’s end marks the beginning of political transformation throughout the Middle East.
That is the possibility that is shaking governments from Washington to Beijing.
It is not just the reliability of the Suez Canal and oil exports that are now in doubt; decades of fixed strategic certainties must now be reexamined.
Consider Israel, which has watched the events in Cairo with a degree of worry unfelt since January 1979, when Ayatollah Ruhollah Khomeini unseated the Shah of Iran.
That strategic nightmare cost Israel and the US their closest ally in the region, one that was soon transformed into an implacable enemy.
Israel’s two most recent wars – against Hezbollah in Lebanon in 2006, and against Hamas in Gaza in 2009 – were fought against groups sponsored, supplied, and trained by Iran.
Clearly, Israeli-Palestinian negotiations will also now lie unattended as Israel concentrates on developments in Egypt.
Above all, Israel must wonder if the peace treaty with Egypt will hold, and, if not, how to carry out the massive restructuring of its defense posture that will be required.
But it is not only the fate of Israel that has now shocked US policy, in particular, to its core.
Egypt, after all, has been the cornerstone of America’s balancing act in the Middle East – and the Islamic world – for three decades.
The Egypt-Israel peace treaty has kept Egypt comfortably neutralized, freeing the US to commit its strategic resources elsewhere.
In turn, Egypt, propped up by massive US aid, has secured the region from a larger conflagration, even though the Israel-Palestine conflict has continued to smolder.
Herein lies the core of the dilemma for the US: it wants Egypt’s basic state apparatus to survive, so that the levers of power do not fall into the wrong hands.
This requires the US to be seen as siding with the public’s demand for change, yet to avoid being identified with political immobility.
There is reason to feel reassured by Obama’s reactions.
He termed Mubarak’s departure a display of “the power of human dignity,” adding that “the people of Egypt have spoken, their voices have been heard, and Egypt will never be the same.”
But nothing that Obama, or anyone else, says can answer the question now occupying the attention of senior US officials: Will the coming of popular sovereignty to Egypt inevitably lead to anti-Americanism?
Ukraine’s Prisoner’s Dilemma
WASHINGTON – The European Union’s most important decision this fall will be whether to sign an Association Agreement with Ukraine at the EU summit in Vilnius on November 28-29.
The issue will turn on whether Ukraine’s President, Viktor Yanukovych, fulfills one vital condition: a full pardon for political prisoner and former Prime Minister Yulia Tymoshenko.
The Association Agreement, which runs to some 1,200 pages, would remove almost all EU tariffs on Ukrainian goods, boosting the country’s long-term GDP by an estimated 12%.
It would also establish a political, economic, and legal reform plan for the country, supported by roughly 60 state agencies in EU member countries.
Although the Association Agreement does not lead automatically to EU membership, it is an important step in that direction.
Under the Treaty of Rome, Ukraine, as a European country, qualifies as a potential EU member.
But it would have to fulfill the EU’s “Copenhagen criteria,” established in 1993, which sets out the basic entry standards.
The Copenhagen criteria are met when the candidate country has achieved “stability of institutions guaranteeing democracy, the rule of law, human rights, and respect for, and protection of, minorities”; can ensure the existence of “a functioning market economy and the capacity to cope with competition and market forces”; and has sufficient “administrative and institutional capacity” to adopt and enforce EU law and “take on the obligations of membership.”
Ukraine is a long way from achieving this, but signing an Association Agreement would pave the way toward entry talks, while also creating tremendous economic opportunities.
Ukraine’s alternative would be to join a Russian-dominated Customs Union that includes Belarus and Kazakhstan.
Membership would require Ukraine to double import tariffs on EU goods, at an annual cost equivalent to 4% of GDP; and it would not even guarantee free trade among its members (Russia already applies trade sanctions against Belarus and Kazakhstan).
The Customs Union thus appears to be little more than a Russian neo-imperialist venture.
Unsurprisingly, Yanukovych has consistently stated his preference for an Association Agreement.
His political future may depend on it.
His advisers, and recent opinion polls, suggest that if he fails to sign a deal, he will lose the March 2015 presidential election.
The electoral math is stark.
While 40% of Ukrainians, based mainly in Yanukovych’s electoral heartland in the east and south of the country, would prefer to join the Customs Union, 60% of voters see their future with or in the EU.
Even allowing for widespread electoral fraud (which would hardly endear him to Brussels), Yanukovych would still struggle to win a majority.
It is not just the swing vote that Yanukovych needs to attract.
Ukraine’s powerful oligarchs are also looking West rather than East for business.
Many are fed up with the arbitrary imposition of trade barriers – affecting goods ranging from chocolate to steel pipes – in their former Soviet markets.
EU markets, by contrast, are viewed as being not only bigger, but safer as well.
Meddling from Moscow has certainly focused minds in Kiev.
Russia’s brief trade war in August frightened Yanukovych into pledging to fulfill all 11 of the EU’s legal and political conditions.
These require Ukraine to overhaul its judiciary and law enforcement, and ensure greater adherence to democratic norms.
The parliament currently is considering 15 bills along these lines, all of which have the full support of the main opposition parties.
But the EU’s demand that Yanukovych pardon Tymoshenko, who narrowly lost the 2010 presidential election, may prove harder to satisfy.
Tymoshenko was arrested in August 2011 and, after what was widely seen as a show trial, received a seven-year prison sentence for “abuse of power” (though she was not accused of benefiting personally) over a 2009 natural-gas deal with Russia.
An EU-appointed mediation commission that includes former Polish President Alexander Kwasniewski and former European Parliament President Pat Cox has proposed a solution.
At the commission’s request, Yanukovych would pardon Tymoshenko, who would be allowed to travel to Germany for medical reasons.
Tymoshenko has accepted the deal; Yanukovych has not.
Rather than a pardon, he wants parliament to pass a law allowing Tymoshenko to go to Germany for treatment, but on the condition that she would resume her prison sentence should she return to Ukraine.
The EU says that those terms are unacceptable.
Acquiescing in Tymoshenko’s political imprisonment would negate the very foundations of the legal and democratic standards that the EU purports to represent.
Any subsequent legal reform in Ukraine would appear hollow.
Some argue that the EU should ease its conditions: the case of a single, albeit important, individual should not stand in the way of Ukraine’s future.
But, far from this being a one-off case, the Tymoshenko affair exposes a deeper malaise.
Even now, Yanukovych is attempting to amend tax rules in order to disqualify the popular Vitali Klitschko, a champion boxer and former German resident, from standing for President.
The corruption and lawlessness that characterizes Yanukovych’s Ukraine should spur the EU to hold fast both to the letter and the spirit of its conditions.
Time is not on Yanukovych’s side.
The European Council of Ministers will make its final decision on November 18.
If Yanukovych has not amnestied Tymoshenko by then, the EU can, as the Polish MEP Jacek Saryusz-Wolski suggests, wait for a Ukrainian president that will uphold EU values.
Yanukovych will be the one blocking Ukraine’s path to the future.
Antarctica’s Point of No Return
POTSDAM – Recent satellite observations have confirmed the accuracy of two independent computer simulations that show that the West Antarctic ice sheet has now entered a state of unstoppable collapse.
The planet has entered a new era of irreversible consequences from climate change.
The only question now is whether we will do enough to prevent similar developments elsewhere.
What the latest findings demonstrate is that crucial parts of the world’s climate system, though massive in size, are so fragile that they can be irremediably disrupted by human activity.
It is inevitable that the warmer the world gets, the greater the risk that other parts of the Antarctic will reach a similar tipping point; in fact, we now know that the Wilkes Basin in East Antarctica, as big or even bigger than the ice sheet in the West, could be similarly vulnerable.
There are not many human activities whose impact can reasonably be predicted decades, centuries, or even millennia in advance.
The fallout from nuclear waste is one; humans’ contribution to global warming through greenhouse-gas emissions from burning fossil fuels, and its impact on rising sea levels, is another.
Indeed, the latest Intergovernmental Panel on Climate Change (IPCC) report stated, in uncharacteristically strong terms, that the sea level is “virtually certain” to continue to rise in the coming centuries or millennia.
Moreover, the greater our emissions, the higher the seas will rise.
But the recent revelations about Antarctica are different.
Rather than reacting to global warming with gradual and predictable patterns of change, the West Antarctic ice sheet has suddenly “tipped” into a new state.
A relatively small amount of melting beneath the Amundsen Sea’s ice shelf has pushed its grounding line to the top of a sub-glacial hill, from which it is now “rolling down.”
Simply put, one thermal kick was enough to initiate an internal dynamic that will now continue under its own momentum, regardless of any action that humans might take to prevent it.
It is not completely clear whether humans have caused this tipping – though nothing like it has ever occurred during the 11,500-year Holocene period before humans started interfering with the planet’s energy balance.
But that is not the point.
What is important is that we recognize the existence of gigantic parts of the earth’s climate system – such as West Antarctica’s three-quadrillion-ton ice sheet – that can be tipped when a fractional temperature rise occurs in key locations.
This risk is no longer merely theoretical.
For the first time, findings based on observations and computer simulations all point to the same conclusion: the huge Amundsen Sea sector of West Antarctica has begun an irreversible ice discharge, and nothing can now halt the subsequent drainage of the entire basin.
It has passed the point of no return.
That is why we must now focus on similar topographic conditions elsewhere.
If an “ice plug” near the coast of Wilkes Basin melts or breaks off into icebergs, the basin’s huge quantities of water will drain into the ocean.
Although no one knows precisely what might destabilize the Wilkes Basin, we can be fairly certain that further global warming, caused by greenhouse-gas emissions, will increase the risk.
The fact that sea levels will continue to rise is now clear.
But we can still determine how high and how fast levels rise by controlling the degree of global warming that we cause.
Climate change is caused by mankind, so the good news is that mankind can stop it by cutting greenhouse-gas emissions.
Although West Antarctica’s fate is sealed, we may still be able to prevent the collapse of East Antarctica’s marine ice sheet.
That means deciding – sooner rather than later – which path to follow.
The current path risks further destabilization in Antarctica; choosing the alternative path of a new energy system for the planet is our last best hope.
The Humanities Crisis
NEW YORK – A striking symmetry is emerging in debates about the future of higher education around the world.
On the one hand, there is growing concern that the United States and many European countries are failing to prepare enough university graduates in the fields driving the twenty-first century “knowledge economy,” such as engineering and information technology.
This fear has led to the narrowing of the concept of education to mean the acquisition of practical skills.
On the other hand, the worry in some parts of Asia is that young people entering the work force with strong technical training lack sufficient experience “thinking outside the box.”
This fear is manifesting itself in an incipient effort to expand education to include the cultivation of feeling and imagination.
Both movements are rooted in economic concerns.
In the US, where most undergraduates bear at least part of the cost of their university education, political pressure is mounting to provide incentives like tuition discounts or loan forgiveness to students of science, technology, engineering, or mathematics (the so-called STEM fields).
Cost-cutting measures, such as compressing traditional four-year degree programs into three years – thereby reducing or eliminating elective courses in “impractical” subjects like literature, philosophy, and fine arts – are also being discussed.
Meanwhile, in Hong Kong, Singapore, and China, there are calls for extending university programs so that students can obtain a broad, liberal education, in the hope that graduates will be more inclined to experiment and innovate.
Hong Kong University, for example, has extended its undergraduate programs from three years to four.
But such a narrow, economics-based view fails to account for the larger questions of value that societies worldwide are facing.
To be sure, progress in any field, from commerce and communications to health and environmental science, will become increasingly dependent on technological innovation, and thus on the high-order skills – acquired through intensive technical training – that drive it.
It is also true, however, that such training does not provide an adequate foundation for addressing the more abstract, but profoundly important, questions that ultimately must guide global policy and decision-making.
For example:
·         How can the imperative of economic development be reconciled with the need to limit climate change?
·         What does national sovereignty mean in a world where diseases, pollutants, and terrorists cross national borders at will?
·         Are there universal human rights that transcend conflicting claims of particular cultural traditions?
·         How should limited resources be distributed in order to provide opportunity and hope to young people, while treating the elderly with dignity and respect?
·         What are a country’s obligations to refugees fleeing from persecution, poverty, or strife elsewhere?
·         How should we balance individual liberty and collective security?
In answering such questions, advances in science and technology (for example, new methods of energy production, surveillance, or online learning) will have a key role to play.
But moral and ethical questions never yield fully to technical solutions; they also require an understanding of humanity’s social and cultural heritage.
Science can help us to attain the life we want, but it cannot teach us what kind of life is worth wanting.
In short, each side in the current education debate is half right.
As human affairs become increasingly complex and morally exigent, future generations will need both scientific and humanistic learning – and they will need them more than ever.
Fortunately, promising new models for making education more coherent and capacious are emerging.
Yale University and the National University of Singapore have worked together to establish Yale-NUS, Singapore’s first liberal arts college.
Led by a literary scholar and an astronomer, this new residential college aims to break down interdisciplinary boundaries and enable students to learn from one another.
Likewise, Quest University in Canada encourages students to bring both scientific and humanistic knowledge to bear on today’s most pressing problems.
Similar efforts have been underway for years in the US.
For example, North Carolina State University’s Benjamin Franklin Scholars program – a collaboration between the College of Engineering and the College of Humanities and Social Sciences – aims “to produce well-rounded professionals who are analytical problem-solvers, ethical decision-makers, and effective communicators.”
Unfortunately, such programs largely lack the visibility and influence needed to shape educational reform.
It is time to abandon the “either/or” discourse that pits science against humanities – which the British chemist and novelist C.P. Snow identified more than a half-century ago as an obstacle to human progress.
It is time to seek out best practices that bridge this putative divide, and scale them up.
In the important work of adapting educational institutions for the future, we must not lose sight of their core mission as articulated in the past.
No one has expressed that mission better than Benjamin Franklin, a man of letters and a scientific innovator, who defined education as the quest for “true merit.”
“True merit,” Franklin wrote, consists in “an inclination joined with an ability to serve mankind, one’s country, friends, and family; which ability is…to be acquired or greatly increased by true learning; and should, indeed, be the great aim and end of all learning.” This is an aspiration that should be renewed for every generation.
King Coal’s Climate Challenge
WASHINGTON, DC – Coal is emerging as a major topic of conversation at the United Nations climate-change negotiations currently taking place in Warsaw – and rightly so.
Indeed, it is a discussion that the world needs to have.
The latest findings of the Intergovernmental Panel on Climate Change conclude that we are quickly using up our carbon “budget” – the amount of carbon that we can afford to emit while still having a good chance of limiting global warming to 2º Celsius.
According to the IPCC, keeping the global temperature increase from pre-industrial levels below this threshold – the recognized tipping point beyond which climate change is likely to get seriously out of control – requires that the world emit only about 1,000 gigatonnes of carbon (GtC).
More than half of this amount was already emitted by 2011.
Unless we shift away from carbon-intensive behavior, the remaining budget will run out in roughly three decades.
When it comes to tolerable CO2 emissions, coal is the budget buster.
Just this week, a group of 27 prominent scientists, representing all major continents, issued a joint statement that explains that burning all known fossil-fuel reserves would produce about 3,800 gigatonnes of CO2, or 1,053 GtC, with coal alone accounting for more than half.
Simply put, if the world burns its known coal reserves using current technologies, it is likely to push global temperature rise far beyond 2ºC.
Many governments and financial institutions recognize this.
In recent months, the World Bank, the European Investment Bank, and the United States Export-Import Bank have introduced policies that restrict financing of new coal-fired power plants unless they can capture and store their CO2 emissions.
Five Nordic countries have joined the US Treasury in ending public financing of new coal-fired power plants overseas, and others may soon follow suit.
And this fall, the US Environmental Protection Agency proposed emissions standards for new power plants that would rule out conventional coal power – an important step that would cut carbon pollution and drive innovation.
Likewise, China, concerned about the serious health costs linked to burning coal, is prohibiting new coal capacity in three coastal provinces under its newly adopted action plan on air pollution.
The Chinese authorities have also introduced policies to reduce the proportion of coal in the country’s overall energy mix.
Against this backdrop, the World Coal Association (WCA) is meeting this week, also in Warsaw – in fact, just across the river from where negotiators are trying to forge the building blocks of a global climate agreement by 2015.
The WCA is calling for the use of “high-efficiency, low-emissions coal-combustion technologies” to lower greenhouse-gas emissions from coal-fired power plants around the world.
But this approach would still consume too much of the CO2 budget.
Even the most modern and advanced conventional coal-fired power plants emit over 15 times more CO2 per unit of electricity than renewable energy systems, and more than twice the amount of efficient gas-fired power stations.
And yet coal power is still going strong globally.
The World Resources Institute estimates that there are close to 1,200 proposed coal-fired power projects around the world, with a total installed capacity of more than 1,400 gigawatts.
If built, the world would commit a large share of the remaining carbon budget to high-carbon infrastructure with a lifespan of 40-50 years.
According to the International Energy Agency, the current trend in coal use is in line with a scenario that would lead to a 6ºC temperature rise.
This is a future that would radically and irreversibly change life on earth as we know it.
This is why the OECD Secretary General has suggested that it is time for a moratorium on the construction of conventional coal-fired power plants.
Governments have far more cost-effective electricity-generation technologies at their disposal.
Renewable energies like solar and wind are already competitive with fossil fuels in many parts of the world, and they can be scaled up rapidly.
Moreover, most economic models do not account for the externalities related to coal and carbon pollution.
For example, a recent report by Trucost estimates that coal-fired power generation worldwide may be responsible for around $1 trillion of damage due to climate change and air pollution.
Many coal-fired power plants would be uncompetitive if they were required to internalize these costs.
Of course, coal continues to offer millions of people a reliable source of electricity – and the transition to low-carbon technologies will not happen overnight.
We need to expand access to these technologies rapidly, while helping people whose livelihoods depend on the coal industry.
While we need to be passionate about climate change, we must also be pragmatic about how we address it.
But so must the coal industry.
Participants at the WCA meeting this week should commit to additional measures that will help ensure that emissions are kept within safe limits.
A moratorium on conventional coal plants would be a smart place to start.
That would help to show the world that the coal industry truly understands the scientific implications of current energy-use patterns, and that it is willing to assume more responsibility for combating climate change.
We need people on both sides of the Vistula River to do their part to build a fair and ambitious universal climate agreement by 2015.
Let’s roll up our sleeves together and plot a viable pathway to a safe and effective low-carbon economy.
PISA’s Promise
PARIS – By assessing the capabilities and knowledge of students in the highest-performing and most rapidly improving education systems, the OECD’s Program for International Student Assessment provides valuable options for reform and information on how to achieve it.
PISA brings together policymakers, educators, and researchers from around the world to discuss what knowledge students need to become successful and responsible citizens in today’s world, and how to develop more effective, inclusive education systems.
Some claim that the PISA results are based on too wide a range of factors to be relevant, while others point out the challenges inherent in testing students in various languages and with different cultural backgrounds.
Of course, comparing education across countries is not easy, but PISA remains the most useful tool yet developed for policymakers attempting to improve their national education systems.
Before PISA, many governments claimed that they oversaw the world’s most successful education systems, and insisted that they had already taken the steps needed to address any shortcomings.
By exposing weaknesses in a particular country’s system, PISA assessments help to ensure that policymakers recognize – and, it is hoped, address – remaining deficiencies.
The sense of accountability that PISA fosters among governments and education ministers has helped to spur them into action.
They increasingly turn to one another to learn how to apply innovations in curricula, pedagogy, and digital resources; how to offer personalized learning experiences that maximize every student’s chances of success; and how to cope with diversity in the classroom.
The OECD established PISA as a global assessment, because in today’s globalized world students must be able to collaborate with people from diverse backgrounds and appreciate different ideas, perspectives, and values.
To give students the best possible chance to succeed, education must prepare them to handle issues that transcend national boundaries.
But PISA’s most important outcomes lie at the national level, because it inspires innovation and broadens educational perspectives within countries.
Education systems as diverse as those in Finland, Japan, China, and Canada – which seldom registered on policymakers’ radars before – have become global reference points for excellence in education, helping other countries to design effective reforms.
When Brazil emerged as the lowest-performing education system in the first PISA assessment, released in 2000, many people rightly questioned the fairness of comparing an emerging economy to advanced countries like Finland and Japan.
But Brazil rose to the challenge, making massive investments in improving the quality of teaching.
The country now boasts one of the world’s most rapidly improving education systems.
Germany also featured in PISA 2000, recording below-average performance and large social inequalities in education – an outcome that stunned Germans and initiated a months-long public debate.
Spurred into action, the government launched initiatives to support disadvantaged and immigrant students, and made the notion of early childhood education a driving force in German education policy.
Today, PISA reports confirm that the quality and fairness of Germany’s education system have improved considerably.
Even in the world’s best-performing education systems, PISA helps to pinpoint areas for improvement.
For example, PISA assessments have revealed that, while Japanese students excel at reproducing what they have learned, they often struggle when asked to extrapolate from that knowledge and apply it creatively.
The effort that this has inspired to create more innovative learning environments was apparent last April, during a visit to the Tohoku schools destroyed by the 2011 tsunami.
This experience offers yet another lesson: even in cases where social and cultural factors seem to be the main force shaping a country’s education style, improvements are possible.
Countries like Japan do not have to change their cultures to address their educational shortcomings; they simply have to adjust their policies and practices.
Creating a global platform for collaboration in education research and innovation has been the PISA initiative’s aspiration from its conception in the late 1990s.
Since then, policymakers, researchers, and experts have built the world’s largest professional network dedicated to the development of robust, reliable, and internationally comparable information on student learning outcomes.
At the same time, PISA measures students’ social and emotional skills and attitudes toward learning, as well as educational equity and parental support – all of which provides indispensable context for understanding scores on international assessments.
Of course, assessments do not cover every important skill or attitude.
But there is convincing evidence that the knowledge and skills that the PISA system assesses are essential to students’ future success, and the OECD works continuously to broaden the range of cognitive and social skills that PISA measures.
PISA has already prompted important advances in education worldwide.
The OECD will continue to work with the 80 participating countries to develop the program further, so that it can continue to help policymakers and educators design and implement better education policies – and give their citizens access to the tools that they need to build better lives.
In Defense of Angela Merkel
PARIS – The recent cover of Der Spiegel showing German Chancellor Angela Merkel in front of the Acropolis surrounded by Nazi officers serves an important purpose: it finally poses, in a way that cannot be evaded, the question of Germanophobia in Europe.
The abuse of Germany has dragged on for quite some time.
Demonstrations in Cyprus in March 2013 included banners bearing caricatures of Merkel done up as Adolf Hitler.
In Valencia at around the same time, on the occasion of the annual Fallas celebration, there was Merkel as an evil headmistress delivering to the head of the Spanish government and his ministers “The Ten Commandments of Angela the Exterminator.”
She ended up being burned in effigy in the flames of the bonfires of St. Joseph.
Two months later, in Portugal, similar parades featured the same Hitlerized Merkel caricatures, borne by howling demonstrators dressed in mourning clothes and decrying the German leader’s “policy of massacring the poor.”
And, naturally, there was Greece, where the phenomenon reached its apogee during the near-riots of October 2012, in which the world was treated to the spectacle of Nazi and German flags flown together – and then burned – together before the Acropolis in scenes that presaged the Der Spiegel cover.
In Italy, the right-wing daily newspaper Il Giornale had no scruples about devoting its headline for August 3, 2012, to the emergence of the “Fourth Reich.”
Likewise, conspiracy websites in the countries of northern Europe claim that Germany’s eagerness to support Ukrainian President Petro Poroshenko against Russian President Vladimir Putin is a reenactment of Hitler’s subjugation of Ukraine.
Then there is France, where the game seems to be to see who can come out on top in populist denunciations of the new and detestable “German empire.”
From the extreme right, National Front leader Marine Le Pen chides Merkel for the “suffering” that she is imposing on the peoples of Europe.
From the opposite extreme, we have the Left Party’s Jean-Luc Mélenchon thundering against Merkel’s “austerity” policy and inviting her to “shut up.”
The problem with this Germanophobia is not simply that it is stupid, or that it is yet another symptom of the decomposition, before our eyes, of the noble European project of integration and ever-closer union.
No, the problem with today’s Germanophobia is that, contrary to what the sorcerer’s apprentices who stoke it would have us believe, their behavior is not a sign of their opposition to the true fascism that lies on the horizon, but rather of their allegiance – and even contribution – to it.
Why?
There are several reasons.
For starters, to oppose Germany’s social, economic, and foreign policies by equating Merkel with Hitler is to banalize Hitler.
However legitimate disagreement with those policies may be, Germany is one of the continent’s most scrupulous and exemplary democracies.
To say that it resembles in any way the Nazi regime – which in Europe still stands for the destruction of democracy (indeed, civilization itself) – is to exonerate that regime, and to reassure and encourage today’s neo-fascists, allowing them, whether intentionally or not, to reenter the public debate.
What is more (and this is key), those keenest to discredit Merkel just happen to be the same people who do not hesitate to waltz with Viennese neo-Nazis or to form an alliance, as in Athens, with the leaders of a genuinely extremist party.
All of the clamor raised around a Germany that has supposedly “reunited with its demons” masks the voice of fascistic parties – from Greece’s Golden Dawn to Hungary’s Jobbik, Slovakia’s SNS, Belgium’s Vlaams Belang, and Bulgaria’s Ataka – that are in the process of establishing themselves in Europe.
It should also be noted that Merkel is a woman, and that hatred for women – the disdain in which they, right alongside the Jews, were regarded by the racist theoreticians of the 1920s and 1930s – has been an essential dimension of every expression of fascism.
Likewise, the slogans slung about in Valencia in October 2012 – with demonstrators urged to chant at the chancellor’s effigy, “You will love money above all else” and “You will honor the banks and the Bank” – had the unmistakably foul odor of the old mantras about “the golden calf” and the “cosmopolitan plutocracy.”
People have finally come to understand that anti-Americanism, born on the extreme right and fed, in Germany, for example, by the philosophy of Martin Heidegger and his acolytes, is a fixture of fascism.
It is now time for us to understand that the same is true of Germanophobia.
In France, it appeared with the French anti-Semitic novelist and activist Maurice Barrès, who saw in the philosophy of Immanuel Kant a vehicle for the “Jewification” of European minds.
It triumphed with Charles Maurras’ Action Française and its protracted war with “Jewish and Germanic abstractions.”
And it culminated with the red-brown cells that, even today, on sites that I prefer not to mention, offer “grub” and a “hideout” for persons willing to “bump off” the “bosses” on the chancellor’s “payroll.”
The history of ideas has its logic, reason, and folly, its unconscious and its trajectory.
It is both futile and dangerous to deny any of them.
That is why, today, it is critically important, in the face of a dark force that is rising, swelling, and unfurling in Europe, to defend Angela Merkel.
Angela Merkel Meets the World
At long last, Angela Merkel is Germany’s new – and first woman – Chancellor.
Although continuity will remain the hallmark of foreign policy, Germany’s international engagement under Merkel will sound and feel different from that under Gerhard Schroeder’s leadership.
Schroeder came to power seven years ago representing a new generation whose formative experience was not the Cold War, European integration, and transatlantic friendship, but German unification and the restoration of national sovereignty.
For him and the team that took over after Helmut Kohl’s 16-year reign, Germany had become a normal country, no different from other European heavyweights like France or Britain.
Indeed, one of Schroeder’s first major foreign-policy experiences was the EU summit of 1999, where the leaders of France and Britain played rough with the newcomer from Berlin.
The lesson that Schroeder drew was to insist that Germany could no longer be taken for granted and would demand a role commensurate to its size and weight.
Self-assertion became the watchword of German foreign policy.
Thus, when Schroeder claimed special circumstances for Germany’s failure to meet the budgetary ceilings of the European Union’s Stability and Growth Pact, he seemed to be arguing that the restrictions should apply only to smaller countries, not to the big players.
When he rightly opposed America’s war against Iraq, the pride of standing up to the world's only superpower was palpable.
When he established a close personal and political relationship with Russian President Vladimir Putin, he signaled to the world – and to the EU’s sensitive new Eastern European members – that Germany’s foreign policy would no longer be constrained by the past.
In fairness, it should be acknowledged that it was under Schroeder that Germany shed hesitations to deploy soldiers abroad.
His support for international crisis missions in Kosovo, Bosnia, or Afghanistan required considerable political courage and made Germany one of the major contributors to international stability efforts.
To have removed the issue from domestic ideological controversy ranks as a major achievement of Schroeder’s tenure.
But it was also meant to convey that Germany had grown up into a proper international power.
With Merkel, the substance of Germany’s foreign policy will change little, but the assertive style will be muted.
American leaders will welcome her election as proof that the estrangement in bilateral relations is over. But that alienation already largely ended earlier this year, when the Bush administration realized that allies are good to have and that Germany is an important one.
Merkel will reintroduce the warmth that has been missing under Schroeder, but she will not become America’s yes-woman.
Nor will she abandon special relations with Russia, to which every German chancellor since Adenauer has attached major importance.
But she has already made clear that Germany’s neighbors to the East will have no reason not feel bypassed.
She may even want to confirm that message by making her first official trip abroad not to Paris but to Warsaw or Vilnius.
On the European project, she is as committed to integration as her predecessors have been.
She will continue to emphasize close relations with France because there is no alternative; Britain, absent from the euro zone and the Schengen border regime, remains the odd man-in of the EU.
But there will be no new initiatives on integration until leaders in the countries that rejected the Constitutional Treaty are ready for a new try.
Then Merkel will be in a key position to add weight to a new effort for moving the EU forward.
She will continue to favor the eventual admission of the Balkan states, but she has left no doubt of her opposition to full membership for Turkey, which is the major substantive change from the Schroeder era (although her government will not block the start of negotiations in early October).
In fact, there is very little Merkel has to do after her election to make her mark on foreign policy; the visible change of style will suffice, at least at first.
In any case, she will have her hands full pushing through the economic reforms for which she will be elected and which are her top priority.
There are indications that Germany is finally emerging from years of economic stagnation, not least thanks to the reforms started under Schroeder.
At home, Merkel can hope to reap the rewards.
Abroad, Merkel has no need to demonstrate that Germany is a big country in Europe; her partners are fully aware of this.
But it is also more than just a normal country: Germany remains central to holding together the two international institutions that will continue to assure its well-being, the European Union and the Atlantic alliance.
There are some indications that Merkel is more aware of this then Schroeder was.
One can only hope that this recognition will serve as her guidepost when tough decisions must be made and changes in style alone will not be enough.
Angela Merkel’s Vision Thing
CAMBRIDGE – As Europe struggles to save the euro, the chorus of complaints about weak leadership in the world’s major economies grows louder.
Many have singled out German Chancellor Angela Merkel for failing to promote a vision of Europe similar to that of her predecessor and mentor, Helmut Kohl.
Are the critics right?
Part of what effective leaders do is communicate a vision that gives meaning to policies and inspires others to support these policies (and those who propose them).
It is one of the ways in which leaders help to create shared objectives and energize common action.
Usually, such a vision provides a scenario for the future that is meant to encourage change, though it may also portray the status quo – or the past – as attractive, thereby encouraging resistance to change.
Either way, without a vision, it is difficult to lead others anywhere.
Frederick Smith, CEO of Federal Express, has argued that “the primary task of leadership is to communicate the vision and values of an organization.”
But one must be cautious about visions.
Sometimes leaders think that vision can solve most of their problems, but the wrong vision – or an overly ambitious vision – can do damage.
George H.W. Bush was faulted (and faulted himself) for not having what he called “the vision thing.”
When pressed by his staff to speak more boldly and expansively, he replied, “It’s just not me.”
After the shock of the September 2001 terrorist attacks, his son, George W. Bush, developed a far more ambitious vision.
As one former adviser put it, he was “irresistibly drawn to Big Ideas like bringing democracy to the Middle East, Big Ideas that stood in sharp contrast to the prudent small ball played by his father.” Yet the elder Bush turned out to have had the better foreign policy.
Some aspiring leaders think that they must proclaim a vision that overawes their followers.
In practice, however, a successful vision often arises from the needs of the group, which are then formulated and articulated by the leader.
The vision that Martin Luther King, Jr., expressed in his “I Have a Dream” speech, for example, was deeply rooted not only in America’s professed values of equality and inclusion, but also in African-Americans’ experience of subordination and exclusion.
At the same time, the pressure to articulate a vision can get a leader into difficulty.
As one university president put it: “Everyone asks, ‘What’s your vision?’
But you offend many people and get into trouble by answering too quickly.
The smart response at the beginning is, ‘What do you think?’ and then listen before you articulate your vision.”
A successful vision has to be attractive to various circles of followers and stakeholders.
What plays well with one group may not sit well with another.
And, to be sustainable, a successful vision must also be an effective diagnosis of the situation that a group faces.
Leaders must get the question right before proposing answers.
To choose goals and articulate them in a vision, they need not only to solicit input from their followers, but also to understand the context of their choices.
They must be able to assess reality accurately.
The boldness of a vision varies with the type of leadership involved.
Leaders of social movements can call forth larger visions than public officials can.
A movement leader can promote a vision that is miles ahead of his followers, while a prime minister with multiple objectives and responsibilities must maintain a continuous dialogue with the public, which keeps him or her from moving too far ahead of citizens.
After former US Vice President Al Gore lost his bid for the presidency in 2000, he became a leader of the social movement to combat global climate change, and his style changed from pragmatic to inspirational and prophetic.
Analysts judge a government leader’s vision in terms of whether it creates a sensible balance between realism and risk, and whether it balances objectives with capabilities.
Anyone can produce a wish list, but effective visions combine inspiration with feasibility.
Critics of former British Prime Minister Tony Blair, for example, acknowledged that his ability to articulate a vision was one of his great strengths as a leader, but complained about his lack of attention to detail.
Similarly, two twentieth-century US presidents, Woodrow Wilson and George W. Bush, were good at articulating an ambitious foreign-policy vision, but were poor at refining and reshaping their vision when they encountered implementation challenges.
Both promoted democracy, but both did so in a manner that generated a backlash against democracy promotion.
Of course, prudence is not enough.
Sometimes leaders need to stretch the boundaries of realism to inspire their followers and call forth extra effort, as Winston Churchill did in Great Britain in 1940.
But, without a degree of prudence based upon comprehension of the context, visions turn from grand to grandiose and undercut the values that they seek to promote.
Like Franklin Roosevelt, who acted very cautiously in trying to persuade American opinion to abandon isolationism in the 1930’s, Merkel has proceeded cautiously on saving the euro.
She faced public skepticism about using German funds to bail out the Greek economy.
Her coalition was divided on the issue, and her party lost state elections.
If she had acted more boldly, she might have lost even more support, but the steps that she agreed to remained insufficient to reassure markets.
At the end of October, however, she finally articulated a vision of the future of Europe that persuaded the German Bundestag to agree to a package of measures to save the euro.
Whether she waited too long – and whether her vision will prove convincing – will be determined in the coming months.
The Voices Behind Angelina Jolie
NEW YORK – On May 26, Angelina Jolie’s aunt, Debbie Martin, died of breast cancer at 61.
Jolie’s mother, Marcheline Bertrand, died at 56 from a related illness, ovarian cancer.
And, two weeks before Martin died, Jolie revealed that she had undergone a preventive double mastectomy after testing positive for a BRCA gene mutation – which is correlated with a woman’s being five times more susceptible to breast cancer and 28 times more susceptible to ovarian cancer.
The test for the BRCA mutation is expensive – roughly $3,500.
In the United States, health insurers cover the cost only if a first-degree relative – for example, a woman’s mother – has had a history of breast or ovarian cancer; other women must pay out of pocket.
Given the benefits of preventive care, the test has become highly controversial, because its manufacturer, Myriad Genetics, holds a genetic patent that gives it a monopoly – and huge profits – on all testing.
Jolie’s announcement has thrown a spotlight on that issue.
More broadly, she is that rare entertainer/sex symbol who, like Madonna and a few other women, largely dictates her own narrative about the “meaning” of her celebrity.
For Jolie, that means often using her iconic status to advance a positive agenda, whether the issue is Syrian refugees in Jordan or breast-cancer awareness.
Her revelation of her mastectomy – and the evident support of her partner, Brad Pitt – has elicited a rapturous response from popular media, including the tabloids that once damned her as the “other woman” who broke up Pitt’s previous marriage.
There is something about the narrative – a sex symbol sacrificing her fetishized breasts for the sake of her children, with her husband staying by her side – that is deeply reassuring to women in Western culture.
One can be reasonably certain, however, that Jolie’s decision will alter the roles available to her as an actress.
As enthusiastically as the global mass media has received her choice, it is nonetheless extremely difficult in the West for a woman to be portrayed as maternal – let alone physically “flawed” or “impaired” – and also as a fantasy sex object.
But the real importance of Jolie’s story is its context: a wave of women and men, in very different settings around the world, who are insisting on narrating their own meanings for events involving their bodies – events that, like breast cancer, were once shrouded in shame, silence, fear, or blame.
Jolie has refused to treat mastectomy as scary or tragic – or as making her “less of a woman” in any way.
She is thus modeling a refusal to be a woman victim; by doing so, she is also modeling agency in relation to her own body and its “story.”
Jolie is prominent, but she is hardly alone.
Consider the Brazilian women who are coming forward to talk publicly about having been raped on public buses –&#160;attacks that echo similar assaults in India and Egypt.
Or consider the two young female staffers of New York officials who have publicly pressed their complaints about having been sexually harassed by New York Assemblyman Vito J. Lopez.
Similarly, the men who were sexually abused in the 1970’s at Horace Mann, a prestigious New York City private school, are refusing to perpetuate the silence and “shame” of their victimization by a circle of pedophiles (and by the school officials who covered up the abusers’ behavior).
They have now joined a highly publicized lawsuit against the school, stepping into the light of day under their own names.
Times have surely changed – partly because of people and actions like these.
Twenty-two years ago, when Anita Hill publicly accused then-US Supreme Court nominee Clarence Thomas of sexual harassment, it was she, the alleged victim, who was scrutinized and smeared as “a little bit nutty and a little bit slutty.”
In all these cases, one can see the once-silenced woman – or child of either gender – take charge of the obligation and the right to speak to her or his own situation and recast the public story.
It is they, and they alone, who may assign authoritative meaning to their breasts, their bodies, and the difficult events related to them.
When I began in recent years to insist that the traditional silence and anonymity assigned to rape victims does not protect them, but only perpetuates a Victorian framework in which rapists attack with impunity and victims are asked to carry the “shame,” my argument was met with hostility.
But events are proving me right: nothing changes until everything changes –&#160;that is, until a critical mass of “victims” comes forward under their own names to reject the shame assigned to them for carrying a scary, “mutilating” disease, for having been assaulted by rapists, or for having been abused by pedophiles.
Angelina Jolie puts a famous face on this phenomenon.
But many others are already standing up and proclaiming, under their own names and bylines: “I have a right to say publicly what happened to me, and to define it in my own terms; it is not my disgrace.”
Argentina’s Sovereign Bondage
WASHINGTON, DC – Sovereign debt has been back in the news recently, this time because of a United States Supreme Court ruling concerning Argentine debt.
As a result of the ruling, a complicated issue is likely to become even more so.
Sovereign debt has been a major feature of the international financial system for centuries.
Kings borrowed, often internationally, to finance wars and other expenditures.
When they couldn’t pay, as sometimes happened, sovereigns defaulted.
Today, sovereigns are more often democratically elected governments, but they still borrow. And they still occasionally find themselves in situations in which their debt has become unsustainable and they need outside help to continue to meet their debt-service obligations.
When private firms (or subnational governments) become insolvent, there are normally legal bankruptcy procedures to determine what to do.
Without such procedures, a market economy would be unable to function.
In part, this is because creditors would otherwise stop extending credit and demand repayment at the first sign of trouble.
This is because the first creditors to be paid would receive the full amount owed to them, leaving less for later creditors – and thus creating an incentive for all creditors to rush for the exits even before debt servicing had become impossible.
Moreover, in many cases, the value of the troubled entity’s assets as a going concern is greater than it would be if the assets were sold separately.
In such cases, all creditors would be better off with a debt write-down than with dissolution.
Bankruptcy law thus protects creditors from each other by preventing an outcome that would needlessly harm all of them.
In the case of sovereign debt, however, there is no binding international law that permits bankruptcy.
Though some routine practices have emerged as international capital markets have grown, they remain ad hoc.
Given the uncertainty involved, and that sovereign debtors can repay domestic-currency debt simply by printing money, creditors have typically demanded significantly higher interest rates if bonds are not issued under the law and in the currency of an advanced country – often the United States or the United Kingdom.
When a sovereign decides that its foreign debt is unsustainable, the government and its creditors have had to negotiate among themselves about what to do.
For sovereign bonds held by other sovereigns, the Paris Club of creditor countries has developed procedures for handling the debt.
But when private creditors hold sovereign debt, organizing them creates a new challenge with each episode.
When debt is unsustainable, there are several possible negotiating outcomes.
Sometimes, debt-service payments are rescheduled and perhaps stretched out over a longer period, thus giving the debtor country time to regain its ability to pay.
Sometimes, creditors agree to exchange the old bonds for new ones, which have either a lower face value or lower interest payments.
Few governments refuse to pay at all in any form.
Argentina defaulted on its debt in 2001.
After several difficult years, the country managed to negotiate an exchange of outstanding bonds for bonds with a considerably lower face value.
About 93% of creditors accepted the exchange and received new bonds with a face value that was about one-quarter of that of the old bonds.
After 2005, Argentina maintained debt service on the new bonds.
But some creditors held out, and sued Argentina in New York (as the bonds were issued under New York law).
Argentine bonds (like most others) had a so-called pari passu clause that committed the government to treat all bondholders alike.
The holdouts claimed that, if the new bonds were being serviced in full (as they were), equal treatment required that the holdouts should receive the full amount owed to them (including not only interest but also principal).
The US Second Circuit Court of Appeals ruled that Argentina was bound to honor its obligations to the holdout bondholders in the same proportion (namely 100%) as the holders of the exchange bonds.
It was that ruling that the Supreme Court recently upheld.
Under the court order, Argentina may not pay the holders of the new bonds unless it also pays the holdouts, and no US financial institution can serve as an intermediary to make payments for Argentina.
As a result, Argentina must either pay the holdouts in full or default on the new bonds.
Regardless of how the current impasse is resolved, the ruling raises many questions for issuers and holders of sovereign debt.
If creditors now believe that holding out makes it more likely that they will receive full value at a later date, restructuring sovereign debt and restoring a debtor economy’s normal functioning will be more difficult.
Since the Argentine crisis, most new bonds have been issued with collective action clauses (CACs), under which bondholders are obliged to accept restructuring if a specified share (usually around 70%) agree to it.
As time passes, there are fewer and fewer outstanding bonds that do not contain CACs.
But CACs may not resolve the problem entirely, because a vote would be required for each separate bond issue, and a holdout position could be achieved by buying up the blocking percentage of a small issue.
It is also possible that language will be found in future bond issues that replaces the pari passu clause but provides sufficient assurance to bondholders to let the market function much as it did until the current ruling.
Until the euro crisis, it was generally believed that problems servicing sovereign debt occurred only in emerging markets and the least developed countries.
The US Supreme Court’s decision on Argentina adds a new wrinkle, and may well further increase the risk attached to holding sovereign debt – and this to the cost of issuing it.
Families of the Future
WASHINGTON, DC – It is graduation season in many countries, a time when classes of bright and fortunate young people don their caps and gowns, receive their diplomas, and hear advice from their elders.
Some commencement speakers focus on the graduates’ accomplishments; others emphasize the career-related challenges that lie ahead.
But there is another critical aspect to success and happiness that is often overlooked during these garlanded celebrations of academic achievement: family.
In fact, these ceremonies are about the graduates’ families – that is, those who have loved and supported them, regardless of their biological connection – as much as they are about the graduates themselves.
Whatever each family’s experience, the result has been a child reaching a level of education of which many people can only dream.
Beyond noting and appreciating what their families have done for them, graduates must consider the kind of family that they want to nurture.
And here they have no choice but to reflect on gender roles and relations.
Given the vastly different expectations and experiences of men and women – depending, of course, on the cultural context – the questions that they must ask themselves vary considerably.
The question of how to balance work and family, typically posed to young women, is actually a critical consideration for young men as well.
The traditional male role as “provider” has often led work to take precedence over time spent with family.
Indeed, in reflecting on their childhoods, many graduates may lament that their fathers spent too little time at home, or were less nurturing than they could have been.
Men must determine how to develop the caring side of their personality, in addition to the competitive side that will enable them to advance their careers.
They must aim to love and give fully, not only as fathers, but also as sons, husbands, brothers, uncles, and even friends.
To this end, they should ask their own fathers and grandfathers what they wish they had done differently – and plan accordingly.
Instead of waiting for challenges to arise, young men should begin establishing their priorities now.
How can they ensure that their relationship with their future partner is equal?
How will they adapt to enable their partner to fulfill his or her career aspirations?
Will they be willing to move for their partner’s job?
Would they be prepared to stop working or reduce their workload, in order to care for a child or parent?
Through all of this, men should remember that, by adopting a new approach, they are not abandoning their roles as providers.
After all, providing care is every bit as important as providing cash.
The reward is the close relationship with their children that women have traditionally enjoyed.
Women, too, must think carefully about the future that they would find most fulfilling.
For many women, the challenge is abandoning the assumption that their work/family balance will have to tip in favor of family, that it is they who will have to sacrifice their careers.
Of course, many women might choose to emphasize family (as would many men).
The point is the choice: the choice of how much energy to devote to one’s home, the choice of a career based on passion, and the choice of a genuinely equal partner.
Upholding an equal partnership of caregivers and breadwinners will require compromises on both sides.
A woman with great career ambitions should be able to find a partner who is willing to slow down or stop working to support her, just as a man should.
But bucking gender roles works both ways.
Indeed, for such a dynamic to work, the woman must recalibrate her expectations of her spouse.
If she wants to build a family with a man, she must not become caught up in traditional perceptions of masculinity.
If she is uncomfortable, say, out-earning her husband, she is limiting both partners.
Simply put, the kind of support that young women’s fathers and grandfathers probably offered to their mothers and grandmothers is not the only kind of support a woman can or should expect from her partner.
Her role should be determined not by old-fashioned rules, but by her individual strengths and ambitions.
And her partner should have the confidence and competence to encourage her to fulfill her potential.
Finally, graduation does not mean that the family’s job is complete.
Parents and grandparents must continue to play a critical role in reshaping expectations – or at least supporting the choices that their children and grandchildren make.
This means accepting the decision of a son or grandson not to use his hard-earned university degree to become the primary breadwinner in his future household.
And it means understanding that what a daughter or granddaughter needs may not be a traditional “provider,” but a partner who makes career sacrifices to enable her to advance hers.
Graduation is a day of ending and beginning.
It is a day for young people to recall the sacrifices that their families have made for them, and consider the kinds of sacrifices they will make for their families.
And it is a day to recognize that, if family comes first, work does not come second; rather, life comes together.
Bringing the Iran Deal Back Home
WASHINGTON, DC – The United States government’s initial statements on the “first-step agreement on Iran’s nuclear program” have been focused, above all, on the great deal that the US and the West have gotten.
Iran has agreed to halt enrichment of uranium above 5% purity; neutralize its stockpile of uranium enriched to near 20% purity; stop building its stockpile of 3.5% enriched uranium; forswear “next generation centrifuges”; shut down its plutonium reactor; and allow extensive new inspections of its nuclear facilities.
In return, Iran will get “limited, temporary, targeted, and reversible relief” from international sanctions.
The agreement covers only the next six months, during which both sides will try to reach a final comprehensive agreement.
For now, as President Barack Obama put it, the burden remains, from the US point of view, “on Iran to prove to the world that its nuclear program will be exclusively for peaceful purposes.”
Framing the issue this way reflects the need to sell even a limited, temporary deal to a skeptical US Congress.
Israel’s manifest displeasure with the entire negotiating process, which Prime Minister Binyamin Netanyahu has emphasized to anyone who will listen over the past three months, reverberates loudly among Israel’s many congressional friends.
Indeed, Israel’s stance bolsters the desire of Obama’s Republican opponents to paint him as weak and naïve in negotiating with Iran, a country that still describes the US as “the great Satan.”
Both Republicans and Democrats are threatening to pass a new round of tough sanctions against Iran in December.
Thus, Obama must focus as much on pushing back against domestic hardliners as on taking a hard line with Iranian negotiators.
This is hardly surprising.
One hopes that the Iranian government’s announcement to its own people reads roughly the same, in reverse, focusing on the important concessions that Iranian negotiators have won.
That includes suspension of international sanctions on Iran’s exports of oil, gold, and cars, which could yield $1.5 billion in revenue; unfreezing $4.2 billion in revenue from oil sales; and releasing tuition-assistance payments from the Iranian government to Iranian students enrolled abroad.
Iranian President Hassan Rouhani needs to marshal support for the deal just as much as Obama does, above all by reducing inflation and getting his country’s economy moving again.
If domestic tensions, above all within Iran’s restive middle class, ease as a result, the government will receive the credit, while the Iranian Republican Guard and other hardliners will be weakened.
The West had better hope that the Iranian narrative proves true, because the political space for any meaningful diplomatic agreement – both the desire for a deal and the room to achieve it – is created at home.
This is particularly true when a new government comes to power with promises of improving the economy.
Rouhani can undercut hardliners who would seek to block any ultimate deal only if the Iranian population both experiences economic relief and attributes it to his administration.
The true test of this interim agreement, therefore, is whether both sides can secure the domestic space to continue negotiating.
The stakes have never been higher – and not only because of the very real and dangerous geopolitical consequences of an Iranian bomb.
As Obama put it, “If Iran seizes this opportunity, the Iranian people will benefit from rejoining the international community, and we can begin to chip away at the mistrust between our two nations.
This would provide Iran with a dignified path to forge a new beginning with the wider world based on mutual respect.”
Let us imagine, just for a moment, what the Middle East and Central Asia could look like if the US and Iran could once again talk to each other.
As we saw briefly after the terrorist attacks of September 11, 2001, the drug trade from Afghanistan could be sharply curtailed.
Moreover, a regional agreement involving Iran, India, Pakistan, Russia, China, Turkey, the European Union, and the US would become much more likely, providing the framework for security and economic growth that diplomats from Henry Kissinger to the late Richard Holbrooke always claimed would be necessary for lasting peace in Afghanistan.
Perhaps most important, a peace settlement in Syria would be much more likely – and more likely to endure – if the US could talk to Iran, which has far more leverage with President Bashar al-Assad’s regime than Russia does.
After all, it was fighters from Hezbollah, Iran’s Lebanese proxy, who turned the tide of battle decisively against the opposition this past summer.
Iran has long made clear that it wants to resume its historic position as a major regional – and indeed global – power, an ambition that can only grow stronger as it watches Turkey’s geopolitical stature rise.
Iran and Turkey, after all, are the 17th and 18th largest countries in the world by population, respectively, with sophisticated elites and illustrious and ancient pasts.
The ultimate winner in the interim agreement with Iran is the cause of diplomacy itself.
US Secretary of State John Kerry, EU High Representative Catherine Ashton, and the other parties to the talks – all supported by able teams of diplomats – hammered out the deal’s details over months, staying at the table, compromising, holding firm, and managing the expectations of multiple players (including the press).
The Obama administration committed itself to global leadership through civilian rather than military power.
That is what it takes.
Obama Versus the Islamic State
WASHINGTON, DC – US President Barack Obama has laid out a detailed strategy for how his administration plans to combat the Islamic State, which controls a substantial portion of Syria and Iraq.
Though I have been harshly critical of Obama’s policy toward Syria for two and a half years, his new strategy reflects a mature and coherent foreign policy – albeit one that does not fully live up to his proclaimed values.
That omission may yet defeat his plan.
Obama’s approach is praiseworthy for three reasons.
First, it combines force and diplomacy.
Second, it attaches careful conditions to the type and scope of American military action.
Third, it ties the fate of these efforts to the existence and effectiveness of a broad Middle East coalition, making clear that though the United States is prepared to lead, it cannot and will not assume the role of global policeman.
In the Middle East game of thrones, Obama is playing his hand as well as he can.
He knows that a US-led military effort can significantly weaken the Islamic State, but that only a combined military-political effort can defeat it.
He created political leverage for himself by drawing a clear line, announcing that the US would “expand our efforts beyond protecting our own people and humanitarian missions” only together with the newly-formed Iraqi government.
If that government makes good on its promises of political inclusion, the US will help it get its country back; if not, not.
Equally important, but less evident, is the leverage that this position provides with respect to Iran.
Obama never mentioned Iran during his speech; but commentators have speculated about whether his strategy gives Iran greater leverage over the US, on the theory that Iranian-backed fighters are critical to the success on the ground in the fight against the Islamic State.
But Iraq’s Shia government is one of Iran’s major strategic anchors in the region; before the US began airstrikes against the Islamic State, it was far from certain that the Iraqi government would survive.
Iran needs US airpower at least as much as the US needs Iranian-backed ground troops.
The US emphasis on a regional coalition to fight the Islamic State is also deft diplomacy.
Secretary of State John Kerry has made it&nbsp;clear that for now Iran is not a welcome member.
Iran, without which the coalition essentially becomes a Sunni front, can have a place at the table – and play a large and overt role in resolving the Syrian civil war – but only if it is willing to reach a deal to rein in its nuclear program.
There has never been a better time to do so.
Where Obama’s strategy is weakest is in reaching ordinary people: the networked web of human relationships that transmits rage, hatred, and despair or hope, trust, and loyalty.
His doctrine that the US will use force to defend its “core interests,” but will mobilize others “to address broader challenges to international order,” is sound logic and good politics in a war-weary US.
But, as a Syrian tweeted to me, what the world hears Obama saying is that the US will use force to avenge the deaths of two American journalists, but will stand by while 200,000 Syrians are slaughtered.
Unless US military action is seen as actually protecting the lives and property of the Iraqi and Syrian people, the US will quickly lose the propaganda war to the Islamic state.
As many experts warn, the first time a drone strike kills a woman or child, a video of the scene and the funeral will be posted for the Muslim world to see.
Even if that video does not actually increase support for the Islamic State, it will convince millions of Muslims that the US is up to its old military tricks: bombing for oil, or for Israel, or simply to crush all Muslims.
Those anti-American attitudes, newly hardened once again, will make it much more difficult to get the necessary intelligence against the Islamic State on the ground and to deprive them of the support of other Sunni militias.
That will not just hurt the US in Syria and Iraq. It will shape popular views in other Arab states, limiting their governments’ ability to work with the US.
Most damaging of all, a purely strategic justification for military action – in defense of core US interests – leaves no room to do what actually needs to be done in Syria.
The only way to bring Syrian President Bashar al-Assad to the negotiating table is to weaken him and the Islamic State simultaneously.
And the only legal or moral justification for striking his air force, ammunition dumps, or heavy weaponry is the international responsibility to protect his people from him – just as the US helped to protect the Yezidis from the Islamic State.
For, contrary to Obama’s claim, the brutality of the Islamic State is not “unique.”
Assad has killed more than 200,000 people, mostly civilians, in a conflict that started with his government’s torture of children.
Simply talking about the responsibility to protect, as Obama once did, accompanied by even limited strikes – perhaps as punishment for Assad’s reported recent use of chlorine gas against civilians – would change the game quickly.
Iran would understand that America’s restraint in Syria is not indefinite; Sunni governments could be shamed in the eyes of their own people for not doing more; and the Islamic State’s narrative of brutality would collide with a narrative of humanity.
The fate of peasants has a direct and important impact on that of kings.
Obama’s policy wavers between geopolitical calculations based on national interest and the rhetoric of universal values, of standing for “our common security and common humanity.”
Making that rhetoric real would buy him the room for maneuver that is needed to pursue his policy’s geopolitical goals.
Post-Shutdown America
WASHINGTON, DC – After 16 days of closed museums, half-empty federal buildings, unnaturally quiet streets, and tens of thousands of workers left in existential limbo, the lights are back on in Washington.
But, while the shutdown of the United States government, initiated by radical congressional Republicans seeking to block implementation of President Barack Obama’s health-care legislation, is over – at least for now – three enduring lessons have emerged.
First, the next time the eurozone crisis flares up, the US will simply have to bite its tongue; after all, the shutdown spectacle revealed pathologies no less severe than those that have characterized the European Union’s economic and political negotiations over the past five years.
Irresponsible behavior threatening the health of the global economy?
Check.
Political posturing and outlandish claims foreclosing any possibility of compromise?
Check.
Breathtaking brinkmanship and 11th-hour decision-making leaving all bystanders wondering whether this time the cart might in fact go over the cliff?
Check.
Few countries in recent years have been spared the pain of their domestic political spectacles being broadcast around the world.
The United Kingdom had mass riots in London just two summers ago; strikes and demonstrations have paralyzed Paris on a regular basis; Greece has a rising fascist party; Mexico City has been practically shut down by teachers occupying the central square; and Turkish Prime Minister Recep Tayyip Erdoğan resorted to violence in June to quell weeks of protests against his increasingly autocratic ways.
Among non-democracies, China had the Bo Xilai scandal, which was worthy of a spy novel, with illicit affairs, rampant corruption, murder, and a senior police official’s dramatic quest for asylum in a US consulate.
Against this backdrop, the US government shutdown looks a little different.
Yes, it was a clear symptom of deep political dysfunction, stemming from the politicized demarcation of electoral districts and the distorting effects of America’s campaign-finance system.
Nonetheless, it is noteworthy that the entire crisis played out according to constitutional rules.
Indeed, as the deadline for raising the debt ceiling neared, Henry Aaron, a distinguished senior fellow at the Brookings Institution, pointed out that the US Constitution requires the president “to spend what Congress has instructed him to spend, to raise only those taxes Congress has authorized him to impose, and to borrow no more than Congress authorizes.”
Honoring all three of those legal obligations simultaneously is impossible if Congress refuses to raise the debt ceiling, but raising the debt ceiling without Congressional approval, though illegal and an impeachable offense, was the least-bad choice.
Even in the face of deeper political polarization than the US has seen in many decades (and, in many places, a visceral hatred of the country’s first African-American president), Americans and their politicians understand that breaking the rules means dissolving the constitutional glue that holds the polity together.
This understanding means that the cure for the current dysfunction will be found at the ballot box rather than in the streets.
And it is this collective commitment to the law governing how political power can be exercised that is the essence of liberal democracy.
But Americans are in no mood to celebrate.
Indeed, the second conclusion to be drawn from the US government shutdown is the virtual disappearance of American triumphalism. Chest-thumping exceptionalism has given way to a more sober patriotism, in which ordinary citizens recognize the long-term trends eroding the promise of equal opportunity, particularly the shortcomings that beset the country’s health-care, education, and infrastructure systems.
The anger of Tea Party Republicans (like the anger of Occupy Wall Street protesters) reflects a sense that nothing but dramatic, even revolutionary, measures can change the system.
In response, however, more pragmatic voters are increasingly irate about political paralysis and their governing institutions’ inability to respond to the preferences of a clear majority of the population. In the midst of the shutdown, the Republican Party’s popular approval rating sank to barely a quarter of the national electorate, a historic low, while the approval rating for Congress as a whole stood at just 5%.
The final lesson of the shutdown is that political systems of every kind benefit from the addition of women.
Many commented on the critical role played by six women senators – Republicans and Democrats – in reaching the compromises needed to end the crisis.
These women have maintained relationships with one another across the partisan divide, while those among their male colleagues have steadily deteriorated, giving way to competitive grandstanding and vituperation.
Equally important, these women felt – and acted upon – the moral necessity of actually governing.
In the words of Senator Susan Collins, a Republican from Maine who first put together the outlines of a deal and took it to the Senate floor, the shutdown “hurt all the small businesses” around Acadia National Park in her home state, “and that is plain wrong.”
The world should note.
Women are not necessarily better than men at governing, but they often have different perspectives and habits of engagement that can be essential for cutting through the standoffs created by the need to defend male egos.
They are also often more focused on the plight of actual people than on the promotion of grand principles, preferring concrete progress to abstract victory.
From parliaments to peace negotiations, adding women improves outcomes.
The US government is back at work, for now.
Negotiations for a real budget that all sides can live with are beginning. And assessments of how the shutdown will affect the Republican Party’s fortunes in the 2014 midterm elections are rife.
But the country’s social and economic divisions will ultimately find political solutions, through elections and the efforts of millions of Americans to achieve fundamental reforms.
As frustrating and embarrassing as the last several weeks have been, it could have been much worse.
Xi’s Recipe
WASHINGTON, DC – China’s government is cracking down hard on Western journalists, threatening not to renew visas for reporters from the New York Times and Bloomberg in retaliation for their reporting on the corruption of senior Chinese officials.
Times columnist Thomas Friedman recently penned an open letter to the Chinese government telling them that, because the top “cause of death of Chinese regimes in history is greed and corruption,” a free press is more likely to help than hurt.
Anyone who holds freedom of the press and freedom of expression to be universal human rights will agree with Friedman’s position.
But, in China, politics – including the politics of rights – is always intertwined with economics.
Last month, President Xi Jinping announced a set of sweeping economic reforms at the Central Committee’s Third Plenum, setting forth his vision of “the great rejuvenation of the Chinese nation.”
His 60-point plan included reforms of fiscal policy and the financial sector that would set market interest rates on loans and deposits, permit some private-investor participation in state-owned enterprises, increase the role of small and medium-size enterprises, loosen labor restrictions, and introduce property taxes to boost revenue for local authorities.
This renewed embrace of the market, reminiscent of Deng Xiaoping’s original turn to capitalism in 1979, will be hard medicine for China’s entrenched business and government elites to swallow.
If Xi’s administration is successful – a big if – its reforms may enable China to negotiate the necessary transition from an economy driven by exports and government investment to a more sustainable growth model based on domestic consumption.
The stakes are high.
A country that has lifted hundreds of millions of people out of poverty over the last two decades must now find a way to safeguard and gradually increase those gains while engineering the same miracle for the hundreds of millions still left behind.
The world has a significant economic, political, and moral interest in the success of China’s reform agenda.
In this context, it is important to understand that Xi’s economic reforms are only one ingredient of a carefully crafted cocktail.
The rest of the recipe includes two parts popular social reforms – an end to the one-child policy for many Chinese parents and the abolition of “reeducation through labor” – and one part political crackdown.
Increased censorship and intimidation of foreign journalists, together with the imprisonment of dissidents and tighter restrictions on dissent, are an effort to ensure that economic disruption does not give rise to political rebellion.
To implement his ambitious reform agenda, Xi has taken several steps to consolidate his personal and bureaucratic power.
He has reduced the membership of the Politburo from nine to seven, making it easier to obtain agreement in a system designed to institutionalize collective leadership.
He has increased the power of the Central Committee, which he chairs.
And he has created a new State Security Council.
To understand how the State Security Council could serve Xi’s interest in centralizing power, consider the United States.
Without the National Security Council and the Domestic Policy Council, the US president would have no routine way to control and coordinate different bureaucracies.
White House staff working for the National Security Council call meetings at which officials from the State Department, Defense Department, Treasury, Justice Department, and other key agencies hash out their views on a given policy.
But it is the president’s staff who guide the outcome and determines the next steps.
Xi’s moves to strengthen his hand have helped to convince observers that he means business with the reform agenda.
Since the Third Plenum ended and the scope of Xi’s reforms has become clear, many China watchers have hailed him as the most transformative leader since Deng.
Time will tell, but a key difference between 2014 and 1979 is that today the Chinese cocktail is spiked with fear.
Evan Osnos, writing in The New Yorker, reports that two years ago, in the midst of the Arab uprisings, a senior official told a meeting in Beijing that if the Chinese government “waver[ed]” in the midst of social-media-fueled global dissidence, “the state could sink into the abyss.”
Recently, Osnos writes, a high-level Chinese diplomat explained the threatened expulsion of New York Times and Bloomberg journalists on the grounds that “the Times and Bloomberg were seeking nothing short of removing the Communist Party from power, and that they must not be allowed to continue.”
That fear is one of the principal forces driving Xi’s reform agenda.
The Communist Party must keep the Chinese economy growing (even if more slowly), while fighting rampant corruption and responding to citizens’ demands.
Chinese citizens cannot vote, but they can – and do – make their displeasure known, which places a premium on what Chinese bureaucrats call “stability maintenance.”
Will Dobson, author of The Dictator’s Learning Curve, describes the Chinese government as a technocracy whose legitimacy is founded on efficient problem-solving. “When a regime’s legitimacy is derived from its performance,” he argues, “any crisis – and how the party responds to it – can raise existential questions about the regime’s right to rule.”
China’s leaders apparently worry that Western-style investigative journalism inside China could trigger just such a crisis.
In any case, they are taking no chances.
They are placing their faith in their ability to wash their own dirty laundry and drive economic, social, and political change from the top down.
And they are less and less willing to play by Western rules.
Germany Steps Up
WASHINGTON, DC – Since the start of his first administration, US President Barack Obama has repeated a simple mantra concerning other countries: “With power comes responsibility.” France has demonstrated repeatedly that it understands and accepts this responsibility; Germany may now be following suit.
Several weeks ago, German President Joachim Gauck’s opening address to the 50th annual Munich Security Conference reflected on the Federal Republic’s evolution over those five decades, a period that gave rise to “a good Germany, the best we have ever known.”
And, because Germany benefits more than most countries from the current open, value-based international order, it has, Gauck said, a greater responsibility to defend and extend that order.
Gauck’s speech reflected the thinking in an important new report, entitled New Power, New Responsibility, released by the Stiftung Wissenschaft und Politik and the German Marshall Fund of the United States.
The report – the product of several months of debate within the German foreign-policy and security community – identifies Germany’s current values and interests as a commitment to “human dignity, freedom, democracy, the rule of law, and to an international order that is based on universal norms.” As Gauck proclaimed, Germany’s “overriding strategic objective” must be the “preservation and continued adaptation” of this order.
To achieve this objective, Germany must become a “shaping power,” a state with the ability to solve problems and resolve conflicts affecting all or part of the international community.
The traditional determinants of states’ power relative to other states – geography, demography, economic heft, and military might, coupled with the availability of resources and technological proficiency – remain important; but they are often insufficient to confer actual influence in international politics.
A shaping power builds relationships and invests in institutions that allow it to work well with others and to create and mobilize “coalitions and networks of like-minded states.”
As a shaping power with an enormous stake in preserving and extending the openness of the international system, Germany has a special responsibility to help integrate new global powers into that system.
Here is where things get interesting.
Germany has long sought a seat on the United Nations Security Council, making common cause with Japan, Brazil, and India.
But New Power, New Responsibility suggests a different path, arguing for the reform of the Security Council in a way that would merge the French and British seats into a permanent European seat in a “slightly enlarged circle of permanent members,” while also ensuring European representation among the non-permanent members.
Under this scenario, Germany would play a role in global peace and security through the European seat, as well as serving as a periodic rotating member.
Moreover, Germany recognizes the need to consolidate Europe’s voting power and reduce the number of European seats in other global institutions, such as the International Monetary Fund and the World Bank, to make room for emerging powers.
This renewed commitment to a strong and united Europe is the second pillar of a twenty-first-century German foreign policy.
New Power, New Responsibility calls for “deepening” the European Union through measures that would include democratizing EU financial decision-making by directly engaging national parliamentarians and exchanging tighter European fiscal constraints on member governments’ budgets for a European banking union, a eurozone budget, and Eurobonds.
In foreign and security policy, New Power, New Responsibility proposes strengthening the role of the EU High Representative and the role of the European Action Service.
Current EU High Representative Catherine Ashton continues to prove the worth of EU foreign-policy institutions by, for example, brokering a remarkable peace between Serbia and Kosovo and playing a key role in nuclear negotiations with Iran.
The third surprise concerns the use of force.
Gauck told Germans in no uncertain terms that they had to be willing to use force, at least as a last resort, and reproached those of his fellow citizens “who use Germany’s guilt for its past as a shield for laziness or a desire to disengage from the world.”
More controversially, Gauck proclaimed the need for Security Council authorization of any use of force, but also hinted at a Kosovo precedent for possible military intervention in Syria.
As he put it, when the international community confronts a clear case for the use of force to protect a population from its own government, but the Security Council is divided, “the relationship between legality and legitimacy will continue to be awkward.”
The participants in the deliberations that resulted in New Power, New Responsibility split on this question.
Some argued for an absolute requirement of Security Council authorization, while others recognized an imperative to contemplate humanitarian intervention without such authorization in “very narrowly defined exceptional cases.”
US Secretary of State John Kerry also spoke at the Munich Security Conference.
But, by not referring to Gauck’s speech, he missed an opportunity to underline the success of one of Obama’s key foreign-policy tenets: as the US steps back from its role as global policeman and focuses more on diplomacy than force, other countries must step up.
Even more important, Kerry and Obama would do well to think hard about a key lesson embedded in Gauck’s speech and the report behind it.
Countries that want to retain power in a changing global order must learn to share it, which requires accepting and embracing the contours of a new world.
The Obama administration should think hard about Security Council reform.
It should signal a real willingness to replace an order that reflects the world of 1945 with one that reflects the world of 2015.
That means supporting a greater global role for all powers that understand and accept real responsibility for maintaining global peace and security.
Stopping the Syria Contagion
WASHINGTON, DC – Syria’s civil war has become a wretchedly complicated problem.
As the parties prepare to meet in Geneva for the second round of United Nations-sponsored peace talks, the government has launched vicious barrel-bomb attacks on Aleppo and other cities; more moderate Islamist rebel groups, including the Free Syrian Army, are openly at war with Al Qaeda affiliates; and Al Qaeda-linked groups are now fighting among themselves.
Meanwhile, the war’s spillover effects are worsening.
The fighting has heightened instability in the region; US and European citizens are streaming into Syria to take up jihad; and there is a growing consensus that the post-World War I Middle East boundaries are coming undone.
Indeed, the viability of Syria, a multi-ethnic state, is being threatened by multiple armed groups supported by external sponsors – Iran, Saudi Arabia, Qatar, Russia, the United States, Turkey, France, and many private donors – who themselves have conflicting aims.
Here are three ways to simplify the equation and maximize the chances that the parties to the Geneva II peace conference will be able to agree on more than the desirability of someday holding a Geneva III.
First, the most important contribution that this conference can make to the possibility of a negotiated settlement and a political transition in Syria is to change the principal parties’ incentives.
In the run-up to Geneva II, each party has sought to strengthen its hand at the negotiating table by killing as many adversaries and holding or regaining as much ground as possible. The task now for would-be peace brokers is to halt that dynamic by agreeing on criteria for participation in whatever elections will eventually be held, regardless of whether President Bashar al-Assad remains in power until then.
Those criteria must include the parties’ willingness to allow humanitarian aid to flow to all Syrian civilians under their control and an end to war crimes and crimes against humanity, including systematic targeting of medical personnel, starvation of populations under siege, and executions of war prisoners.
Here the UN must reaffirm its “responsibility to protect” doctrine, not as a justification for military intervention, but as a fundamental principle agreed by all countries: governments must protect their citizens.
If Assad’s Ba’ath party cannot uphold that responsibility, it forfeits its own legitimacy as a participant in any future government.
Second, the international community must re-establish the basis for its engagement.
When the Syrian conflict began, it was an internal matter, with UN involvement limited to humanitarian and refugee issues.
But now the conflict has spread across the Middle East, destabilizing Lebanon and Jordan and threatening to fracture Iraq.
The UN Security Council is charged with addressing breaches or threats to international peace, a criterion that is now clearly met.
As a permanent member of the Security Council, Russia thus has an obligation to act; it (and China) can no longer hide behind the argument that the UN should not be engaged in Syria’s internal affairs.
At a time when the Winter Olympic Games in Sochi put Russia squarely on the international stage, the US and other Security Council members should plan a series of resolutions that confront the Kremlin with the choice of meeting its responsibility or applying its own leverage to bring the conflict to an end.
Finally, the single most important step that US President Barack Obama could take is to put the credible threat of force back on the table.
In three years of increasingly bloody conflict, the only diplomatic success was achieved when Assad believed that he faced US missile strikes. He suddenly saw the desirability of getting rid of his chemical weapons.
But most experts believe that military force is off the table.
The US public sharply rejected Obama’s planned missile strikes to punish Assad for the repeated use of chemical weapons, and a recent Pew poll indicates that a majority of Americans believe that the US “should mind its own business internationally and let other countries get along the best they can on their own.”
Obama’s job, however, is to look beyond opinion polls, particularly when it comes to safeguarding national security.
The US has withdrawn from Afghanistan and Iraq, but the gains so painfully won are being reversed.
Al Qaeda is back and is fighting for its own proto-state in western Iraq and eastern Syria, which is far closer to Europe and the US than the caves of Afghanistan.
Perhaps Obama thinks that he or his successor can deal with that threat down the road.
If Al Qaeda operatives begin threatening the US from the Islamic State of Iraq and Syria, the US will just take them out with drones, as it has done in Afghanistan, Pakistan, and Yemen.
But if he is willing to contemplate using force against Al Qaeda without international authorization in the future, why not use drones now to strengthen the moderate Syrian opposition and force Assad into serious negotiations?
The threat of cruise-missile strikes last September was enough to send Al Qaeda members in Syria scrambling for the hills.
A strike designed to destroy Assad’s air force and prevent him from dropping bombs full of nails on his people would concentrate his mind on a diplomatic solution.
Obama should announce that the US is committed to a political solution in Syria, and that his government will do whatever it can to bring about such a solution through next week’s peace conference and follow-up action.
But if a ceasefire has not been achieved in the next three months, the US should work with regional organizations and all friends of the Syrian people to authorize a set of military strikes on Al Qaeda-linked forces and on the killing machine that Assad’s government has aimed at civilians.
The Obama administration should make the case for this to the American people in terms of straightforward US security interests.
After all, if Geneva II fails, Geneva III will not be about Syria alone. It will be about how to end a war raging across the entire Middle East.
World Cup America
WASHINGTON, DC – Something changed – or perhaps was revealed – in the United States during the last month.
Many millions more Americans watched the World Cup soccer tournament in English and Spanish than ever before.
True, with the World Cup’s end, many are arguing, as usual, that Americans pay attention only every four years – and only when the US is playing.
But this time something was different: Americans continued to watch even after the US team was eliminated.
Indeed, on a weekday afternoon in the middle of summer, nearly 15 million Americans tuned in to the Brazil-Germany match in the semifinal.
That is more than the usual viewership for ESPN’s Monday Night Football, the biggest regular television draw for fans of American football.
Almost every young person at my organization, New America, found ways to watch the US games in the early rounds.
My apartment mate explained that everyone in her office, in the US Department of Education, had used the excuse of a birthday party to watch the US-Germany match.
On the Tuesday afternoon when the US played Belgium in the knockout round, every bar in Aspen, Colorado, was packed.
Of course, Aspen is one of the country’s wealthiest communities, and perhaps not representative of the US as a whole.
But US television showed an enormous crowd of fans in Kansas City following the US-Belgium match on a large outdoor screen.
It was not quite the equivalent of the final match between Italy and France in 2006, when virtually every small Italian town turned out to watch on the main square; but Americans all over the country spent the month ducking out of work and into sports bars.
America’s growing embrace of soccer reflects some important ways in which the US has “joined” the world.
For starters, both the US team and the US audience for soccer derive their growing strength from immigrants – many from countries where the sport is a national passion.
For example, in Washington, DC, almost all taxi drivers are newcomers to America.
When my driver was Ethiopian, as often happened, we would commiserate over the national team’s defeat by Nigeria in a qualifying round, then celebrate the US defeat of Ghana, and end by agreeing that in four years, or certainly in eight, the US team would be among the world’s best.
In almost every case, my driver would tell me that his children were playing in local youth leagues.
These immigrants are not only providing homegrown soccer talent for US teams; they are a core part of the expanding US audience for soccer worldwide.
Dan Levy, lead writer for the US sports website The Bleacher Report, points out that most commentators define “American soccer” as the number of Americans who watch American players in US league play.
Obviously, that is a ridiculous metric.
US tennis fans watch tennis wherever it is played all over the world, and the US audience for golf does not plummet when a tournament is played in the sport’s birthplace, Scotland.
More Americans watch soccer in the European and Mexican leagues, in English and in Spanish, than watch baseball and ice hockey, traditionally considered two of the “big four” US sports (along with American football and basketball).
For the US, in particular, the World Cup is a great equalizer.
My mother is originally Belgian, though she has been a US citizen for over 50 years; I still have an uncle, aunt, and cousins in Brussels.
During the US-Belgium match, emails flew fast and thick across the family network, with lots of friendly rivalry.
My mother claimed divided loyalty, because Belgium, after all, was “the David against the mighty Goliath.”
Her three American children all weighed in simultaneously, pointing out that in soccer it is the US that is the underdog.
Where else can the US experience what it is like to be a small country on the global stage?
Like viewers around the world, Americans rooted for their team together, regardless of their domestic differences.
At a bar in Aspen, where the only open seat was at a table with an older man and his son-in-law (who welcomed me and offered to put my beer on their tab), we cheered and groaned whenever the US got close to scoring a goal or missed a kick.
In the periodic short breaks, we sounded each other out enough to find out that we were definitely in opposing political camps.
Given the current state of polarization in US politics, I think it is likely that in most other settings, my tablemates would not willingly have bought several rounds of beer for someone who spent two years working at the State Department for Hillary Clinton.
Here, though, we were cheering not for our political side, but for our national side.
As our team maneuvered the ball down the field, politics fell away.
That happens at the Olympics, too, of course.
But the Olympics is a smorgasbord of sports, each with its core of devotees, who often cheer on their favorites at the same time, but separately, in different arenas.
And, more often than not, what we are witnessing is individual achievement – the deeply concentrated agility and courage of the downhill racer or the finely disciplined movements of the gymnast – rather than true team effort.
The World Cup allows all of the supporters of one country to come together at one moment for one game between two groups that must, like them, become more than the sum of their parts.
It actually feels incomplete to watch the World Cup alone.
At the end of the game, amid regret over the loss to mighty Belgium but convinced that the US had played a great game, my new friend said: “We need much more of this.”
US exceptionalism remains alive and well, of course.
I suspect that we will always call the world’s game “soccer.”
But now we love it, and it is our game, too.
Another Argentine History
On top of Argentina’s bestseller list is The Myths of Argentine History, Volume Two . In second place is The Myths of Argentine History, Volume One .
Both, of course, are by the same author: Felipe Pigna, a 45-year-old historian.
It is a rare event when two volumes of the same book top the Argentine bestseller list.
Nevertheless, the same thing occurred with the first and second volumes of The Argentines , another look at our history by Jorge Lanata, one of Argentina’s best known journalists.
Argentina has been on the front pages of the world’s newspapers, with stories describing an economic and social crisis born of debt default and devaluation, unemployment and widespread poverty.
The subplot is inevitably how a Latin American country that once seemed more like Europe developed all the maladies of its Southern neighbors: a state unable to guarantee public health and education; a growing gap between rich and poor; the disappearance of the middle class; and the decline of industrial capacity in favor of producing raw materials.
All of this is undeniable, and yet the most important change in Argentina – one that occurred a few years earlier – went unnoticed.
Argentina had been, since the end of the nineteenth century, the country of the future.
Millions of immigrants arrived with great expectations of making a country – and making it
In the collective imagination, this idea was expressed in the phrase, “The country that we all deserve.”
The immigrants would raise a new generation of doctors, lawyers, and engineers.
For the individual, Argentina embodied the dream that one’s children would live better – and their children even better.
This idea of promise and progress was central to Argentines.
It was the basis for Argentina, the paradigm for our lives and our way of living.
It lasted for nearly a century, until the early 1980’s.
Since then, not even campaigning politicians have dared to promise a prosperous future.
Slowly, many parents began to accept the fact that their children would be worse off.
The notion of Argentina as a country with infinite promise became a
We lost our organizing principle and no other idea has replaced it.
We no longer have a guide, an idea of how to think about our country, how to understand it and how to imagine who we are and who we can become.
Argentina has become a country without direction.
It hasn’t been easy living without knowing who we are, and it became even more difficult to live this way as we watched our world crumble.
This absence of animating purpose, of faith in the future, has made us hungry for our past.
Faced with the loss of the nation’s central idea and desperately in search of a new one, millions of Argentines have become interested in their history.
These books tell our history in an odd way.
To begin with, they reject all academic conventions, such as footnotes, graphics, or judicious explanations in favor of agreeable journalistic narratives pitched to a mass audience.
They appeal, above all, to the logic of popular suspicion that perhaps becomes inevitable when a proud nation is suddenly laid low: Pigna, like Lanata, presents a history full of conspiracy, lies, treason, and corruption.
Both books apply to the past the lens that Argentines are accustomed to using when they look at the present: the lens of the press.
If these books can be read as developing a new idea of Argentina, it is the idea that there is little to trust, that everything is fraudulent, and that leeriness must be our worldview.
This is an interesting view – and perhaps a necessary one – but it is also dangerous.
The process of developing and coming to terms with a new national idea cannot begin and end with a rejection of the very concept.
Argentina’s ongoing search is an untold, fascinating story of how we Argentines imagine and define who we want to be in the next decades.
In an uncertain age, whoever defines us first, whether a politician, an artist, or an intellectual, will merit a prominent place in our history.
Another Asian Wake-Up Call
NEW HAVEN – For the second time in three years, global economic recovery is at risk.
In 2008, it was all about the subprime crisis made in America. Today, it is the sovereign-debt crisis made in Europe.
The alarm bells should be ringing loud and clear across Asia – an export-led region that cannot afford to ignore repeated shocks to its two largest sources of external demand.
Indeed, both of these shocks will have long-lasting repercussions.
In the United States, the American consumer (who still accounts for 71% of US GDP) remains in the wrenching throes of a Japanese-like balance-sheet recession.
In the 15 quarters since the beginning of 2008, real consumer spending has increased at an anemic 0.4% average annual rate.
Never before has America, the world’s biggest consumer, been so weak for so long.
Until US households make greater progress in reducing excessive debt loads and rebuilding personal savings – a process that could take many more years if it continues at its recent snail-like pace – a balance-sheet-constrained US economy will remain hobbled by exceedingly slow growth.
A comparable outcome is likely in Europe.
Even under the now seemingly heroic assumption that the eurozone will survive, the outlook for the European economy is bleak.
The crisis-torn peripheral economies – Greece, Ireland, Portugal, Italy, and even Spain – are already in recession.
And economic growth is threatened in the once-solid core of Germany and France, with leading indicators – especially sharply declining German orders data – flashing ominous signs of incipient weakness.
Moreover, with fiscal austerity likely to restrain aggregate demand in the years ahead, and with capital-short banks likely to curtail lending – a serious problem for Europe’s bank-centric system of credit intermediation – a pan-European recession seems inevitable.
The European Commission recently slashed its 2012 GDP growth forecast to 0.5% – teetering on the brink of outright recession.
The risks of further cuts to the official outlook are high and rising.
It is difficult to see how Asia can remain an oasis of prosperity in such a tough global climate.
Yet denial is deep, and momentum is seductive.
After all, Asia has been on such a roll in recent years that far too many believe that the region can shrug off almost anything that the rest of the world dishes out.
If only it were that easy.
If anything, Asia’s vulnerability to external shocks has intensified.
On the eve of the Great Recession of 2008-2009, exports had soared to a record 44% of combined GDP for Asia’s emerging markets – fully ten percentage points higher than the export share prevailing during Asia’s own crisis in 1997-1998.
So, while post-crisis Asia focused in the 2000’s on repairing the financial vulnerabilities that had wreaked such havoc – namely, by amassing huge foreign-exchange reserves, turning current-account deficits into surpluses, and reducing its outsize exposure to short-term capital inflows – it failed to rebalance its economy’s macro structure.
In fact, Asia became more reliant on exports and external demand for economic growth.
As a result, when the shock of 2008-2009 hit, every economy in the region either experienced a sharp slowdown or fell into outright recession.
A similar outcome cannot be ruled out in the months ahead.
After tumbling sharply in 2008-2009, the export share of emerging Asia is back up to its earlier high of around 44% of GDP – leaving the region just as exposed to an external-demand shock today as it was heading into the subprime crisis three years ago.
China – long the engine of the all-powerful Asian growth machine – typifies Asia’s potential vulnerability to such shocks from the developed economies.
Indeed, Europe and the US, combined, accounted for fully 38% of total Chinese exports in 2010 – easily its two largest foreign markets.
The recent data leave little doubt that Asia is now starting to feel the impact of the latest global shock.
As was the case three years ago, China is leading the way, with annual export growth plummeting in October 2011, to 16%, from 31% in October 2010 – and likely to slow further in coming months.
In Hong Kong, exports actually contracted by 3% in September – the first year-on-year decline in 23 months.
Similar trends are evident in sharply decelerating exports in Korea and Taiwan.
Even in India – long thought to be among Asia’s most shock-resistant economies – annual export growth plunged from 44% in August 2011 to just 11% in October.
As was true three years ago, many hope for an Asian “decoupling” – that this high-flying region will be immune to global shocks.
But, with GDP growth now slowing across Asia, that hope appears to be wishful thinking.
The good news is that a powerful investment-led impetus should partly offset declining export growth and allow Asia’s landing to be soft rather than hard.
All bets would be off, however, in the event of a eurozone breakup and a full-blown European implosion.
This is Asia’s second wake-up call in three years, and this time the region needs to take the warning seriously.
With the US, and now Europe, facing long roads to recovery, Asia’s emerging economies can no longer afford to count on solid growth in external demand from the advanced countries to sustain economic development.
Unless they want to settle for slower growth, lagging labor absorption, and heightened risk of social instability, they must move aggressively to shift focus to the region’s own 3.5 billion consumers.
The need for a consumer-led Asian rebalancing has never been greater.
Another Balkan High Noon
With the world focused on Iraq, North Korea, and a possible clash with Iran over nuclear weapons, Kosovo has fallen off the radar screen.
That inattention will end soon; a decision about the province’s fate is looming.
The United States and its European friends have repeatedly stated their intent to make the difficult decision before the end of the year on whether to separate Kosovo from Serbia.
This decision – crucial to the future of an unstable region – will test Western determination and unity.
Negotiations this year in Vienna, brokered by the United Nations, showed that an agreed settlement between Serbia and Kosovo on “final status” will not happen.
Talks continue, but, as UN negotiator and former Finnish President Martti Ahtisaari diplomatically told the Security Council, they are effectively dead.
No Serbian leader will agree to Kosovo’s independence, because nationalism remains the dominant political force in the country.
Indeed, Prime Minister Vojislav Kostunica, the apostle of Serbian nationalism, has been trying in every way to undermine Kosovo’s interim government.
He is rushing to hold a national referendum this month on a new constitution without serious parliamentary debate or the usual public education.
The main purpose of his new constitution is its preamble, which enshrines Kosovo as an inalienable part of Serbia.
Kosovo’s ethnic Albanians have proclaimed that they will not accept any tie to Serbia, no matter how tenuous.
Throughout the 1990’s, they virtually opted out of Serbian-run Kosovo by creating parallel institutions.
Their forced mass exodus in 1999 and NATO’s subsequent intervention, which ended Serbia’s rule and established a quasi-state under UN administration, has made anything other than independence intolerable.
Some time over the next month or two, the Balkan Contact Group — the US, UK, France, Germany, Italy, and Russia – will consider Ahtisaari’s recommendations on Kosovo’s final status and possibly propose a solution to the Security Council, which must make the final decision.
In public, all Contact Group members have tried to leave the question of Kosovo’s final status open, but informally the US and some of its allies have told the two parties that they will propose independence this year.
Some members of the Security Council – particularly Russia and China – are opposed to or skeptical of an imposed settlement, and few governments favor dividing up another country’s territory, however compelling the circumstances.
Whether the Security Council will approve independence largely depends on averting a Russian veto, which will require considerable diplomatic effort.
The nature of the independence bestowed is also important.
An independent Kosovo must be secured and its minorities protected.
Northern Kosovo, now largely under Belgrade’s control, must not be partitioned off in all but name.
In the interest of reducing the blow to Serbia, the Security Council must avoid granting independence in ways that are so contorted that the new state cannot effectively function.
If the Security Council fails to reach a decision on final status, it will produce a GRAVE situation: Kosovo would declare independence unilaterally, and all nations would have to make up their mind whether or not to recognize the new state.
If that happens, it is likely that the Serbs of North Kosovo would declare their own independence.
At a minimum, Serbia would campaign strongly against recognition.
In fact, Serbia’s government is already trying to persuade the West to postpone a decision until mid-2007.
It claims that if Kosovo is granted independence, the ultranationalist Radical Party will come to power in the next elections, and believes that holding elections as early as this year will cause the Contact Group to delay a proposal to the Security Council.
Moreover, the government has encouraged the leaders of Bosnia’s Republika Srpska to threaten to hold their own referendum on separation from a still fragile Bosnia.
And they continue to push &#45;&#45; unsuccessfully &#45;&#45; for Ahtisaari’s removal in order to prolong the Vienna talks.
The timing of the constitutional referendum appears to be a part of this delaying strategy.
Some hope that postponement will stimulate violence in Kosovo and further encourage Western reconsideration of independence.
That tactic may be working.
Many European Union countries are worried about the implications of taking away a country’s territory, as well as the impact of Kosovo’s independence on Serbian democracy.
Given Serbia’s political instability, they question the harm of a short-term postponement – albeit mostly self-inflicted.
But delay only offers more room for Kostunica to find ways to make a Security Council decision more difficult.
The West must ignore Belgrade’s siren song.
Serbian politics will be chaotic and unstable for the foreseeable future, and Serbian politicians will attempt to present this as an excuse to avoid facing the loss of Kosovo.
Likewise, there will be problems establishing ties between Serbia and Kosovo under any circumstances.
But failure to proceed definitively now on Kosovo’s final status will produce a worse Balkan situation, one that blocks Serbia’s move toward the West and ultimate membership in the EU, condemns Kosovo’s ethnic minorities to dangerous ambiguity, and imperils fragile states like Bosnia and Macedonia.
No realistic solution exists for Kosovo but independence.
If Serbia wants to join the West, it must not forsake that opportunity by trapping itself in its nationalist past.
Another BRIC in the Wall?
NEW YORK – Conventional wisdom rarely survives a good stress test, and few tests have been as stressful as that which the global economy has endured over the past 24 months.
A healthy season of reappraisal has dawned, shining a new light on boom-time notions like the value of opaque markets, the untouchable status of the American consumer, or the wisdom of deregulation.
One piece of bubble wisdom that has escaped relatively unscathed, however, is the assumption that the “BRIC” countries – Brazil, Russia, India, and China – will increasingly call the economic tune in years to come.
The BRIC notion, coined in a 2003 Goldman Sachs report, is not all bad: at 75% correct, it scores a good deal better than most economic prognostications of the day.
Yet the economic crisis that began in 2008 exposed one of the four as an impostor.
Set the vital statistics of the BRIC economies side-by-side and it becomes painfully obvious that, in the words of the old Sesame Street game, “One of these things is not like the other.”
The weakness of the Russian economy and its highly leveraged banks and corporations, in particular, which was masked in recent years by the windfall brought by spiking oil and gas prices, burst into full view as the global economy tumbled.
Saddled with a rust-belt infrastructure, Russia further disqualifies itself with dysfunctional and revanchist politics and a demographic trend in near-terminal decline.
Even with the modest recovery in commodity prices over the past six months, Russia’s energy sector has experienced declining production in recent years, due in part to fears among foreign investors of expropriation.
Russia’s sovereign wealth fund, integral in propping up an increasingly re-centralized economy, is being depleted fast.
If negative trends continue, Russia’s reserve fund could eventually be exhausted.
Russia’s fall back to earth, meanwhile, spawned a kind of parlor game among academics, foreign-policy wonks, and educated investors, aimed at replacing the country in the club of major emerging-market economies.
A variety of acronyms has been suggested, from the cutesy BRICET (adding Eastern Europe and Turkey) to BRICKETs (the former plus South Korea) and – an even greater stretch – BRIMC, which shoehorns Mexico into the mix.
In all of these revisions, Russia survives, despite the writing on its economic wall.
While Russia retains the world’s largest (if somewhat aging) arsenal of nuclear weapons, as well as a permanent seat (and thus veto power) on the UN Security Council, it is more sick than BRIC.
Purely from the standpoint of economic potential and fundamentals, the case is far stronger for South Korea, a sophisticated economic power whose primary liability is the danger that the regime of its evil twin to the north will collapse and inundate it with hungry refugees.
The same is true of Turkey, with its robust banking sector, thriving domestic market, growing importance to Middle East and energy politics, NATO membership, European Union membership bid, and ties to ethnic cousins across Central Asia.
Perhaps the most compelling case of all is that of Indonesia, the world’s largest Muslim state, with a rapidly expanding middle class, relatively stable democratic politics, and an economy that has been a star performer in Asia despite the global recession.
From an American perspective, Indonesia is an attractive alternative to Russia, which recently has vied with Venezuela for leadership of the “America in decline” cheering section.
Indonesia, moreover, has shown resilience not only economically, but also as a nation.
In spite of its diverse ethnic makeup and far-flung island territory, the country has made a quick transition from military dictatorship and has recovered from myriad challenges and setbacks, including the 1997 Asian financial crisis, the tsunami in 2004, the emergence of radical Islam, and domestic unrest.
While Indonesia’s per capita GDP remains low, it is a country’s potential that matters in economic affairs, and here Indonesia shines.
Indonesia depends less on exports than its Asian peers (let alone Russia), and its asset markets (timber, palm oil, and coal, in particular) have attracted major foreign investment.
The government in Jakarta, meanwhile, has taken a strong stand against corruption and moved to address structural problems.
Even demographic trends favor Indonesia, which, with 230 million people, is already the fourth largest country in the world by population – a full Germany (80-plus million) larger than Russia.
But catchy ideas die hard, and Russia has moved to cement the current concept of the BRICs into an irreversible reality.
The ossification of the BRICs into a
That meeting produced a notable broadside against the United States, as each member declared its desire to unseat the dollar as the global reserve currency.
A few months earlier, the four were moved to issue a joint communiqué ahead of the G-20 Summit in April noting their shared determination to change the rules of the global economic system.
In the private sector, BRIC index funds have proliferated, though Goldman Sachs has radically hedged its own BRIC bet by introducing a second term – the “Next 11,” or N-11 – to the debate.
This grouping adds
Russia sniffs at the idea of demotion, and American officials appear to have decided to steer clear of the semantic debate.
Still, it should surprise no one that Russia lobbied hard for the Yekaterinburg BRIC summit, and footed the bill for much of it as well.
Why risk exposure too soon?
Another European Failure
JERUSALEM: The European Union has failed once again.
Its total impotence to prevent war near the heart of Europe was amply proved in Bosnia and Kosovo over the last decade.
Now the European Union has once again failed to respond to the challenge posed by the Haider phenomenon in Austria.
By lifting the half-hearted sanctions imposed by the 14 members of the EU on Austria in February, any talk about Europe standing for a community of values sounds even more hollow than ever before.
In the case of Bosnia and Kosovo, Brussels proved itself to be totally irrelevant and impotent when the use of force – or the threat of the use of force – was concerned.
Fine words and mellifluous phrases filled many documents – but when Vukovar was destroyed, Dubrovnik shelled, Sarajevo besieged for years and then the horrible mass murders in Srebrenica occurred – all that the European Union was able to muster were more words and self-righteous indignation.
But then one could argue that the European Union was not a military alliance.
In the end, it proved that – of all people – Machiavelli was right when he argued that even prophets need to be armed in order to be effective: the moral imperative not to allow another genocide-like development in Europe needed the NATO’s armaments to be effective.
The European Union continued to produce words.
When it came to Austria, however, there was a feeling that since this was not a military, but a purely political and moral situation, Brussels – and the Continent-wide political clout signified by it – would be able to prove efficient.
Alas, it failed as dismally as the League of Nations failed in the l930's.
Let us revisit what the issue was and still is: in the heart of Europe – and in a country burdened by the political ideologies which gave rise to Hitler, himself an Austrian – Jörg Haider and his party revived the political discourse of xenophobia, racism and visceral anti-foreign sentiment.
It is true that democracies always find it difficult to balance their commitment to human rights with their commitment to free speech: it is a delicate path to tread, and there is no easy answer on a legal and constitutional level.
Yet the issue is not legal or constitutional – it is political.
To preserve democracy and human rights, democratic parties have realized that the most effective ways to confront racist and xenophobic parties is to marginalize and exclude them – to treat them as beyond the pale as potential partners for government.
The Austrians are right that Haider-like parties exist in many European countries – in Britain, France, even in some Scandinavian countries.
But in all these countries, the political discourse of all democratic parties ostracized these racist groups and parties: British Conservatives have never entered into an alliance with the British National Front; the same goes for France, where French conservatives have expelled from their own party local leaders who fashioned municipal alliances with Le Pen's representatives.
This is exactly what the Austrian conservative People's Party under Wolfgang Schuessel did not do.
Confronted with an election outcome of whether to rejoin the Social Democrats or Haider's Freedom Party, they made a Faustian pact with Haider.
There may be good political reasons why another alliance with the Social Democrats was not appealing to Schuessel's party (for one, he would not be Chancellor in such a coalition).
But there are basic values which should have overruled such purely tactical considerations and have prevented Schuessel's party from joining with Haider.
It is the moral blindness of Schuessel and his party that triggered the response of the 14 members of the EU.
One could argue that the bilateral sanctions imposed by the 14 on Austria were inadequate and even ineffective.
This is besides the point: the point is, what is the European Union, committed to democracy and human rights, going to do now?
Let us put it bluntly: the continued participation of Haider's party in a governing coalition in a European country is totally unacceptable.
The language Haider and many leaders of his party have used over the years is informed by the same racist and anti-Semitic discourse that gave birth to Nazism: in the specific Austrian context, it is violently anti-Slav as well as anti-Turkish.
While Haider is careful not to say anything which can be construed as anti-Semitic, his praise for the valor and honor of Waffen-SS veterans as well as comments on Nazi concentration camps clearly suggest where his ideological home is.
Haider and his party deserve to be politically isolated and ostracized.
The EU countries have failed twice in their attempt to respond to this challenge – once by half-hearted sanctions; now by lifting them.
What is Brussels to do?
Continue with business-as-usual, churning out document upon document of bureaucratic mumbo-jumbo, perhaps even continue to give free advice to Israelis and Palestinians about how to work out their differences?
One wonders what a good European word for chutzpa would be.
Charity begins at home.
At a time when the EU is on the verge of an ambitious project of enlargement to include many Slav and other Eastern European nations, to allow a racist and xenophobic party to be in power in Austria – or anywhere else within the EU – is a continued reminder of the moral bankruptcy of the idea of European unification.
After the l930's and l940's one would have hoped that European countries would take threats emanating from a kind of language and sentiment expressed by Haider and his party more seriously.
This is the challenge for European leaders now, and one would hope that under the French Presidency, and with the traditions of the Enlightenment being so central to French and European discourse, a vigorous, efficient response will be found.
Another Failed British Experiment
FLORENCE – British politics has always been something of an experimental laboratory for the industrialized world.
In the 1970’s, Britain was where the preeminent postwar model of how to manage the economy collapsed.
That model had been based politically on the creation of consensus, and economically on Keynesian demand management. Today, the equivalent collapse has been of the “regulation-lite” regime in which a party that styled itself as “New Labour” accepted a powerful role for markets – particularly for largely deregulated financial markets.
In the 1960’s, Keynesian policies delivered the illusion that everyone was benefiting, with high levels of employment and significant wage growth.
Britain was the coolest place on earth, boasting the Beatles and the Rolling Stones and the pastel fashions of Carnaby Street.
But Keynesianism involved continued fiscal expansion, with no offsetting monetary contraction.
By the 1970’s, it had brought to the United Kingdom large and ultimately unsustainable current-account deficits, high levels of inflation, and then political gridlock over what to do.
Which group should be the first to make a sacrifice?
In early 1974, Edward Heath’s Conservative government was locked in a struggle with the powerful coal miners’ union over “who rules Britain.” He called a premature election in February, in which there was no clear winner.
Heath was deeply unpopular. But the opposition Labour Party was not convincing either, and had little in the way of an intellectual alternative.
It simply sought to avoid confrontation with the unions.
The election produced a political stalemate.
The centrist Liberal Democrats appeared to hold the balance of power, and stories circulated of how Heath was prepared to concede a reformed voting system.
He held out the promise of proportional representation, which would ensure a greater number of parliamentary seats for the Liberal Democrats in future elections, in exchange for the party’s support for a new Conservative government.
There appears to be an overwhelming likelihood that the 1974 stalemate will be repeated in the upcoming general election on May 6.
The political maneuvering has already started, with the unpopular incumbent prime minister, Gordon Brown, today’s equivalent of Heath, bidding for the Liberal Democrats’ support by promising a constitutional reform that would give the party major advantages.
In 1974, the touted Conservative-Liberal Democrat coalition never materialized, as the Liberal Democrats were wary of hitching their fortunes to an unpopular and discredited politician.
The result was a minority government that struggled for support and legitimacy, and in the end offered only policies that provided no real answer to the country’s underlying problems.
Britain today resembles 1974 much more than it resembles 1979, when the Thatcher revolution set the country on a new path.
There is again a major economic problem, the end of a credit-driven boom, and a threat to the banks (except that it all looks much bigger, owing to the financial system’s massive growth and internationalization).
Both major political parties look tired, and at the same time as if they are competing to imitate each other.
The choice appalls voters.
There is also an ominous resemblance to Italy in 1992, when both major parties of the previous 40 years, the Christian Democrats and the Communists, simply melted away in a mixture of corruption and intellectual failure.
In the 2000’s boom, as in the 1960’s, it looked as if everyone could live on the never-never.
In 1960’s, it was counter-cyclical fiscal policy that held out the promise of prosperity for all; in the 2000’s, it was that individuals rather than the state piled up debt.
The magic of markets made possible an individualization of borrowing and consumption.
As in the meltdown of the 1970’s, it is easy to see how everyone benefited from the recent boom: homeowners saw their houses rising in price, social-welfare payments were expanded, and people seemed swept up in a new wave of 1960’s-style “Cool Britannia.”
But now, as then, Britain’s future is bleak and overshadowed by debt.
Major adjustments are needed.
At the same time, the main parties find it hard to address the country’s problems, because they are reluctant to call for sacrifice before an election.
And, because the party programs of the Labour government and the Conservative opposition are not clearly distinguishable, they find it hard to differentiate themselves from the Liberal Democrats.
Both major parties are appealing to the political center, but they will never be as convincing as a political party that really is in the political center, and that is unencumbered by the scandals attached to the past exercise of power.
The course of the electoral struggle so far indicates that the Liberal Democrats will do very well.
Their leader outshines his Conservative and Labour counterparts in television debates and on the campaign trail.
Moreover, Labour and the Conservatives are in a political trap.
The moment they start to disagree with the Liberal Democrats, they will make themselves look extreme and will forfeit voter sympathies.
But this demand for political moderation impedes the search for the radical and painful solutions that Britain needs.
Little wonder, then, that currency markets are treating the likely outcome in Britain – a hung parliament, with no clear majority for any party – as a repeat of the mid-1970’s, with no clear solution to the country’s underlying economic problems on offer.
Another Fine Italian Mess
ROME – A game of smoke and mirrors: this is how Italy’s current electoral campaign appears – both to Italians and the wider world.
Of course, there is nothing new in this: Italy’s political dynamics have always baffled participants and observers alike.
That a small centrist party may now get the courts to postpone the election merely adds to the usual confusion.
But one thing that seems certain this time is the likely result.
Silvio Berlusconi, the leader of the right-wing alliance, will win his third election (he has also lost twice), while the vote for the Senate is expected to produce a draw.
In this case, Berlusconi’s forces could ally themselves with Pier Ferdinando Casini’s centrist Catholic party, or work to form a coalition with their center-left adversary, the Democratic Party, led by Walter Veltroni.
The latter option, once unthinkable, is possible because Berlusconi is not running the type of inflammatory electoral campaign that he has in the past.
The sharp tone and fierce partisanship of the past 13 years have been cast aside.
Berlusconi seems to be fully aware of the difficulty of governing Italy.
He needs to be.
With public debt expected to stand at 102% of GDP in 2009, rising inflation, and growth of just 0.2%, it will be difficult to keep electoral promises.
Sagging public infrastructure and an inability to attract foreign capital have made the economic outlook even worse.
In addition, while the state-owned companies Telecom, Autostrade, and Alitalia were subject to an extremely interventionist policy by Romano Prodi’s outgoing government, they have little to show for it.
Plans to build a high-speed train connecting Italy with northern Europe continue to experience delays.
The garbage crisis in Naples remains unresolved putting the international reputation of one of Italy’s most famous products, mozzarella, at risk.
With global financial markets in crisis and Europe’s economy softening, the challenges for the new Italian government will only become greater.
Foreign policy, too, may prove difficult to manage.
New activism on the part of France and the United Kingdom, along with Germany’s emergence as a central player in EU affairs, risk marginalizing Italy’s influence even more.
If Berlusconi returns to office, he will again seek strong cooperation with the United States, the path now being followed by French President Nicolas Sarkozy and British Prime Minister Gordon Brown.
If he succeeds, something like a six-nation “contact group” (France, the UK, Germany, Spain, Poland, and Italy) will have formed to determine EU relations with the US.
This leadership will be needed, because, regardless of who wins the US presidential election, the next American administration is bound to ask for greater EU participation in addressing international conflicts.
But Italy, unlike France, is in no position to substitute the beauty of Carla Bruni, Sarkozy’s new wife, for real prestige.
To achieve that, the country must promote itself as a motor of serious European reform, without neglecting the debate on the member states’ role in the EU’s economic choices.
Here Italy could join the more nationally minded economic policies now being pursued by France and the UK, to the detriment of EU technocrats in Brussels.
The one thing that seems certain from the upcoming vote is that – barring any last-minute surprises – the billionaire Berlusconi will re-assert his hold over Italian politics.
In fact, he has been Italy’s true ruler for the past 13 years.
Born as a “plastic party” to unite a gamut of political forces following the implosion of the Christian Democrats in 1994, Berlusconi’s Forza Italia showed itself to be a very cunningly structured movement, with a strong and stable consensus among its members on core doctrine.
In this election, Berlusconi decided to open the door to Gianfranco Fini’s right-wing National Alliance, with which he founded a new group, People of Freedom – the only party allied with Umberto Bossi’s Northern League – in an effort to ensure that the government is backed by an even stronger and more cohesive core party.
The Catholics of the Union of Christian and Center Democrats and the post-fascist right of Francesco Storace have left the coalition.
A similar choice was made on the left by Veltroni, whose Democratic Party is now allied with Antonio Di Pietro’s Italy of Values Party.
The Communist Party and the Socialists have left the coalition that Prodi forged to gain his parliamentary majority.
The purpose of this realignment was to create more stable large parties, but further changes are likely.
Strong pan-European center-right and center-left political parties are likely to contest the European Parliament elections in the spring of 2009.
As Europe presses ahead with reform, the question for Italy is whether smoke and mirrors is all its politics have to offer.
Another Roller Coaster Ride for Exchange Rates in 2009?
CAMBRIDGE – 2008 has been an exceptionally tumultuous year for exchange rates.
The American dollar soared, the Japanese yen went into orbit, the euro fell to earth, and the British pound crashed, leaving a giant crater.
Emerging-market currencies were hammered, as were “commodity currencies” such as the Canadian, Australian, and New Zealand dollars, and the South African rand.
Indeed, the currency of any country that is significantly dependent on commodity exports has suffered.
So, what will the New Year bring for exchange rates?
While the only safe bet is continuing high volatility, we are at an unusual juncture where the short- and long-term trends appear to be very different.
In the short run, the yen and the dollar continue to benefit from a flight to safety, as panicked investors seek a place to hide.
The yen and dollar are also being bolstered as central banks elsewhere continue to cut interest rates towards zero, territory that the yen and dollar policy rates already occupy.
Thus, even though the United States and Japan will not be raising interest rates anytime soon, lower foreign rates still make the dollar and yen relatively more attractive.
Commodity prices will continue to be soft, pulling down commodity currencies, and bolstering the yen especially, since resource-poor Japan is so reliant on commodity imports.
Normally, short-run and long-run exchange-rate trends point in the same direction.
Indeed, a huge body of research shows that for most major currencies, the best forecast of next week’s exchange rate, next month’s exchange rate, or even next year’s exchange rate is simply today’s exchange rate.
But times are hardly normal.
The continuing financial crisis is putting steady upward pressure on the dollar thanks to its safe haven status.
Commodity prices are plumbing new depths.
Yet the financial crisis will eventually end, as will the global recession.
Neither will end soon, mind you, perhaps not for another seven or eight months, if not longer.
But, when more normal growth does resume, the recent trends underpinning dollar and yen appreciation will disappear.
Perhaps international investors will be grateful to the US for its aggressive monetary and fiscal stimulus, which will accelerate sharply when President-elect Barack Obama takes office on January 20.
But investors will still worry about what happens when the bills come due.
Many emerging markets will also want to engage in countercyclical macroeconomic policy, but they are hemmed in by concerns of fiscal sustainability and fear of rampant inflation.
European fiscal policy is constrained by the Maastricht Treaty, while European monetary policy is rather single-mindedly devoted to price stability.ampnbsp;
True, China, with its vast foreign exchange reserves, has the wherewithal to spend as much on countercyclical macroeconomic policy as anyone.
But China’s rulers know that their highly repressed banking system is vulnerable as the country continues to pursue gradual financial liberalization, and that foreign currency reserves may be needed for recapitalization.
Thus perhaps no region will be as expansionary as the US.
For the moment, global investors cannot get enough of US treasury bills, as collapsing interest rates for short-term US securities demonstrates.
But a lot of this demand is driven by short-term, crisis-fueled fear.
As markets normalize, surely investors will look around and realize that the US has vastly increased its debt in fighting the downturn, possibly by several trillion dollars.
At the same time, today’s falling prices (or “deflation”) will eventually morph into inflation as aggressive monetary easing takes its toll on price stability.
Admittedly, some of the major currency’s movements during the past year can be regarded as normalizing.
On a purchasing power basis (a crude measure of what different currencies can buy in terms of real goods), the euro was absurdly overvalued at $1.60, just as the yen was absurdly undervalued at over ¥120 to the dollar.
Commodity currencies had to come off their meteoric highs.
Thus, the past year’s currency alignments have, to some extent, simply brought relative domestic price levels and exchange rates into better balance.
But by now, emerging-market countries’ exchange rates, and even more so commodity currencies, have probably overshot on the downside.ampnbsp;
Over the long run, globalization and economic convergence will resume, and emerging market and commodity currencies will have to strengthen.
At the same time, the prospect of higher US inflation and massively higher US public debt levels must eventually weigh on the dollar, as does the still worrisome US trade deficit.
As for the yen, it, too, will suffer from the continuing rise in Japan’s public debt levels, which are already among the highest in the world.
Continuing weakness in the Japanese economy will eventually hit the yen.
If today’s constellation of exchange rates represents some excessive dollar and yen appreciation, especially against emerging-market currencies, when it will unwind?
That depends on when you think the financial crisis will abate, and the timing of that is as hard to predict as exchange rates.
But come it will. Then watch for the dollar and yen to boomerang.
Anti-Americanism and Europe\u0027s Identity
The question of how the international community should deal with Saddam Hussein, Iraq's ruthless dictator, is rightly the year's dominant theme.
In one sense it has been answered: the United Nations is and will continue to be involved, and the United States has and will continue to play the leading role.
Containment of Iraq by intervention is the method that now seems most likely.
In the process of reaching this decision, however, several long simmering issues have come to the fore.
One, of course, concerns the supposed "clash of civilisations": how do we keep a focused and limited conflict between the UN and Iraq distinct from the need to maintain a relationship of dialogue between world religions?
Another question may seem more parochial to some but is of equal significance globally: what are we to make of the differences between Europe and America that have become so manifest in the Iraq debate?
Is this its own form of "clashing civilizations."
No doubt, the differences that now exist between America and Europe are profound, and are not confined to a temporary cooling of German-American relations or to a half-serious exchange of invectives about "gun-slinging America" and "old Europe."
Indeed, even intellectuals are caught up in the emotional undertones.
When the British historian Timothy Garton Ash, writing in the New York Review of Books , distinguished the US and Europe by paraphrasing the title of a bestselling book, saying that "Americans are from Mars, Europeans are from Venus," some American readers objected to the sexual portrayal of an effiminate Europe and a macho America.
Yet Garton Ash is among the most pro-American Europeans, whose views of a united Europe are closer to those of his many friends in the "new", postcommunist Europe than to those of France or Germany.
But views about what Europe is and should be are actually at the heart of today's anti-Americanism.
The countries of Europe are moving inexorably towards the "ever closer union" that the founding Treaty of Rome demands.
There is a single market, crowned--at least for most EU members--by a single currency; there is a constitutional convention that will propose a new basic treaty, perhaps by mid-June; there are ambitious plans for a common foreign and security policy and other common policies.
So what is the problem?
One problem--probably the most fundamental--is that European integration no longer fires the imagination of Europeans.
There are still Euro-enthusiasts, but among the peoples of Europe indifference and, in some places, mild hostility, prevails.
Even the common currency has so far not really caught on; it is useful, but somehow "foreign."
Underneath all this is the niggling question: why are we doing all this?
What is the compelling reason that provides the driving force behind "ever closer union"?
In the 1950s, the answer was simple: Europeans should never go to war against each other again.
On the contrary, they need to stand together against the Communist threat.
Fifty years later, these goals are no longer relevant.
Economic union has benefited many; but it is not the type of driving force that inspires.
More recently, the idea of a "European identity" has been in vogue.
The EU supposedly expresses it.
But how is this identity to be defined?
This is the point at which many begin to use language that defines Europe by distinction, indeed by contrast, to the US--Europe as the anti-America.
Throughout the Cold War, what was then the Soviet Union provided a
Comparing and contrasting the two sides of the Atlantic has a long pedigree, of course.
European culture and American commerce, European profundity and American materialism--these are ancient and tired themes.
Most would today use more subtle language.
They point to what they regard as America's unfettered capitalism and hold up Europe's social market economies against it.
Internationally, Europe likes multilateral arrangements, whereas America prefers to go it alone.
From the other stereotypical point-of-view, Europe wallows in the complexity of issues whereas America likes simple lines of conflict--you are either for us or against us.
It is easy to see how the belief in such differences affects the Iraq debate.
The result is that many leading Europeans begin to define their intentions for the Union by contrasting it to the USA.
The euro must hold its own against the dollar--and hurrah!--it is now above parity.
European foreign policy must provide a counterweight to that of the hyperpower across the Atlantic.
On closer scrutiny, such facile phrases are deeply disturbing.
The eight (and now nine or more) governments that signed the Aznar/Berlusconi/Blair statement supporting the US realized this.
They insisted on undivided Western values, the values of enlightenment and liberty.
These values are shared between Europe and America--and some others--and they are worth defending in an alliance.
When it comes to values, any attempt to divide the American and the European traditions is misguided.
It may be that these shared values make it more difficult to find the much-desired European identity.
But feeding anti-American sentiment, however unintentionally, into the European construction would be intellectually dishonest, morally suspect, and politically dangerous for all freedom-loving Europeans.
Immigration and the New Class Divide
SINGAPORE – The British shadow minister for Europe, Pat McFadden, recently warned members of his Labour Party that they should try to make the most of the global economy and not treat immigration like a disease.
As he put it, “You can feed on people’s grievances or you can give people a chance.
And I think our policies should be around giving people a chance.”
In a world increasingly dominated by grievances – against immigrants, bankers, Muslims, “liberal elites,” “Eurocrats,” cosmopolitans, or anything else that seems vaguely alien – such wise words are rare.
Leaders worldwide should take note.
In the United States, Republicans – backed by their Tea Party activists – are threatening to close the government down just because President Barack Obama has offered undocumented immigrants who have lived and worked in the US for many years a chance to gain citizenship.
The United Kingdom Independence Party (UKIP) wants to introduce a five-year ban on immigration for permanent settlement.
Russia’s deputy prime minister, Dmitry Rogozin, once released a video promising to “clean the rubbish” – meaning migrant workers, mostly from former Soviet republics – “away from Moscow.”
Even the once famously tolerant Dutch and Danes are increasingly voting for parties that fulminate against the scourge of immigration.
Always keen to assert the freedom to insult Muslims, the Dutch Freedom Party wants to ban all mosques.
And the tiny and much-harassed opposition parties in Singapore – a country where almost everyone is descended from immigrants – are gaining traction by appealing to popular gripes about immigrants (mostly from India and China) who are supposedly taking jobs from “natives.”
What can American Tea Party enthusiasts, Russian chauvinists, fearful Dutch and Danes, and Singaporean leftists possibly have in common that is driving this anti-immigrant sentiment?
Retaining one’s job in a tightening economy is undoubtedly a serious concern.
But the livelihoods of most of the middle-aged rural white Americans who support the Tea Party are hardly threatened by poor Mexican migrants.
UKIP is popular in some parts of England where immigrants are rarely seen.
And many of the Dutch Freedom Party’s voters live nowhere near a mosque.
Anti-immigrant sentiment cuts across the old left-right divide.
One thing Tea Party or UKIP supporters share with working-class voters who genuinely fear losing their jobs to low-paid foreigners is anxiety about being left behind in a world of easy mobility, supranational organizations, and global networking.
On the right, support for conservative parties is split between business interests that benefit from immigration or supranational institutions, and groups that feel threatened by them.
That is why the British Tories are so afraid of UKIP.
Nigel Farage, UKIP’s leader, is less concerned with economic growth than with pursuing his extreme conception of national independence.
On the left, opinion is split between those who oppose racism and intolerance above all and those who want to protect employment and preserve “solidarity” for what is left of the native-born working class.
It would be a mistake to dismiss anxiety about immigration as mere bigotry or apprehension about the globalized economy as simply reactionary.
National, religious, and cultural identities (for lack of a better word) are being transformed, though less by immigration than by the development of globalized capitalism.
In the new global economy, there are clear winners and losers.
Educated men and women who can communicate effectively in varied international contexts are benefiting.
People who lack the needed education or experience – and there are many of them – are struggling.
In other words, the new class divisions run less between the rich and the poor than between educated metropolitan elites and less sophisticated, less flexible, and, in every sense, less connected provincials.
It is irrelevant that the provincials’ political leaders (and their backers) are sometimes wealthier than the resented metropolitan elites.
They still feel looked down upon.
And so they share the bitterness of those who feel alienated in a world they find bewildering and hateful.
Populist rabble-rousers like to stir up such resentments by ranting about foreigners who work for a pittance or not at all.
But it is the relative success of ethnic minorities and immigrants that is more upsetting to indigenous populations.
This explains the popular hostility toward Obama.
Americans know that, before too long, whites will be just another minority, and people of color will increasingly be in positions of power.
At this point, all Tea Partiers and others like them can do is declare, “We want our country back!”
Of course, this is an impossible demand.
Short of unleashing massive and bloody ethnic cleansing – Bosnia, on a continental scale – Americans and others have no choice but to get used to living in increasingly diverse societies.
Likewise, economic globalization cannot be undone.
But regulation can and should be improved.
After all, some things are still worth protecting.
There are good reasons not to leave culture, education, lifestyles, or jobs completely exposed to the creative destruction of market forces.
McFadden has pinpointed the central solution to globalization’s challenges: giving people “the tools to reap the benefits” of the globalized world, thereby making the “connected world work better for people.”
The problem is that this call is more likely to appeal to the highly educated, already privileged classes than to those who feel disenfranchised in today’s global economy.
This is a serious problem for political parties on the left, which increasingly seem to be speaking for the metropolitan elites, while provincial populists are pushing traditional conservatives further to the right by fishing in the dark waters of popular resentment.
Anti-Semitism on Trial
When Brazil's Supreme Court ruled in the case of Sigfried Ellwanger ­- an editor, author, and notorious Nazi sympathizer - it entered the perilous field where free speech and efforts to contain racism meet.
For years, Ellwanger published anti-Semitic books, such as The Protocols of the Elders of Zion , as well as books of Holocaust denial, such as his own Jewish or German Holocaust: Behind the Lie of the Century .
By a vote of eight to three, the Court upheld his conviction on charges of racism.
Of course, the enormity of the Holocaust ought to have eradicated anti-Semitism for all time.
Shamefully, it did not.
In many places, hatred of Jews thrives.
Elsewhere - including Europe and the United States - anti-Semitism survives among a fringe of neo-Nazis and renegades like Ellwanger, but also, more widely, in milder forms of prejudice.
But punishing someone criminally for being an anti-Semite and a racist propagandist raises troublesome issues that different countries approach in different ways.
To be sure, every country places some limits on speech.
As Oliver Wendell Holmes famously put it in a 1919 US Supreme Court decision, "Even the most stringent protection of free speech would not protect a man in falsely shouting 'fire' in a crowded theater and causing a panic."
Banning someone from shouting "Fire!" in a crowded theater is not the same, however, as convicting him for holding and propagating an opinion, even a despicable one, such as anti-Semitism.
In a democracy, standard restrictions regulate the time, place, and manner of speech in order to prevent imminent violence and civil disorder.
They bar threats against, and harassment of, individuals. They forbid libel and fraud.
Some countries, such as the US, refuse to go further and regulate speech because of its
Why, then, do many countries prosecute the hate speech of racists?
Why do International Human Rights Conventions stipulate that the law should prohibit speech that supports national, racial, or religious hatred?
Is any form of race-related speech that anybody finds offensive to be prosecuted?
Will such prosecutions actually deter hard-core racists?
No court should convict someone lightly because of the views he espouses in the public sphere.
But Ellwanger's appeal, which took almost a year for Brazil's Supreme Court to hear and decide, put Brazil squarely on the side of those who believe that inciting hatred against even a small minority - such as Jews in Brazil - cannot be allowed in the name of freedom of speech.
The Ellwanger case arose because many believe that anti-racism laws can be effective in reassuring minorities of their safety and place in the community.
Brazil is a large, pluralist, multi-ethnic country.
Its social fabric, like that of many other countries around the world, depends on mutual trust among citizens.
Constitutional and legal provisions that make practicing racism a crime punishable by imprisonment have great symbolic significance and help insure - indeed, create and secure - social peace.
Defining the offensive racist views proscribed by the Constitution was the first challenge in the Ellwanger case, because the defense denied that anti-Semitism constitutes racism at all.
The Jews, the defense claimed, do not constitute a race.
In fact, the Jews are, of course,
The second issue the Court considered was the conflict between constitutional principles: the clash between freedom to express one's thoughts and condemnation of Ellwanger for the crime of racism.
The court ruled that, ultimately, freedom to express one's thoughts, however generously conceived in a democracy, must be balanced against other values, such as reputation, honor, privacy, dignity, and equality.
Ellwanger crossed the line separating free expression from hate speech.
As in the Ellwanger case, restrictions on free expression should be defined narrowly.
But by opting for a balanced concept of free speech, Brazil's Supreme Court followed precedents in a number of European countries condemning Holocaust deniers, as well the opinion of the committee charged with monitoring compliance with the UN Convention on the Elimination of all Forms of Racial Discrimination and the European Court of Human Rights.
In a world where anti-Semitism and racism fester, where prejudice on national, religious, colored-based, or ethnic grounds foster discrimination, that is the view that best nurtures the rights of all.
रोगाणुरोधी प्रतिरोध के ख़िलाफ़ निष्पक्ष लड़ाई
ब्राइटन - मौजूदा रोगाणु-रोधी दवाएँ अप्रभावी होती जा रही हैं। अगर मौजूदा रुझान जारी रहते हैं, तो हम एंटीबायोटिक की खोज से पहले की स्थितियों में दोबारा जी रहे होंगे, जब संक्रामक रोग प्रमुख प्राणघातक थे।

दवा-रोधी रोगाणुओं की चुनौती का सामना करना कठिन होगा।  इसके लिए न केवल नई रोगाणु-रोधी दवाओं के अनुसंधान और विकास में प्रमुख निवेश की ज़रूरत होगी, बल्कि नए इलाजों को नियंत्रित और सीमित करने की ज़रूरत भी होगी, ताकि उनकी प्रभावकारिता संरक्षित रखी जा सके। जैसा कि जलवायु परिवर्तन पर प्रतिक्रिया के साथ है, प्रभावी रणनीति के लिए अंतर्राष्ट्रीय समन्वय की ज़रूरत होगी। ख़ास तौर से, सरकारी भुगतानकर्ताओं और वैश्विक ग़रीबों के साथ फ़ार्मास्यूटिकल कंपनियों की ज़रूरतों का समाधान किया जाना चाहिए।



दरअसल, किसी भी प्रयास के लिए ग़रीबों को जोड़ना महत्वपूर्ण होगा। निम्न और मध्यम आय वाले देश दवा-रोधी जीवों के महत्वपूर्ण स्रोत हैं। भीड़-भाड़ वाले आवास, ख़राब स्वच्छता, और प्रतिरक्षा प्रणाली को ख़तरे में डालना, चाहे वह कुपोषण या HIV जैसे जीर्ण संक्रमण के कारण हो, संक्रमण के लिए उपजाऊ ज़मीन प्रदान करते हैं। एंटीबायोटिक का अक्सर दुरुपयोग किया जाता है या उनकी गुणवत्ता कम होती है, जिससे बैक्टीरिया को प्रतिरोध विकसित करने का अवसर मिलता है। एंटीबायोटिक की बड़ी मात्रा का इस्तेमाल पशुपालन में भी किया जाता है। इस बीच, परिवहन की बुनियादी सुविधाओं में अत्यधिक सुधार - ग्रामीण और शहरी क्षेत्रों के बीच और देशों के बीच - का मतलब है कि प्रतिरोधी जीन शीघ्र वैश्विक पूल का हिस्सा बन जाते हैं।


कई असुरक्षित देशों में, सरकारी स्वास्थ्य-देखभाल प्रणाली माँग पूरा नहीं कर पाती, और विविध प्रदाता इस खाई को पाटने की कोशिश कर रहे हैं। इनमें चिकित्सा विशेषज्ञों से लेकर अनौपचारिक प्रदाता तक शामिल हैं, जो मुख्यतः विनियामक ढाँचे के बाहर काम करते हैं। पैबंद वाली इन प्रणालियों के लाभ भी हैं। उदाहरण के लिए, बांग्लादेश में एक ताज़ा अध्ययन में निष्कर्ष निकाला गया है कि अक्सर बाज़ार के स्टालों से संचालन करने वाले तथाकथित "गाँव के डॉक्टरों" द्वारा प्रदान की जाने वाली एंटीबायोटिक दवाओं ने प्रसवोत्तर रोगाणुता और बचपन के निमोनिया से मृत्यु दर में गिरावट लाने में योगदान किया है। लेकिन इसके भी काफ़ी सबूत हैं कि प्रदान की जा रही दवाएँ विविध गुणवत्ता की होती हैं और अक्सर उन्हें बिना आवश्यकता के ले लिया जाता है। बहुत बार, रोगी इलाज का पूरा कोर्स नहीं ख़रीदते।



इस पर एक प्रतिक्रिया यह हो सकती है कि ऐसे क़ानून तैयार और लागू किए जाएँ जिनसे एंटीबायोटिक दवाएँ केवल डॉक्टर के पर्चे पर उपलब्ध हो सकें। बहरहाल, इसके परिणामस्वरूप एंटीबायोटिक दवाओं तक ग़रीब लोगों की पहुँच गंभीर रूप से सीमित हो सकती है, जिससे संक्रमण से मृत्यु दर उच्च हो सकती है, जो इसे राजनीतिक रूप से अस्वीकार्य और इसलिए लागू करने में मुश्किल बना देगा। इसका बेहतर विकल्प यह होगा कि एंटीबायोटिक इलाजों को बेहतर बनाने के लिए ऐसी नई रणनीतियाँ विकसित की जाएँ जिनसे इन्हें अनौपचारिक स्रोतों के माध्यम से प्रदान किया जाए।


शुरूआत करनेवालों के लिए, उन दवाओं पर भरोसेमंद निगरानी डेटा उत्पन्न करने के लिए निवेश करने की ज़रूरत है जो आ�� संक्रमण के ख़िलाफ़ प्रभावी हैं। इलाज के दिशा-निर्देशों में यह जानकारी शामिल की जानी चाहिए और एंटीबायोटिक दवाओं के सभी प्रदाताओं की दी जानी चाहिए।


इस बीच, उच्च गुणवत्ता वाली एंटीबायोटिक दवाएँ किफ़ायती क़ीमतों पर उपलब्ध कराई जानी चाहिए। नकली उत्पादों की पहचान की जानी चाहिए और उन्हें बाज़ार से निकाल दिया जाना चाहिए, और गुणवत्ता नियंत्रित करने के लिए सरकारों, फ़ार्मास्यूटिकल क्षेत्र, और नागरिक समूहों के बीच नियामक साझेदारी विकसित की जानी चाहिए। क़ीमतों को थोक ख़रीद के माध्यम से कम रखा जाना चाहिए; कुछ मामलों में, सार्वजनिक आर्थिक सहायता भी ज़रूरी हो सकती है।


क़ीमतों को कम करने के उपायों के पूरक के रूप में बहुत ज़्यादा इस्तेमाल को हतोत्साहित करने की ज़रूरत होगी। पैकेजिंग में नवाचार, शायद दवाओं के उचित संयोजन का पूरा कोर्स उपलब्ध कराना, इलाज के फ़ैसले को आसान बना सकेगा। इसी तरह, कम-लागत की नैदानिक प्रौद्योगिकियों का विकास केवल लक्षणों के आधार पर इलाज प्रदान करने की ज़रूरत कम करने में मदद कर सकता है।
सबसे बड़ी चुनौती एंटीबायोटिक दवाओं के प्रदाताओं को अपना व्यवहार बदलने के लिए प्रोत्साहित करना होगी। इसके लिए, तकनीकी सहायता देने और कार्य-निष्पादन की निगरानी के लिए मान्यता, भुगतान तंत्र के संशोधन, और मध्यस्थ संगठनों की भागीदारी जैसे उपायों की ज़रूरत होगी। इन संगठनों में गैर-सरकारी संगठन, धार्मिक संगठन, सामाजिक उद्यमी, और दवाएँ वितरित करने वाली कंपनियाँ शामिल हो सकती हैं। इसकी संभावना नहीं है कि ये गतिविधियाँ वाणिज्यिक रूप से स्थायी हो सकेंगी, और इसलिए इनके लिए सरकारों, परोपकारी संस्थाओं, और शायद दवा उत्पादकों से समर्थन की ज़रूरत होगी।


इस बीच, लोगों को एंटीबायोटिक दवाओं के समुचित इस्तेमाल पर भरोसेमंद जानकारी और सलाह मिलनी चाहिए। यह ख़ास तौर से वहाँ महत्वपूर्ण है जहाँ नागरिक स्वास्थ्य की समस्याओं से निपटने के लिए काफ़ी हद तक अपने खुद के संसाधनों पर निर्भर करते हैं।



एंटीबायोटिक दवाओं के इस्तेमाल में प्रणाली में व्यापक बदलाव लागू करने के लिए राष्ट्रीय और वैश्विक गठबंधनों की ज़रूरत होगी। एक मुख्य लक्ष्य स्वास्थ्य कर्मियों और दवा कंपनियों के आचरण के बुनियादी मानक स्थापित करना होगा जिसमें रोगियों और समुदायों की ज़रूरतें प्रतिबिंबित हों। सरकारों को इस प्रक्रिया में प्रभावी भूमिका निभाने के लिए अपनी क्षमता का निर्माण करने की ज़रूरत होगी, और दवाओं और नैदानिक प्रौद्योगिकियों का विकास, उत्पादन, और वितरण करने वाली कंपनियों को सहयोगी समाधानों की खोज के लिए सक्रिय रूप से योगदान करना होगा। हम एंटीबायोटिक दवाओं से सही रूप में लाभ तभी उठा सकेंगे जब हम उनका निष्पक्ष और स्थायी तरीके से प्रबंधन कर सकेंगे।
दवा का सामाजिक विज्ञान





डावोस – 1980 के दशक के मध्य में जब मैं एक मेडिकल छात्र था, मुझे पापुआ न्यू गिनी में मलेरिया हुआ था। यह एक कष्टकारी अनुभव था। मेरे सिर में दर्द होता था। मेरा तापमान बढ़ गया था। मुझमें खून की कमी हो गई थी। लेकिन मैंने दवा लेना जारी रखा, और मैं ठीक हो गया। यह अनुभव सुखद नहीं था, लेकिन सस्ती, प्रभावशाली मलेरिया की दवाओं की बदौलत मैं बहुत ज्यादा खतरे में कभी नहीं था।

क्लोरोक्विन की जिन गोलियों से मैं ठीक हुआ था वे गोलियां अब बिल्कुल काम नहीं करती हैं। यहां तक कि जब मैं उन्हें ले रहा था तब भी, जिस परजीवी के कारण मलेरिया होता है वह पहले ही दुनिया के कई हिस्सों में क्लोरोक्विन का प्रतिरोधी बन चुका था; पापुआ न्यू गिनी उन कुछ स्थानों में से एक था जहां गोलियाँ प्रभावशाली बनी हुई थीं, और इसके बावजूद वहां भी उनकी शक्ति कम होती जा रही थी। आज, क्लोरोक्विन मूल रूप से हमारे चिकित्सा शस्त्रागार से गायब हो गई है।

एंटीबायोटिक दवाओं और अन्य रोगाणुरोधी दवाओं का प्रतिरोध करनेवाले रोगाणुओं की बढ़ती क्षमता आजकल के स्वास्थ्य देखभाल के क्षेत्र में सबसे बड़े उभरते संकट में तब्दील हो रही है - और यह एक ऐसा संकट है जिसे अकेले विज्ञान द्वारा हल नहीं किया जा सकता है।



अब क्लोरोक्विन की जगह अन्य दवाएं आने लगी हैं। तपेदिक की बहु-दवा-प्रतिरोधी प्रजातियां, ई.कोली, और साल्मोनेला अब आम हो चुकी हैं। अधिकांश सूजाक संक्रमण लाइलाज हैं। मेथिसिलिन-प्रतिरोधी स्टैफ़िलोकॉकस ऑरियस (एसआरएसए) और क्लोस्ट्रीडियम डिफ़िसाइल जैसे सुपरबग, तेजी से फैल रहे हैं। भारत में एंटीबायोटिक-प्रतिरोधी संक्रमणों से 2013 में 58,000 से अधिक नवजात शिशुओं की मृत्यु हो गई थी।
आज, मलेरिया का इलाज अक्सर चीनी जड़ी-बूटी से निकाली गई एक दवा - आर्टीमिसिनिन - और अन्य मलेरिया-रोधी दवाओं के संयोजन से किया जाता है। लेकिन इन क्रांतिकारी दवाओं के क्लोरोक्विन की ही तरह अप्रचलन में होने का खतरा है; दक्षिण पूर्व एशिया में मलेरिया की प्रतिरोधी-प्रजातियां होने का पता चला है।
यह मात्र चिकित्सा समस्या नहीं है; यह एक संभावित आर्थिक आपदा है। अर्थशास्त्री जिम ओ नील की अध्यक्षता में की गई रोगाणुरोधी प्रतिरोध पर समीक्षा द्वारा की गई शोध में यह अनुमान लगाया गया है कि यदि मौजूदा प्रवृत्तियां जारी रहती हैं तो दवा प्रतिरोधी संक्रमणों से 2050 तक प्रति वर्ष दस लाख लोगों की मृत्यु होगी और अगले 35 वर्षों में वैश्विक अर्थव्यवस्था को लगभग $100 ट्रिलियन खर्च करना पड़ेगा।


हो सकता है कि यह नाटकीय भविष्यवाणी भी बहुत कम हो क्योंकि इसमें संक्रमण के कारण जीवन और स्वास्थ्य की होने वाली हानि की दृष्टि से केवल प्रत्यक्ष लागतें ही शामिल हैं। आधुनिक चिकित्सा के कई अन्य पहलू भी एंटीबायोटिक दवाओं पर भरोसा करते हैं। कीमोथेरेपी प्राप्त करनेवाले कैंसर रोगी इन्हें बैक्टीरिया को दबाने के लिए लेते हैं जो अन्यथा उनकी कमजोर प्रतिरक्षा प्रणाली पर हमला कर देगा। आजकल जोड़ों के प्रतिस्थापन और सीजेरियन वर्गों सहित जिन शल्यक्रियाओं को नेमी मान लिया जाता है, उन्हें केवल तभी सुरक्षित ���ूप से किया जा सकता है जब एंटीबायोटिक दवाओं से संभावित संक्रमणों को रोका जाता है।

दवा प्रतिरोध के मूल विकास के अच्छी तरह से समझे-बूझे मामले हैं। यदि रोगजनकों पर विषाक्त दवाओं का चयनात्मक दबाव पड़ता है, तो अंततः वे उसके अनुकूल हो जाएंगे। मैं जिस वैलकम ट्रस्ट का नेतृत्व करता हूं, उसने इन तंत्रों के बारे में शोध, निदान में सुधार, और नई दवाएं तैयार करने में करोड़ों डॉलर का निवेश किया है।



समस्या का प्रभावी ढंग से समाधान करने के लिए, इस प्रयास को जैविक विज्ञान के दायरे से आगे बढ़ाकर दवा के साथ पारंपरिक रूप से न जुड़े क्षेत्रों तक ले जाना चाहिए। अमीर और गरीब देशों दोनों में ही समान रूप से, हम एंटीबायोटिक दवाओं के नियमित नशेड़ी बन गए हैं। प्रतिरोध का मुकाबला करने की कुंजी यह है कि रोगजनक जिस गति से अनुकूलन कर सकते हैं उस गति को कम किया जाए। लेकिन, एंटीबायोटिक दवाओं के अधिक उपयोग और उपचार के लिए आवश्यक कोर्स को पूरा न करने के फलस्वरूप, हम रोगाणुओं का उपयोग अभी पर्याप्त दवा प्रतिरोध को प्रोत्साहित करने के लिए कर रहे हैं। वास्तव में, हम रोगाणुओं का टीका लगाकर हम उनके खिलाफ जो प्रयोग करना चाहते हैं उसे दवाओं के खिलाफ कर रहे हैं।
यह इसलिए है कि हम एंटीबायोटिक दवाओं को लगभग उपभोक्ता वस्तुओं के रूप में मानने लग गए हैं, क्योंकि हम डॉक्टरों से इसकी मांग करते हैं, और हम इसे अपनी मर्ज़ी से लेते हैं या जब हमें ठीक लगता है हम इसे लेना बंद कर देते हैं। यहां तक कि सबसे अधिक सूचनाप्राप्त रोगियों द्वारा इन चमत्कारी दवाओं का दुरुपयोग किया जाता है। यूनाइटेड किंगडम में की गई शोध से पता चला है कि यहां तक कि जो लोग यह समझते हैं कि प्रतिरोध कैसे विकसित होता है वे अक्सर समस्या को इस रूप में बढ़ा देते हैं कि वे डॉक्टर के पर्चे के बिना एंटीबायोटिक लेने लगते हैं या अपनी दवाएं अपने परिवार के सदस्यों को दे देते हैं।

ऐसे विनाशकारी व्यवहार को बदलने के लिए यह आवश्यक होगा कि हम इसके सामाजिक और सांस्कृतिक कारणों को बेहतर रूप से समझें। इतिहास, मनोविज्ञान, समाजशास्त्र, नृविज्ञान, अर्थशास्त्र, बाजार अनुसंधान, और सामाजिक विपणन जैसे विषय इसमें मदद कर सकते हैं।

यह केवल रोगाणुरोधी प्रतिरोध के लिए ही सत्य नहीं है। यह इबोला जैसी महामारी के फैलने पर भी लागू होता है। वायरस का मुकाबला करने के लिए उसके जीव विज्ञान, इसके संचारण के महामारी विज्ञान, और उन दवाओं और टीकों के बारे में ज्ञान की आवश्यकता है जिनका संभवतः इसके खिलाफ उपयोग किया जा सकता है। लेकिन इसके लिए उन व्यवहारों को भी समझने की आवश्यकता है जिनके कारण यह संक्रमण लाइबेरिया, सिएरा लियोन, और गिनी में फैल सका।
यह समझाने के लिए कि ये समाज किन कारणों से इतने कमजोर बने हैं, इसके लिए इन क्षेत्रों के हाल के इतिहास के बारे में जानने और यह समझने की आवश्यकता है कि वहां के लोगों में सरकारी अधिकारियों के प्रति इतना अधिक अविश्वास क्यों है। इबोला को नियंत्रण में रखने के लिए रोगियों को अलग रखना और मृतकों को सुरक्षित रूप से दफन करना महत्वपूर्ण हैं, लेकिन दोनों को सांस्कृतिक संवेदनशीलता के साथ लागू किए जाने की जरूरत है – केवल उनके पीछे मौजूद विज्ञान संबंधी कारणों के स्पष्टीकरण की नहीं।
आज के सार्वजनिक स्वास्थ्य के बड़े खतरों के आर्थिक परिणाम बहुत गंभीर होते हैं। उनके कारण होनेवाले जोखिमों को न्यूनतम रखने के लिए यह जानना बहुत जरूरी है कि वे सामाजिक, व्यवहार संबंधी और सांस्कृतिक परिदृश्य के साथ परस्पर गुंथे हुए हैं। विज्ञान शक्तिशाली उपकरण उपलब्ध करता है। लेकिन इन उपकरणों का प्रभावी रूप से उपयोग करने के लिए हमें केवल विज्ञान की ही जरूरत नहीं है।


APEC at the Apex
BRISBANE – The significance of the upcoming Asia-Pacific Economic Cooperation Summit in Beijing consists not so much in what is on APEC’s agenda as in what transpires on the sidelines.
Meetings between Chinese President Xi Jinping and US President Barack Obama; as well as Xi’s meetings with Japanese Prime Minister Shinzo Abe loom especially large.
These bilateral relationships constitute much of the strategic undercurrent of East Asian security at a time when the region’s long-term geostrategic stability has come into question.
The core reality is that the Asia-Pacific region comprises a group of rapidly globalizing twenty-first-century economies sitting on top of a set of nineteenth-century national tensions.
That contradiction matters for the entire world, because the region accounts for some 60% of global output.
Economically speaking, where Asia goes in the future, the world will follow.
But Asia is home to a multiplicity of unresolved territorial disputes.
It is the epicenter of underlying tensions stemming from China’s rise and its impact on the United States, the region’s established power since World War II’s end.
Indeed, many of the region’s territorial disputes pit China against US allies.
More broadly, the region’s rifts are endemic: a divided Korean Peninsula; territorial disputes between Russia and Japan, China and Korea, and China and Japan; the unique circumstances of Taiwan; and conflicting maritime claims in the South China Sea involving China, the Philippines, Indonesia, Brunei, Malaysia, Vietnam, and Taiwan.
There are also long-standing border disputes between China and India, and between India and China’s ally, Pakistan.
As if that were not worrying enough, Asia has become the next global arms bazaar, with military outlays in the region now higher than in Europe.
Moreover, six Asian states have nuclear weapons.
Both the tone and the content of the China-US relationship are a cause for concern.
China argues that it is subject to a US policy of isolation and containment.
It points to America’s “rebalancing” strategy, to military and/or diplomatic support for those countries with which China has bilateral territorial disputes, and US support for Japan’s revision of its post-WWII “peace constitution” as a precursor for what China views as significant Japanese rearmament.
The Chinese also see the commercial equivalent of containment in the US-proposed Trans-Pacific Partnership, which includes Japan but excludes China.
Furthermore, Chinese leaders point to what they regards as intrusive US human-rights diplomacy aimed at fomenting political protest within China (including Hong Kong) and undermining the regime’s domestic legitimacy.
The US, no surprise, disputes these claims.
For starters, the US argues that it is the various states of East Asia that have actively sought American support for their security, owing to their collective concerns about China.
Moreover, the US insists that it is not containing China (as it did the Soviet Union); on the contrary, China’s economic rise has been facilitated by access to US markets, as well as to global markets through American support for Chinese accession to the World Trade Organization.
On human rights, the US argues that there are indeed fundamental differences between the two countries’ political traditions and current systems.
But, in the American view, this is vastly different from an organized national strategy of undermining the Chinese state and its institutions.
For these reasons, the bilateral strategic-trust deficit is growing.
Xi, to his credit, has advanced what he describes as a concept for “a new type of great power relationship,” one that seeks to avoid what others have concluded is the near-inevitability of long-term conflict between a rising power (China) and the established power (America).
It is imperative that both parties try to close the trust deficit.
Doing so calls for a framework of what I call “constructive realism.”
Such a framework embraces realism about areas of contention defined by significant conflicting national interests and values.
These issues should simply be peacefully managed over time, until sufficient political capital has been created in the rest of the relationship to address them directly.
At the same time, it is “constructive” in the sense of identifying areas of sufficient commonality to create new public goods, such as bilateral investment treaties, a non-nuclear Korean Peninsula, and a global agreement on climate change.
A constructive realist approach should also begin to sketch the broad outlines of a long-term “common security” concept for East Asia.
The outlook for the China-Japan relationship appears somewhat better.
Just a few months ago, the bilateral relationship had sunk to an all-time post-war low, owing to a toxic cocktail of territorial disputes over the Diaoyu/Senkaku Islands, Japan’s handling of its wartime history (particularly prime ministerial visits to the controversial Yasukuni Shrine), and Chinese fears about Japanese rearmament.
But now both governments appear to have recognized the growing risk of unintended conflict in the seas and airspace around the disputed territories, given the sheer concentration of naval and air assets in a limited space and the absence of effective protocols to manage incidents and prevent them from escalating.
Both sides have concluded that even limited armed conflict would be disastrous.
Moreover, with Japan and China facing increasing economic uncertainty, they have recognized that it makes sense for the world’s second and third largest economies to remove major political impediments to expanded bilateral trade and investment.
For these reasons, barring any last-minute diplomatic indelicacies, the APEC Summit is likely to represent the start of a formal thaw in Sino-Japanese relations.
APEC, an Australian diplomatic initiative launched 25 years ago, was originally conceived as an exclusively economic forum.
Fortunately, it has also become an annual forum for US, Chinese, Japanese, and other leaders to engage with one another on critical questions of long-term strategic stability.
The future of the region’s economy and the global economy – and the stability upon which they are predicated – will be powerfully shaped by the outcome of these deliberations.
Appeal for freedom of speech and respect for minority rights in Russia
We were taken aback and dismayed by reports of actions directed against ethnic Georgians in Russia.
These include accounts in the international media that Moscow police have asked schools to draw up lists of pupils with Georgian surnames as part of their search for illegal immigrants, and verifiable cases where Georgian businesses in Russia have been closed.
Knowing the importance to poor families of remittance to Georgia, we are also concerned at reports of measures to block bank transfers.
We feel obliged to emphasize that disputes between governments are not grounds for actions against the civilian population.
We would hope that the leadership of the Russian Federation will affirm the rights of ethnic minorities; refrain from hostile rhetoric and actions against Georgians; and ensure that our common democratic values and respectful relations between neighbours are upheld.
André Glucksmann
Vartan Gregorian
Frederik Willem de Klerk
Václav Havel
Mike Moore
Michael Novak
Yohei Sasakawa
Karel Schwarzenberg
Appeasement Revisited
I vividly remember the slightly ludicrous, slightly risqué, and somewhat distressing predicament in which Western diplomats in Prague found themselves during the Cold War.
They regularly needed to resolve the delicate issue of whether to invite to their embassy celebrations various Charter 77 signatories, human rights activists, critics of the communist regime, displaced politicians, or even banned writers, scholars, and journalists – people with whom the diplomats were generally friends.
Sometimes we dissidents were not invited, but received an apology, and sometimes we were invited, but did not accept the invitation so as not to complicate the lives of our courageous diplomat friends.
Or we were invited to come at an earlier hour in the hope that we would leave before the official representatives arrived, which sometimes worked and sometimes didn’t.
When it didn’t, either the official representatives left in protest at our presence, or we left hurriedly, or we all pretended not to notice each other, or – albeit on rare occasions – we started to converse with each other, which frequently were the only moments of dialogue between the regime and the opposition (not counting our courthouse encounters).
This all happened when the Iron Curtain divided Europe – and the world – into opposing camps.
Western diplomats had their countries’ economic interests to consider, but, unlike the Soviet side, they took seriously the idea of “dissidents or trade.”
I cannot recall any occasion at that time when the West or any of its organizations (NATO, the European Community, etc.) issued some public appeal, recommendation, or edict stating that some specific group of independently-minded people – however defined – were not to be invited to diplomatic parties, celebrations, or receptions.
But today this is happening.
One of the strongest and most powerful democratic institutions in the world – the European Union – has no qualms in making a public promise to the Cuban dictatorship that it will re-institute diplomatic Apartheid.
The EU’s embassies in Havana will now craft their guest lists in accordance with the Cuban government’s wishes.
The shortsightedness of socialist Prime Minister José Zapatero of Spain has prevailed.
Try to imagine what will happen: at each European embassy, someone will be appointed to screen the list, name by name, and assess whether and to what extent the persons in question behave freely or speak out freely in public, to what extent they criticize the regime, or even whether they are former political prisoners.
Lists will be shortened and deletions made, and this will frequently entail eliminating even good personal friends of the diplomats in charge of the screening, people whom they have given various forms of intellectual, political, or material assistance.
It will be even worse if the EU countries try to mask their screening activities by inviting only diplomats to embassy celebrations in Cuba.
I can hardly think of a better way for the EU to dishonor the noble ideals of freedom, equality, and human rights that the Union espouses – indeed, principles that it reiterates in its constitutional agreement.
To protect European corporations’ profits from their Havana hotels, the Union will cease inviting open-minded people to EU embassies, and we will deduce who they are from the expression on the face of the dictator and his associates.
It is hard to imagine a more shameful deal.
Cuba’s dissidents will, of course, happily do without Western cocktail parties and polite conversation at receptions.
This persecution will admittedly aggravate their difficult struggle, but they will naturally survive it.
The question is whether the EU will survive it.
Today, the EU is dancing to Fidel’s tune.
That means that tomorrow it could bid for contracts to build missile bases on the coast of the People’s Republic of China.
The following day it could allow its decisions on Chechnya to be dictated by Russian President Vladimir Putin’s advisers.
Then, for some unknown reason, it could make its assistance to Africa conditional on fraternal ties with the worst African dictators.
Where will it end?
The release of Milosevic?
Denying a visa to Russian human rights activist Sergey Kovalyov?
An apology to Saddam Hussein?
The opening of peace talks with Al Qaida?
It is suicidal for the EU to draw on Europe’s worst political traditions, the common denominator of which is the idea that evil must be appeased and that the best way to achieve peace is through indifference to the freedom of others.
Just the opposite is true: such policies expose an indifference to one’s own freedom and pave the way for war.
After all, Europe is uniting in order to defend its freedom and values, not to sacrifice them to the ideal of harmonious coexistence with dictators and thus risk gradual infiltration of its soul by the anti-democratic mindset.
I firmly believe that the new members of the EU will not forget their experience of totalitarianism and non-violent opposition to evil, and that that experience will be reflected in how they behave in EU bodies.
Indeed, this could be the best contribution they can make to the common spiritual, moral, and political foundations of a united Europe.
Appeasing Serbia
This month has been a bad one for the cause of human rights in Europe, as Serbia was allowed to begin its six-month presidency of the Council of Europe, the Continent’s oldest political body.
With Serbia at the helm, the Council, which aims to promote human rights and the rule of law, is now overseen by a state that thumbs its nose at the Genocide Convention and harbors an indicted war crimes suspect, former Bosnian Serb army chief Ratko Mladic.
Moreover, the European Commission has indicated that it is ready to resume talks aimed at bringing Serbia closer to the European Union as soon as a reform-oriented government is formed in Belgrade.
Earlier this year, the International Court of Justice (ICJ) found Serbia guilty of failing to prevent the massacre of more than 7,000 Bosnian Muslim men in Srebrenica.
The Court also declared that Serbia will remain in violation of the Genocide Convention until it transfers Mladic—who is believed responsible for some of the worst crimes in Europe since the Second World War—to the International Criminal Tribunal for Former Yugoslavia (ICTY) in The Hague.
But the EU seems ready to ignore Serbia’s disdain for international law.
The EU is understandably eager to support a pro-European government in Serbia, for this might pave the way for Serbia to swallow the prospect of Kosovo’s independence.
That explains why some EU member states are keen to resume the negotiations on a Stabilization and Association Agreement, which were suspended a year ago due to Serbia’s failure to cooperate fully with the ICTY.
The proposed u-turn by the EU means that Mladic’s arrest and transfer to The Hague is no longer a condition for restarting talks.
Of course, Europe needs to sweeten the Kosovo deal for Serbia.
But an immediate resumption of negotiations amounts to an approach that is all carrot and no stick, damaging the EU’s own credibility.
Indeed, the West has already tried this approach before, with paltry results.
In December 2006, NATO allowed Serbia to join its Partnership for Peace, even though there were still war criminals at large in the country.
This softer approach will prove counterproductive, as it will not strengthen democratic forces in Serbia.
Just last week, caretaker Prime Minister Vojislav Kostunica, once hailed by Europe as a great democrat, showed his true colors.
He went so far as to support the election of an extreme nationalist, Tomislav Nikolic, who was an old ally of Milosevic’s, as the Speaker of the Serbian Parliament.
The head of Nikolic’s party, Vojislav Seselj, is in the dock in The Hague facing trial for war crimes.
Although Nikolic soon resigned after a new Serbian government was formed, the cabinet’s composition suggests that the EU might be foolish to expect greater cooperation with the ICTY.
By effectively abandoning conditionality, the EU will be rewarding the most intransigent hard-liners in Serbia – that is, the very people who have opposed the arrest of Mladic for years.
With the ICTY’s closure just one year away, there is a risk that Mladic will never be held accountable.
The effect that the resumption of talks might have on the system of international law is no less chilling.
Serbia’s leadership of the Council of Europe is a done deal.
But the EU must insist on Serbia’s compliance with the ICTY, the ICJ decision, and its own Copenhagen political criteria.
Mladic must be arrested before talks start, not after.
As a signal of their seriousness, European governments should think twice before they accept Serbia’s invitation to attend the Council of Europe’s festive 1,000th meeting in June.
A minute of silence for the victims of unarrested war criminals might be a more appropriate way to pay tribute to the Council’s core values of human rights and justice than attending the party now being planned in Belgrade.
Realism on North Korea
BERLIN – The world’s task in addressing North Korea’s saber rattling is made no easier by the fact that it confronts an impoverished and effectively defeated country.
On the contrary, it is in such circumstances that calm foresight is most necessary.
The genius of the Habsburg Empire’s Prince Klemens von Metternich in framing a new international order after the Napoleonic Wars was that he did not push a defeated France into a corner.
Although Metternich sought to deter any possible French resurgence, he restored France’s prewar frontiers.
By contrast, as Henry Kissinger has argued, the victors in World War I could neither deter a defeated Germany nor provide it with incentives to accept the Versailles Treaty.
Instead, they imposed harsh terms, hoping to weaken Germany permanently.
We know how that plan ended.
John F. Kennedy was in the Metternich mold.
During the Cuban missile crisis, he did not try to humiliate or win a total victory over the Soviet Union.
Rather, he put himself in Nikita Khrushchev’s shoes and agreed to dismantle, secretly, American missiles in Turkey and Italy in exchange for withdrawal of Soviet missiles from Cuba.
Kennedy’s pragmatism prevented World War III.
Sadly, North Korea has not received such far-sighted statesmanship.
Faced with the North’s dangerous nuclear game, we should ask what would have happened if, over the last 20 some years, the North Korea problem had been approached with the sagacity of Metternich and Kennedy.
Of course, North Korea is not early-nineteenth century France or the USSR of 1962.
In the eyes of Western (including Japanese) political leaders, it has never amounted to more than a small, fringe country whose economic failings made it appear to be poised perpetually on the edge of self-destruction.
For the most part, world leaders preferred not to be bothered with North Korea, and so reacted in an ad hoc way whenever it created a security problem.
But now, following the North’s recent nuclear tests, and given its improving ballistic-missile capabilities, that approach is no longer tenable.
Perhaps the best chance to address the problem at an earlier stage was immediately after the Soviet Union’s collapse in 1991.
Back then, Kim Il-sung – the North’s founder – faced economic collapse, diminution of his conventional military forces, and diplomatic isolation.
In interviews with Asahi Shimbun and The Washington Times in March and April 1992, Kim clearly expressed a wish to establish diplomatic relations with the US.
But US and South Korean leaders were not ready to accommodate Kim’s overture.
Their received ideas about North Korea prevented them from recognizing a fast-changing political reality.
Another opportunity was missed later in the decade.
If North Korea had reciprocated in a timely manner following US envoy William Perry’s visit to Pyongyang in May 1999, President Bill Clinton’s policy of engagement with the North might have been upgraded to a push for normalization of diplomatic relations.
Instead, the North procrastinated, sending Vice Marshall Jo Myong-rok to the US only in October 2000, near the end of Clinton’s presidency.
A few months later, newly elected President George W. Bush reversed Clinton’s North Korea policy.
I still recall the difficulty that I faced, as South Korea’s foreign minister, in convincing Bush administration policymakers to negotiate with North Korea instead of merely applying pressure and waiting for the North to capitulate.
Back then, North Korea was restarting its Yongbyon nuclear facility and producing plutonium, thus strengthening its bargaining position vis-à-vis the US.
Precious time was squandered before North Korea’s first nuclear test in 2006.
Though Bush shifted his policy toward bilateral negotiations with the North a few months later, the Kim regime had become much more obstinate.
Indeed, North Korea’s behavior has since become even more volatile.
Its sinking of the South Korean corvette Cheonan and the shelling of Yeonpyeong Island in 2010 were unprecedented, and raised inter-Korean tensions to their highest level in decades.
Today, following the North’s third nuclear test, we seem to have entered the most precarious stage yet, with the regime declaring that it will never surrender its nuclear option.
So, what should be done?
The first option should be deterrence of further aggression through diplomacy.
But achieving diplomatic deterrence will depend on China’s cooperation, and this requires that China’s vital national-security interests be recognized.
China fears not only the social and economic consequences of a North Korean implosion, but also the strategic consequences of reunification – in particular, that the US military, through its alliance with South Korea, would gain access to territory on its border.
A mere statement by the US that it has no intention to press this military advantage will not assuage China’s fears.
Chinese leaders recall that the US promised Soviet President Mikhail Gorbachev that German reunification and democratic transition in Eastern Europe would not mean eastward expansion of NATO.
So a more concrete undertaking, one that preserves South Korea’s bedrock security concerns, is needed.
Only after its security is assured will China free itself from complicity in North Korean brinkmanship and be better able to control the North’s behavior.&#160;
But Chinese cooperation, though necessary, will not resolve the North Korea problem on its own.
A comprehensive approach must recognize the speed of internal change, especially in the minds of ordinary North Koreans.
Simply put, North Koreans are not as isolated as they once were, and have a growing appreciation of their impoverishment, owing primarily to greater trade and closer connections with booming China.
This internal change needs to be encouraged, because it will prove more effective than external pressure in influencing the regime’s behavior.
But such encouragement must be undertaken in ways that do not incite the North’s fears of being destroyed by indirect means.&#160; South Korean President Park Geun-hye’s recent proposal to provide humanitarian assistance despite the recent spike in tension, is a start in the right direction.
The lives of ordinary North Koreans matter as much as the security of North Korea’s neighbors.
A comprehensive approach is required – one that focuses as much on the human dimension as on the security dimension.
It remains to be seen whether this approach requires more foresight and courage than today’s political leaders in South Korea, the West, and China can muster.
Arab Fathers and Sons
The deaths of Yasir Arafat and of Sheikh Zayd, the long-standing ruler of the United Arab Emirates, continues the generational change that began in 1999-2000, when the leaders of Jordan, Morocco, Bahrain, and Syria died in quick succession.
Across the Middle East people are younger, and their political leaders older, than the world average.
The gradual replacement of one generation of elites by another may be one of the key factors in determining whether or not effective reform takes place in the Arab world.
At present, four political generations co-exist on the region’s socio-political map.
The outgoing leadership generation – that of Arafat, King Hussein or Hafiz al-Assad, King Fahd and President Mubarak – was born before 1935 and has determined events in the Middle East since the 1970’s.
These leaders came of age and began their careers during the era of decolonization.
They were weaned on Gamal Abdel-Nasser’s pan-Arab nationalism, and the crucial political event for them was the Arab defeat in the 1967 Arab-Israeli war.
Members of this generation sought a strong Arab leadership that would create a balance of power with Israel.
They also believed in – or at least toyed with – forms of socialism and étatism, and did not consider democracy or civil rights to be priorities.
The next generation was born between 1935 and 1955, and in many respects represents a generation “in between.”
Most benefited from the economic growth and expanded educational opportunities associated with the oil boom of the 1970’s.
At the same time, political participation remained blocked by the previous generation, which never intended to give up power voluntarily.
Unsurprisingly, many in this generation grew dissatisfied, and not a few began to look for Islamic alternatives to the prevailing political systems.
Rather than determining events in the coming two or three decades, this generation is likely to be sidelined by the next cohort, born between 1955 and 1975.
This is the generation of Syria’s President Bashar al-Assad, Jordan’s King Abdullah and Morocco’s King Muhammad VI. Some call this the “generation of sons” – sons of leaders who led their states for decades.
This age cohort was not much influenced by the Arab-Israeli wars or the East-West conflict. Instead, their political education included the Gulf War of 1991 and the Arab-Israeli peace process of the 1990’s, with its crises and breakdown.
Jailed West Bank Fatah leader Marwan Barghouti is as representative of this group as the leaders of Syria and Jordan.
Members of this generation are better acquainted with notions of globalization and economic reform than with socialism and revolution.
Except for the Palestinians, they have never known their countries other than as independent and comparatively stable states.
In the Palestinian territories, the jil al-intifada , the generation of the (first and second) Palestinian uprising, will likely become the founding generation.
But it is the fourth group that underscores the relevance of generational issues in the Arab world.
Even when combined, the first three generations make up barely one-third of the entire Arab population.
Almost 60% of all Arabs are younger than 20, with roughly 70% below the age of 30.
This raises a key question: what happens to these Arab “baby boomers” if the generation now coming to power clings to it as tenaciously as the generation of Mubarak, Assad, and Hussein?
The political generation of Bashar al-Assad, King Abdullah, and Gamal Mubarak – son of Egypt’s ailing president – forms a less coherent picture than that of the outgoing leadership.
In that elder generation, many had pursued military careers, and many of their aides and collaborators were engineers and civil servants.
The socio-professional profile of the new elite is broader.
Economists, bankers, and entrepreneurs as well as of technology or communication experts are common.
There are also more traditional politicians: personalities who see themselves as representatives of particular social or economic interests, not as apolitical technocrats.
This new leadership elite is in many ways more cosmopolitan than its predecessors; their average level of education is higher; a few have foreign degrees.
Women also play a somewhat greater role.
Developments in Morocco, Bahrain, and Jordan certainly seem to suggest that this changing of the guard can help soften rigid political structures and allow for broader participation.
But generational change need not be accompanied by economic reform and steps towards political liberalization – witness North Korea under Kim Il Sung’s son, Kim Jong Il.
Indeed, experience gives little reason to presume that a modern way of speaking, willingness to liberalize the economy, and an urge for technological development automatically translates into a democratic opening.
It is more realistic to expect that the new Arab elites will make use of their states’ authoritarian institutions, both to overcome resistance to their economic agendas and to consolidate their newly acquired power.
This is anything but a risk-free path.
Without a significant increase in opportunities for political participation, including genuinely competitive elections, the chasm between a predominantly young population and a ruling elite with a narrow generational base will widen.
Such continuing political inertia leaves an increasingly young Arab population prey to the appeal of extremist ideologies, while driving the best and brightest to seek their fortune elsewhere.
Arab Fathers and Sons
The problem of succession in the Arab secular republics highlights their predicament in the transition to a post-revolutionary phase, for succession in regimes that fail to build strong institutions always risks triggering a systemic crisis.
While the decision by some in favor of dynastic succession may be lacking in democracy, it is not entirely devoid of merit.
Arguably, it is a choice for economic modernization, for an end to the politics of conflict, and for positive political change further down the road.
Years of Western-backed repressive authoritarianism nipped in the bud any potential growth of a liberal alternative to the incumbent Arab regimes, and turned any abrupt move to free elections into a dangerous exercise in Islamic democracy.
A democracy that produces governments led by Hamas, Hezbollah, or the Muslim Brotherhood is inevitably bound to be anti-Western and opposed to an American-inspired “peace process” with Israel.
Syria has already sought to assure regime continuity through quasi-monarchic hereditary succession with the move from Hafez al-Assad to his son Bashar.
There are indications that Egypt might follow suit, with Hosni Mubarak’s son, Gamal, taking over.
Likewise, Libya’s Muammar Khaddafi may be succeeded by his son, Seif el Islam.
As products of revolutionary military takeovers, these secular nationalist regimes failed to produce genuine popular legitimacy and have had to fall back on the dynastic succession practiced by the regimes they toppled.
The centrality of hereditary succession in the quest for peace and stability was shown by Hafez al-Assad when he agreed to unprecedented good will gestures aimed at drawing Ehud Barak’s Israeli government into a peace deal.
An old and sick man who was to die a few months later, he acted with a sense of urgency to reach a deal that would relieve his inexperienced son of the burden of struggling for the recovery of the Golan Heights.
Bashar Assad remains essentially loyal to his father’s legacy.
Not unlike North Korea’s and Iran’s defiant nuclear policies, Bashar’s membership in the region’s “axis of evil” is a call for dialogue with America, not an invitation to an invasion, and for a settlement with Israel, not a drive to wage war on it.
In Egypt, Mubarak turned his back on the lofty rhetoric of Gamal Abdel-Nasser’s revolution and its grand strategic designs.
Stability is at the heart of his thinking.
Hence, he could not accept America’s awkward pro-democracy agenda.
But he was more than willing to occupy center stage in Arab diplomacy’s support of the Annapolis peace conference.
After all, the passion that the Palestinians’ plight evokes among ordinary Egyptians is a dangerous source of instability.
Mubarak’s succession is being conducted in an especially sophisticated manner.
His son’s ascension, unlike that of Bashar on the eve of his father’s death, is anything but settled.
But, by being allowed to acquire popular legitimacy and a high degree of acceptance within the political establishment as the driving force behind the ruling party’s preparations for the post-Mubarak era, Gamal is being positioned strategically to compete effectively for the presidency.
He is widely credited for setting the country’s agenda, and for being the motor behind the liberal economic reforms that since 2004 have meant a qualitative leap in the Egyptian economy.
It may be, as President Mubarak’s critics argue, that the faltering progress of democratization reflects the attempt to block all potential challengers to Gamal.
But, with the decline of secular nationalism and Islamism’s rise, the hidden electoral power of the Muslim Brotherhood poses a mortal threat to the regime and its strategic alliance with the West.
As a result, the regime refuses to take any chances.
Nor was Muammar Khaddafi’s decision to stop being an international pariah entirely unrelated to his concern to bequeath to his son a state that lives in peace with the world.
His abysmal human rights record remains, but the flamboyant “Guide of the Revolution” ceased flirting with weapons of mass destruction and global terrorism in exchange for the end of sanctions and international rehabilitation.
A sick man whose rule at home is being challenged by Islamist opponents, he decided that international ostracism and domestic troubles is too explosive a combination for his son, a spoiled playboy, to handle.
Algeria is an especially difficult case.
The last of the revolutionary generation, President Abdulaziz Buteflika must still conceive a succession that ends his country’s civil war.
Fully-fledged democracy might lead to victory for Islamists, as it did in 1991.
A transition to democracy in the old revolutionary Arab regimes will not correspond to a Western model, nor can it be imposed by American F-16’s.
But, as countries like Egypt, Syria, and Lybia might be indicating, hereditary succession is not an inherently reactionary move.
Rather, it means opting for a controlled transition to a post-revolutionary phase in which economic modernization and international integration might usher in greater political change in the future.
Arab Myths and Realities
WASHINGTON, DC – With Hosni Mubarak’s ouster in Egypt – widely considered to have one of the region’s most stable regimes until only recently – and Colonel Muammar Qaddafi clinging to power in Libya, there is no clear end in sight to the turmoil sweeping across the Arab world.
Protests have already toppled governments in Tunisia and Egypt, leaving other Arab countries faced with widespread discontent.
The unrest caught most people by surprise – both inside and outside the region – and has fundamentally upended at least five conventional beliefs about the Arab world.
Arabs don’t go into the street.
Before the protests began in Egypt and Tunisia, many people argued that there was no real urgency to political reform, and that those who were calling for change did not understand the public mood – things weren’t as bad as the dissidents made them out to be.
This line of thinking led governments to believe that Arabs would not demonstrate in large numbers and demand change.
In each country, rapid reform was seen as detrimental to national interests.
This argument clearly is no longer tenable.
No one predicted what happened in Egypt and Tunisia, which means that no Arab country is immune.
Governments don’t have the luxury of waiting forever, and they can no longer use the myth of popular quiescence to avoid initiating the necessary reforms that will address the public’s underlying grievances.
Economic liberalization should precede political reform.
Arab governments – and many Westerners – claimed that privatization and other economic reforms should be given priority over political change.
But, while it is easy to argue that citizens want bread before freedom, economic liberalization came without a system of checks and balances, and thus largely resulted in neither bread nor freedom.
Instead, the benefits of privatization and other initiatives went largely to political and business elites.
As a result, Arabs have come to view liberalization and globalization negatively.
It is clear by now that economic reform must be coupled with political reform, so that institutional mechanisms of accountability are developed to monitor any excesses and ensure that benefits are made available to all.
Governments have been quick to believe that the protests are fundamentally about high prices and unemployment, but the issue that unites Arab discontent is inadequate governance.
Closed systems are necessary to prevent Islamists from taking power.
The West is often afraid that democracy will give Islamists the opening they need to gain control – a fear that Arab regimes exploit to justify maintaining closed political systems.
But Islamists did not play a big role in Egypt or Tunisia, and they are not expected to lead any of the new governments that are formed – though they are an important part of Arab societies and should play a role in their emerging regimes.
So it is untrue that the only viable alternative to unrelenting absolutist rule must be Islamist.
The protests are clearly the result of ordinary citizens becoming fed up with corruption, the lack of any semblance of rule of law, and arbitrary treatment.
There is an opportunity here to start developing pluralistic systems where not only Islamists, but also other parties and discourses can play a role.
Elections equal democracy.
No one is fooled by this claim anymore.
In order to maintain their dominance, Arab governments have relied on flawed laws and elections that don’t produce strong parliaments or lead to real change.
Indeed, in countries like Egypt and Tunisia, government and parliament alike were unpopular.
Throughout the region, elections have been used to create a façade of democracy aimed at impressing citizens and the outside world while insulating the regimes from pressure for genuine reform.
The Arab public, however, will no longer accept the status quo.
People will not be satisfied with economic handouts or cosmetic changes in governance; they are demanding real change that puts their country on a clear path toward democracy.
The international community has no role to play.
While the reform process should certainly be homegrown, the United States and the rest of the international community can encourage democratic development without imposing it from afar.
President Barack Obama rejected many of the policies of the George W. Bush administration that were seen as trying to force democracy on Arab countries.
But the subsequent silence on democratization aggravated – though it certainly did not cause – the unraveling of the Arab reform process in the last few years.
The US and the West can discuss with Arab countries how political reform should be carried out in a way that would contribute to greater openness and opportunities for power-sharing.
The West should not sacrifice these objectives for others; if allies ultimately lose power in popular revolts, such a tradeoff would not have furthered the West’s interests, to say the least.
The unfolding events grabbing headlines around the world have shattered key myths about the Arab world.
These countries’ people need to start gradual, sustained, and serious political reform now.
At the dawn of a new Arab era, it is up to them to build new, open political systems that can head off the looming threat of escalating crises.
Arab Spring, Western Fall
TEL AVIV – The old vocation of what Rudyard Kipling called the “White Man’s Burden” – the driving idea behind the West’s quest for global hegemony from the days of imperial expansion in the nineteenth century to the current, pathetically inconclusive, Libyan intervention – has clearly run out of steam.
Politically and economically exhausted, and attentive to electorates clamoring for a shift of priorities to urgent domestic concerns, Europe and America are no longer very capable of imposing their values and interests through costly military interventions in faraway lands.
US Secretary of Defense Robert Gates was stating the obvious when he recently lambasted NATO’s European members for their lukewarm response to the alliance’s missions, and for their poor military capabilities.
(Ten weeks into the fighting in Libya, the Europeans were already running out of munitions.)
He warned that if Europe’s attitude to NATO did not change, the Alliance would degenerate into “collective military irrelevance.”
Europe’s reluctance to participate in military endeavors should not come as a revelation.
The Old Continent has been immersed since World War II in a “post-historical” discourse that rules out the use of force as a way to resolve conflicts, let alone to bring about regime change.
And now it is engaged in a fateful struggle to secure the very existence and viability of the European Union. As a result, Europe is retreating into a narrow regional outlook – and assuming that America will carry the burden of major global issues.
But America itself is reconsidering its priorities.
These are trying economic times for the US, largely owing to imperial overstretch financed by Chinese credit.
Admiral Mike Mullen, the US Chairman of the Joint Chiefs of Staff, recently defined America’s colossal fiscal deficits as the biggest threat to its national security.
Indeed, at a time of painful budget cuts – the US is facing a $52 trillion shortfall on public pensions and health care in the coming decades – the US can no longer be expected to maintain its current level of global military engagement.
But the fiscal crisis is not the whole story.
The dire lessons of the wars in Iraq and Afghanistan will shape future debate about America’s international role in the twenty-first century.
At an address in February to cadets at the US Military Academy at West Point, Gates said that “any future defense secretary who advises the president to send a big American land army into Asia or into the Middle East or Africa should have his head examined.”
Gates’s recent statements are by no means those of a lonely isolationist in an otherwise interventionist America.
He expressed a widely perceived imperative for strategic reassessment.
In 1947, in a landmark article, “The Sources of Soviet Conduct,” which he signed as “X,” George Kennan defined America’s foreign-policy strategy for the Cold War as one of containment and deterrence.
It is difficult to imagine a more marked departure from Kennan’s concepts than a report recently released by the Pentagon – A National Strategic Narrative – authored by two active-duty military officers who signed as “Y.”
The report can be dismissed as just the musings of two senior members of the Joint Chiefs of Staff writing in their “personal capacity.”
But its real power stems from the degree to which it reflects America’s mood in an era of declining global influence and diminishing expectations regarding the relevance of military power to sustaining US global hegemony.
Just as Kennan’s “X” article was fully reflective of the mood in America at the time, so the Narrative expresses the current American Zeitgeist.
Thus, the idea that “Y” might turn out to be a latter-day “X” – defining the nature of America’s international role in the twenty-first century – may not be far-fetched.
Conspicuously, there is much in the Narrative that coincides with Europe’s emphasis on soft power.
The authors call for a shift from outdated Cold War strategies of “power and control” to one of civic engagement and sustainable prosperity.
Security, they maintain, means more than defense.
It means engagement whereby America should not seek “to bully, intimidate, cajole, or persuade others to accept our unique values or to share our national objectives.”
America, “Y” argues, must first put its own house in order if it is to recover credible global influence as a beacon of prosperity and justice.
This would require improving America’s diplomatic capabilities, as well as regaining international competitiveness through greater investment in education and infrastructure at home.
The message emanating now from the US is not one of non-interventionism, but a strategy of restraint that assumes that there are limits to American power and seeks to minimize the risk of entanglement in foreign conflicts.
As Gates put it in his West Point address, the US Army would no longer be “a Victorian nation-building constabulary designed to chase guerrillas, build schools, or sip tea.”
The bad news is that Europe’s feebleness and America’s fatigue might also signal the limits of noble ideas such as the obligation to interfere in order to protect populations being brutalized by their own rulers.
America’s reluctance to be drawn into the Libyan quagmire, and the West’s failure to intervene in order to stop the Syrian army from massacring civilians, now looks like a sad, and fairly accurate, guide to the future.
Arafat\u0027s Ghost
History gave Yasir Arafat far more time than most leaders to achieve his mission.
After all, at the time of his death he had been leader of the Palestinians for 35 years.
Yet he left his people in a terrible situation, with no state, in the midst of a losing war, and with a bankrupt economy.
Whether his successors can revive and complete the Palestinians' historic mission depends on how they define their goal.
Looking back at his career, Arafat never really veered from the belief that his life's mission was to destroy Israel by any means necessary and replace it with a Palestinian Arab state.
An independent Palestinian state that did not include all of Israel held no appeal to him.
He was equally indifferent to his people's material welfare and anything particular about the design of a viable political and economic system.
Now, in the post-Arafat era, Palestinians must choose one of several strategies.
Unfortunately, most of the alternatives call for the continued use of violence and terrorism.
The moderate strategy seeks an independent Palestine state as quickly as possible, on the assumption that once there is no more Israeli presence or violence, the Palestinians can concentrate on constructive pursuits, including resettling refugees and improving living standards.
But this is the view of only a small minority of leaders, notably former Prime Minister Abu Mazin and Muhammad Dahlan, who heads his own militia in the Gaza Strip.
If Arafat had taken this road - accepting Israel's existence, ending terrorism, and confronting Palestinian extremists - the conflict would have ended long ago.
But, with no single all-powerful leader, it will be hard for any successor to force through the difficult decisions required by such an orientation.
The
The younger generation of indigenous West Bank Palestinians, whose leaders began political activity in the uprising of the late 1970's, embraces a
The militants argue that a two-stage strategy is needed to defeat Israel.
First, long-term continuation of violence will force Israel to withdraw from the occupied territories.
Then, with Palestinians gaining the upper hand, they can advance to a second stage in which all of Israel is conquered, implying armed struggle - which often takes the form of anti-civilian terrorism - for many more years.
Finally, there is the
The problem for Palestinian moderates is clear: any leader willing to agree a peace treaty with Israel would be opposed - passionately and even violently - by roughly 80% of the movement.
A key question is whether the Palestinian masses, fed up with their leadership's bickering, corruption, and incompetence, could make their wishes known to find an end to a conflict that has cost them so much.
But none of the main leadership factions are proposing that the masses be consulted very much.
Nor did Arafat leave in place any institutional mechanisms for doing so.
Moreover, the popular appeal of radical religion, ideology, and misinformation should not be underestimated.
Few Palestinians are even aware that four years ago Arafat turned down an independent state equal in size to the entire West Bank and Gaza Strip, in addition to more than $20 billion in refugee compensation.
The main problem left by Arafat is the lack of any leadership at all.
Rarely in history has a political movement been so deliberately set by its founder on a course toward chaos.
Arafat not only left no successor, but no order.
Over the decades, the movement has developed a political culture of indiscipline.
Arafat presided over a sort of anarchy, encouraging rivalries, undermining other potential leaders, and ensuring that all authority (and money) ran through his hands.
Only if the post-Arafat movement decides that it really wants a Palestinian state in exchange for ending the conflict with Israel in every respect will there be a real chance of peace.
Arafat's death may well mark the beginning of that process, but the transition to a new Palestinian leadership could take years, and there is no assurance that it will be a moderate one.
Arafat’s Last Hurrrah
In his protracted moment of death, Yasir Arafat performed his last act of duty to the Palestinian cause to which he devoted his entire life.
Everything about the man was, indeed, protracted.
He carried out a protracted war of national liberation.
He withstood a series of protracted sieges – in Amman (1970), Beirut (1982), and in Ramallah (2002-2004).
Arafat’s leadership was the most protracted among his counterparts in the Arab World, as he outlived three Egyptian Presidents (Naguib, Nasser, Sadat and spanned all of Mubarak’s quarter of a century), five Lebanese Presidents, three Iraqis, five Algerians, three Syrians, three Saudi Monarchs, and two in Morocco, not to mention other world leaders, from Eisenhower to Bush in the US, from de Gaulle to Chirac in France, and from Maó to three successors in China.
Probably no other political figure alive today met and endured as many world leaders as Arafat.
But there is much more to Arafat’s legacy than endurance.
It has been correctly said over and again that Arafat was a mixed blessing for his people.
Their fate and destiny have been inextricably linked, to the near demise of both at times.
For several decades after the usurpation of their homeland, Palestinians were reduced to aggregates of refugees, some remaining in the newly-created state of Israel as second-class citizens, with others scattered over the Arab World and far beyond.
It was Yasir Arafat, through the Palestinian Liberation Organization (PLO) he founded, that gave them a sense of identity as a people.
Regardless of its effectiveness, the armed struggle waged by the PLO did empower the Palestinians and internalize a sense of collective dignity and self respect within them.
Their cause could no longer be ignored.
No other modern issue has appropriated as many UN resolutions or as much international diplomacy.
If politics is defined as the art of compromise, Arafat was a master of it at the Palestinian and Arab levels.
He managed to stay at the helm for over forty years with no serious challengers.
Internationally, however, he was out of step with the post Cold War era.
Whether or not he was solely to blame, a true opportunity for historical compromise was missed at Camp David in August 2000, and he himself acknowledged it a year later.
By that time it was too late, as the leadership in both the US and Israel had changed and there was no interest to engage him.
During the last four years of his life, Arafat’s public space was literally and metaphorically diminishing.
He was unable to re-engage his Israeli adversaries or control his suicide-bound Palestinian militants.
Nor was he able to contain let alone combat rampant corruption in the Palestinian Authority.
Nor was Arafat helped by world events that shifted the spotlight to Bush’s wars on terrorism in Afghanistan and Iraq.
If anything, they had adverse effects for him and his life-long cause.
Like his own body, Arafat’s familiar world was steadily fading away with irreversible loss of control.
Ironically however, as he was dying, world leaders and the media were rediscovering the importance of Arafat’s leadership if not his persona.
The sustained focus of the media on him, to the point of near saturation, focused world attention on the Palestinian Question once again.
Statements by Tony Blair, Jacques Chirac, Kofi Annan and others on the occasion of Arafat’s death have been forceful in demanding a speedy and long overdue resolution of the conflict.
It is as if in death, Arafat has given his people a chance to achieve what he could not achieve in life –the dream of an independent democratic Palestinian state.
It is Arafat’s last hurrah.
Are Bad Banks a Good Idea?
STOCKHOLM – The idea of a “bad bank” appears to grow more popular by the day in countries where toxic assets have paralyzed lending.
The Swedish bank cleanup in the early 1990’s is often cited as an example of how successful this idea can be.
But the lessons that are sometimes derived from Sweden’s experience are based on misunderstandings of what we actually did, and of how our system worked.
The initiative to set up a “bad bank” in Sweden was taken not by politicians, but by the management of Nordbanken.
Following years of mismanagement and reckless lending, the bank was the first big victim of the commercial property market’s decline in 1990.
Nordbanken had become fully state-owned and a new management was put in place to restore the bank to viability.
But it soon turned out that the managers had little time to spend on Nordbanken’s core banking business, because they had to focus disproportionately on handling an enormous variety of assets.
And every quarter brought new write-offs that ruined efforts to rebuild the bank’s reputation and its employees’ morale.
The radical solution was to separate all the assets that were alien to the bank’s core business, mainly real estate companies, but also firms in the manufacturing, construction, and service industries.
The “bad bank” that was established for this purpose, Securum, needed an enormous injection of capital from the owner, the Swedish government.
But Securum was then able to recruit skilled staff members who could maximize the assets’ value when markets recovered, and to be in a financial position to await that recovery.
The rest of Nordbanken, now known as Nordea, proceeded to become the largest bank in Scandinavia.
In contrast to today’s situation, the bad assets were usually entire companies, not complex securities.
But, as with today’s toxic assets, there was no market, and rapid disinvestment would have triggered fire-sale prices, depressing all asset values in the economy and resulting in more bank failures.
Furthermore, the point was not to help private banks get rid of their troubled assets.
When most other Swedish banks followed Nordbanken’s example and established their own bad banks, they did so without state participation.
But this was possible only because the Swedish government already owned all the assets, thereby circumventing the hopelessly difficult issue of pricing them.
With a private owner, huge public subsidies would have been politically unacceptable.
The assets either would have to be priced at far above their market value, with taxpayers thereby subsidizing the previous, failed owners, or the private bank would not have been helped at all.
A government-sponsored bad bank for private assets is thus a very bad idea.
In 1994, when I became State Secretary for Financial Affairs in Sweden’s Ministry of Finance, recovery appeared to be on the horizon, following the abolition of the fixed exchange rate, the ensuing sharp depreciation of the Krona, and lower interest rates.
The new government implemented an effective and very big program to close a budget deficit of roughly 12% of GDP.
Gradually, confidence grew, and financial markets began to function again.
As opportunities appeared, we began to re-privatize assets, and within a few years Securum was closed.
With hindsight, I believe we sold its assets too quickly.
Taxpayers could have recovered more of their losses if we had been more patient, as prices continued to rise for a long time.
But the stigma of socialism was stronger than the instinct to make a profit.
The following lessons of Sweden’s experience seem relevant today:
·        A bad bank can be an effective instrument in the recovery of losses and the revival of banks.
·        Although Sweden’s experience concerned shares in companies used as collateral for credit, rather than bonds or similar financial instruments, this situation will likely arise in many countries today as the crisis continues, more companies go bankrupt, and banks recall their collateral and take possession of shares in indebted companies.
·        Government subsidies for private bad banks, or public bad banks to clean up private banks’ toxic assets, are a bad way for taxpayers to transfer money to troubled banks compared to normal capital injections.
All subsidies should be transparent, and public/private bad banks are not.
·        It is vital to staff bad banks with professional and experienced managers who are untainted by previous scandals.
Here, Sweden’s experience is encouraging.
It was easier than we expected to recruit good people for Securum, because working in the public interest for this pioneering state-owned bad bank was perceived as a unique challenge.
·        Maximizing taxpayers’ economic interests, not ideology or political considerations, must be the guiding principle.
The public should be in no doubt about this, for their trust is essential.
Are Bankers Really Overpaid?
LONDON – Are financial sector workers paid too much?
Not all of them are, of course, for there are poorly paid bank clerks and cleaners who count in this category.  But is it possible to justify the enormous rewards earned – or should we say received – by investment bankers, hedge fund managers and private equity partners?
Most people would easily and quickly answer “no.”
Certainly that is what Congressmen in the US, and Members of Parliament in the UK think.
They are trying to cook up ways to discipline financial firms, albeit without conspicuous success so far, as demonstrated by the large sums stashed away for employee compensation by Goldman Sachs after its most recent profitable quarter.
But what does it mean to say that financial folk are paid too much?
By what measure, and in relation to whom are they overpaid?
Like many other people, I tend to believe that anyone paid more than me is prima facie over-rewarded, but I know this is not the most rigorous test I could apply.
Economists have been trying to produce more robust answers to those questions.
Thomas Philippon and Ariell Reshef, for the National Bureau of Economic Research, have looked at a hundred years of data in the US, for pay in finance, and in other occupations.
Their conclusions are fascinating.
They find that if you control for educational attainment and skills, financial jobs were highly paid until the Great Depression of the 1930s, higher than the quality of the people who held the jobs would imply.
Then from the Depression, and the introduction of new and tighter regulation, financial sector pay reverted to the norm, and remained there until around 1990.
But from that date up to 2006 it raced ahead and, on average, employees in financial firms were paid between a third and a half more than similarly qualified counterparts elsewhere.
We just don’t know yet whether the crisis will cause another reversion to the mean, but some downward adjustment looks likely.
So there is some basis for saying they are overpaid, but why?
Philippon and Reshef argue that regulation, or deregulation is a big part of the story.
Deregulation increased the opportunities for innovation and trading, and for profit.
There is also evidence to support that proposition from the observable fact that rewards in the less regulated parts of the asset management sector- hedge funds etc- are typically higher than in Security and Exchange Commission regulated competitors.
But is this a good enough explanation?  As rewards went up, why did new competitors, prepared to undercut, fail to come into the market?
In other parts of the economy, where we see excess returns, we usually look for some weakness in competition, or perhaps for the exploitation of insider information, which excludes new entrants.
That may be part of the story, but competition for talent and for customers seems intense between investment banks and others, yet they have collectively been extravagantly rewarded at the expense of those customers.
An alternative hypothesis, which seems to fit the facts, recently emerged from the Paul Woolley Centre for the Study of Dysfunctionality in Capital Markets, at the London School of Economics.
Researchers there argue that in fragile speculative industries (and finance has certainly been in that category in recent years) it is hard for investors to monitor those who manage their money.
They can see short-term returns, but they do not understand very well how those returns are generated.
Managers can demand higher and higher returns in the upturn.
But eventually these high returns reduce the payouts to investors (Bernie Madoff may be the reduction
If this explanation is broadly correct (and it incorporates the deregulation point as well, as you can see) then what can be done about it?
Politicians and regulators are exploring a number of options, from higher tax rates, through fines for certain types of bonus arrangements, to variable capital requirements.
Higher taxes may be justified for other reasons, but are unlikely to solve the problem described.
Regulators have struggled with the problem for years without finding a solution.
The Bank of England has described the way in which remuneration policy can create risks for banks and said that, as a result, “it is of increasing interest and concern to supervisors and regulators.” But that was written in 1997, and progress since then has been very slow, on both sides of the Atlantic.
Shouldn’t shareholders take more of an interest?
After all, it is their money which is at stake.
They have earned low returns from financial sector investments, indeed those returns have been very strongly negative in the last two years.
Shareholders seem to take little interests in pay policy.
The arrival of “say on pay” provisions in the US – whereby boards will need to put their compensation policies to a shareholder vote in future– may focus minds, though the impact of similar provisions in the UK has been modest.
Yet without shareholder pressure, all the signs are that the problem will persist.
What Good Are Economists?
NEW HAVEN – Since the global financial crisis and recession of 2007-2009, criticism of the economics profession has intensified.
The failure of all but a few professional economists to forecast the episode – the aftereffects of which still linger – has led many to question whether the economics profession contributes anything significant to society.
If they were unable to foresee something so important to people’s wellbeing, what good are they?
Indeed, economists failed to forecast most of the major crises in the last century, including the severe 1920-21 slump, the 1980-82 back-to-back recessions, and the worst of them all, the Great Depression after the 1929 stock-market crash.
In searching news archives for the year before the start of these recessions, I found virtually no warning from economists of a severe crisis ahead.
Instead, newspapers emphasized the views of business executives or politicians, who tended to be very optimistic.
The closest thing to a real warning came before the 1980-82 downturn. In 1979, Federal Reserve Chair Paul A. Volcker told the Joint Economic Committee of the US Congress that the United States faced “unpleasant economic circumstances,” and had a “need for hard decisions, for restraint, and even for sacrifice.”
The likelihood that the Fed would have to take drastic steps to curb galloping inflation, together with the effects of the 1979 oil crisis, made a serious recession quite likely.
Nonetheless, whenever a crisis loomed in the last century, the broad consensus among economists was that it did not.
As far as I can find, almost no one in the profession – not even luminaries like John Maynard Keynes, Friedrich Hayek, or Irving Fisher – made public statements anticipating the Great Depression.
As the historian Douglas Irwin has documented, a major exception was the Swedish economist Gustav Cassel.
In a series of lectures at Columbia University in 1928, Cassel warned of “a prolonged and worldwide depression.”
But his rather technical discussion (which focused on monetary economics and the gold standard) forged no new consensus among economists, and the news media reported no clear sense of alarm.
Interestingly, contemporary news accounts reveal little evidence of public anger at economists after disaster struck in 1929.
So why has the failure to foresee the latest crisis turned out so differently for the profession?
Why has it – unlike previous forecasting failures – stoked so much mistrust of economists?
One reason may be the perception that many economists were smugly promoting the “efficient markets hypothesis” – a view that seemed to rule out a collapse in asset prices.
Believing that markets always know best, they dismissed warnings by a few mere mortals (including me) about overpricing of equities and housing.
After both markets crashed spectacularly, the profession’s credibility took a direct hit.
But this criticism is unfair.
We do not blame physicians for failing to predict all of our illnesses.
Our maladies are largely random, and even if our doctors cannot tell us which ones we will have in the next year, or eliminate all of our suffering when we have them, we are happy for the help that they can provide.
Likewise, most economists devote their efforts to issues far removed from establishing a consensus outlook for the stock market or the unemployment rate.
And we should be grateful that they do.
In his new book Trillion Dollar Economists, Robert Litan of the Brookings Institution argues that the economics profession has “created trillions of dollars of income and wealth for the United States and the rest of the world.”
That sounds like a nice contribution for a relatively small profession, especially if we do some simple arithmetic.
There are, for example, only 20,000 members of the American Economic Association (of which I am President-Elect); if they have created, say, $2 trillion of income and wealth, that is about $100 million per economist.
A cynic might ask, “If economists are so smart, why aren’t they the richest people around?” The answer is simple: Most economic ideas are public goods that cannot be patented or otherwise owned by their inventors.
Just because most economists are not rich does not mean that they have not made many people richer.
The fun thing about Litan’s book is that he details many clever little ideas about how to run businesses or to manage the economy better.
They lie in the realm of optimal pricing and marketing mechanisms, regulation of monopolies, natural-resource management, public-goods provision, and finance.
None of them is worth even a trillion dollars, but, taken together, Litan’s conclusion is plausible indeed.
The 2010 book Better Living through Economics, edited by John Siegfried, emphasizes the real-world impact of such innovations: emissions trading, the earned-income tax credit, low trade tariffs, welfare-to-work programs, more effective monetary policy, auctions of spectrum licenses, transport-sector deregulation, deferred-acceptance algorithms, enlightened antitrust policy, an all-volunteer military, and clever use of default options to promote saving for retirement.
The innovations described in Litan’s and Siegfried’s books show that the economics profession has produced an enormous amount of extremely valuable work, characterized by a serious effort to provide genuine evidence.
Yes, most economists fail to predict financial crises – just as doctors fail to predict disease.
But, like doctors, they have made life manifestly better for everyone.
Are Foreign Investors Still Welcome?
World flows of foreign direct investment (FDI) have soared over the past two decades, from $40 billion in the early 1980’s to $900 billion last year.
The cumulative stock of FDI has reached close to $10 trillion, making it the most important mechanism for delivery of goods and services to foreign markets: sales by foreign affiliates total roughly $19 trillion, compared to world exports of $11 trillion.
At the same time, the liberalization of FDI regimes by virtually all countries has been a driving force of intra-firm trade – the lifeblood of the emerging system of integrated international production and already around one-third of world trade.
But are the good times coming to an end?
FDI can bring a range of benefits, but it also can have costs.
During the 1970’s, when the transnational corporations (TNC’s) undertaking such investment caught the public eye, many governments believed that the costs of FDI outweighed its benefits, so they controlled it.
Led by the developed countries, the pendulum began to swing in the 1980’s.
Once viewed as part of the problem, FDI became part of the solution to economic growth and development.
Nothing exemplifies this more than changes in national FDI regimes.
As the United Nations Conference on Trade and Development reports, of the 2,156 changes that took place between 1991 and 2004, 93% were in the direction of creating a more hospitable environment for TNC’s.
But there is a real danger that the pendulum is beginning to swing back, leading to a reversal of that liberalization process.
FDI in developed countries (and increasingly in emerging markets) often takes the form of cross-border mergers and acquisitions (M&amp;A’s).
Resistance to such M&amp;A’s is becoming more frequent when they involve domestic firms that are regarded by politicians as “national champions” or important for national security, economic development, or cultural identity.
The growing involvement of private equity groups in M&amp;A activity implies additional controversy, as such transactions are typically regarded as being purely speculative.
In the name of “economic patriotism,” security, and other considerations, resistance to M&amp;A’s is being codified in an increasing number of countries.
For example, a United States Senate committee recently sought to block the planned liberalization of foreign takeover rules for airlines, while Europe has enacted more restrictive takeover laws.
Moreover, governments are applying more strictly existing regulatory provisions concerning the vetting of takeovers by foreign firms.
This response is intertwined with a defensive reaction to the growing role of TNC’s from emerging markets, the “new kids on the block.”
Established TNC’s, and their home countries, will need to adjust to this new constellation of forces and its implications for the world market.
As we know from other contexts, adjustment to newcomers is not easy: compare, say, the reaction to the tie-up between France’s Alcatel and America’s Lucent to the bids by the China National Offshore Oil Corporation for Chevron or Mittal for Acelor.
Another type of defensive reaction – this time to outward FDI – may well arise once the offshoring of services gathers more speed.
All indications are that offshoring has reached the tipping point, and more of it will take place through FDI.
If home countries do not put in place the adjustment mechanisms to deal with the rapidly unfolding revolution in making service industry jobs tradable, a backlash against such outward FDI will become inevitable.
The growing unease with FDI is so far largely confined to developed countries.
But there are signs that it is spreading to emerging markets.
In the case of large-scale projects, some host countries are raising questions about the contracts that define their relationship with TNC’s, and governments are reviewing such contracts because they believe (rightly or wrongly) that they did not get a fair deal.
Of the 219 known international arbitration cases concerning investment projects, some two-thirds were initiated during the past three years.
Approaches to FDI have changed in the past, and they can change again in the future, depending on how governments view the balance of costs and benefits.
This balance involves not only economic factors, but also such considerations as security and the desire to control one’s own economic development.
The concept of “twenty-first-century nationalization,” introduced by Peruvian presidential candidate Ollanta Humala, mirrors in this respect the “economic patriotism” of French Prime Minister Dominique de Villepin.
Reservations against FDI (as against anything foreign) can be found in all groups of countries, and politicians can bring them to the surface, resulting in protectionism.
It would be ironic, though, if developed countries – which led the FDI liberalization wave of the past two decades – now led a backlash against FDI.
Let us hope that the de-liberalization seen in developed countries can be checked before it spreads to other parts of the world and ultimately brings undesirable consequences for all.
Are Housing Prices a House of Cards?
The first big city to boom was London, starting around 1996.
Boom mentality spread to Los Angeles, New York, and Sydney around 1997, to Paris in 1998, to Miami, Moscow, and Shanghai in 2001, and Vancouver around 2002.
These and other cities have been booming pretty much ever since; prices in most are up at least 50% in real terms since 2000.
This has been a big windfall to homeowners, but has hurt anyone planning to buy.
Now growth in home prices is weakening in some of these cities.
The rate of price growth in London and New York slowed sharply over the past year, to only about a 1% real increase in the second quarter of 2004.
In Sydney, home prices actually fell in the second quarter.
Has the boom ended?
Will no other cities benefit?
Worse still, could the mood in housing markets soon lead prices in downward?
No one predicted this boom, so predicting its end is risky.
Housing prices have shown tremendous upward momentum in the face of previous warnings that the party is over.
Any prediction concerning the boom's end requires understanding why it occurred in so many places.
Surprisingly, there is no well-received explanation, because this boom's ultimate causes are mostly psychological.
Economists would rather talk about interest rates or unemployment statistics - factors that are concrete and knowable.
Of course, these indicators do have a legitimate role to play in explaining housing markets, but they are simply not adequate to account for the recent booms.
Three psychological causes stand out: first, a change in people's perceptions about the source of value in a changing world economy; second, increasing public faith in "glamour" cities with international name recognition; and third, the plain giddy dynamics of speculative bubbles.
Each factor deserves greater attention if we are to understand current housing market conditions and discern future price trends.
First, the world economy does look more chaotic than it did a decade ago.
The crash in equity prices since 2000 in most countries has made financial assets look less secure, spurring a "flight to quality" - in this case, housing.
Moreover, terrorism is now viewed as a problem for everyone, with major tragedies in Indonesia, Spain, and Russia.
People feel safest investing in their homes, and there is little reason to expect imminent change.
Fear and upward momentum in home prices go together.
Second, the public's faith in glamorous international cities has increased with the explosive growth in global communications due to the Internet and the cell phone.
Just as people increasingly admire international celebrities, so they believe that world famous centers of business, technology, and culture - whose names are household words to people everywhere - are uniquely valuable.
As with fear of terrorism and suspicion of equities, geographical celebrity appears resilient, if not self-reinforcing: the more famous New York, Paris, and London get, the more glamorous they become.
Third, and no less important, is the speculative contagion that underlies any bubble.
The current boom has seen contagion
In contrast to the other two psychological causes, speculative contagion has a natural end.
A speculative bubble, sustaining itself solely by reaction to price increases, cannot go on forever.
So, where does this leave us?
Two of the three psychological causes suggest continued upward momentum in housing prices, while the third suggests that the momentum will come to an end some day, but does not pinpoint when.
I am betting that some high-flying glamour cities will continue to see decelerating growth in home prices - and eventually decreases.
Historically, housing prices have shown a lot of momentum, and prices in all these cities are still going up at a brisk rate, though usually somewhat slower than a year or more ago.
Based on extrapolation of growth trends, it looks safe to predict that prices will go up substantially in most of these places for another year or more, even as the rate of increase continues to decline.
The psychological factors are more important for longer-term forecasts, beyond a year, where momentum no longer plays an important role.
At this point, there is likely to be some downward instability in prices, because enthusiasm for investing in houses is likely to wane in line with declining price growth.
Prices in glamour cities are likely to drop sharply the next time there is a serious recession, or if the local economy suffers a severe shock, or if interest rates rise too fast.
Then, contagion within and across markets can work in a downward direction, propelling prices lower for years.
Are Human Rights Universal?
Even in our globalizing world, the question as to whether "human rights" is an essentially Western concept, which ignores the very different cultural, economic, and political realities of the South, persists.
Can the values of a consumer society be applied to societies with nothing to consume?
At the risk of sounding frivolous: When you stop a man in traditional dress from beating his wife, are you upholding her human rights or violating his?
The fact is that a number of serious objections exist to the concept of universal human rights, which its defenders need to acknowledge - honestly - if only to refute them.
The first objection argues that all rights and values are defined and limited by cultural perceptions; there is no universal culture, therefore there are no universal human rights.
Some philosophers object that the concept of human rights is founded on an individualistic view of man as an autonomous being whose greatest need is to be free from interference by the state, imbued, as it were, with the right to be left alone.
Non-Western societies often espouse a communitarian ethic that sees society as more than the sum of its individual members, and considers duties to be more important than rights.
Then there is the usual North/South argument, with "human rights" cast as a cover for Western intervention in the developing world.
Developing countries, some also argue, cannot afford human rights, since the tasks of nation-building and economic development remain unfinished; suspending or limiting human rights thus sacrifices the few to benefit the many.
Others object to specific rights which they say reflect Western cultural bias, the most troublesome here being women's rights.
How can women's rights be universal when, in some societies, marriage is seen not as a contract between two individuals but as an alliance between lineages, and when the permissible behavior of women is central to a society's perception of familial honor?
In addition, some religious leaders argue that human rights can be acceptable only if they are founded on the transcendent values of faith and are thus sanctioned by God.
There is a built-in conflict between the universality of human rights and the particularity of religious perspectives.
How to respond to these objections?
Concepts of justice and law, legitimacy and dignity, protection from oppressive rule, and participation in community affairs are found in every society; the challenge facing human rights advocates is to identify the common denominators, and not throw up their hands at the impossibility of universalism.
These objections reflect a false opposition between the primacy of the individual and the paramountcy of society.
Culture is too often cited as a defence against human rights by authoritarians who crush culture whenever it suits them.
Besides, which country can claim to be following its pure "traditional culture"?
You cannot follow the model of a "modern" nation-state cutting across tribal boundaries and conventions, and then argue that tribal traditions should be applied to judge the state's human-rights conduct.
There is nothing sacrosanct about culture anyway.
Culture constantly evolves in any living society, responding to both internal and external stimuli, and societies outgrow and reject much in every culture.
Let us concede that child marriage, female circumcision, and the like are not found reprehensible by many societies; but let us also ask the victims of these practices how they feel.
Where coercion exists, rights are violated, and these violations must be condemned whatever the traditional justification.
Coercion, not culture, is the test.
As for religion, every religion embodies certain verities that are applicable to all mankind - justice, truth, mercy, compassion - and men often allow God to be blamed for their own sins.
As UN Secretary-General Kofi Annan put it, the problem is not with the faith, but with the faithful.
As for suspending human rights in the interests of development, authoritarianism promotes repression, not development.
Development is about change, but repression prevents change.
Though there may be cases where authoritarian societies had success in achieving economic growth, Botswana, an exemplar of African democracy, has grown faster than most authoritarian states.
A number of developing countries – notably India, China, Chile, Cuba, Lebanon, and Panama – played an active and influential part in drafting the Universal Declaration of Human Rights.
The principles of human rights have been widely adopted, imitated, and ratified by developing countries, so it is hardly fair to suggest that they have been imposed on them.
When one hears of the unsuitability or ethnocentricism of human rights, what are these human rights that someone in a developing country can do without?
The right to life?
Freedom from torture?
The right not to be enslaved, not to be physically assaulted, not to be arbitrarily arrested, imprisoned, or executed?
No one actually advocates the abridgement of any of these rights.
Objections to the applicability of human-rights standards are all too frequently voiced by authoritarian rulers and power elites to rationalize violations that keep them in power.
Just as the Devil can quote scripture for his purpose, Third World communitarianism can be the slogan of a deracinated tyrant trained, as in the case of Pol Pot, at the Sorbonne.
The authentic voices of the South know how to cry out in pain.
Those are the voices that must be heeded.
Are Humans Getting Better?
MELBOURNE – With daily headlines focusing on war, terrorism, and the abuses of repressive governments, and religious leaders frequently bemoaning declining standards of public and private behavior, it is easy to get the impression that we are witnessing a moral collapse.
But I think that we have grounds to be optimistic about the future.
Thirty years ago, I wrote a book called The Expanding Circle, in which I asserted that, historically, the circle of beings to whom we extend moral consideration has widened, first from the tribe to the nation, then to the race or ethnic group, then to all human beings, and, finally, to non-human animals.
That, surely, is moral progress.
We might think that evolution leads to the selection of individuals who think only of their own interests, and those of their kin, because genes for such traits would be more likely to spread.
But, as I argued then, the development of reason could take us in a different direction.
On the one hand, having a capacity to reason confers an obvious evolutionary advantage, because it makes it possible to solve problems and to plan to avoid dangers, thereby increasing the prospects of survival.
Yet, on the other hand, reason is more than a neutral problem-solving tool.
It is more like an escalator: once we get on it, we are liable to be taken to places that we never expected to reach.
In particular, reason enables us to see that others, previously outside the bounds of our moral view, are like us in relevant respects.
Excluding them from the sphere of beings to whom we owe moral consideration can then seem arbitrary, or just plain wrong.
Steven Pinker’s recent book The Better Angels of Our Nature lends weighty support to this view.&nbsp; Pinker, a professor of psychology at Harvard University, draws on recent research in history, psychology, cognitive science, economics, and sociology to argue that our era is less violent, less cruel, and more peaceful than any previous period of human existence.
The decline in violence holds for families, neighborhoods, tribes, and states.
In essence, humans living today are less likely to meet a violent death, or to suffer from violence or cruelty at the hands of others, than their predecessors in any previous century.
Many people will doubt this claim.
Some hold a rosy view of the simpler, supposedly more placid lives of tribal hunter-gatherers relative to our own.
But examination of skeletons found at archaeological sites suggests that as many as 15% of prehistoric humans met a violent death at the hands of another person.
(For comparison, in the first half of the twentieth century, the two world wars caused a death rate in Europe of not much more than 3%.)
Even those tribal peoples extolled by anthropologists as especially “gentle” – for example, the Semai of Malaysia, the Kung of the Kalahari, and the Central Arctic Inuit – turn out to have murder rates that are, relative to population, comparable to Detroit, which has one of the highest murder rates in the United States.
In Europe, your chance of being murdered is now less than one-tenth, and in some countries only one-fiftieth, of what it would have been had you lived 500 years ago.
Pinker accepts that reason is an important factor underlying the trends that he describes.
In support of this claim, he refers to the “Flynn Effect” – the remarkable finding by the philosopher James Flynn that since IQ tests were first administered, scores have risen considerably.
The average IQ is, by definition, 100; but, to achieve that result, raw test results have to be standardized.
If the average teenager today took an IQ test in 1910, he or she would score 130, which would be better than 98% of those taking the test then.
It is not easy to attribute this rise to improved education, because the aspects of the tests on which scores have risen the most do not require a good vocabulary, or even mathematical ability, but instead assess powers of abstract reasoning.
One theory is that we have gotten better at IQ tests because we live in a more symbol-rich environment.
Flynn himself thinks that the spread of the scientific mode of reasoning has played a role.
Pinker argues that enhanced powers of reasoning give us the ability to detach ourselves from our immediate experience and from our personal or parochial perspective, and frame our ideas in more abstract, universal terms.
This, in turn, leads to better moral commitments, including avoidance of violence.
It is just this kind of reasoning ability that improved during the twentieth century.
So there are grounds to believe that our improved reasoning abilities have enabled us to reduce the influence of those more impulsive elements of our nature that lead to violence.
Perhaps this underlies the significant drop in deaths inflicted by war since 1945 – a decline that has become even steeper over the past 20 years.
If so, there would be no denying that we continue to face grave problems, including of course the threat of catastrophic climate change.
But there would nonetheless be some reason to hope for moral progress.
Are Humans to Blame for Global Warming?
Global warming is an environmental, economic, scientific, and political problem of the first order, and one doubly difficult to address because its dangers lie decades in the future.
So if we are to act now to head it off, we must first scrutinize what is known about the nature of the threat.
Should we place our faith in the Kyoto Treaty, which sets firm limits on human emissions of so-called greenhouse gases?
Or is the US administration right to reject the Kyoto Treaty, because targeting emissions is based on "bad science"?
Circumstantial evidence does indeed point to our profligate burning of fossil fuels and perhaps also to its impact on global warming.
Since 1900 the global temperature of the Earth's atmosphere and ocean surface waters has risen by 0.5-1 degree Celsius, and the prime suspect is atmospheric carbon dioxide, CO2, which is second only to water vapor in its greenhouse effect.
Since 1860, when the industrial revolution and soaring population growth led to widespread consumption of fossil fuels, the volume of atmospheric CO2 has increased by about 28%.
The increase began slowly, rising from 290 parts per million in 1860 to 295 ppm in 1900.
But it then accelerated rapidly, reaching 310 ppm in 1950 and 370 ppm in 2000, with half of the total gain of 80 ppm occurring just since 1975.
Numerical global climate models suggest that a doubling of the current atmospheric accumulation of CO2 will produce further warming of 3-5 degrees Celsius, perhaps as soon as 2050.
The consequences of this would be devastating: inland areas desiccated, low-lying coastal regions battered and flooded as polar ice melts and sea levels rise, and possibly further warming and a runaway greenhouse effect due to an increase in atmospheric water vapor.
The only rational course of action would seem to be to curtail global consumption of fossil fuels, as the Kyoto Treaty's proponents contend, and invest in alternative energy sources.
But while researchers created impressive global climate models in recent years, they are the first to admit that such models can include only a fraction of the many physical forces that together determine the climate and global mean temperature.
For example, studies during the past 20 years have shown that changes in solar magnetic activity cause the Sun's brightness to vary by 0.1%, and that the average annual temperature in the northern Temperate Zone has tracked the level of solar activity over the last 1,000 years.
Indeed, monitoring of other solar-type stars has revealed one whose brightness decreased by 0.5% in a period of 5 years, during which its magnetic activity declined sharply, suggesting that the Sun behaves similarly.
Core samples from the Greenland ice cap, for example, show occasional sudden drops in temperature.
Contrary to what climate models focusing on greenhouse gas emissions would predict, the samples show that a decline in atmospheric CO2 followed, rather than preceded, these frigid intervals.
What, then, is responsible for global warming so far? A safe bet is that from 1900 until 1950, global warming was driven mainly by the solar brightening, as solar magnetic activity increased by a factor of two or three during this period.
Atmospheric CO2 could not have been a major contributor, because it had increased by only about 7% before 1950, when the warming leveled off for a couple of decades. After 1950, however, solar activity showed no significant rise, while atmospheric CO2 increased by 20%, accounting for the warming from 1970 to 2000.
Atmospheric CO2 is therefore presumably the controlling factor for the coming century as well.
But this does not mean that human emissions are responsible for the growing accumulation of atmospheric CO2. The atmosphere contains about 750 gigatons of CO2, while total annual human emission is approximately 5.5 Gt, thus adding annually roughly 0.7% of the total.
However, there is also an estimated exchange of 90 Gt per year between the atmosphere and the oceans.
This means that Human CO2 emissions do not simply linger and accumulate in the atmosphere.
They are rapidly distributed to the ocean surface, so that atmospheric CO2 remains at an equilibrium level.
This equilibrium is, in turn, determined by the temperature of ocean surface water. So it is plausible that the solar-driven ocean warming between 1900 and 1950 started things off by shifting the equilibrium toward higher concentrations of CO2 in the atmosphere, accelerating global warming since then.
So, while our own contribution of CO2 is not helping matters, it hardly seems to be the determining factor. On the available evidence, then, skeptics of the Kyoto Treaty appear to have a powerful case.
Yet the threat posed by global warming is nonetheless real, and focusing on human CO2 emissions is not necessarily "bad science," just incomplete science.
For example, aside from solar magnetic activity, the Sun affects the Earth's climate in several other ways, including ultraviolet warming of the upper stratosphere, the nucleation of aerosols, and cloud formation. The climate is also subject to the rate of water vapor exchange between the atmosphere and Earth's surface, which requires taking into account ocean currents, wind, and geography.
All of these contributing effects must be understood quantitatively in order to produce an accurate model of global climate change and we remain far from that point.
So the only rational response is to research aggressively into the many unknown factors: the physics of cloud formation, the dynamic coupling of the upper stratosphere to the lower atmosphere, the accumulation of atmospheric water vapor.
If effective solutions are to be found, they must await a fuller definition of the problem.
Are Israel and Syria Ready for Peace?
JERUSALEM – The resumption of peace talks between Israel and Syria after eight years of saber-rattling is not a diversion from the political troubles of Israel’s lame-duck prime minister.
Nor are the talks a Syrian ploy to avoid facing an international tribunal on the assassination of Lebanon’s former prime minister, Rafik Hariri.
An Israeli-Syrian peace deal is strategically vital for both sides, and both sides know it.
The two major formative experiences of Syria’s Ba’ath regime have been Hafez al-Assad’s loss of the Golan Heights in the 1967 war with Israel, and the loss of Lebanon by his son, Bashar, who was forced to withdraw his army under irresistible American-led international pressure.
Recovering the Golan Heights and protecting Syria’s vital interests in Lebanon are not only major strategic concerns for Syria’s president; they are also crucial to the regime’s drive for national legitimacy, and to Bashar’s assertion of his own leadership.
Peace with Israel is not Assad’s priority.
Rather, it is the prerequisite without which superior goals – rapprochement with the United States, legitimization of Syria’s special status in Lebanon, and avoidance of a potentially devastating war with Israel if the Golan Heights are not recovered by peaceful means – cannot be attained.
Indeed, the regime has hinted that it may be willing to compromise on the issue – the delineation of the 1967 border along a tiny piece of land on the Eastern shore of the Sea of Galilee – that wrecked the negotiations eight years ago.
An Israeli-Syrian peace is a weighty strategic necessity for Israel, too.
The complexities of the threats to Israel are such that a possible confrontation with Hamas in Gaza might trigger a flare-up with Hezbollah in Lebanon.
Such a war could be won only by the total destruction of Lebanon by Israel’s air force.
In that case, Syria would likely seize the opportunity to break the deadlock over the Golan Heights through a military move that could develop into a massive war of missiles targeting Israel’s vulnerable home front.
And Iran, in its drive to protect its nuclear program from an Israeli-American attack, might be very active in supporting this ominous scenario.
Admittedly, the strategic conditions in the region are far more complex today than they were eight years ago, when Israel’s requirements for a deal with Syria focused mainly on security arrangements on the Golan Heights, and on Syria using its leverage in Lebanon to permit an Israeli settlement with that country.
Syria’s alliance with Iran was not a major issue.
Syria’s subsequent forced withdrawal from Lebanon was not good news for Israel.
In the last round of Israeli-Palestinian peace talks eight years ago, it was clear that a deal with Syria would automatically pave the way to a settlement with Lebanon, and an end to Hezbollah’s threat to Israel’s northern border.
Today, peace with Syria might facilitate an Israeli peace with Lebanon down the road, but that will not be an automatic outcome.
Indeed, while Hezbollah prospered under Syrian occupation, it never reached the extraordinary political power that it has today.
Nevertheless, peace with Syria could be a major building block in a wider Israeli-Arab settlement, and consequently of a more stable Middle East, though it is unrealistic to expect that Syria would automatically sever its special relationship with Iran in exchange for the Golan Heights.
These are peace talks, not a defense treaty, and Syria would not abruptly disengage from its Iranian friends.
But good relations between an Arab state at peace with Israel and Iran are not necessarily a bad thing.
Syria’s stance might limit, rather than extend, the reach of Iran’s strategy of regional destabilization.
As always, much will depend on America’s readiness to move away from military solutions and rigid ideological imperatives and instead embrace the pragmatic culture of conflict resolution.
A US-backed Israeli-Syrian peace could transform the strategic environment, potentially drawing other Middle East spoilers into a system of regional cooperation and security.
Violence and Innovation
ABU DHABI – In the 1949 British film The Third Man, the character Harry Lime observes that, during the Borgia family’s rule in Renaissance Italy, the country “had warfare, terror, murder, and bloodshed.
But [it] produced Michelangelo, Leonardo da Vinci, and the Renaissance.”
By contrast, he contends, Switzerland’s 500 years of democracy and peace produced little more than the cuckoo clock.
While the implication that innovation and creativity are born only of conflict is extreme – in fact, Switzerland is a world leader in innovation – Lime makes a crucial point.
Although peace, order, and political stability are widely perceived as essential prerequisites for invention, entrepreneurship, and economic development, there have been many exceptions to this rule – especially when it comes to creativity and innovation.
The United States is consistently ranked among the world’s top ten countries for innovation, including by INSEAD’s Global Innovation Index.
But, on the Global Peace Index, it is ranked 88th of 153 countries.
Likewise, the United Kingdom and the Netherlands rank, respectively, fifth and sixth on the Innovation Index, but only 28th and 29th on the Peace Index.
Conversely, Bhutan is among the top 20 most peaceful nations, but does not even make it onto innovation indices.
Of course, crime, terrorism, conflict, and political instability severe enough to cause a total breakdown of law and order significantly impede creativity and innovation.
But some countries show strong resilience in the face of pervasive violence and volatility.
For example, despite widespread violent crime, Mexico and South Africa have high levels of innovation (measured by patent filing and trademark registration).
When terrorism indicators are taken into account, Lebanon, Turkey, Jordan, and Israel emerge as resilient innovators.
Just as peace and stability do not always lead to creativity and innovation, fighting and uncertainty do not necessarily deter it.
Although peace, political stability, and civil order are important factors to consider when selecting a location for a large-scale foreign production or service operation, they are far less important when it comes to sourcing creativity and making the related investments.
In particular, creative industries, such as animation, arts, design, and software – which are mostly based on individual skills and talent – tend to be more resilient to conflict than others.
Given this, officials, investors, and business leaders in search of revolutionary ideas, cutting-edge solutions, and untapped talent should not allow turbulence in some societies, or tranquility in others, to influence their decisions excessively.
In fact, stepping out of one’s comfort zone may offer significant benefits.
Some evidence suggests that the prevalence of uncertainty may boost competition, thereby sparking innovation.
Furthermore, social environments that are characterized by lower levels of consensus and higher levels of violence may be more likely than their more harmonious counterparts to catalyze radical innovation.
Lebanon’s experience supports this assessment.
Despite its long history of political violence, its creative industries are expanding.
According to a 2007 study of Lebanon’s copyright-based industries, conducted by the World Intellectual Property Organization, the main challenges facing the country’s software sector – an important part of its economy – include restricted markets, intense competition, a brain drain (loss of human capital), inadequate technology policy, a lack of government incentives, and rampant piracy.
Violence is conspicuously absent from the list.
To be sure, violence is always a problem.
But countries like Lebanon have become resistant to its effects – for example, by developing creative industries – diminishing its negative impact on economic, social, and intellectual development.
In 2005, 10% of all new businesses in Lebanon were in the creative sector, and the copyright-based industries contributed 4.75% of GDP.
Similarly, despite high levels of political violence, Nigeria produces more than 1,000 films annually.
Indeed, Nigeria’s film industry is the world’s third largest, after the US and India, and is second only to oil production in terms of its economic significance to the country.
According to a 2010 United Nations report on the creative economy, global trade in creative goods grew at an annual rate of 14% from 2002 to 2008.
Meanwhile, exports of such goods from developing countries, which tend to experience more violence, grew at a rate of 13.5%, reaching $176 billion (43% of total world trade in creative industries) in 2008.
Although overall global trade declined by 12% that year, trade in creative goods and services continued to expand.
This has significant implications for political and business leaders – especially in turbulent regions like the Middle East.
In order to bolster economic growth and innovation amid conflict and volatility, policymakers and investors should focus on building the creative industries.
The resilience and adaptability that they provide are crucial to supporting long-term economic growth and job creation – no matter what the future brings.
Are Sanctions Saving Russia?
MOSCOW – The economic sanctions imposed on Russia by the West in March 2014 have undoubtedly been painful.
But they have so far failed to achieve the goal of weakening Russian President Vladimir Putin’s position.
In fact, they may have the opposite effect, leaving Russia – and its president – even stronger than before.
European Union countries are estimated to have lost about $100 billion in trade with Russia, hitting the likes of Bavarian dairy farmers and eastern German industrial exporters.
Russian GDP, which grew modestly in 2014, contracted by 4.6% in annual terms in the second quarter of this year.
The ruble lost more than half of its US dollar value in the second half of last year, fueling inflation, which increased by 15.6% year on year in July.
But inflation now seems to have peaked, and the effects of the drop in oil and gas prices were mitigated by the US dollar’s appreciation, so that the value of Russia’s foreign reserves actually increased, reaching $362 billion in June (13% of which is in gold).
And despite belt-tightening in Russia, Putin is more popular than ever.
The rationale behind economic sanctions is straightforward: free trade and free markets deliver growth (and thus political support for the government), whereas restrictions choke off growth (and thus erode support for the government).
This emphasis on free trade and free markets was a central tenet of nineteenth-century British classical economics.
It remains a core message of today’s dominant neoclassical school – embodied in the so-called “Washington Consensus,” adopted across the world under the International Monetary Fund’s advice – which claims that the key to economic development is to open up, deregulate, liberalize, and privatize.
But the theory is fundamentally flawed.
No economic power has ever developed solely on the basis of laissez-faire policies.
The economic rise of the United Kingdom, for example, was heavily dependent on strategic protection, industrial policy, tariffs, and non-tariff trade barriers.
The UK’s industrial prowess originated with the textile industry.
The country’s leaders realized that the export of raw materials, mainly wool, would be inadequate to spur economic development.
For that, England would have to move up the value-added ladder, by importing raw materials and exporting finished goods.
So England’s leaders devised an industrial policy, which entailed bringing in Flemish textile weavers to provide know-how to British firms.
Moreover, they erected trade barriers: By banning the export of raw wool and the import of finished wool products, Indian textiles, which were often superior and cheaper, could not compete with domestic output.
They adopted navigation laws that restricted foreign ships’ access to British ports and even enacted a demand-boosting law requiring the dead to be buried in woolens.
Ultimately, the mechanization of the textile industry ushered in the Industrial Revolution, and mass production and exports underpinned the development of the world’s largest maritime fleet.
In the mid-nineteenth century, the German economist Friedrich List highlighted the role that such policies played in the UK’s development.
In line with his advice, the United States, Germany, and Japan employed judicious trade protection and industrial policies, while working actively to support nascent sectors – a strategy that enabled them to develop rapidly and even overtake Britain.
Restrictions also proved effective to spur economic development: In 1812, when the UK declared war and imposed a trade embargo on the US, import substitution caused American manufacturing to flourish.
When the embargo was lifted and trade tariffs were reduced, US manufacturing floundered – until 1828, when new British tariffs boosted US manufacturing again.
Likewise, during World War I, a British trade embargo spurred the development of German high-tech industries due to the demand for substitutes.
Of course, embargoes can have a devastating effect when a country lacks the resources needed for import substitution.
That is why economic sanctions were so damaging for Iran and, earlier, for Iraq’s population.
But, for a country like Russia, with its abundant natural resources, technological expertise, and skilled workforce, sanctions can have the opposite effect.
The Soviet Union struggled to capitalize on these factors, owing to communism’s weak incentive structure.
Today, by contrast, Russia has a capitalist system that offers considerable benefits to those who adapt best to the restrictions.
In short, Russia has all it needs to thrive, despite – or because of – the sanctions.
But turning opportunity into reality requires Russia to pursue an economic transformation.
Neoclassical trade theory is based on the concept of comparative advantage: countries should capitalize on their relative strengths, from technological prowess to resource endowments.
But, as English leaders knew and as the experience of many African and Latin American countries has shown, simply exporting raw materials is inadequate to propel development.
Historically, the most effective development policy has centered on government intervention to establish higher-value-added domestic industries.
In previous decades, Japan, Taiwan, South Korea, and China have all taken this path.
For Russia, moving up the value-added ladder should not be difficult; it has all it needs to manufacture the finished products that it previously imported.
In fact, import substitution has already increased productivity in several key sectors: engineering, petrochemicals, light industry, pharmaceuticals, and agriculture.
Annual exports of high-value-added goods rose by 6% in the first quarter of this year.
Furthermore, Russia’s leadership has accelerated cooperation with the other BRICS economies (Brazil, India, China, and South Africa), and Putin recently announced ambitious plans to boost domestic demand.
The West’s sanctions against Russia may not only fail to change the Ukraine situation; they may well spur the country’s long-awaited structural transformation.
If Russia successfully replicates the credit-guidance regime used by East Asia’s economies, while increasing managerial efficiency, yet another economic miracle is possible.
Are Saudi Women Next?
LONDON – The unexpected visibility and assertiveness of women in the revolutions unfolding across the Arab world – in Tunisia, Egypt, Libya, Yemen, Bahrain, Syria, and elsewhere – has helped propel what has become variously known as the “Arab awakening” or “Arab Spring.”
Major changes have occurred in the minds and lives of women, helping them to break through the shackles of the past, and to demand their freedom and dignity.
Since January 2011, images of millions of women demonstrating alongside men have been beamed around the world by television journalists, posted on YouTube, and splashed on the front pages of newspapers.
One saw women from all walks of life marching in hope of a better future, for themselves and for their countries.
They appeared prominently – eloquent and outspoken, marching daily, holding caricatures of dictators and chanting calls for democratic change.
They walked, bussed, traveled in carts, telephoned and tweeted with compatriots, motivated in part by social demands – above all for their own empowerment.
The contrast between this dynamic space for open protest and Saudi Arabia could hardly be starker.
Saudi women find themselves living in a petrified system.
Faces of the royal family are seen everywhere; the faces of women are shrouded, forcibly hidden.
Nowhere else in the world do we see modernity experienced as such a problem.
Skyscrapers rise out of the desert, yet women are not permitted to ride with men in their lifts.
Nor are they allowed to walk in the streets, drive a car, or leave the country without the permission of a male guardian.
Fatima, a young woman from Mecca, sent me an email at the height of the Egyptian revolution: “Forget about the cries for freedom; I can’t even give birth without being accompanied to hospital by a mihrim (male guardian).”
She went on, “And the mataw’a (the religious police, known officially as the Committee for the Promotion of Virtue and the Prevention of Vice, and whose leader has ministerial rank) have been given the right to humiliate us in public.”
Indeed, the mutaw’a saw their wide powers enhanced even more by decrees issued by King Abdullah in March, after helping to suppress protests in the kingdom earlier in the month.
Yet globalization knows no limits, not even those set by the guardians of Islamic probity.
Nine-year-old Saudi girls chat online, disregarding fatwas issued by Wahhabi clerics that forbid them access to the Internet without the supervision of a male guardian.
Many women remain secretly glued to satellite television channels, watching their peers in the public squares of Egypt or Yemen, beyond their reach but not beyond their imagination.
On May 21, a brave woman named Manal al Sharif broke the silence and apathy, daring to defy the ban on women driving.
For the next week, she sat in a Saudi prison.
But, within two days of her detention, 500,000 viewers had watched the YouTube video of her excursion.
Thousands of Saudi women, frustrated and humiliated by the ban, have vowed to stage a “driving day” on June 17.
Saudi Arabia is the only country in the world that forbids women to drive cars.
The system of confinement that the ban represents is justified neither by Islamic texts, nor by the nature of the diverse society that the Al Saud and their Wahhabi partners’ rule.
Indeed, it is far removed even from the rest of the Arab world – which has become glaringly obvious in the context of massive social upheaval almost everywhere else in the region.
Enforced segregation is mirrored in every aspect of Saudi life.
Religious education constitutes up to 50% of students’ curriculum.
As a result, Wahhabi dogma penetrates every home in the country.
Textbooks – pink for girls, blue for boys, each with different contents – emphasize the rules prescribed by Imam Muhammad bin Abdul Wahhab, an eighteenth-century cleric and the founder of Wahhabism.
The Saudi judicial system is one of the most formidable obstacles to women’s aspirations, relying on Islamic interpretations that protect a defensive patriarchal system.
Indeed, not only do judges’ decisions support the system, but the reverse is also true: patriarchy has become the driving force of the law.
Thus, Saudi women are barred from the legal profession on the basis of a Wahhabi stricture that “a woman is lacking in mind and religion.”
In other words, the rule of law in Saudi Arabia is the rule of misogyny – the comprehensive legal exclusion of women from the public sphere.
Saudi rulers have announced that demonstrations are haram – a sin punishable by jail and flogging.
Now some clerics have pronounced driving by women to be foreign-inspired haram, punishable in the same way.
Yet, despite such threats, thousands of Saudi women joined “We are all Manal al Sharif” on Facebook, and countless other videos of women driving have appeared on YouTube since her arrest.
Like Mamal, they, too, have been detained, and the government appears determined to prosecute them.
But Wajeha al Huwaider, Bahia al Mansour, Rasha al Maliki, and many other activists are nonetheless insisting that driving a car is their legitimate right, and are eloquently demanding the removal of restrictions and an end to women’s dependency.
Rosa Parks’ revolutionary bravery in refusing to move to the back of a Montgomery, Alabama municipal bus in 1955 helped spark the American civil rights movement.
We shall soon find out whether Manal al Sharif’s defiance of the Saudi regime’s systemic confinement of women produces a similar effect.
Are Terrorists Insane?
ORLANDO – One of the most common popular misunderstandings about the causes of terrorism is the notion that terrorists must be “insane” to behave as they do.
That idea is as wrong as it is comforting.
Conservatives in the United States, for example, frequently rail against the “madness” of Islamic terrorists, and regard attempts to understand terrorism as appeasement or liberalism gone wild.
In the wake of September 11, 2001, in particular, many on the right mistook the attempt to understand or explain the terrorists’ actions as an effort to condone them.
We have been here before, though.
After World War II, the myth of the “mad Nazi” exerted a forceful grip upon the popular imagination; surely, only insane individuals could perpetrate something like the Holocaust.
But social science research in the 1940’s and 1950’s, including interviews with surviving Nazi leaders, demonstrated that members of the German governmental hierarchy were not only sane, but also highly intelligent.
Moreover, by the early 1960’s, the social psychologist Stanley Milgram had shown that ordinary Americans would go to extraordinary lengths in obeying malevolent authority.
He famously induced people from a variety of social classes and occupations to administer what they thought were increasingly harsh electrical shocks to a helpless victim (played by an actor) sitting in an adjoining room, and his findings have since been replicated around the world.
This was an unpalatable conclusion.
Faced with the horror of what the Nazis had done, most people found it psychologically easier to think of what had happened as the behavior of mentally unhinged individuals, or the result of some sort of collective fugue.
But had vast numbers of Germans suddenly lost their senses overnight, or were they part of a situation in which most of us would simply have done as we were told?
A similar resistance to noisome conclusions – and similarly understandable from a psychological viewpoint – informs today’s thinking about terrorists.
Our default reaction, often reinforced by Western philosophical traditions and simplistic political rhetoric, is that evil acts must be the product of fundamentally evil or insane individuals.
As with the Nazis, the study of modern terrorism began from the starting position that a single disposition – known in the literature as the “terrorist personality” – characterizes most or all terrorists.
In the 1970’s and 1980’s, West German authorities allowed psychologists and psychiatrists to interview terrorism suspects then being held in prison or awaiting trial, including members of the Red Army Faction.
A brigade of experts descended on the jails, looking for evidence to justify their own pet theories of terrorist psychology.
Terrorists were all self-serving narcissists, some found after the interviews were done.
Others argued that terrorists were all victims of clinical paranoia or some other psychosis.
Some even suggested, somewhat bizarrely, that terrorists tend to have lost a parent in their childhood years and are acting out the aggression that derives from their resulting frustration with life.
All of these views shared the belief that there was something fundamentally dysfunctional about the “terrorist personality,” something warped and unusual that sets “them” apart from “us.”
Never mind that different researchers found different features of this so-called personality salient, and came to fundamentally different conclusions about it.
In the years since, social science has reinforced skepticism that all terrorists share such essential personality traits.
There is also a growing recognition that the social circumstances to which terrorists are exposed play a significant role.
What we know about the mindset of terrorists tells us that they are mostly not deranged or insane, but have acquired a different set of beliefs and been exposed to social conditions very different from our own.
Put simply, the causes of terror are largely situational, and the situations are themselves as varied as the acts themselves (members of the IRA, for instance, have obviously been exposed to circumstances very different from members of Al Qaeda).
It must be admitted, of course, that our access to real-life terrorists is limited, and we still have much to learn about the kind of environments that foster terroristic behavior.
Arguably, our knowledge of the factors that led to the July 2005 bombings in London, for example, is still far less impressive than our ignorance.
The great contribution of social science to the understanding of human evil has been to expose unpalatable truths.
When we resort to psychologically comforting but misleading assumptions about terrorism, we hamper our own understanding of political violence in general – and hence weaken our ability to avert or minimize it.
Are the Barbarians at the EU Gates?
BRUSSELS – The euro area confronts a fundamental crisis that attacks on financial speculators will do nothing to resolve.
The European Council of Ministers had to promise hundreds of billions of euros to its financially imperiled member countries, even though the European economy as a whole is not really in crisis.
On the contrary, most surveys and hard economic indicators point to a strong upswing, with the one country that is in really serious trouble, Greece, representing only 3% of the area’s GDP.
Nevertheless, the crisis poses an almost existential challenge to the European Union – and has required such huge sums – because it directly implicates the key underlying principle of European governance: the nature of the state.
The case of Greece has raised the simple but profound question: can a member state of the EU be allowed to fail?
One view is that the state is sacrosanct: the EU has to intervene and help any errant member to get back on its feet.
But this view assumes that all member states adhere to the Union’s underlying economic values of fiscal prudence and market reform.
Problems could arise only because of unanticipated shocks, temporary local political difficulties, and – the favorite culprit – irrational markets.
Applied to Greece, this view implies that the country’s fiscal crisis resulted from an overreaction by world financial markets to local political difficulties (excessive spending by the Greek government before last year’s elections).
Moreover, it implies that the crisis is fully under European control, and that the European authorities have elaborated a comprehensive plan that will resolve all of Greece’s fiscal and structural problems.
Hence the official – let’s say “Southern” – refrain: “The IMF/EU plan will succeed.
Failure is not an option.”
The alternative view is more pragmatic and rules-based.
This “Northern” view starts from the premise that member states remain sovereign units, and that it is possible that a member country does not implement a necessary economic-adjustment program.
This view is embodied in the “no bailout” clause in the euro’s founding document, which stipulates that each country is responsible for its own public debt.
Failure then becomes an option if the country concerned violates the single currency’s basic rules.
Financial markets do not participate directly in this debate.
But they have much skin in this game.
Any holder of Greek debt, especially long-term debt, must calculate the likelihood that Greece’s political system will prove strong enough to push through the reforms needed to enable the country to service its debt fully (and on time).
The collective judgment of financial markets on any government’s economic and fiscal policy is expressed in the risk premium that the government must pay on its external debt.
Doubts in financial markets lead to higher risk premia, which make it even more difficult to finance a government that is already facing financial problems.
Financial markets are often wrong in their judgments.
But they are a fact of life that cannot just be wished or regulated away.
One might object that the distinction between Southern and Northern views is academic nowadays, because failure really isn’t an option, given that it would trigger a disastrous reaction in global financial markets.
But the European Council also created a Task Force under President Herman Van Rompuy to elaborate concrete proposals for reforming the monetary union.
The key choice for this group is simple: should they direct their efforts solely at preventing failure (including open-ended fiscal support), or should they also prepare for the failure of a member state in order to mitigate the consequences if that should happen?
The first choice is bound to imply elaborate measures designed to deliver “more of the same” – a strengthening of the Stability and Growth Pact, for example, with more provisions for economic policy surveillance and cooperation.
But this approach has no answer to the fundamental question: What if the framework does not work?
So long as EU leaders cannot answer that question, financial markets will continue to harbor doubts about the euro’s long-term stability.
The eurozone cannot stabilize in political and economic terms without a solid framework for crisis resolution and an ability to deal with sovereign default by a member state. The view that member states cannot be allowed to fail logically implies that a political or at least a fiscal union must underpin the euro.
This is the choice that European leaders now confront: a radical step forward toward political or policy integration, or a clear framework to deal with the consequences of a member country’s failure to abide by the fundamental rules of the monetary union.
No amount of money will allow European leaders to fudge this issue.
Are the Dollar\u0027s Days Numbered?
A year ago, the dollar bestrode the world like a colossus.
Now it is humbled and the euro looks triumphant.
Is the dollar on the way out as the world's unchallenged reserve and trade currency?
Or is "euro triumphalism" premature?
That question preoccupies not only speculators tracking the dollar's decline, but ordinary businessmen who wonder what currency to use when invoicing imports or exports.
Indeed, the part that currencies play in world trade through their role in invoicing receives too little attention.
Currently, the US dollar remains dominant.
Most US exports and imports are denominated in dollars, and the dollar is extensively used in trade that does not involve America.
Since 1980, however, the dollar has lost ground.
Estimates from the European Commission indicate that the dollar's share in world trade fell from 56% in 1980 to 52% in 1995 (the latest year for which statistics are available).
The Deutsche Mark's share remained relatively unchanged between 1980 and 1995.
The yen lags behind, but had the highest relative growth, with its share of world trade more than doubling from 2% in 1980 to almost 5% in 1995.
Among the reasons for the dollar's longtime dominance as the premier international currency are lower transactions costs in foreign exchange markets, the historical role of the dollar in world trade since 1945, and the sheer size of America's economy.
But the role of size is more complex than it seems.
The second biggest economy in the world is Japan's, but the fraction of its trade denominated in yen remains low, even when compared to the smallest European countries.
One factor that explains this is the large share of US firms in markets where Americans sell their goods.
To understand the reasons behind all this, consider what factors are in play when a firm chooses the currency it uses to invoice for goods.
Here an exporter faces two types of risk: price risk and competitiveness risk.
Consider a Japanese firm seeking to make the highest yen profits on goods sold in Switzerland.
If the Japanese firm sets the price in Swiss francs, it is exposed to price risk as the yen price will fluctuate with the yen-Swiss franc exchange rate.
This tends to make Japanese exporters prefer to price in yen.
But firms also care about what their competitors do.
If the Japanese firm sells its goods to a particular Swiss market dominated by Swiss firms (which invoice in Swiss francs), it would prefer to price in Swiss francs too.
If it priced in yen, it would risk losing its market share if the yen appreciated.
If Japanese firms are dominant in a particular Swiss market, they prefer to price in yen: a Japanese firm then would not have to worry about losing market share when the yen appreciated, because its competitors would face the same pressures.
These arguments explain the big role played by the dollar in trade.
The fact that the US is large makes it more likely that US firms are dominant in a particular market, either as an exporter or as import-competitors when foreign goods are sold in America.
This implies that US firms price in dollars, whether they sell at home or abroad, and foreign firms for competitive reasons will also price in dollars when they export to the US.
Because Japan has the second largest economy in the world, the yen should be a more important currency.
Competitiveness is a key reason for why it is not.
First, the US is Japan's largest trading partner: more than half of Japanese trade with industrialized countries is with the US.
Over 80% of Japanese exports to the US are priced in dollars, in markets where US firms tend to dominate.
Second, even when selling to countries other than the US, Japanese exporters often face stiff American competition.
Take Japanese exports to South East Asia, which are almost 50% denominated in dollars due to competition from US exporters.
These factors are unlikely to change soon and lead us to predict that the yen will keep a low profile in world trade.
They also explain why, over time, the euro should gain weight in international trade.
Euro-zone countries can be considered a single country when dealing with the currency denomination of trade.
This `country' has more market power than the individual countries that form the European Monetary Union.
So the euro should play a larger role in international trade in the future than the sum of the currencies it replaced.
Yet these changes will only occur gradually.
So the "euro triumphalism" that has greeted the dollar's decline is, indeed, premature.
Despite its current distress, the dollar should retain its predominance for some time to come.
Are the Saudis Fanatics?
Terrorist attacks in Saudi Arabia have led many to question not only the ruling House of Saud's prospects for survival, but also whether the kingdom is fundamentally dysfunctional and destructive.
Somehow, it seems, Saudi society has produced a stream of violent fanaticism that draws its inspiration from extreme religious orthodoxy.
The fact that 15 of the 19 hijackers in the September 11, 2001, attacks on the United States were Saudis crystallized a long-held view of the kingdom as a bastion of authoritarianism and intolerance.
In some respects, this perception is accurate, but it cannot be applied to the broad Saudi public.
On the contrary, it would be a grave mistake to assume that fanatical Islamism fully defines Saudi attitudes toward religion.
Between 2001 and 2003, I was part of a team that undertook an extensive survey of values in Saudi Arabia, Egypt, Iran, and Jordan.
Our results provide a surprisingly nuanced picture of Saudi attitudes.
Compared to respondents in the other Middle Eastern countries, Saudis were less religious overall, and their attitudes toward democracy and arranged marriage also indicate a moderate undercurrent.
To be sure, in all four countries, religiosity is widespread, with more than 90% of respondents collectively reporting that they believe in God, in life after death, and in heaven and hell.
But the Saudis appear to be less religious than their fellow Muslims.
Sixty-two percent of Saudis described themselves as religious, compared with 82% of Iranians, 85% of Jordanians, and 98% of Egyptians.
Americans also appear to be far more religious than Saudis, with 81% describing themselves that way.
Some of this variation may be explained by cross-national differences regarding what it means to be religious.
For example, Americans may define religiosity differently than Middle Easterners, with perhaps a weaker attachment to religious beliefs than is true in Islamic countries.
This might also account in part for the differences between Muslim countries.
But the gap in self-defined religiosity between Saudis, on the one hand, and Iranians, Jordanians, and Egyptians, on the other, is so great that it challenges the prevalent perception of Saudi Arabia as a highly conservative and religious society.
Indeed, actions speak louder than words: only 28% of Saudis said that they participate in weekly religious services, compared to 27% of Iranians, 44% of Jordanians, 42% of Egyptians, and 45% of Americans.
These findings, while running contrary to popular perceptions of Saudi culture, are less startling than they appear.
Sociologists of religion have long argued that in a monolithic religious environment, or when religious institutions are closely tied to the state, the overall religiosity of the public declines.
It makes sense to think that when state authorities enforce strict codes of behavior, people tend to rebel and move away from officially sanctioned religious institutions.
Little wonder, then, that Egyptians and Jordanians, who live in countries where the state does not enforce piety, are more religious than Iranians or Saudis, who must cope with local "virtue" police backed by the state.
Even on marriage, many Saudis expressed surprisingly liberal views.
Respondents were nearly evenly split on the question of arranged marriages, with half supporting the idea that marriage should be based on parental consent, while 48% preferred love as the basis of matrimony.
Given entrenched gender segregation and paternal dominance, this finding appears to reveal a strong desire for greater individual choice in what has traditionally been a family-driven decision.
Finally, the Saudis turn out to be strong supporters of democracy, once again contradicting a popular image of Saudi conservatism.
Of the Saudis polled, 58% considered democracy the best form of government, 23% disagreed, and 18% did not express an opinion.
Majority support for democracy in a country with no prior secular and nationalist history seems counter-intuitive.
In fact, support for democracy corresponds with a number of other liberal attitudes that we found in Saudi Arabia.
Supporters of democracy tend to be less religious, more secular, more tolerant of others, more critical of public-sector performance, and more concerned with Western cultural invasion.
Beyond the survey data, history has shown that liberal ideas become more popular when a despotic monarch governs people in alliance with a religious establishment.
A strong current of liberalism appeared in the late nineteenth century in Ottoman Syria in response to the religious despotism of Sultan Abdulhamid.
At the same time, an anti-clerical, secular movement on behalf of constitutionalism appeared in Iran - a reaction to the absolutist alliance between the Quajar Shahs and the religious establishment.
In view of the similarities between those historical precedents and current conditions in Saudi Arabia, we ought not to rule out the possibility of reform.
Now survey data, too, suggest that Saudis may well begin demanding a more transparent politics and a less interventionist religion.
Are US Middle-Class Incomes Really Stagnating?
CAMBRIDGE – The challenge of raising the incomes of middle-class families has emerged as an important focus of the presidential election campaign in the United States.
Everyone agrees that incomes at the top have surged ahead in recent decades, helped by soaring rewards for those with a high-tech education and rising share prices.
And there is general support for improving programs – such as food stamps and means-tested retiree benefits – that help those who would otherwise be poor.
But the public debate is largely about how to help the more numerous (and politically more important) middle class.
Here, much can be done by improving existing government programs: expanding market-relevant training, increasing opportunities for married women to join or rejoin the labor force, reducing the penalties in Social Security rules for continued employment by older workers, and changing tax rules in ways that will increase productivity and wages.
But, while strengthening such programs should be a high priority, we should not lose sight of how well middle-income families have actually done over the past few decades.
Unfortunately, the political debate is distorted by misleading statistics that grossly understate these gains.
For example, it is frequently said that the average household income has risen only slightly, or not at all, for the past few decades.
Some US Census figures seem to support that conclusion.
But more accurate government statistics imply that the real incomes of those at the middle of the income distribution have increased about 50% since 1980.
And a more appropriate adjustment for changes in the cost of living implies a substantially greater gain.
The US Census Bureau estimates the money income that households receive from all sources and identifies the income level that divides the top and bottom halves of the distribution.
This is the median household income.
To compare median household incomes over time, the authorities divide these annual dollar values by the consumer price index to create annual real median household incomes.
The resulting numbers imply that the cumulative increase from 1984 through 2013 was less than 10%, equivalent to less than 0.3% per year.
Any adult who was alive in the US during these three decades realizes that this number grossly understates the gains of the typical household.
One indication that something is wrong with this figure is that the government also estimates that real hourly compensation of employees in the non-farm business sector rose 39% from 1985 to 2015.
The official Census estimate suffers from three important problems.
For starters, it fails to recognize the changing composition of the population; the household of today is quite different from the household of 30 years ago.
Moreover, the Census Bureau’s estimate of income is too narrow, given that middle-income families have received increasing government transfers while benefiting from lower income-tax rates.
Finally, the price index used by the Census Bureau fails to capture the important contributions of new products and product improvements to Americans’ standard of living.
Consider first the changing nature of households.
From 1980 to 2010, the share of “households” that consisted of just a single man or woman rose from 26% to 33%, while the share that contained married couples declined from 60% to 50%.
When the nonpartisan Congressional Budget Office (CBO) conducted a detailed study of changes in household incomes from 1979 to 2011, it expanded the definition of income to include near-cash benefits like food stamps and in-kind benefits like health care.
It also subtracted federal taxes, which fell from 19% of pretax income for middle-income households in 1980 to just 11.5% in 2010.
To convert annual incomes to real incomes, the CBO used the price deflator for consumer expenditures, which many believe is better for this purpose than the consumer price index.
The CBO also presented a separate analysis that adjusted for household size.
With the traditional definition of money income, the CBO found that real median household income rose by just 15% from 1980 to 2010, similar to the Census Bureau’s estimate.
But when they expanded the definition of income to include benefits and subtracted taxes, they found that the median household’s real income rose by 45%.
Adjusting for household size boosted this gain to 53%.
And, again, even this more substantial rise probably represents a substantial underestimate of the increase in the real standard of living.
The authorities arrive at their estimates by converting dollar incomes into a measure of real income by using a price index that reflects the changes in the prices of existing goods and services.
But that price index does not reflect new products or improvements to existing goods and services.
Thus, if everyone’s money incomes rose by 2% from one year to the next, while the prices of all goods and services also rose by 2%, the official calculation would show no change in real incomes, even if new products and important quality improvements contributed to our wellbeing.
Indeed, the US government does not count the value created by Internet services like Google and Facebook as income at all, because these services are not purchased.
No one knows how much such product innovations and improvements have added to our wellbeing.
But if the gains have been worth just 1% a year, over the past 30 years that would cumulate to a gain of 35%.
And combining that with the CBO estimate of a gain of about 50% would imply that the real income of the median household is up nearly 2.5% a year over the past 30 years.
So the US middle class has been doing much better than the statistical pessimists assert.
And with better policies, these households can do even better in the future.
Are We Five Years Wiser?
As the fifth anniversary of the September 11, 2001, attacks on the United States by al-Qaeda approaches, we should take the opportunity to assess the results of the response by the US and the international community.
The attacks and the response to them have obviously brought about a sea change in international relations, but it would be difficult to argue that further atrocities have become less likely as a result.
Why are we no more secure than we were five years ago?
Within a week of the attacks, President George W. Bush declared a “war on terrorism.”
The metaphor of war has the singular advantage that it clearly and strongly evokes the intensity of the counterattack that was called for.
Moreover, the metaphor of war constitutes an implicit appeal to intense mobilization, not only by a country that comes under attack, but also by its friends and allies.
Naturally, no one questions America’s right to defend itself.
The legitimacy of a violent counterattack has never been in doubt.
But the war metaphor also carries inevitable connotations that, when applied to terrorism, are misleading and counterproductive.
Whenever war is invoked, it implies a fight against nations, peoples, or states.
It implies that whole territories and the populations living there are to be considered hostile.
War implies armies and command structures that can be recognized, if not clearly known; in any case, war entails a military confrontation with an identifiable adversary .
On all of these points, the concept of war, to paraphrase US Defense Secretary Donald Rumsfeld, is not helpful.
Even if the scale of the September 11 attack was of such a dimension that only the American army seemed able to face the challenge, in technical terms dealing with a threat that is extra-national rather than international is a matter of police techniques, not military tactics.
The negative consequences of this mistaken vision very quickly became apparent.
It is now widely known that the US government, perhaps partly unconsciously, embraced a deeply distorted image of al-Qaeda that portrayed it as a hierarchical organization with a seamless command structure – the prototype of a foe that the American army could attack and destroy.
But al-Qaeda – the word means “the base” or “the camp,” that is, nothing more or less than a point of gathering and training – is more like a blurred sphere of influence, comprising individuals and small local cells that act on their own initiative and cooperate very rarely, and only for large-scale operations.
It has not been proved that the attacks in London, Madrid, or Bali in the years since the September 11 plot, or the attack on America’s warship the USS Cole in 2000, reflected the existence of a “center” that coordinated the operations or gave orders to carry them out.
It is also wrong to conflate Islamic terrorism with that of the Basque ETA, Sri Lanka’s Tamil Tigers, or the Irish Republican Army.
Whereas these groups have a territorial base and are preoccupied with national aims, Islamic terrorism appears to be the work of a very small number of individuals who seek to avenge the centuries-long “humiliation” of the Muslim world, brought about by colonization, absence of economic development, and political weakness.
The goal of Islamic terrorists is nothing less than the destruction of the “hegemonic” Western world, despite most Muslim nations’ desire to live in peace within the international community and to cooperate in crafting effective development strategies.
The only viable strategy for confronting the threat of Islamic terrorism was, and continues to be, a search for agreement among Muslims, and among the leaders of Muslim nations, on the forms of mutual cooperation, including police cooperation, that are needed to isolate, weaken, or destroy the militants in their midst.
This is a long and difficult enterprise, but there remains no alternative.
Instead, the war metaphor continues to define the US response and that of several of America’s allies.
The attraction of this metaphor may be attributable to the excessive trust that Americans place not only in their army, which is understandable, but in force in general, which is much less understandable in the case of an intelligent people.
Whatever the case, casting the fight against terrorism as a war has led American policymakers to multiply violent military operations that have absolutely no chance of winning hearts and minds in the Muslim world.
Quite the contrary.
Afghanistan was the only case where a military response was understandable: its government had, after all, given al-Qaeda a temporary territorial home.
But to implicate Iraq, which had nothing to do with al-Qaeda or the September 11 attacks, was a huge mistake, one that has strengthened Islamic extremists and has probably helped them recruit terrorists.
Moreover, the US response has strengthened Israel’s belief in the effectiveness of military methods, leading to the recent war in Lebanon and the ongoing invasion of Gaza.
Powerless, the international community does nothing.
The rigidity and brutality of America’s behavior – resulting in many times more civilian deaths than occurred on September 11 – have blocked any useful intervention by countries such as Algeria, Morocco, Jordan, Saudi Arabia, or the United Arab Emirates.
Likewise, the appeal of war has ruled out the prospect of serious negotiations between Israel, Syria, and Lebanon.
By attacking one Muslim country after another, the US and its allies have created the impression that Islam itself is the enemy, leading inexorably to the “clash of civilizations” that America says it wants to avoid.
But America’s strategy has failed.
Force cannot accomplish everything.
The international community must say clearly that Islam is not our enemy and that terrorism must be fought in other ways.
Muslim political leaders, for their part, should declare just as openly that terrorism is not their choice.
If both sides can stifle their murderous deviances, the hope of cultural and political reconciliation will be reborn.
Are We Really Secessionists Now?
LONDON – The World Court’s recent ruling on Kosovo’s unilateral declaration of independence is being widely touted as giving a green light to secessionist movements to gain statehood.
According to Kosovo President Fatmir Sejdiu, “The decision finally removes all doubts that countries which still do not recognize the Republic of Kosovo could have.”
But this reading is largely wishful thinking by those who support secession.
The Court's non-binding advisory opinion responded to a narrow question posed by the United Nations General Assembly: whether declaring independence is legal under international law. The judges rightly held that there is no international rule preventing a group from stating its intention or wish to form a state.
But they said nothing about the terms and conditions that apply to following through on this intention – i.e., the act of secession itself.
Indeed, the Court sought to leave no doubt about this: “The question is narrow and specific... it does not ask whether or not Kosovo has achieved statehood.” The judges contrasted their opinion with that handed down by the Supreme Court of Canada when it was asked to rule on Quebec’s right to secede unilaterally.
In that case, the question went far beyond a declaration of independence; the court was asked whether and under what conditions Quebec had a right to break away from Canada, under either the Canadian constitution or international law.
The Canadian judges held that international law granted no such unilateral right (and nor did the country's own constitution).
As the World Court pointed out, its judgment last week did not refute that crucial point: “The Court is not required by the question it has been asked to take a position…on whether international law generally confers an entitlement on entities within a State to break away from this [State].”
Moreover, the Court noted the radically different views expressed before it on whether self-determination in international law implies a unilateral right to secede.
By acknowledging the range and intensity of disagreement among states on a right to secede, the Court seems to have hinted that the necessary consent of the world community does not exist to establish firmly the existence of any such right.
Before concluding that there is now a “clear path” to Kosovo's independence, it is worth pondering the important questions that the Court did not answer (and was not asked by the General Assembly).
The Court was not asked, and thus did not rule on, whether international law requires that the final status of Kosovo protect the group and individual rights of minorities, whether Kosovar Serbs or Roma.
Likewise, the Court was not asked and did not rule on whether Serbia or, indeed, any other state in the world community is required to recognize Kosovo as an independent state.
Nor did the Court’s decision address the borders of an independent Kosovo, or whether and under what circumstances force could legally be used either to impose independence or to resist it.
If the fate of Kosovo – and the entire Balkan region – is to be guided by the global rule of law, these questions need to be answered, not swept under the table.
Under existing procedures, framing questions to the World Court is entirely a prerogative of states, either as contending parties or, as with the Kosovo opinion, operating through the UN.
But the rights of persons and peoples, not just interests of states, are at stake in controversies such as this one.
To fulfill international justice today, we need a new kind of World Court, open to other voices.
Are We Running Out of Oil (Again)?
Oil prices are now running well above $50 a barrel, partly owing to short-run supply shocks, such as the Iraq conflict, Nigerian labor disputes, the conflict between Yukos Oil and the Russian government, and Florida's recent hurricanes.
Oil prices may fall once these shocks dissipate, but speculative effects could keep them relatively high, weakening the world economy and depressing stock markets.
Even a temporary spike in oil prices can have long-term effects because of the social reactions they provoke. High oil prices fuel public discussion about the future of oil prices.
The outcome of any public discussion can never be known with certainty, but chances are that it will amplify stories that imply risks of higher oil prices.
Experts may say that short-run supply factors caused the recent price increases, but the price increases will nonetheless lend credibility to scarier long-term stories.
The scary story that is being amplified now concerns the developing world, notably China and India, where rapid economic growth - and no restrictions on emissions under the Kyoto Protocol - are seen as creating insatiable demands for oil.
The story's premise is that the world will run out of oil faster than we thought, as these billions of people chase their dreams of big houses and sport utility vehicles.
Is this plausible?
Certainly, China, India, and some other emerging countries are developing fast.
But experts find it difficult to specify the long-run implications of this for the energy market.
Too many factors remain fuzzy: the rate of growth of these countries' energy demand, discoveries of new oil reserves, developments in oil-saving technology, and the ultimate replacement of oil by other energy sources.
But what matters for oil prices now and in the foreseeable future is the perception of the story, not the ambiguities behind it.
If there is a perception that prices will be higher in the future, then prices will tend to be higher today.
That is how markets work.
If it is generally thought that oil prices will be higher in the future, owners of oil reserves will tend to postpone costly investments in exploration and expansion of production capacity, and they may pump oil at below capacity.
They would rather sell their oil and invest later, when prices are higher, so they restrain increases in supply.
Expectations become self-fulfilling, oil prices rise, a speculative bubble is born.
But if owners of oil reserves think that prices will fall in the long run, they gain an incentive to explore for oil and expand production now in order to sell as much oil as possible before the fall.
The resulting supply surge drives down prices, reinforces expectations of further declines, and produces the inverse of a speculative bubble: a collapse in prices.
All of this may seem obvious, but we tend not to think of oil prices as being determined by expectations of future prices.
For example, in January 1974, when the first world oil crisis began, oil prices doubled in just days.
The immediate cause was believed to have been Israel's stunning success in the Yom Kippur War, which led Arab oil producers to retaliate by choking off output.
The second crisis, in 1979, is usually attributed to supply disruptions from the Persian Gulf following the Islamic revolution in Iran and the subsequent start of the Iran-Iraq war.
Why, then, did real inflation-corrected oil prices remain at or above their 1974 levels until 1986?
Speculative pressures are likely to have been at work, influencing the decisions of OPEC and many others.
Although changes in market psychology are difficult to understand, the broad concerns that underlie such episodes of irrational exuberance are almost always clear.
For example, in 1972, scientists at the Massachusetts Institute of Technology, including computer pioneer Jay Forrester, published The Limits to Growth .
The book launched an international debate on whether the world would soon face immense economic problems due to shortages of oil and other natural resources - problems that seemed to be presaged by OPEC's production cuts eighteen months later.
The second crisis was immediately preceded by the accident at the Three-Mile Island nuclear reactor in Pennsylvania in March 1979, which reinvigorated the anti-nuclear movement.
With nuclear power - regarded as the main technological bulwark against depletion of the world's oil supplies - suddenly suspect, oil prices doubled again by the year's end.
After 1979, fears about limits to growth and nuclear power ebbed.
Oil prices gradually fell, and the stock market began its long climb towards its peak in 2000.
But the current rise in oil prices shows that people are still eager to embrace "running out of oil" stories - this time focused on China and India - even when short-run factors are to blame.
Indeed, the International Energy Agency noted in September that the usual relationship between oil prices and inventory levels has broken down, with prices much higher than the usual relationship would suggest.
The IEA's report calls this breakdown evidence of a "structural shift in the market."
But the same pattern followed the 1973-4 and 1979-80 oil crises, when prices dropped from their highest peaks, but stayed quite high for years, representing a drag on the stock market, the housing market, and the world economy.
Let's hope that the effects of the present spike will be more short-lived.
But don't hold your breath.
Are We Still Evolving?
NEW HAVEN – Many public-policy decisions are based on implicit assumptions about “human nature,” and it is currently popular to speculate about how evolution might have shaped human behavior and psychology.
But this raises some important questions: are humans continuing to evolve –&#160;and, if so, is our basic biological nature changing – or has modern culture stopped evolution?
For some traits, we do not have to speculate – we can measure and compare on the basis of studies covering thousands of individuals over several generations.
Such studies have not yet been done on most of the traits where speculation is popular, but they have been done on some traits of medical interest.
What have we learned?
Scientists are taking two approaches.
In one, they sequence the DNA of particular genes in many individuals with or without some determined health condition and look for differences between the two groups.
This genetic approach measures effects that have accumulated over hundreds to thousands of generations, and the message is clear: humans have evolved in these respects fairly recently, some in one direction, some in another, depending on their environment and other conditions encountered.
From this approach, we have learned, for example, that the ability to digest milk as adults evolved within the last 10,000 years – and several times – in cultures that domesticated sheep, goats, or cattle.
Similar studies have taught us that sensitivity to alcohol consumption and resistance to diseases like malaria and leprosy also evolved within the last several thousand years.
Some scientists, myself included, have taken a different approach.
Instead of looking for changes in genes that take many generations to accumulate until they can be detected, we have measured natural selection directly.
This method can reveal selection in action, working over periods of time as short as one generation – so that it can answer the question of whether modern culture has stopped evolution.
The message of this approach is also clear: natural selection continues to operate in modern cultures.
Whether it will operate consistently enough for a long enough time to produce significant genetic change can be answered only by future generations.
Nevertheless, it is interesting to see in what direction natural selection is starting to shape us.
Some of the answers are surprising.
We measured natural selection operating on women in Framingham, Massachusetts, where a long-term medical study on heart disease produced the data that we used.
The women were born between 1892 and 1956.
We found significant selection and projected that if it continued for ten generations, the women would evolve to be about two centimeters shorter and have their first child about five months earlier.
This is a surprising result, because women in developed countries have become taller thanks to better nutrition, and are having children later in life for many reasons, some of them cultural.
So what is going on here?
Three things:
First, we know that giving birth for the first time when younger carries a cost in increased infant mortality, but modern medicine and hygiene have strikingly reduced infant mortality, reducing the cost of younger age at first birth.
We therefore expect a shift toward earlier reproduction, because the costs previously associated with doing so have disappeared – exactly what we found in Framingham.
And we expect those younger women to be shorter simply because they have had less time to grow.
In five other cases, scientists found women in developed countries maturing earlier, in two of them at smaller size (in the other three cases, size was not measured).
It is too early to say that this is a general trend, but right now, all signs point that way.
Second, we measured the effects of natural selection by noting that women who were shorter and first gave birth when younger had more children.
But genes are only one of many factors that influence height and age at first birth.
Personal decisions, nutrition, income level, education, and religious affiliation all enter the mix.
When we estimated how much of the variation among individuals could be attributed to biology, the answer was less than 5%.
That left 95% of the variation to be explained by the effects of culture and individual decisions.
But, while the effects of biology on the traits that we measured are relatively small for humans living in complex modern cultures, even small effects, when repeated consistently, will accumulate.
Third, traits like these are always the result of interactions between genes and environment.
A woman could have genes that would tend to make her taller than average but end up shorter than average if she had been poorly nourished as a child.&#160;
If evolution took its steady course and changed the genetic basis of height and age at first birth, we might not see women ten generations later who were shorter and matured earlier, for the effects of nutrition and culture could more than compensate for the genetic change.
As a colleague of mine likes to put it, one good school-lunch program could be enough to obscure the biological effects.
Even when we focus on a simple physical trait like height, natural selection in humans turns out to be a multifaceted and nuanced process.
Similar studies on human behavior and psychology, where causation is more complex, remain beyond our grasp.
In such cases, silence may be wiser than speculation.
Are We Working Ourselves to Death?
Work can give structure and meaning to life.
But working conditions can also trigger or accelerate the symptoms of ill health - physical and mental - that feed back into our productivity and earning capacity, as well as into our social and family relationships.
In fact, an alarmingly large number of people appear to be at risk.
Of the EU's 160 million-strong labour force, 56% report working at very high speeds, and 60% to tight deadlines.
More than a third have no influence on task order, and 40% perform monotonous tasks.
This probably contributes to a host of health-related problems: 15% of the workforce complain of headaches, 33% of backache, 23% of fatigue, and 23% of neck and shoulder pains, plus a host of other illnesses, including life-threatening ones.
Sustained work-related stress is also an important determinant of depressive disorders - the fourth-largest cause of disease world-wide.
They are expected to rank second by 2020, behind only heart disease.
In the EU, the cost of these and related mental health problems is estimated to average 3-4% of GNP, amounting to approximately 265 billion euros annually.
Moreover, sustained work-related stress is likely to contribute to `metabolic syndrome,' a cluster of pathogenic mechanisms characterised by an accumulation of abdominal fat, a decrease in sensitivity to insulin, increased levels of cholesterol, and heightened blood pressure, all related to the onset of heart disease and diabetes.
Of course, working conditions may be experienced as threatening even when objectively they are not, or trivial symptoms may be interpreted as manifestations of serious illness.
But stress is worrisome precisely because even misinterpretations can add to, or result in, a wide variety of health problems, including heart disease, stroke, cancer, musculoskeletal and gastrointestinal diseases, anxiety and depression, accidents, and suicides.
Briefly stress consists of a pattern of built-in processes preparing the human organism for physical activity in response to demands and influences that tax its capacity to adapt.
Activation of our "fight or flight" mechanism is an appropriate adaptive response when facing a wolf pack, but not so when struggling to adjust to rotating shifts, monotonous and fragmented tasks, or over-demanding customers.
If sustained, stress is often maladaptive and eventually disease provoking.
Stress-related paths to pathologies take a wide variety of forms.
They can be emotional (anxiety, depression, hypochondria, and alienation), cognitive (loss of concentration or recall, inability to learn new things, be creative, make decisions), behavioural (abuse of drugs, alcohol, and tobacco, refusal to seek or accept treatment), or physiological (neuroendocrine and immunological dysfunction).
To identify, prevent, and counteract the causes and consequences of work-related stress, we need to monitor job content, working conditions, terms of employment, social relations at work, health, well-being and productivity.
The first step is to identify the incidence, prevalence, severity, and trends of work-related stress and its causes and health consequences.
Are they likely to contribute to stress-related ill health?
Can they be changed?
Are such changes acceptable to workers and employers?
Wherever the answers are affirmative, an integrated package of organisational changes should be considered.
Such changes are likely to include the following areas:
Work schedule.
Design labor time to avoid conflict with demands and responsibilities unrelated to the job;
Participation/control.
Allow workers to take part in decisions or actions affecting their jobs;
Workload.
Ensure that workers have enough time to complete assigned tasks, and allow for recovery from especially demanding physical or mental tasks;
Content.
Design tasks to provide meaning, stimulation, a sense of completeness, and an opportunity to use skills;
Roles.
Define work roles and responsibilities clearly;
Social environment.
Ensure a working atmosphere free of all forms of invidious discrimination and harassment;
Future.
Avoid ambiguity in matters of job security and career development; promote life-long learning and employability.
Although it is likely, the short- and long-term outcomes of such changes may not always suffice in the fight against work-related stress.
They need therefore to be evaluated in terms of exposures and reactions to stress, the incidence and prevalence of ill health, and the quality and quantity of goods or services.
Many companies world-wide recognize that success requires satisfying the three elements of sustainable development: financial, environmental, and social.
Failure to do so leads, over time, to terminal organizational weakness, owing to lost credibility amongst employees, shareholders, customers, and communities.
This has numerous implications for relations with employees.
Ensuring long-term economic growth and social cohesion requires a commitment to health and safety, a better balance between work, family and leisure, lifelong learning, greater workforce diversity, gender-blind pay and career prospects, and profit-sharing and equity-ownership schemes.
These practices can have a positive impact on profits through increased productivity, lower staff turnover, greater amenability to change, more innovation, and better, more reliable output.
Indeed, companies often have an interest in going beyond minimum legal requirements: peer respect and a good reputation as an employer are marketable assets.
The challenge for science is to find out what to do, for whom, and how.
The challenge to workers, employers, governments, and communities is to translate what we now know into coordinated and sustainable programs.
Argentina: Open Up or Shut Down
"I have an important political mission," Eduardo Amadeo said on being appointed Argentina's ambassador to Washington. "I must explain our transition."
But diplomatic explanations are not what Argentina needs.
It does not need to waste scarce money on diplomacy of dubious value--not when the country lacks an agency dedicated to helping Argentine businessmen sell their goods abroad.
Indeed, the sum Argentina spends on its diplomats is what tiny Ireland spends on its Export Promotion Agency, an institution Argentina never bothered to create.
Instead of talking to fellow diplomats, Argentina's ambassador to the US should talk to US supermarkets, convincing their managers to buy Argentine goods and arranging for them to meet with small businessmen from his country.
He should not be duplicating what Argentina's President and Foreign Minister are capable of doing.
Export diplomacy is important, but export promotion , visiting stores and talking to buyers, is even more vital.
European grocery shops are full of products from Israel, but how often do you see Argentine beef or other goods?
Argentina's economy opened up significantly in recent years, notwithstanding a strong exchange rate, which made exporting difficult.
Total exports doubled in 1991-2001, from US$12 billion to $25 billion, with industrial exports growing from $3 billion to $8 billion.
But the numbers remain very small.
In fact, Argentina is amazingly closed for an economy its size.
Exports do not exceed 10% of GDP, and manufactured goods account for only about a third of total exports.
Brazil, a country eight times the size, exports 12% of its economy's output, and 57% of Brazilian exports are manufactured goods.
Chile exports almost 30% of its output.
Some small European countries come close to 50%.
Little wonder, then, that Argentina's current crisis is so harsh: the portion of its economy that can generate the export revenues necessary to repay foreign debt is too small.
When a country reaches the point that it needs all its exports to service its national debt, and the size of the export sector is fixed, nothing is left to pay for imports.
So imports dry up and the economy stops.
The more open an economy is, the more easily it can avoid this trap.
Of course, all countries eventually overcome crises.
The question is how.
Argentina now faces a choice that is both economic and political.
